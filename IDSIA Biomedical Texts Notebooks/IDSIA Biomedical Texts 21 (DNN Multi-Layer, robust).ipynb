{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1uiEYfBVhnw4iG25VL7JGht90QkCQ6SC1","timestamp":1689747244256}],"authorship_tag":"ABX9TyNUBzR/G7GJZXBBrSw0B8+6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POzA_GGacj6B","executionInfo":{"status":"ok","timestamp":1689749147831,"user_tz":-330,"elapsed":15806,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"3f904fdf-4819-42fb-abe4-89a9d3fbced1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle"],"metadata":{"id":"2v8HPluLcudI","executionInfo":{"status":"ok","timestamp":1689749148233,"user_tz":-330,"elapsed":410,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/IDSIA Biomedical Texts/AllSource_Intensity_ThirdJuly.csv', low_memory=False)\n","df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"UV6xvkLSc1ZZ","executionInfo":{"status":"ok","timestamp":1689749150019,"user_tz":-330,"elapsed":1790,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"a75b0a36-36a2-4bc6-e52b-e87411c2fc02"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                urls  \\\n","0  https://www.quora.com/What-are-panic-attacks-l...   \n","\n","                                                text source  label   WC  \\\n","0  i have been dealing with these for quite some ...  Quora      1  607   \n","\n","   Analytic  Clout  Authentic  Tone    WPS  ...  \\\n","0     55.22  35.35      48.82   1.0  26.39  ...   \n","\n","                                      all_emo_labels  \\\n","0  ['fear', 'nervousness', 'confusion', 'curiosit...   \n","\n","                                  all_emo_label_rank  anger_intensity  \\\n","0  {'fear': 1, 'nervousness': 2, 'confusion': 3, ...         0.415048   \n","\n","   anticipation_intensity  disgust_intensity  fear_intensity  joy_intensity  \\\n","0                0.553423           0.272333        0.568205         0.4095   \n","\n","   sadness_intensity  surprise_intensity  trust_intensity  \n","0           0.467625              0.4345         0.522773  \n","\n","[1 rows x 165 columns]"],"text/html":["\n","\n","  <div id=\"df-0d9fe1e9-f466-4394-a633-090a41295a46\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>urls</th>\n","      <th>text</th>\n","      <th>source</th>\n","      <th>label</th>\n","      <th>WC</th>\n","      <th>Analytic</th>\n","      <th>Clout</th>\n","      <th>Authentic</th>\n","      <th>Tone</th>\n","      <th>WPS</th>\n","      <th>...</th>\n","      <th>all_emo_labels</th>\n","      <th>all_emo_label_rank</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.quora.com/What-are-panic-attacks-l...</td>\n","      <td>i have been dealing with these for quite some ...</td>\n","      <td>Quora</td>\n","      <td>1</td>\n","      <td>607</td>\n","      <td>55.22</td>\n","      <td>35.35</td>\n","      <td>48.82</td>\n","      <td>1.0</td>\n","      <td>26.39</td>\n","      <td>...</td>\n","      <td>['fear', 'nervousness', 'confusion', 'curiosit...</td>\n","      <td>{'fear': 1, 'nervousness': 2, 'confusion': 3, ...</td>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.4095</td>\n","      <td>0.467625</td>\n","      <td>0.4345</td>\n","      <td>0.522773</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows Ã— 165 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d9fe1e9-f466-4394-a633-090a41295a46')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-df647a9c-268d-4a6c-b7b2-c4b5d24fb19a\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df647a9c-268d-4a6c-b7b2-c4b5d24fb19a')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-df647a9c-268d-4a6c-b7b2-c4b5d24fb19a button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0d9fe1e9-f466-4394-a633-090a41295a46 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0d9fe1e9-f466-4394-a633-090a41295a46');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":[],"metadata":{"id":"cClrfrz3c2-I","executionInfo":{"status":"ok","timestamp":1689749150020,"user_tz":-330,"elapsed":15,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Getting 2 panic features"],"metadata":{"id":"vNM-C1avc59u"}},{"cell_type":"code","source":["import regex as re"],"metadata":{"id":"FjKZR5P6c6-F","executionInfo":{"status":"ok","timestamp":1689749150020,"user_tz":-330,"elapsed":12,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["panic_symptoms = [\"Palpitations\", \"Pounding heart\", \"Accelerated heart rate\", \"Sweating\", \"Trembling\", \"Shaking\", \"Shortness of breath\",\n","\"Smothering\", \"Feelings of choking\", \"Chest pain\", \"Discomfort\", \"Abdominal distress\", \"Nausea\", \"Dizziness\", \"Unsteadiness\", \"Lightheadedness\",\n","\"Faintness\", \"Chills\", \"Heat flashes\", \"Paresthesia\", \"Numbness\", \"Tingling sensations\", \"Derealization\", \"Depersonalization\", \"Fear of losing control\",\n","\"Fear of going crazy\", \"Fear of dying\", \"Mental images of dying\", \"Mental images of collapsing\", \"Agoraphobia\", \"Need to escape\"]\n","\n","\n","panic_symptoms_ext = [\"Palpitations\", \"Pounding heart\", \"Accelerated heart rate\", \"Sweating\", \"Trembling\", \"Shaking\", \"Shortness of breath\",\n","\"Smothering\", \"Feelings of choking\", \"Chest pain\", \"Discomfort\", \"Abdominal distress\", \"Nausea\", \"Dizziness\", \"Unsteadiness\", \"Lightheadedness\",\n","\"Faintness\", \"Chills\", \"Heat flashes\", \"Paresthesia\", \"Numbness\", \"Tingling sensations\", \"Derealization\", \"Depersonalization\", \"Fear of losing control\",\n","\"Fear of going crazy\", \"Fear of dying\", \"Mental images of dying\", \"Mental images of collapsing\", \"Agoraphobia\", \"Need to escape\"\n","\"Sweat\", \"Tremble\", \"Shake\", \"Shortage of breath\",\"Feeling of choking\",\"Dizzy\",\n","\"Faint\",\"Fainted\",\"Chill\",\"Heat flash\", \"Numb\", \"Tingling sensation\",\"Mental image of dying\", \"Mental image of collapsing\"]"],"metadata":{"id":"coacXg3Sc8u7","executionInfo":{"status":"ok","timestamp":1689749150021,"user_tz":-330,"elapsed":11,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def count_symptoms_in_text(text, panic_list):\n","    if isinstance(text, str):\n","        count = 0\n","        for symptom in panic_list:\n","            match = re.search(r'\\b{}\\b'.format(symptom), text, re.IGNORECASE)\n","            if match:\n","                count += 1\n","        return count"],"metadata":{"id":"BbpjCIMLc-G1","executionInfo":{"status":"ok","timestamp":1689749150021,"user_tz":-330,"elapsed":10,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df['symptoms_count'] = df['text'].apply(lambda x: count_symptoms_in_text(x,panic_symptoms))\n","df['symptoms_ext_count'] = df['text'].apply(lambda x: count_symptoms_in_text(x,panic_symptoms_ext))"],"metadata":{"id":"tESUupBgc_6Y","executionInfo":{"status":"ok","timestamp":1689749156721,"user_tz":-330,"elapsed":6709,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RDVOyi81dBhm","executionInfo":{"status":"ok","timestamp":1689749156721,"user_tz":-330,"elapsed":14,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZV-Ir0kydEBe","executionInfo":{"status":"ok","timestamp":1689749156722,"user_tz":-330,"elapsed":13,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6itEHx-jdEDq","executionInfo":{"status":"ok","timestamp":1689749156722,"user_tz":-330,"elapsed":13,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["pickle_in = open(\"/content/drive/MyDrive/IDSIA Biomedical Texts/Sentence Embeddings/AllSource_alldistilrobertav1_via_UMAP_SHORTembeddings.pickle\", 'rb')\n","sentence_embeddings = pickle.load(pickle_in)\n","sentence_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OK9PWgG7dEG3","executionInfo":{"status":"ok","timestamp":1689749157451,"user_tz":-330,"elapsed":742,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"7b124881-7a9b-42bc-8162-f8f454b5777f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[10.64194  ,  5.0430765,  5.6824026, ...,  4.9058275,  6.8707986,\n","         4.538727 ],\n","       [11.312859 ,  5.364349 ,  4.41365  , ...,  4.92234  ,  6.8475184,\n","         4.5590596],\n","       [10.531799 ,  4.894456 ,  5.387705 , ...,  4.8968716,  6.8360796,\n","         4.530069 ],\n","       ...,\n","       [10.346373 ,  4.4247556,  3.5815325, ...,  5.0401225,  6.552696 ,\n","         4.490976 ],\n","       [10.454275 ,  4.5640407,  3.6035635, ...,  5.0320673,  6.564847 ,\n","         4.4918733],\n","       [11.222271 ,  5.1468487,  4.0054016, ...,  5.079988 ,  6.6341186,\n","         4.5597043]], dtype=float32)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"2ZHd-LcbdnI9","executionInfo":{"status":"ok","timestamp":1689749157452,"user_tz":-330,"elapsed":35,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ApIkoC0pdnWP","executionInfo":{"status":"ok","timestamp":1689749157452,"user_tz":-330,"elapsed":33,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"682EAc95dEeW","executionInfo":{"status":"ok","timestamp":1689749157453,"user_tz":-330,"elapsed":33,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["sentemb_column_names = [\"sentemb\" + str(i+1) for i in range(28)]"],"metadata":{"id":"pjEhoNSAdlvj","executionInfo":{"status":"ok","timestamp":1689749157453,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["sentembdf = pd.DataFrame(sentence_embeddings, columns=sentemb_column_names)\n","sentembdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"a_8NGCwldpS7","executionInfo":{"status":"ok","timestamp":1689749157454,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"27a7e76d-f267-43e1-9684-448632a19bb1"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     10.641940  5.043077  5.682403  3.366873  3.939331  3.919311  6.919125   \n","1     11.312859  5.364349  4.413650  3.407885  5.023540  4.247440  6.088093   \n","2     10.531799  4.894456  5.387705  3.325495  4.051551  4.119681  6.826452   \n","3     11.310531  5.330986  4.330414  3.431627  5.095810  4.284573  6.036744   \n","4     10.990587  5.196148  4.968183  2.576940  4.233728  4.119200  6.174312   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","7400  10.507652  4.949894  4.014671  2.117899  4.715438  4.335719  5.412321   \n","7401  10.698858  4.546772  3.540320  3.286137  5.087534  5.156605  5.941041   \n","7402  10.346373  4.424756  3.581532  3.153925  5.020442  4.948900  5.897359   \n","7403  10.454275  4.564041  3.603564  3.078566  4.991286  4.955261  5.872911   \n","7404  11.222271  5.146849  4.005402  3.371954  4.682106  5.396935  6.367755   \n","\n","      sentemb8  sentemb9  sentemb10  ...  sentemb19  sentemb20  sentemb21  \\\n","0     1.789982  1.404625   7.134058  ...   6.754729   4.308768   2.225483   \n","1     1.780003  1.160577   6.596563  ...   7.253571   4.070558   2.360492   \n","2     1.776312  1.471099   6.926485  ...   6.786397   4.259876   2.223957   \n","3     1.780587  1.134592   6.539715  ...   7.298054   4.057921   2.369854   \n","4     1.775400  1.475707   6.684998  ...   7.061465   4.159153   2.327722   \n","...        ...       ...        ...  ...        ...        ...        ...   \n","7400  1.769552  1.720969   6.056923  ...   7.375135   3.952120   2.305240   \n","7401  1.688843  1.656772   5.678233  ...   7.371179   3.950364   2.242772   \n","7402  1.686590  1.781551   5.741636  ...   7.339849   3.958114   2.226620   \n","7403  1.702558  1.761993   5.793803  ...   7.350019   3.961870   2.231675   \n","7404  1.753800  1.507380   6.102673  ...   7.279993   4.084011   2.253345   \n","\n","      sentemb22  sentemb23  sentemb24  sentemb25  sentemb26  sentemb27  \\\n","0      3.196717   5.969540   5.937778   5.176552   4.905828   6.870799   \n","1      3.181391   6.144005   5.662973   5.073269   4.922340   6.847518   \n","2      3.178261   5.996410   5.876356   5.186982   4.896872   6.836080   \n","3      3.181388   6.149067   5.650796   5.068528   4.935538   6.840829   \n","4      3.183620   6.181925   5.809379   5.113574   4.873700   6.771983   \n","...         ...        ...        ...        ...        ...        ...   \n","7400   3.210462   6.340523   5.595186   5.102685   4.922517   6.645929   \n","7401   3.236705   6.118145   5.502766   5.187657   5.083427   6.556334   \n","7402   3.229278   6.177763   5.498463   5.200507   5.040123   6.552696   \n","7403   3.226660   6.186529   5.515781   5.197260   5.032067   6.564847   \n","7404   3.232021   6.046115   5.681019   5.217414   5.079988   6.634119   \n","\n","      sentemb28  \n","0      4.538727  \n","1      4.559060  \n","2      4.530069  \n","3      4.564339  \n","4      4.528791  \n","...         ...  \n","7400   4.465776  \n","7401   4.512558  \n","7402   4.490976  \n","7403   4.491873  \n","7404   4.559704  \n","\n","[7405 rows x 28 columns]"],"text/html":["\n","\n","  <div id=\"df-7c2739b2-9159-443e-b4dd-2f1469987f86\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>sentemb19</th>\n","      <th>sentemb20</th>\n","      <th>sentemb21</th>\n","      <th>sentemb22</th>\n","      <th>sentemb23</th>\n","      <th>sentemb24</th>\n","      <th>sentemb25</th>\n","      <th>sentemb26</th>\n","      <th>sentemb27</th>\n","      <th>sentemb28</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10.641940</td>\n","      <td>5.043077</td>\n","      <td>5.682403</td>\n","      <td>3.366873</td>\n","      <td>3.939331</td>\n","      <td>3.919311</td>\n","      <td>6.919125</td>\n","      <td>1.789982</td>\n","      <td>1.404625</td>\n","      <td>7.134058</td>\n","      <td>...</td>\n","      <td>6.754729</td>\n","      <td>4.308768</td>\n","      <td>2.225483</td>\n","      <td>3.196717</td>\n","      <td>5.969540</td>\n","      <td>5.937778</td>\n","      <td>5.176552</td>\n","      <td>4.905828</td>\n","      <td>6.870799</td>\n","      <td>4.538727</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11.312859</td>\n","      <td>5.364349</td>\n","      <td>4.413650</td>\n","      <td>3.407885</td>\n","      <td>5.023540</td>\n","      <td>4.247440</td>\n","      <td>6.088093</td>\n","      <td>1.780003</td>\n","      <td>1.160577</td>\n","      <td>6.596563</td>\n","      <td>...</td>\n","      <td>7.253571</td>\n","      <td>4.070558</td>\n","      <td>2.360492</td>\n","      <td>3.181391</td>\n","      <td>6.144005</td>\n","      <td>5.662973</td>\n","      <td>5.073269</td>\n","      <td>4.922340</td>\n","      <td>6.847518</td>\n","      <td>4.559060</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.531799</td>\n","      <td>4.894456</td>\n","      <td>5.387705</td>\n","      <td>3.325495</td>\n","      <td>4.051551</td>\n","      <td>4.119681</td>\n","      <td>6.826452</td>\n","      <td>1.776312</td>\n","      <td>1.471099</td>\n","      <td>6.926485</td>\n","      <td>...</td>\n","      <td>6.786397</td>\n","      <td>4.259876</td>\n","      <td>2.223957</td>\n","      <td>3.178261</td>\n","      <td>5.996410</td>\n","      <td>5.876356</td>\n","      <td>5.186982</td>\n","      <td>4.896872</td>\n","      <td>6.836080</td>\n","      <td>4.530069</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.310531</td>\n","      <td>5.330986</td>\n","      <td>4.330414</td>\n","      <td>3.431627</td>\n","      <td>5.095810</td>\n","      <td>4.284573</td>\n","      <td>6.036744</td>\n","      <td>1.780587</td>\n","      <td>1.134592</td>\n","      <td>6.539715</td>\n","      <td>...</td>\n","      <td>7.298054</td>\n","      <td>4.057921</td>\n","      <td>2.369854</td>\n","      <td>3.181388</td>\n","      <td>6.149067</td>\n","      <td>5.650796</td>\n","      <td>5.068528</td>\n","      <td>4.935538</td>\n","      <td>6.840829</td>\n","      <td>4.564339</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10.990587</td>\n","      <td>5.196148</td>\n","      <td>4.968183</td>\n","      <td>2.576940</td>\n","      <td>4.233728</td>\n","      <td>4.119200</td>\n","      <td>6.174312</td>\n","      <td>1.775400</td>\n","      <td>1.475707</td>\n","      <td>6.684998</td>\n","      <td>...</td>\n","      <td>7.061465</td>\n","      <td>4.159153</td>\n","      <td>2.327722</td>\n","      <td>3.183620</td>\n","      <td>6.181925</td>\n","      <td>5.809379</td>\n","      <td>5.113574</td>\n","      <td>4.873700</td>\n","      <td>6.771983</td>\n","      <td>4.528791</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>10.507652</td>\n","      <td>4.949894</td>\n","      <td>4.014671</td>\n","      <td>2.117899</td>\n","      <td>4.715438</td>\n","      <td>4.335719</td>\n","      <td>5.412321</td>\n","      <td>1.769552</td>\n","      <td>1.720969</td>\n","      <td>6.056923</td>\n","      <td>...</td>\n","      <td>7.375135</td>\n","      <td>3.952120</td>\n","      <td>2.305240</td>\n","      <td>3.210462</td>\n","      <td>6.340523</td>\n","      <td>5.595186</td>\n","      <td>5.102685</td>\n","      <td>4.922517</td>\n","      <td>6.645929</td>\n","      <td>4.465776</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>10.698858</td>\n","      <td>4.546772</td>\n","      <td>3.540320</td>\n","      <td>3.286137</td>\n","      <td>5.087534</td>\n","      <td>5.156605</td>\n","      <td>5.941041</td>\n","      <td>1.688843</td>\n","      <td>1.656772</td>\n","      <td>5.678233</td>\n","      <td>...</td>\n","      <td>7.371179</td>\n","      <td>3.950364</td>\n","      <td>2.242772</td>\n","      <td>3.236705</td>\n","      <td>6.118145</td>\n","      <td>5.502766</td>\n","      <td>5.187657</td>\n","      <td>5.083427</td>\n","      <td>6.556334</td>\n","      <td>4.512558</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>10.346373</td>\n","      <td>4.424756</td>\n","      <td>3.581532</td>\n","      <td>3.153925</td>\n","      <td>5.020442</td>\n","      <td>4.948900</td>\n","      <td>5.897359</td>\n","      <td>1.686590</td>\n","      <td>1.781551</td>\n","      <td>5.741636</td>\n","      <td>...</td>\n","      <td>7.339849</td>\n","      <td>3.958114</td>\n","      <td>2.226620</td>\n","      <td>3.229278</td>\n","      <td>6.177763</td>\n","      <td>5.498463</td>\n","      <td>5.200507</td>\n","      <td>5.040123</td>\n","      <td>6.552696</td>\n","      <td>4.490976</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>10.454275</td>\n","      <td>4.564041</td>\n","      <td>3.603564</td>\n","      <td>3.078566</td>\n","      <td>4.991286</td>\n","      <td>4.955261</td>\n","      <td>5.872911</td>\n","      <td>1.702558</td>\n","      <td>1.761993</td>\n","      <td>5.793803</td>\n","      <td>...</td>\n","      <td>7.350019</td>\n","      <td>3.961870</td>\n","      <td>2.231675</td>\n","      <td>3.226660</td>\n","      <td>6.186529</td>\n","      <td>5.515781</td>\n","      <td>5.197260</td>\n","      <td>5.032067</td>\n","      <td>6.564847</td>\n","      <td>4.491873</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>11.222271</td>\n","      <td>5.146849</td>\n","      <td>4.005402</td>\n","      <td>3.371954</td>\n","      <td>4.682106</td>\n","      <td>5.396935</td>\n","      <td>6.367755</td>\n","      <td>1.753800</td>\n","      <td>1.507380</td>\n","      <td>6.102673</td>\n","      <td>...</td>\n","      <td>7.279993</td>\n","      <td>4.084011</td>\n","      <td>2.253345</td>\n","      <td>3.232021</td>\n","      <td>6.046115</td>\n","      <td>5.681019</td>\n","      <td>5.217414</td>\n","      <td>5.079988</td>\n","      <td>6.634119</td>\n","      <td>4.559704</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 28 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c2739b2-9159-443e-b4dd-2f1469987f86')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-11ac1dc4-2192-4b99-8177-178a9f8845db\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11ac1dc4-2192-4b99-8177-178a9f8845db')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-11ac1dc4-2192-4b99-8177-178a9f8845db button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7c2739b2-9159-443e-b4dd-2f1469987f86 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7c2739b2-9159-443e-b4dd-2f1469987f86');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":[],"metadata":{"id":"sKUBPcSpdpsI","executionInfo":{"status":"ok","timestamp":1689749157454,"user_tz":-330,"elapsed":28,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["stdliwcdf = df.loc[:, 'WC':'Emoji']\n","stdliwcdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"S39j3QfVdy2J","executionInfo":{"status":"ok","timestamp":1689749157455,"user_tz":-330,"elapsed":25,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"bb285e31-1fb5-4823-acfb-083f5bd273cf"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       WC  Analytic  Clout  Authentic   Tone    WPS  BigWords    Dic  \\\n","0     607     55.22  35.35      48.82   1.00  26.39     25.86  93.74   \n","1     401     54.08   1.31      99.00   8.57  13.83     14.21  90.02   \n","2     446     25.83  93.36      75.79   1.00  12.74     15.47  95.74   \n","3     525     30.63   2.97      96.06   6.86  15.44     12.38  90.86   \n","4     323     21.57   1.00      99.00   1.12  13.46     15.48  93.50   \n","...   ...       ...    ...        ...    ...    ...       ...    ...   \n","7400  237      5.24  20.52      53.23  15.51  16.93     18.57  93.25   \n","7401   20     39.70   1.00      28.56  99.00  20.00     25.00  95.00   \n","7402   19     36.67   3.34      70.28  99.00  19.00     21.05  94.74   \n","7403   38     36.67  90.88      33.61  92.27  19.00     21.05  97.37   \n","7404  186     26.78  52.89      86.48   2.39  23.25     15.59  98.39   \n","\n","      Linguistic  function  ...  nonflu  filler  AllPunc  Period  Comma  \\\n","0          68.86     57.50  ...     0.0     0.0    19.93    4.61   9.88   \n","1          74.81     61.60  ...     0.0     0.0    13.47    6.98   4.74   \n","2          75.34     59.64  ...     0.0     0.0    16.59    8.07   2.69   \n","3          73.33     56.57  ...     1.9     0.0    21.52    5.33   4.95   \n","4          75.85     60.99  ...     0.0     0.0    18.27    7.12   4.33   \n","...          ...       ...  ...     ...     ...      ...     ...    ...   \n","7400       81.86     62.87  ...     0.0     0.0    10.13    5.49   1.69   \n","7401       65.00     40.00  ...     0.0     0.0     0.00    0.00   0.00   \n","7402       73.68     47.37  ...     0.0     0.0     0.00    0.00   0.00   \n","7403       63.16     52.63  ...     0.0     0.0     2.63    2.63   0.00   \n","7404       79.03     61.83  ...     0.0     0.0    12.90    3.76   5.38   \n","\n","      QMark  Exclam  Apostro  OtherP  Emoji  \n","0      0.16    0.16     2.80    2.31   0.33  \n","1      0.25    0.00     1.50    0.00   0.00  \n","2      0.22    0.00     4.71    0.90   0.00  \n","3      1.14    0.00     6.67    3.43   0.00  \n","4      0.93    0.00     5.26    0.62   0.00  \n","...     ...     ...      ...     ...    ...  \n","7400   0.00    0.00     2.53    0.42   0.00  \n","7401   0.00    0.00     0.00    0.00   0.00  \n","7402   0.00    0.00     0.00    0.00   0.00  \n","7403   0.00    0.00     0.00    0.00   2.63  \n","7404   0.00    0.54     1.08    2.15   0.00  \n","\n","[7405 rows x 118 columns]"],"text/html":["\n","\n","  <div id=\"df-1ade755e-1055-400e-b434-0667bf6a0ebe\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>WC</th>\n","      <th>Analytic</th>\n","      <th>Clout</th>\n","      <th>Authentic</th>\n","      <th>Tone</th>\n","      <th>WPS</th>\n","      <th>BigWords</th>\n","      <th>Dic</th>\n","      <th>Linguistic</th>\n","      <th>function</th>\n","      <th>...</th>\n","      <th>nonflu</th>\n","      <th>filler</th>\n","      <th>AllPunc</th>\n","      <th>Period</th>\n","      <th>Comma</th>\n","      <th>QMark</th>\n","      <th>Exclam</th>\n","      <th>Apostro</th>\n","      <th>OtherP</th>\n","      <th>Emoji</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>607</td>\n","      <td>55.22</td>\n","      <td>35.35</td>\n","      <td>48.82</td>\n","      <td>1.00</td>\n","      <td>26.39</td>\n","      <td>25.86</td>\n","      <td>93.74</td>\n","      <td>68.86</td>\n","      <td>57.50</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>19.93</td>\n","      <td>4.61</td>\n","      <td>9.88</td>\n","      <td>0.16</td>\n","      <td>0.16</td>\n","      <td>2.80</td>\n","      <td>2.31</td>\n","      <td>0.33</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>401</td>\n","      <td>54.08</td>\n","      <td>1.31</td>\n","      <td>99.00</td>\n","      <td>8.57</td>\n","      <td>13.83</td>\n","      <td>14.21</td>\n","      <td>90.02</td>\n","      <td>74.81</td>\n","      <td>61.60</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13.47</td>\n","      <td>6.98</td>\n","      <td>4.74</td>\n","      <td>0.25</td>\n","      <td>0.00</td>\n","      <td>1.50</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>446</td>\n","      <td>25.83</td>\n","      <td>93.36</td>\n","      <td>75.79</td>\n","      <td>1.00</td>\n","      <td>12.74</td>\n","      <td>15.47</td>\n","      <td>95.74</td>\n","      <td>75.34</td>\n","      <td>59.64</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.59</td>\n","      <td>8.07</td>\n","      <td>2.69</td>\n","      <td>0.22</td>\n","      <td>0.00</td>\n","      <td>4.71</td>\n","      <td>0.90</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>525</td>\n","      <td>30.63</td>\n","      <td>2.97</td>\n","      <td>96.06</td>\n","      <td>6.86</td>\n","      <td>15.44</td>\n","      <td>12.38</td>\n","      <td>90.86</td>\n","      <td>73.33</td>\n","      <td>56.57</td>\n","      <td>...</td>\n","      <td>1.9</td>\n","      <td>0.0</td>\n","      <td>21.52</td>\n","      <td>5.33</td>\n","      <td>4.95</td>\n","      <td>1.14</td>\n","      <td>0.00</td>\n","      <td>6.67</td>\n","      <td>3.43</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>323</td>\n","      <td>21.57</td>\n","      <td>1.00</td>\n","      <td>99.00</td>\n","      <td>1.12</td>\n","      <td>13.46</td>\n","      <td>15.48</td>\n","      <td>93.50</td>\n","      <td>75.85</td>\n","      <td>60.99</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>18.27</td>\n","      <td>7.12</td>\n","      <td>4.33</td>\n","      <td>0.93</td>\n","      <td>0.00</td>\n","      <td>5.26</td>\n","      <td>0.62</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>237</td>\n","      <td>5.24</td>\n","      <td>20.52</td>\n","      <td>53.23</td>\n","      <td>15.51</td>\n","      <td>16.93</td>\n","      <td>18.57</td>\n","      <td>93.25</td>\n","      <td>81.86</td>\n","      <td>62.87</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.13</td>\n","      <td>5.49</td>\n","      <td>1.69</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.53</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>20</td>\n","      <td>39.70</td>\n","      <td>1.00</td>\n","      <td>28.56</td>\n","      <td>99.00</td>\n","      <td>20.00</td>\n","      <td>25.00</td>\n","      <td>95.00</td>\n","      <td>65.00</td>\n","      <td>40.00</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>19</td>\n","      <td>36.67</td>\n","      <td>3.34</td>\n","      <td>70.28</td>\n","      <td>99.00</td>\n","      <td>19.00</td>\n","      <td>21.05</td>\n","      <td>94.74</td>\n","      <td>73.68</td>\n","      <td>47.37</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>38</td>\n","      <td>36.67</td>\n","      <td>90.88</td>\n","      <td>33.61</td>\n","      <td>92.27</td>\n","      <td>19.00</td>\n","      <td>21.05</td>\n","      <td>97.37</td>\n","      <td>63.16</td>\n","      <td>52.63</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.63</td>\n","      <td>2.63</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.63</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>186</td>\n","      <td>26.78</td>\n","      <td>52.89</td>\n","      <td>86.48</td>\n","      <td>2.39</td>\n","      <td>23.25</td>\n","      <td>15.59</td>\n","      <td>98.39</td>\n","      <td>79.03</td>\n","      <td>61.83</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.90</td>\n","      <td>3.76</td>\n","      <td>5.38</td>\n","      <td>0.00</td>\n","      <td>0.54</td>\n","      <td>1.08</td>\n","      <td>2.15</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 118 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ade755e-1055-400e-b434-0667bf6a0ebe')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-0698c155-0b2e-4974-930a-0d7cd275ac18\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0698c155-0b2e-4974-930a-0d7cd275ac18')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-0698c155-0b2e-4974-930a-0d7cd275ac18 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1ade755e-1055-400e-b434-0667bf6a0ebe button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1ade755e-1055-400e-b434-0667bf6a0ebe');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"PIONnicXdzTR","executionInfo":{"status":"ok","timestamp":1689749157455,"user_tz":-330,"elapsed":23,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["emodf = df.loc[:, 'admiration':'neutral']\n","emodf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"XhRKa7preIUd","executionInfo":{"status":"ok","timestamp":1689749157455,"user_tz":-330,"elapsed":23,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"18e69b0b-9c07-4222-9398-a1d98c0503c2"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      admiration  amusement     anger  annoyance  approval    caring  \\\n","0       0.000016   0.000150  0.000705   0.001447  0.000643  0.009114   \n","1       0.000054   0.167888  0.011522   0.201494  0.000443  0.001504   \n","2       0.000101   0.000596  0.000428   0.001275  0.006295  0.013178   \n","3       0.000054   0.000639  0.043696   0.003672  0.000041  0.007463   \n","4       0.000004   0.000040  0.000176   0.000860  0.000181  0.000255   \n","...          ...        ...       ...        ...       ...       ...   \n","7400    0.000907   0.000017  0.000027   0.000027  0.000360  0.001514   \n","7401    0.000451   0.000075  0.000005   0.000022  0.000736  0.000157   \n","7402    0.000228   0.000024  0.000010   0.000034  0.000405  0.000364   \n","7403    0.000064   0.000080  0.000109   0.000155  0.012040  0.932658   \n","7404    0.003813   0.000036  0.000079   0.000095  0.039129  0.920536   \n","\n","      confusion  curiosity.1    desire  disappointment  ...      love  \\\n","0      0.048850     0.010012  0.000057        0.000440  ...  0.000210   \n","1      0.002532     0.000539  0.000486        0.053486  ...  0.003212   \n","2      0.412494     0.034596  0.000124        0.002020  ...  0.001481   \n","3      0.000333     0.000094  0.000294        0.002422  ...  0.005427   \n","4      0.001674     0.000182  0.000016        0.001535  ...  0.000145   \n","...         ...          ...       ...             ...  ...       ...   \n","7400   0.000162     0.000076  0.000035        0.000038  ...  0.000018   \n","7401   0.000070     0.000227  0.000052        0.000015  ...  0.000010   \n","7402   0.000123     0.000703  0.000040        0.000015  ...  0.000008   \n","7403   0.000593     0.001206  0.000311        0.000126  ...  0.000124   \n","7404   0.000142     0.000082  0.000070        0.000138  ...  0.000231   \n","\n","      nervousness  optimism     pride  realization    relief   remorse  \\\n","0        0.068864  0.000185  0.000041     0.000323  0.001267  0.000330   \n","1        0.013415  0.000246  0.000617     0.022932  0.000231  0.003261   \n","2        0.035853  0.000615  0.000224     0.336612  0.002241  0.001373   \n","3        0.010949  0.000076  0.000740     0.000619  0.000275  0.001561   \n","4        0.079422  0.000020  0.000017     0.000338  0.000211  0.000071   \n","...           ...       ...       ...          ...       ...       ...   \n","7400     0.000038  0.000060  0.000021     0.000021  0.000448  0.000136   \n","7401     0.000004  0.000037  0.000003     0.000018  0.000051  0.000023   \n","7402     0.000007  0.000077  0.000003     0.000009  0.000134  0.000023   \n","7403     0.016793  0.015985  0.000026     0.000285  0.005689  0.000256   \n","7404     0.000211  0.007032  0.000072     0.001102  0.007063  0.000425   \n","\n","       sadness  surprise   neutral  \n","0     0.000575  0.000205  0.000843  \n","1     0.416074  0.001216  0.003240  \n","2     0.007805  0.013074  0.041802  \n","3     0.057985  0.000332  0.000073  \n","4     0.002956  0.000103  0.000174  \n","...        ...       ...       ...  \n","7400  0.000022  0.000016  0.000068  \n","7401  0.000008  0.000011  0.001105  \n","7402  0.000008  0.000013  0.000393  \n","7403  0.000404  0.000174  0.003708  \n","7404  0.000141  0.000089  0.015839  \n","\n","[7405 rows x 28 columns]"],"text/html":["\n","\n","  <div id=\"df-ffcdc4d2-18dd-4e7b-bf9e-d48e724f95d7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>admiration</th>\n","      <th>amusement</th>\n","      <th>anger</th>\n","      <th>annoyance</th>\n","      <th>approval</th>\n","      <th>caring</th>\n","      <th>confusion</th>\n","      <th>curiosity.1</th>\n","      <th>desire</th>\n","      <th>disappointment</th>\n","      <th>...</th>\n","      <th>love</th>\n","      <th>nervousness</th>\n","      <th>optimism</th>\n","      <th>pride</th>\n","      <th>realization</th>\n","      <th>relief</th>\n","      <th>remorse</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>neutral</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000016</td>\n","      <td>0.000150</td>\n","      <td>0.000705</td>\n","      <td>0.001447</td>\n","      <td>0.000643</td>\n","      <td>0.009114</td>\n","      <td>0.048850</td>\n","      <td>0.010012</td>\n","      <td>0.000057</td>\n","      <td>0.000440</td>\n","      <td>...</td>\n","      <td>0.000210</td>\n","      <td>0.068864</td>\n","      <td>0.000185</td>\n","      <td>0.000041</td>\n","      <td>0.000323</td>\n","      <td>0.001267</td>\n","      <td>0.000330</td>\n","      <td>0.000575</td>\n","      <td>0.000205</td>\n","      <td>0.000843</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000054</td>\n","      <td>0.167888</td>\n","      <td>0.011522</td>\n","      <td>0.201494</td>\n","      <td>0.000443</td>\n","      <td>0.001504</td>\n","      <td>0.002532</td>\n","      <td>0.000539</td>\n","      <td>0.000486</td>\n","      <td>0.053486</td>\n","      <td>...</td>\n","      <td>0.003212</td>\n","      <td>0.013415</td>\n","      <td>0.000246</td>\n","      <td>0.000617</td>\n","      <td>0.022932</td>\n","      <td>0.000231</td>\n","      <td>0.003261</td>\n","      <td>0.416074</td>\n","      <td>0.001216</td>\n","      <td>0.003240</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000101</td>\n","      <td>0.000596</td>\n","      <td>0.000428</td>\n","      <td>0.001275</td>\n","      <td>0.006295</td>\n","      <td>0.013178</td>\n","      <td>0.412494</td>\n","      <td>0.034596</td>\n","      <td>0.000124</td>\n","      <td>0.002020</td>\n","      <td>...</td>\n","      <td>0.001481</td>\n","      <td>0.035853</td>\n","      <td>0.000615</td>\n","      <td>0.000224</td>\n","      <td>0.336612</td>\n","      <td>0.002241</td>\n","      <td>0.001373</td>\n","      <td>0.007805</td>\n","      <td>0.013074</td>\n","      <td>0.041802</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000054</td>\n","      <td>0.000639</td>\n","      <td>0.043696</td>\n","      <td>0.003672</td>\n","      <td>0.000041</td>\n","      <td>0.007463</td>\n","      <td>0.000333</td>\n","      <td>0.000094</td>\n","      <td>0.000294</td>\n","      <td>0.002422</td>\n","      <td>...</td>\n","      <td>0.005427</td>\n","      <td>0.010949</td>\n","      <td>0.000076</td>\n","      <td>0.000740</td>\n","      <td>0.000619</td>\n","      <td>0.000275</td>\n","      <td>0.001561</td>\n","      <td>0.057985</td>\n","      <td>0.000332</td>\n","      <td>0.000073</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000004</td>\n","      <td>0.000040</td>\n","      <td>0.000176</td>\n","      <td>0.000860</td>\n","      <td>0.000181</td>\n","      <td>0.000255</td>\n","      <td>0.001674</td>\n","      <td>0.000182</td>\n","      <td>0.000016</td>\n","      <td>0.001535</td>\n","      <td>...</td>\n","      <td>0.000145</td>\n","      <td>0.079422</td>\n","      <td>0.000020</td>\n","      <td>0.000017</td>\n","      <td>0.000338</td>\n","      <td>0.000211</td>\n","      <td>0.000071</td>\n","      <td>0.002956</td>\n","      <td>0.000103</td>\n","      <td>0.000174</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.000907</td>\n","      <td>0.000017</td>\n","      <td>0.000027</td>\n","      <td>0.000027</td>\n","      <td>0.000360</td>\n","      <td>0.001514</td>\n","      <td>0.000162</td>\n","      <td>0.000076</td>\n","      <td>0.000035</td>\n","      <td>0.000038</td>\n","      <td>...</td>\n","      <td>0.000018</td>\n","      <td>0.000038</td>\n","      <td>0.000060</td>\n","      <td>0.000021</td>\n","      <td>0.000021</td>\n","      <td>0.000448</td>\n","      <td>0.000136</td>\n","      <td>0.000022</td>\n","      <td>0.000016</td>\n","      <td>0.000068</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.000451</td>\n","      <td>0.000075</td>\n","      <td>0.000005</td>\n","      <td>0.000022</td>\n","      <td>0.000736</td>\n","      <td>0.000157</td>\n","      <td>0.000070</td>\n","      <td>0.000227</td>\n","      <td>0.000052</td>\n","      <td>0.000015</td>\n","      <td>...</td>\n","      <td>0.000010</td>\n","      <td>0.000004</td>\n","      <td>0.000037</td>\n","      <td>0.000003</td>\n","      <td>0.000018</td>\n","      <td>0.000051</td>\n","      <td>0.000023</td>\n","      <td>0.000008</td>\n","      <td>0.000011</td>\n","      <td>0.001105</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.000228</td>\n","      <td>0.000024</td>\n","      <td>0.000010</td>\n","      <td>0.000034</td>\n","      <td>0.000405</td>\n","      <td>0.000364</td>\n","      <td>0.000123</td>\n","      <td>0.000703</td>\n","      <td>0.000040</td>\n","      <td>0.000015</td>\n","      <td>...</td>\n","      <td>0.000008</td>\n","      <td>0.000007</td>\n","      <td>0.000077</td>\n","      <td>0.000003</td>\n","      <td>0.000009</td>\n","      <td>0.000134</td>\n","      <td>0.000023</td>\n","      <td>0.000008</td>\n","      <td>0.000013</td>\n","      <td>0.000393</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.000064</td>\n","      <td>0.000080</td>\n","      <td>0.000109</td>\n","      <td>0.000155</td>\n","      <td>0.012040</td>\n","      <td>0.932658</td>\n","      <td>0.000593</td>\n","      <td>0.001206</td>\n","      <td>0.000311</td>\n","      <td>0.000126</td>\n","      <td>...</td>\n","      <td>0.000124</td>\n","      <td>0.016793</td>\n","      <td>0.015985</td>\n","      <td>0.000026</td>\n","      <td>0.000285</td>\n","      <td>0.005689</td>\n","      <td>0.000256</td>\n","      <td>0.000404</td>\n","      <td>0.000174</td>\n","      <td>0.003708</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.003813</td>\n","      <td>0.000036</td>\n","      <td>0.000079</td>\n","      <td>0.000095</td>\n","      <td>0.039129</td>\n","      <td>0.920536</td>\n","      <td>0.000142</td>\n","      <td>0.000082</td>\n","      <td>0.000070</td>\n","      <td>0.000138</td>\n","      <td>...</td>\n","      <td>0.000231</td>\n","      <td>0.000211</td>\n","      <td>0.007032</td>\n","      <td>0.000072</td>\n","      <td>0.001102</td>\n","      <td>0.007063</td>\n","      <td>0.000425</td>\n","      <td>0.000141</td>\n","      <td>0.000089</td>\n","      <td>0.015839</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 28 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffcdc4d2-18dd-4e7b-bf9e-d48e724f95d7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-5c8b0121-6a64-43b3-b7be-445adb12feff\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c8b0121-6a64-43b3-b7be-445adb12feff')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-5c8b0121-6a64-43b3-b7be-445adb12feff button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ffcdc4d2-18dd-4e7b-bf9e-d48e724f95d7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ffcdc4d2-18dd-4e7b-bf9e-d48e724f95d7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"0Gu-9yZkeIzZ","executionInfo":{"status":"ok","timestamp":1689749157456,"user_tz":-330,"elapsed":21,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["intensitydf = df.loc[:, 'anger_intensity':'trust_intensity']\n","intensitydf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Sb3tFdoweL9Q","executionInfo":{"status":"ok","timestamp":1689749157457,"user_tz":-330,"elapsed":22,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"4123e163-38aa-429c-df74-fb072e1acc9a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      anger_intensity  anticipation_intensity  disgust_intensity  \\\n","0            0.415048                0.553423           0.272333   \n","1            0.530400                0.519750           0.541250   \n","2            0.428600                0.533500           0.228167   \n","3            0.567200                0.533462           0.114667   \n","4            0.487000                0.508000           0.482250   \n","...               ...                     ...                ...   \n","7400         0.396000                0.609000           0.484000   \n","7401         0.000000                0.000000           0.000000   \n","7402         0.000000                0.000000           0.000000   \n","7403         0.344000                0.528667           0.000000   \n","7404         0.376750                0.502500           0.422000   \n","\n","      fear_intensity  joy_intensity  sadness_intensity  surprise_intensity  \\\n","0           0.568205       0.409500           0.467625            0.434500   \n","1           0.432167       0.453429           0.315600            0.247333   \n","2           0.526192       0.413444           0.468533            0.348500   \n","3           0.501952       0.505000           0.522095            0.320500   \n","4           0.624833       0.489167           0.505333            0.000000   \n","...              ...            ...                ...                 ...   \n","7400        0.527500       0.434000           0.591000            0.793000   \n","7401        0.156000       0.000000           0.000000            0.000000   \n","7402        0.156000       0.000000           0.000000            0.000000   \n","7403        0.414000       0.515500           0.500000            0.363500   \n","7404        0.515333       0.431900           0.418800            0.316500   \n","\n","      trust_intensity  \n","0            0.522773  \n","1            0.508875  \n","2            0.504500  \n","3            0.593615  \n","4            0.527167  \n","...               ...  \n","7400         0.540800  \n","7401         0.000000  \n","7402         0.641000  \n","7403         0.613000  \n","7404         0.519286  \n","\n","[7405 rows x 8 columns]"],"text/html":["\n","\n","  <div id=\"df-f3783c6b-8c36-4f13-933d-0d4d68b0a777\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3783c6b-8c36-4f13-933d-0d4d68b0a777')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-62deac4b-3a58-40c2-ad1f-1febb26db6e7\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62deac4b-3a58-40c2-ad1f-1febb26db6e7')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-62deac4b-3a58-40c2-ad1f-1febb26db6e7 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f3783c6b-8c36-4f13-933d-0d4d68b0a777 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f3783c6b-8c36-4f13-933d-0d4d68b0a777');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"_IHHilFiePUx","executionInfo":{"status":"ok","timestamp":1689749157458,"user_tz":-330,"elapsed":21,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["final_df = pd.concat([sentembdf, stdliwcdf, emodf, intensitydf, df['symptoms_ext_count']], axis=1)\n","final_df['label'] = df['label']\n","final_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"v0e0WIhZeSyu","executionInfo":{"status":"ok","timestamp":1689749180101,"user_tz":-330,"elapsed":258,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"1cb39929-6a84-46eb-fb6f-9c2f7205c77d"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     10.641940  5.043077  5.682403  3.366873  3.939331  3.919311  6.919125   \n","1     11.312859  5.364349  4.413650  3.407885  5.023540  4.247440  6.088093   \n","2     10.531799  4.894456  5.387705  3.325495  4.051551  4.119681  6.826452   \n","3     11.310531  5.330986  4.330414  3.431627  5.095810  4.284573  6.036744   \n","4     10.990587  5.196148  4.968183  2.576940  4.233728  4.119200  6.174312   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","7400  10.507652  4.949894  4.014671  2.117899  4.715438  4.335719  5.412321   \n","7401  10.698858  4.546772  3.540320  3.286137  5.087534  5.156605  5.941041   \n","7402  10.346373  4.424756  3.581532  3.153925  5.020442  4.948900  5.897359   \n","7403  10.454275  4.564041  3.603564  3.078566  4.991286  4.955261  5.872911   \n","7404  11.222271  5.146849  4.005402  3.371954  4.682106  5.396935  6.367755   \n","\n","      sentemb8  sentemb9  sentemb10  ...  anger_intensity  \\\n","0     1.789982  1.404625   7.134058  ...         0.415048   \n","1     1.780003  1.160577   6.596563  ...         0.530400   \n","2     1.776312  1.471099   6.926485  ...         0.428600   \n","3     1.780587  1.134592   6.539715  ...         0.567200   \n","4     1.775400  1.475707   6.684998  ...         0.487000   \n","...        ...       ...        ...  ...              ...   \n","7400  1.769552  1.720969   6.056923  ...         0.396000   \n","7401  1.688843  1.656772   5.678233  ...         0.000000   \n","7402  1.686590  1.781551   5.741636  ...         0.000000   \n","7403  1.702558  1.761993   5.793803  ...         0.344000   \n","7404  1.753800  1.507380   6.102673  ...         0.376750   \n","\n","      anticipation_intensity  disgust_intensity  fear_intensity  \\\n","0                   0.553423           0.272333        0.568205   \n","1                   0.519750           0.541250        0.432167   \n","2                   0.533500           0.228167        0.526192   \n","3                   0.533462           0.114667        0.501952   \n","4                   0.508000           0.482250        0.624833   \n","...                      ...                ...             ...   \n","7400                0.609000           0.484000        0.527500   \n","7401                0.000000           0.000000        0.156000   \n","7402                0.000000           0.000000        0.156000   \n","7403                0.528667           0.000000        0.414000   \n","7404                0.502500           0.422000        0.515333   \n","\n","      joy_intensity  sadness_intensity  surprise_intensity  trust_intensity  \\\n","0          0.409500           0.467625            0.434500         0.522773   \n","1          0.453429           0.315600            0.247333         0.508875   \n","2          0.413444           0.468533            0.348500         0.504500   \n","3          0.505000           0.522095            0.320500         0.593615   \n","4          0.489167           0.505333            0.000000         0.527167   \n","...             ...                ...                 ...              ...   \n","7400       0.434000           0.591000            0.793000         0.540800   \n","7401       0.000000           0.000000            0.000000         0.000000   \n","7402       0.000000           0.000000            0.000000         0.641000   \n","7403       0.515500           0.500000            0.363500         0.613000   \n","7404       0.431900           0.418800            0.316500         0.519286   \n","\n","      symptoms_ext_count  label  \n","0                      8      1  \n","1                      1      1  \n","2                      3      1  \n","3                      1      1  \n","4                      3      1  \n","...                  ...    ...  \n","7400                   1      0  \n","7401                   0      0  \n","7402                   0      0  \n","7403                   0      0  \n","7404                   0      0  \n","\n","[7405 rows x 184 columns]"],"text/html":["\n","\n","  <div id=\"df-2bb5154a-9698-435c-8c74-2cff0e1ba1c7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","      <th>symptoms_ext_count</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10.641940</td>\n","      <td>5.043077</td>\n","      <td>5.682403</td>\n","      <td>3.366873</td>\n","      <td>3.939331</td>\n","      <td>3.919311</td>\n","      <td>6.919125</td>\n","      <td>1.789982</td>\n","      <td>1.404625</td>\n","      <td>7.134058</td>\n","      <td>...</td>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","      <td>8</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11.312859</td>\n","      <td>5.364349</td>\n","      <td>4.413650</td>\n","      <td>3.407885</td>\n","      <td>5.023540</td>\n","      <td>4.247440</td>\n","      <td>6.088093</td>\n","      <td>1.780003</td>\n","      <td>1.160577</td>\n","      <td>6.596563</td>\n","      <td>...</td>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.531799</td>\n","      <td>4.894456</td>\n","      <td>5.387705</td>\n","      <td>3.325495</td>\n","      <td>4.051551</td>\n","      <td>4.119681</td>\n","      <td>6.826452</td>\n","      <td>1.776312</td>\n","      <td>1.471099</td>\n","      <td>6.926485</td>\n","      <td>...</td>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.310531</td>\n","      <td>5.330986</td>\n","      <td>4.330414</td>\n","      <td>3.431627</td>\n","      <td>5.095810</td>\n","      <td>4.284573</td>\n","      <td>6.036744</td>\n","      <td>1.780587</td>\n","      <td>1.134592</td>\n","      <td>6.539715</td>\n","      <td>...</td>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10.990587</td>\n","      <td>5.196148</td>\n","      <td>4.968183</td>\n","      <td>2.576940</td>\n","      <td>4.233728</td>\n","      <td>4.119200</td>\n","      <td>6.174312</td>\n","      <td>1.775400</td>\n","      <td>1.475707</td>\n","      <td>6.684998</td>\n","      <td>...</td>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>10.507652</td>\n","      <td>4.949894</td>\n","      <td>4.014671</td>\n","      <td>2.117899</td>\n","      <td>4.715438</td>\n","      <td>4.335719</td>\n","      <td>5.412321</td>\n","      <td>1.769552</td>\n","      <td>1.720969</td>\n","      <td>6.056923</td>\n","      <td>...</td>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>10.698858</td>\n","      <td>4.546772</td>\n","      <td>3.540320</td>\n","      <td>3.286137</td>\n","      <td>5.087534</td>\n","      <td>5.156605</td>\n","      <td>5.941041</td>\n","      <td>1.688843</td>\n","      <td>1.656772</td>\n","      <td>5.678233</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>10.346373</td>\n","      <td>4.424756</td>\n","      <td>3.581532</td>\n","      <td>3.153925</td>\n","      <td>5.020442</td>\n","      <td>4.948900</td>\n","      <td>5.897359</td>\n","      <td>1.686590</td>\n","      <td>1.781551</td>\n","      <td>5.741636</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>10.454275</td>\n","      <td>4.564041</td>\n","      <td>3.603564</td>\n","      <td>3.078566</td>\n","      <td>4.991286</td>\n","      <td>4.955261</td>\n","      <td>5.872911</td>\n","      <td>1.702558</td>\n","      <td>1.761993</td>\n","      <td>5.793803</td>\n","      <td>...</td>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>11.222271</td>\n","      <td>5.146849</td>\n","      <td>4.005402</td>\n","      <td>3.371954</td>\n","      <td>4.682106</td>\n","      <td>5.396935</td>\n","      <td>6.367755</td>\n","      <td>1.753800</td>\n","      <td>1.507380</td>\n","      <td>6.102673</td>\n","      <td>...</td>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 184 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bb5154a-9698-435c-8c74-2cff0e1ba1c7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-00d16d94-adb1-407c-abf3-5a590fc0bfb4\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00d16d94-adb1-407c-abf3-5a590fc0bfb4')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-00d16d94-adb1-407c-abf3-5a590fc0bfb4 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2bb5154a-9698-435c-8c74-2cff0e1ba1c7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2bb5154a-9698-435c-8c74-2cff0e1ba1c7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[],"metadata":{"id":"CXNGvOXm5Oef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kIovAAj29Ixb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Random Undersampling\n","\n"],"metadata":{"id":"MluOTq7y9I5X"}},{"cell_type":"code","source":["final_df['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-W0KEws5Og9","executionInfo":{"status":"ok","timestamp":1689749217846,"user_tz":-330,"elapsed":267,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6bcb5d66-9e84-469e-da4b-300027910ef8"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    4640\n","0    2765\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["from imblearn.under_sampling import RandomUnderSampler"],"metadata":{"id":"lfeARuRv5Ojd","executionInfo":{"status":"ok","timestamp":1689749671806,"user_tz":-330,"elapsed":2440,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["Xtemp = final_df.drop('label', axis=1)\n","ytemp = final_df['label']"],"metadata":{"id":"OhtO_Dmx5vbQ","executionInfo":{"status":"ok","timestamp":1689750078130,"user_tz":-330,"elapsed":348,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["undersampler = RandomUnderSampler(sampling_strategy=1, random_state=42)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html"],"metadata":{"id":"hO_ykuZS5veJ","executionInfo":{"status":"ok","timestamp":1689750078452,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)"],"metadata":{"id":"Vkgbu8ka5vgu","executionInfo":{"status":"ok","timestamp":1689750078453,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["X_undersampled"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"NuXJBnCV8pdN","executionInfo":{"status":"ok","timestamp":1689750078786,"user_tz":-330,"elapsed":7,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"fa29f741-c55b-423d-9a9d-3581d1da4e7f"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     12.319857  6.399014  4.530356  2.865929  4.445246  5.065509  6.307887   \n","1     11.981301  5.855036  4.455084  2.877874  4.566389  4.754900  6.224051   \n","2     12.306263  6.337527  4.459904  2.941618  4.498397  5.115978  6.315321   \n","3     11.924356  5.831368  4.232168  3.345199  4.772059  5.092751  6.328898   \n","4     11.751195  5.696429  4.387308  3.400336  4.734811  4.937661  6.364964   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","5525  10.427677  4.712157  4.923399  3.956240  4.162726  5.006993  7.153138   \n","5526   8.398520  2.988861  2.252746  3.048421  5.798511  5.158401  4.810905   \n","5527  10.368590  4.730114  5.105931  3.170660  4.135172  4.259716  6.612472   \n","5528   9.916215  3.867956  3.379334  3.135911  5.451319  4.645429  5.375762   \n","5529   9.306035  3.675035  3.137268  2.864412  5.409729  4.707642  5.179926   \n","\n","      sentemb8  sentemb9  sentemb10  ...   neutral  anger_intensity  \\\n","0     1.829383  1.249323   6.747220  ...  0.000320         0.278333   \n","1     1.759501  1.451402   6.514011  ...  0.003006         0.459300   \n","2     1.815021  1.249940   6.686715  ...  0.000928         0.344000   \n","3     1.776461  1.269352   6.457453  ...  0.001544         0.294750   \n","4     1.778782  1.192163   6.539055  ...  0.010126         0.453000   \n","...        ...       ...        ...  ...       ...              ...   \n","5525  1.760024  1.536282   6.597105  ...  0.005895         0.000000   \n","5526  1.738988  1.730299   4.858199  ...  0.006126         0.147000   \n","5527  1.772626  1.521696   6.705473  ...  0.001772         0.000000   \n","5528  1.727962  1.417521   5.503230  ...  0.000054         0.620500   \n","5529  1.715438  1.629607   5.339017  ...  0.013418         0.369000   \n","\n","      anticipation_intensity  disgust_intensity  fear_intensity  \\\n","0                   0.583333             0.1410        0.625333   \n","1                   0.560700             0.4735        0.531849   \n","2                   0.609000             0.0000        0.594000   \n","3                   0.590600             0.1410        0.509800   \n","4                   0.516000             0.3910        0.375000   \n","...                      ...                ...             ...   \n","5525                0.644500             0.1800        0.750000   \n","5526                0.536500             0.1410        0.328000   \n","5527                0.000000             0.0000        0.000000   \n","5528                0.516000             0.2890        0.906000   \n","5529                0.515750             0.1410        0.380000   \n","\n","      joy_intensity  sadness_intensity  surprise_intensity  trust_intensity  \\\n","0          0.671500           0.410250              0.5430         0.518000   \n","1          0.490187           0.535074              0.4725         0.549682   \n","2          0.000000           0.500000              0.0000         0.453000   \n","3          0.523333           0.418000              0.3515         0.492500   \n","4          0.441000           0.422000              0.3200         0.468500   \n","...             ...                ...                 ...              ...   \n","5525       0.419750           0.281000              0.3435         0.562500   \n","5526       0.599750           0.172000              0.2890         0.567500   \n","5527       0.000000           0.000000              0.0000         0.000000   \n","5528       0.000000           0.433429              0.0000         0.000000   \n","5529       0.523750           0.424800              0.3590         0.518000   \n","\n","      symptoms_ext_count  \n","0                      0  \n","1                      3  \n","2                      0  \n","3                      1  \n","4                      0  \n","...                  ...  \n","5525                   0  \n","5526                   0  \n","5527                   0  \n","5528                   1  \n","5529                   0  \n","\n","[5530 rows x 183 columns]"],"text/html":["\n","\n","  <div id=\"df-a0251298-478c-4e16-b2d0-7649d047cd59\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>neutral</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","      <th>symptoms_ext_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12.319857</td>\n","      <td>6.399014</td>\n","      <td>4.530356</td>\n","      <td>2.865929</td>\n","      <td>4.445246</td>\n","      <td>5.065509</td>\n","      <td>6.307887</td>\n","      <td>1.829383</td>\n","      <td>1.249323</td>\n","      <td>6.747220</td>\n","      <td>...</td>\n","      <td>0.000320</td>\n","      <td>0.278333</td>\n","      <td>0.583333</td>\n","      <td>0.1410</td>\n","      <td>0.625333</td>\n","      <td>0.671500</td>\n","      <td>0.410250</td>\n","      <td>0.5430</td>\n","      <td>0.518000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11.981301</td>\n","      <td>5.855036</td>\n","      <td>4.455084</td>\n","      <td>2.877874</td>\n","      <td>4.566389</td>\n","      <td>4.754900</td>\n","      <td>6.224051</td>\n","      <td>1.759501</td>\n","      <td>1.451402</td>\n","      <td>6.514011</td>\n","      <td>...</td>\n","      <td>0.003006</td>\n","      <td>0.459300</td>\n","      <td>0.560700</td>\n","      <td>0.4735</td>\n","      <td>0.531849</td>\n","      <td>0.490187</td>\n","      <td>0.535074</td>\n","      <td>0.4725</td>\n","      <td>0.549682</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12.306263</td>\n","      <td>6.337527</td>\n","      <td>4.459904</td>\n","      <td>2.941618</td>\n","      <td>4.498397</td>\n","      <td>5.115978</td>\n","      <td>6.315321</td>\n","      <td>1.815021</td>\n","      <td>1.249940</td>\n","      <td>6.686715</td>\n","      <td>...</td>\n","      <td>0.000928</td>\n","      <td>0.344000</td>\n","      <td>0.609000</td>\n","      <td>0.0000</td>\n","      <td>0.594000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>0.0000</td>\n","      <td>0.453000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.924356</td>\n","      <td>5.831368</td>\n","      <td>4.232168</td>\n","      <td>3.345199</td>\n","      <td>4.772059</td>\n","      <td>5.092751</td>\n","      <td>6.328898</td>\n","      <td>1.776461</td>\n","      <td>1.269352</td>\n","      <td>6.457453</td>\n","      <td>...</td>\n","      <td>0.001544</td>\n","      <td>0.294750</td>\n","      <td>0.590600</td>\n","      <td>0.1410</td>\n","      <td>0.509800</td>\n","      <td>0.523333</td>\n","      <td>0.418000</td>\n","      <td>0.3515</td>\n","      <td>0.492500</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11.751195</td>\n","      <td>5.696429</td>\n","      <td>4.387308</td>\n","      <td>3.400336</td>\n","      <td>4.734811</td>\n","      <td>4.937661</td>\n","      <td>6.364964</td>\n","      <td>1.778782</td>\n","      <td>1.192163</td>\n","      <td>6.539055</td>\n","      <td>...</td>\n","      <td>0.010126</td>\n","      <td>0.453000</td>\n","      <td>0.516000</td>\n","      <td>0.3910</td>\n","      <td>0.375000</td>\n","      <td>0.441000</td>\n","      <td>0.422000</td>\n","      <td>0.3200</td>\n","      <td>0.468500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5525</th>\n","      <td>10.427677</td>\n","      <td>4.712157</td>\n","      <td>4.923399</td>\n","      <td>3.956240</td>\n","      <td>4.162726</td>\n","      <td>5.006993</td>\n","      <td>7.153138</td>\n","      <td>1.760024</td>\n","      <td>1.536282</td>\n","      <td>6.597105</td>\n","      <td>...</td>\n","      <td>0.005895</td>\n","      <td>0.000000</td>\n","      <td>0.644500</td>\n","      <td>0.1800</td>\n","      <td>0.750000</td>\n","      <td>0.419750</td>\n","      <td>0.281000</td>\n","      <td>0.3435</td>\n","      <td>0.562500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5526</th>\n","      <td>8.398520</td>\n","      <td>2.988861</td>\n","      <td>2.252746</td>\n","      <td>3.048421</td>\n","      <td>5.798511</td>\n","      <td>5.158401</td>\n","      <td>4.810905</td>\n","      <td>1.738988</td>\n","      <td>1.730299</td>\n","      <td>4.858199</td>\n","      <td>...</td>\n","      <td>0.006126</td>\n","      <td>0.147000</td>\n","      <td>0.536500</td>\n","      <td>0.1410</td>\n","      <td>0.328000</td>\n","      <td>0.599750</td>\n","      <td>0.172000</td>\n","      <td>0.2890</td>\n","      <td>0.567500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5527</th>\n","      <td>10.368590</td>\n","      <td>4.730114</td>\n","      <td>5.105931</td>\n","      <td>3.170660</td>\n","      <td>4.135172</td>\n","      <td>4.259716</td>\n","      <td>6.612472</td>\n","      <td>1.772626</td>\n","      <td>1.521696</td>\n","      <td>6.705473</td>\n","      <td>...</td>\n","      <td>0.001772</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5528</th>\n","      <td>9.916215</td>\n","      <td>3.867956</td>\n","      <td>3.379334</td>\n","      <td>3.135911</td>\n","      <td>5.451319</td>\n","      <td>4.645429</td>\n","      <td>5.375762</td>\n","      <td>1.727962</td>\n","      <td>1.417521</td>\n","      <td>5.503230</td>\n","      <td>...</td>\n","      <td>0.000054</td>\n","      <td>0.620500</td>\n","      <td>0.516000</td>\n","      <td>0.2890</td>\n","      <td>0.906000</td>\n","      <td>0.000000</td>\n","      <td>0.433429</td>\n","      <td>0.0000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5529</th>\n","      <td>9.306035</td>\n","      <td>3.675035</td>\n","      <td>3.137268</td>\n","      <td>2.864412</td>\n","      <td>5.409729</td>\n","      <td>4.707642</td>\n","      <td>5.179926</td>\n","      <td>1.715438</td>\n","      <td>1.629607</td>\n","      <td>5.339017</td>\n","      <td>...</td>\n","      <td>0.013418</td>\n","      <td>0.369000</td>\n","      <td>0.515750</td>\n","      <td>0.1410</td>\n","      <td>0.380000</td>\n","      <td>0.523750</td>\n","      <td>0.424800</td>\n","      <td>0.3590</td>\n","      <td>0.518000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5530 rows Ã— 183 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0251298-478c-4e16-b2d0-7649d047cd59')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-72eda6a6-6cc5-40de-b1e5-58e3a110355f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72eda6a6-6cc5-40de-b1e5-58e3a110355f')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-72eda6a6-6cc5-40de-b1e5-58e3a110355f button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a0251298-478c-4e16-b2d0-7649d047cd59 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a0251298-478c-4e16-b2d0-7649d047cd59');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# Convert the undersampled data back to a dataframe (if needed)\n","undersampled_df = X_undersampled.copy()\n","undersampled_df['label'] = y_undersampled"],"metadata":{"id":"BC0Mzcfo5vlD","executionInfo":{"status":"ok","timestamp":1689750078788,"user_tz":-330,"elapsed":7,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["undersampled_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"qw0tYGsn-AVC","executionInfo":{"status":"ok","timestamp":1689750343207,"user_tz":-330,"elapsed":299,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"a79a8aec-0368-4e0a-8274-97121eebbb7f"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     12.319857  6.399014  4.530356  2.865929  4.445246  5.065509  6.307887   \n","1     11.981301  5.855036  4.455084  2.877874  4.566389  4.754900  6.224051   \n","2     12.306263  6.337527  4.459904  2.941618  4.498397  5.115978  6.315321   \n","3     11.924356  5.831368  4.232168  3.345199  4.772059  5.092751  6.328898   \n","4     11.751195  5.696429  4.387308  3.400336  4.734811  4.937661  6.364964   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","5525  10.427677  4.712157  4.923399  3.956240  4.162726  5.006993  7.153138   \n","5526   8.398520  2.988861  2.252746  3.048421  5.798511  5.158401  4.810905   \n","5527  10.368590  4.730114  5.105931  3.170660  4.135172  4.259716  6.612472   \n","5528   9.916215  3.867956  3.379334  3.135911  5.451319  4.645429  5.375762   \n","5529   9.306035  3.675035  3.137268  2.864412  5.409729  4.707642  5.179926   \n","\n","      sentemb8  sentemb9  sentemb10  ...  anger_intensity  \\\n","0     1.829383  1.249323   6.747220  ...         0.278333   \n","1     1.759501  1.451402   6.514011  ...         0.459300   \n","2     1.815021  1.249940   6.686715  ...         0.344000   \n","3     1.776461  1.269352   6.457453  ...         0.294750   \n","4     1.778782  1.192163   6.539055  ...         0.453000   \n","...        ...       ...        ...  ...              ...   \n","5525  1.760024  1.536282   6.597105  ...         0.000000   \n","5526  1.738988  1.730299   4.858199  ...         0.147000   \n","5527  1.772626  1.521696   6.705473  ...         0.000000   \n","5528  1.727962  1.417521   5.503230  ...         0.620500   \n","5529  1.715438  1.629607   5.339017  ...         0.369000   \n","\n","      anticipation_intensity  disgust_intensity  fear_intensity  \\\n","0                   0.583333             0.1410        0.625333   \n","1                   0.560700             0.4735        0.531849   \n","2                   0.609000             0.0000        0.594000   \n","3                   0.590600             0.1410        0.509800   \n","4                   0.516000             0.3910        0.375000   \n","...                      ...                ...             ...   \n","5525                0.644500             0.1800        0.750000   \n","5526                0.536500             0.1410        0.328000   \n","5527                0.000000             0.0000        0.000000   \n","5528                0.516000             0.2890        0.906000   \n","5529                0.515750             0.1410        0.380000   \n","\n","      joy_intensity  sadness_intensity  surprise_intensity  trust_intensity  \\\n","0          0.671500           0.410250              0.5430         0.518000   \n","1          0.490187           0.535074              0.4725         0.549682   \n","2          0.000000           0.500000              0.0000         0.453000   \n","3          0.523333           0.418000              0.3515         0.492500   \n","4          0.441000           0.422000              0.3200         0.468500   \n","...             ...                ...                 ...              ...   \n","5525       0.419750           0.281000              0.3435         0.562500   \n","5526       0.599750           0.172000              0.2890         0.567500   \n","5527       0.000000           0.000000              0.0000         0.000000   \n","5528       0.000000           0.433429              0.0000         0.000000   \n","5529       0.523750           0.424800              0.3590         0.518000   \n","\n","      symptoms_ext_count  label  \n","0                      0      0  \n","1                      3      0  \n","2                      0      0  \n","3                      1      0  \n","4                      0      0  \n","...                  ...    ...  \n","5525                   0      1  \n","5526                   0      1  \n","5527                   0      1  \n","5528                   1      1  \n","5529                   0      1  \n","\n","[5530 rows x 184 columns]"],"text/html":["\n","\n","  <div id=\"df-c7a9ec16-15b9-4ae5-9cf5-3c2442e48277\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","      <th>symptoms_ext_count</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12.319857</td>\n","      <td>6.399014</td>\n","      <td>4.530356</td>\n","      <td>2.865929</td>\n","      <td>4.445246</td>\n","      <td>5.065509</td>\n","      <td>6.307887</td>\n","      <td>1.829383</td>\n","      <td>1.249323</td>\n","      <td>6.747220</td>\n","      <td>...</td>\n","      <td>0.278333</td>\n","      <td>0.583333</td>\n","      <td>0.1410</td>\n","      <td>0.625333</td>\n","      <td>0.671500</td>\n","      <td>0.410250</td>\n","      <td>0.5430</td>\n","      <td>0.518000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11.981301</td>\n","      <td>5.855036</td>\n","      <td>4.455084</td>\n","      <td>2.877874</td>\n","      <td>4.566389</td>\n","      <td>4.754900</td>\n","      <td>6.224051</td>\n","      <td>1.759501</td>\n","      <td>1.451402</td>\n","      <td>6.514011</td>\n","      <td>...</td>\n","      <td>0.459300</td>\n","      <td>0.560700</td>\n","      <td>0.4735</td>\n","      <td>0.531849</td>\n","      <td>0.490187</td>\n","      <td>0.535074</td>\n","      <td>0.4725</td>\n","      <td>0.549682</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12.306263</td>\n","      <td>6.337527</td>\n","      <td>4.459904</td>\n","      <td>2.941618</td>\n","      <td>4.498397</td>\n","      <td>5.115978</td>\n","      <td>6.315321</td>\n","      <td>1.815021</td>\n","      <td>1.249940</td>\n","      <td>6.686715</td>\n","      <td>...</td>\n","      <td>0.344000</td>\n","      <td>0.609000</td>\n","      <td>0.0000</td>\n","      <td>0.594000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>0.0000</td>\n","      <td>0.453000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.924356</td>\n","      <td>5.831368</td>\n","      <td>4.232168</td>\n","      <td>3.345199</td>\n","      <td>4.772059</td>\n","      <td>5.092751</td>\n","      <td>6.328898</td>\n","      <td>1.776461</td>\n","      <td>1.269352</td>\n","      <td>6.457453</td>\n","      <td>...</td>\n","      <td>0.294750</td>\n","      <td>0.590600</td>\n","      <td>0.1410</td>\n","      <td>0.509800</td>\n","      <td>0.523333</td>\n","      <td>0.418000</td>\n","      <td>0.3515</td>\n","      <td>0.492500</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11.751195</td>\n","      <td>5.696429</td>\n","      <td>4.387308</td>\n","      <td>3.400336</td>\n","      <td>4.734811</td>\n","      <td>4.937661</td>\n","      <td>6.364964</td>\n","      <td>1.778782</td>\n","      <td>1.192163</td>\n","      <td>6.539055</td>\n","      <td>...</td>\n","      <td>0.453000</td>\n","      <td>0.516000</td>\n","      <td>0.3910</td>\n","      <td>0.375000</td>\n","      <td>0.441000</td>\n","      <td>0.422000</td>\n","      <td>0.3200</td>\n","      <td>0.468500</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5525</th>\n","      <td>10.427677</td>\n","      <td>4.712157</td>\n","      <td>4.923399</td>\n","      <td>3.956240</td>\n","      <td>4.162726</td>\n","      <td>5.006993</td>\n","      <td>7.153138</td>\n","      <td>1.760024</td>\n","      <td>1.536282</td>\n","      <td>6.597105</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.644500</td>\n","      <td>0.1800</td>\n","      <td>0.750000</td>\n","      <td>0.419750</td>\n","      <td>0.281000</td>\n","      <td>0.3435</td>\n","      <td>0.562500</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5526</th>\n","      <td>8.398520</td>\n","      <td>2.988861</td>\n","      <td>2.252746</td>\n","      <td>3.048421</td>\n","      <td>5.798511</td>\n","      <td>5.158401</td>\n","      <td>4.810905</td>\n","      <td>1.738988</td>\n","      <td>1.730299</td>\n","      <td>4.858199</td>\n","      <td>...</td>\n","      <td>0.147000</td>\n","      <td>0.536500</td>\n","      <td>0.1410</td>\n","      <td>0.328000</td>\n","      <td>0.599750</td>\n","      <td>0.172000</td>\n","      <td>0.2890</td>\n","      <td>0.567500</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5527</th>\n","      <td>10.368590</td>\n","      <td>4.730114</td>\n","      <td>5.105931</td>\n","      <td>3.170660</td>\n","      <td>4.135172</td>\n","      <td>4.259716</td>\n","      <td>6.612472</td>\n","      <td>1.772626</td>\n","      <td>1.521696</td>\n","      <td>6.705473</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5528</th>\n","      <td>9.916215</td>\n","      <td>3.867956</td>\n","      <td>3.379334</td>\n","      <td>3.135911</td>\n","      <td>5.451319</td>\n","      <td>4.645429</td>\n","      <td>5.375762</td>\n","      <td>1.727962</td>\n","      <td>1.417521</td>\n","      <td>5.503230</td>\n","      <td>...</td>\n","      <td>0.620500</td>\n","      <td>0.516000</td>\n","      <td>0.2890</td>\n","      <td>0.906000</td>\n","      <td>0.000000</td>\n","      <td>0.433429</td>\n","      <td>0.0000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5529</th>\n","      <td>9.306035</td>\n","      <td>3.675035</td>\n","      <td>3.137268</td>\n","      <td>2.864412</td>\n","      <td>5.409729</td>\n","      <td>4.707642</td>\n","      <td>5.179926</td>\n","      <td>1.715438</td>\n","      <td>1.629607</td>\n","      <td>5.339017</td>\n","      <td>...</td>\n","      <td>0.369000</td>\n","      <td>0.515750</td>\n","      <td>0.1410</td>\n","      <td>0.380000</td>\n","      <td>0.523750</td>\n","      <td>0.424800</td>\n","      <td>0.3590</td>\n","      <td>0.518000</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5530 rows Ã— 184 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7a9ec16-15b9-4ae5-9cf5-3c2442e48277')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-b7a0bed8-de44-4c8c-8df2-f112a6851707\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7a0bed8-de44-4c8c-8df2-f112a6851707')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-b7a0bed8-de44-4c8c-8df2-f112a6851707 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7a9ec16-15b9-4ae5-9cf5-3c2442e48277 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7a9ec16-15b9-4ae5-9cf5-3c2442e48277');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# Check the class distribution in the undersampled dataframe\n","undersampled_df['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MravwUDH5vn0","executionInfo":{"status":"ok","timestamp":1689750099606,"user_tz":-330,"elapsed":306,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"0eaa178a-94d8-437c-ff30-2f55810e1318"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    2765\n","1    2765\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":[],"metadata":{"id":"FU7Yeqsc5vug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9_lZawqQ-Qqx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Multilayer DNN"],"metadata":{"id":"LSMISrc8BVGd"}},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"BnTNvKynBXbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"0xv80zaHBdLD","executionInfo":{"status":"ok","timestamp":1689751249650,"user_tz":-330,"elapsed":10,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Conv1D, Dense, Concatenate, GlobalMaxPooling1D, Reshape, Dropout, MaxPooling1D, MaxPooling2D, MaxPooling3D\n","from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"xWXP9m3GBbod","executionInfo":{"status":"ok","timestamp":1689751262636,"user_tz":-330,"elapsed":12994,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["scaling = MinMaxScaler(feature_range=(0,1))  # (0,1) is default\n","sc = StandardScaler()"],"metadata":{"id":"AbfRKnGpADRn","executionInfo":{"status":"ok","timestamp":1689750899710,"user_tz":-330,"elapsed":432,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eiY8EYNDBint"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"_2lyD33K-Qtp","executionInfo":{"status":"ok","timestamp":1689750413023,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"4fc083cc-79da-418f-82c8-7adc3f0ba8d9"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     10.641940  5.043077  5.682403  3.366873  3.939331  3.919311  6.919125   \n","1     11.312859  5.364349  4.413650  3.407885  5.023540  4.247440  6.088093   \n","2     10.531799  4.894456  5.387705  3.325495  4.051551  4.119681  6.826452   \n","3     11.310531  5.330986  4.330414  3.431627  5.095810  4.284573  6.036744   \n","4     10.990587  5.196148  4.968183  2.576940  4.233728  4.119200  6.174312   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","7400  10.507652  4.949894  4.014671  2.117899  4.715438  4.335719  5.412321   \n","7401  10.698858  4.546772  3.540320  3.286137  5.087534  5.156605  5.941041   \n","7402  10.346373  4.424756  3.581532  3.153925  5.020442  4.948900  5.897359   \n","7403  10.454275  4.564041  3.603564  3.078566  4.991286  4.955261  5.872911   \n","7404  11.222271  5.146849  4.005402  3.371954  4.682106  5.396935  6.367755   \n","\n","      sentemb8  sentemb9  sentemb10  ...  anger_intensity  \\\n","0     1.789982  1.404625   7.134058  ...         0.415048   \n","1     1.780003  1.160577   6.596563  ...         0.530400   \n","2     1.776312  1.471099   6.926485  ...         0.428600   \n","3     1.780587  1.134592   6.539715  ...         0.567200   \n","4     1.775400  1.475707   6.684998  ...         0.487000   \n","...        ...       ...        ...  ...              ...   \n","7400  1.769552  1.720969   6.056923  ...         0.396000   \n","7401  1.688843  1.656772   5.678233  ...         0.000000   \n","7402  1.686590  1.781551   5.741636  ...         0.000000   \n","7403  1.702558  1.761993   5.793803  ...         0.344000   \n","7404  1.753800  1.507380   6.102673  ...         0.376750   \n","\n","      anticipation_intensity  disgust_intensity  fear_intensity  \\\n","0                   0.553423           0.272333        0.568205   \n","1                   0.519750           0.541250        0.432167   \n","2                   0.533500           0.228167        0.526192   \n","3                   0.533462           0.114667        0.501952   \n","4                   0.508000           0.482250        0.624833   \n","...                      ...                ...             ...   \n","7400                0.609000           0.484000        0.527500   \n","7401                0.000000           0.000000        0.156000   \n","7402                0.000000           0.000000        0.156000   \n","7403                0.528667           0.000000        0.414000   \n","7404                0.502500           0.422000        0.515333   \n","\n","      joy_intensity  sadness_intensity  surprise_intensity  trust_intensity  \\\n","0          0.409500           0.467625            0.434500         0.522773   \n","1          0.453429           0.315600            0.247333         0.508875   \n","2          0.413444           0.468533            0.348500         0.504500   \n","3          0.505000           0.522095            0.320500         0.593615   \n","4          0.489167           0.505333            0.000000         0.527167   \n","...             ...                ...                 ...              ...   \n","7400       0.434000           0.591000            0.793000         0.540800   \n","7401       0.000000           0.000000            0.000000         0.000000   \n","7402       0.000000           0.000000            0.000000         0.641000   \n","7403       0.515500           0.500000            0.363500         0.613000   \n","7404       0.431900           0.418800            0.316500         0.519286   \n","\n","      symptoms_ext_count  label  \n","0                      8      1  \n","1                      1      1  \n","2                      3      1  \n","3                      1      1  \n","4                      3      1  \n","...                  ...    ...  \n","7400                   1      0  \n","7401                   0      0  \n","7402                   0      0  \n","7403                   0      0  \n","7404                   0      0  \n","\n","[7405 rows x 184 columns]"],"text/html":["\n","\n","  <div id=\"df-e4d346d0-3ce6-4be5-979c-4d1eb1ba4405\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","      <th>symptoms_ext_count</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10.641940</td>\n","      <td>5.043077</td>\n","      <td>5.682403</td>\n","      <td>3.366873</td>\n","      <td>3.939331</td>\n","      <td>3.919311</td>\n","      <td>6.919125</td>\n","      <td>1.789982</td>\n","      <td>1.404625</td>\n","      <td>7.134058</td>\n","      <td>...</td>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","      <td>8</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11.312859</td>\n","      <td>5.364349</td>\n","      <td>4.413650</td>\n","      <td>3.407885</td>\n","      <td>5.023540</td>\n","      <td>4.247440</td>\n","      <td>6.088093</td>\n","      <td>1.780003</td>\n","      <td>1.160577</td>\n","      <td>6.596563</td>\n","      <td>...</td>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.531799</td>\n","      <td>4.894456</td>\n","      <td>5.387705</td>\n","      <td>3.325495</td>\n","      <td>4.051551</td>\n","      <td>4.119681</td>\n","      <td>6.826452</td>\n","      <td>1.776312</td>\n","      <td>1.471099</td>\n","      <td>6.926485</td>\n","      <td>...</td>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.310531</td>\n","      <td>5.330986</td>\n","      <td>4.330414</td>\n","      <td>3.431627</td>\n","      <td>5.095810</td>\n","      <td>4.284573</td>\n","      <td>6.036744</td>\n","      <td>1.780587</td>\n","      <td>1.134592</td>\n","      <td>6.539715</td>\n","      <td>...</td>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10.990587</td>\n","      <td>5.196148</td>\n","      <td>4.968183</td>\n","      <td>2.576940</td>\n","      <td>4.233728</td>\n","      <td>4.119200</td>\n","      <td>6.174312</td>\n","      <td>1.775400</td>\n","      <td>1.475707</td>\n","      <td>6.684998</td>\n","      <td>...</td>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>10.507652</td>\n","      <td>4.949894</td>\n","      <td>4.014671</td>\n","      <td>2.117899</td>\n","      <td>4.715438</td>\n","      <td>4.335719</td>\n","      <td>5.412321</td>\n","      <td>1.769552</td>\n","      <td>1.720969</td>\n","      <td>6.056923</td>\n","      <td>...</td>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>10.698858</td>\n","      <td>4.546772</td>\n","      <td>3.540320</td>\n","      <td>3.286137</td>\n","      <td>5.087534</td>\n","      <td>5.156605</td>\n","      <td>5.941041</td>\n","      <td>1.688843</td>\n","      <td>1.656772</td>\n","      <td>5.678233</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>10.346373</td>\n","      <td>4.424756</td>\n","      <td>3.581532</td>\n","      <td>3.153925</td>\n","      <td>5.020442</td>\n","      <td>4.948900</td>\n","      <td>5.897359</td>\n","      <td>1.686590</td>\n","      <td>1.781551</td>\n","      <td>5.741636</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>10.454275</td>\n","      <td>4.564041</td>\n","      <td>3.603564</td>\n","      <td>3.078566</td>\n","      <td>4.991286</td>\n","      <td>4.955261</td>\n","      <td>5.872911</td>\n","      <td>1.702558</td>\n","      <td>1.761993</td>\n","      <td>5.793803</td>\n","      <td>...</td>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>11.222271</td>\n","      <td>5.146849</td>\n","      <td>4.005402</td>\n","      <td>3.371954</td>\n","      <td>4.682106</td>\n","      <td>5.396935</td>\n","      <td>6.367755</td>\n","      <td>1.753800</td>\n","      <td>1.507380</td>\n","      <td>6.102673</td>\n","      <td>...</td>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 184 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4d346d0-3ce6-4be5-979c-4d1eb1ba4405')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-0e359721-b9cb-4383-8d0a-36cec5122eda\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e359721-b9cb-4383-8d0a-36cec5122eda')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-0e359721-b9cb-4383-8d0a-36cec5122eda button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e4d346d0-3ce6-4be5-979c-4d1eb1ba4405 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e4d346d0-3ce6-4be5-979c-4d1eb1ba4405');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":[],"metadata":{"id":"suVEyDev-Up5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JjaTIFyuDn2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to register f1 score separately in Keras (working)\n","\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.metrics import Metric\n","\n","class F1Score(Metric):\n","    def __init__(self, name='f1_score', **kwargs):\n","        super(F1Score, self).__init__(name=name, **kwargs)\n","        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n","        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n","        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_true = tf.cast(y_true, tf.float32)\n","        y_pred = tf.cast(y_pred, tf.float32)\n","\n","        true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n","        false_positives = tf.reduce_sum(tf.round(tf.clip_by_value((1 - y_true) * y_pred, 0, 1)))\n","        false_negatives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * (1 - y_pred), 0, 1)))\n","\n","        self.true_positives.assign_add(true_positives)\n","        self.false_positives.assign_add(false_positives)\n","        self.false_negatives.assign_add(false_negatives)\n","\n","    def result(self):\n","        precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n","        recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n","        f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n","        return f1"],"metadata":{"id":"5kH208hWDn4X","executionInfo":{"status":"ok","timestamp":1689753350919,"user_tz":-330,"elapsed":235,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MQUrF-cJ5Fzn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM CNN nothing nothing"],"metadata":{"id":"AmMyBGf65GCH"}},{"cell_type":"code","source":["undersample_seed = [1,2,3,4,5]\n","split_seed = [6,7,8,9,10]"],"metadata":{"id":"Dw3tRF8N-U3U","executionInfo":{"status":"ok","timestamp":1689750506041,"user_tz":-330,"elapsed":246,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["accuracies = []\n","losses = []\n","f1scores = []"],"metadata":{"id":"CfVb4cJqI1C-","executionInfo":{"status":"ok","timestamp":1689753459393,"user_tz":-330,"elapsed":312,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["for i in undersample_seed:\n","    Xtemp = final_df.drop('label', axis=1)\n","    ytemp = final_df['label']\n","    undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","    X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","    final_df = X_undersampled.copy()\n","    final_df['label'] = y_undersampled\n","    #print(final_df.shape, final_df['label'].value_counts())\n","\n","    for j in split_seed:\n","\n","        X_sentemb = final_df.loc[:, 'sentemb1':'sentemb28']\n","        # putting panic extended feature with liwc features\n","        X_liwc = final_df.loc[:, 'WC':'Emoji']\n","        X_liwc['symptoms_ext_count'] = final_df['symptoms_ext_count']\n","        X_emotions = final_df.loc[:, 'admiration':'neutral']\n","        X_intensity = final_df.loc[:, 'anger_intensity':'trust_intensity']\n","        y = final_df['label']\n","\n","        # train test split with stratification\n","        X_sentemb_train, X_sentemb_test, X_liwc_train, X_liwc_test, X_emotions_train, X_emotions_test, X_intensity_train, X_intensity_test, y_train, y_test = train_test_split(\n","            X_sentemb, X_liwc, X_emotions, X_intensity, y, test_size=0.2, random_state=j, stratify=y)\n","\n","        # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # Standardization of train and test LIWC features\n","        train_scaled_liwc = sc.fit_transform(X_liwc_train)\n","        test_scaled_liwc = sc.fit_transform(X_liwc_test)\n","        liwc_column_names = list(df.loc[:, 'WC':'Emoji'].columns) + ['symptoms_ext_count']\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=(28,))\n","        lstm_sentemb = LSTM(32)(Reshape((1, 28))(input_sentemb))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=(119,))\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usvM2AWc5OmI","executionInfo":{"status":"ok","timestamp":1689754366743,"user_tz":-330,"elapsed":725390,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"8a2cc4cd-eaff-4124-f68a-50e8ebe58c36"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","139/139 [==============================] - 8s 15ms/step - loss: 0.5763 - accuracy: 0.6948 - f1_score: 0.6876 - val_loss: 0.4881 - val_accuracy: 0.7794 - val_f1_score: 0.7663\n","Epoch 2/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.4608 - accuracy: 0.7868 - f1_score: 0.7807 - val_loss: 0.4438 - val_accuracy: 0.8029 - val_f1_score: 0.7892\n","Epoch 3/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.3903 - accuracy: 0.8273 - f1_score: 0.8237 - val_loss: 0.4017 - val_accuracy: 0.8201 - val_f1_score: 0.8209\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3324 - accuracy: 0.8621 - f1_score: 0.8608 - val_loss: 0.3752 - val_accuracy: 0.8373 - val_f1_score: 0.8282\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2823 - accuracy: 0.8899 - f1_score: 0.8886 - val_loss: 0.4012 - val_accuracy: 0.8237 - val_f1_score: 0.7983\n","Epoch 6/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2440 - accuracy: 0.8987 - f1_score: 0.8972 - val_loss: 0.3764 - val_accuracy: 0.8436 - val_f1_score: 0.8275\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2246 - accuracy: 0.9075 - f1_score: 0.9066 - val_loss: 0.3621 - val_accuracy: 0.8517 - val_f1_score: 0.8423\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2016 - accuracy: 0.9268 - f1_score: 0.9261 - val_loss: 0.3846 - val_accuracy: 0.8508 - val_f1_score: 0.8387\n","Epoch 9/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.1922 - accuracy: 0.9272 - f1_score: 0.9269 - val_loss: 0.4100 - val_accuracy: 0.8418 - val_f1_score: 0.8248\n","Epoch 10/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.1766 - accuracy: 0.9311 - f1_score: 0.9304 - val_loss: 0.3790 - val_accuracy: 0.8463 - val_f1_score: 0.8449\n","Epoch 11/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1550 - accuracy: 0.9403 - f1_score: 0.9400 - val_loss: 0.4375 - val_accuracy: 0.8526 - val_f1_score: 0.8452\n","Epoch 12/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1429 - accuracy: 0.9460 - f1_score: 0.9458 - val_loss: 0.4244 - val_accuracy: 0.8463 - val_f1_score: 0.8426\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8517 - f1_score: 0.8423\n","Epoch 1/20\n","139/139 [==============================] - 10s 15ms/step - loss: 0.5685 - accuracy: 0.6964 - f1_score: 0.6961 - val_loss: 0.4781 - val_accuracy: 0.7812 - val_f1_score: 0.7828\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4578 - accuracy: 0.7914 - f1_score: 0.7848 - val_loss: 0.4306 - val_accuracy: 0.8011 - val_f1_score: 0.7809\n","Epoch 3/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.3900 - accuracy: 0.8314 - f1_score: 0.8268 - val_loss: 0.3722 - val_accuracy: 0.8418 - val_f1_score: 0.8433\n","Epoch 4/20\n","139/139 [==============================] - 1s 7ms/step - loss: 0.3281 - accuracy: 0.8601 - f1_score: 0.8570 - val_loss: 0.3549 - val_accuracy: 0.8544 - val_f1_score: 0.8586\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2922 - accuracy: 0.8800 - f1_score: 0.8777 - val_loss: 0.3247 - val_accuracy: 0.8689 - val_f1_score: 0.8676\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2612 - accuracy: 0.8940 - f1_score: 0.8922 - val_loss: 0.3288 - val_accuracy: 0.8662 - val_f1_score: 0.8655\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2301 - accuracy: 0.9118 - f1_score: 0.9112 - val_loss: 0.3205 - val_accuracy: 0.8698 - val_f1_score: 0.8693\n","Epoch 8/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2011 - accuracy: 0.9193 - f1_score: 0.9185 - val_loss: 0.3510 - val_accuracy: 0.8734 - val_f1_score: 0.8708\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1932 - accuracy: 0.9218 - f1_score: 0.9211 - val_loss: 0.3667 - val_accuracy: 0.8734 - val_f1_score: 0.8772\n","Epoch 10/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1804 - accuracy: 0.9299 - f1_score: 0.9296 - val_loss: 0.3611 - val_accuracy: 0.8644 - val_f1_score: 0.8631\n","Epoch 11/20\n","139/139 [==============================] - 3s 19ms/step - loss: 0.1592 - accuracy: 0.9387 - f1_score: 0.9381 - val_loss: 0.3590 - val_accuracy: 0.8653 - val_f1_score: 0.8624\n","Epoch 12/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.1445 - accuracy: 0.9480 - f1_score: 0.9475 - val_loss: 0.3930 - val_accuracy: 0.8707 - val_f1_score: 0.8704\n","35/35 [==============================] - 0s 8ms/step - loss: 0.3205 - accuracy: 0.8698 - f1_score: 0.8693\n","Epoch 1/20\n","139/139 [==============================] - 9s 26ms/step - loss: 0.5860 - accuracy: 0.6856 - f1_score: 0.6757 - val_loss: 0.5018 - val_accuracy: 0.7550 - val_f1_score: 0.7392\n","Epoch 2/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.4668 - accuracy: 0.7801 - f1_score: 0.7708 - val_loss: 0.4439 - val_accuracy: 0.7911 - val_f1_score: 0.7777\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3996 - accuracy: 0.8140 - f1_score: 0.8076 - val_loss: 0.3872 - val_accuracy: 0.8219 - val_f1_score: 0.8188\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3429 - accuracy: 0.8533 - f1_score: 0.8505 - val_loss: 0.3761 - val_accuracy: 0.8309 - val_f1_score: 0.8364\n","Epoch 5/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2988 - accuracy: 0.8700 - f1_score: 0.8674 - val_loss: 0.3539 - val_accuracy: 0.8508 - val_f1_score: 0.8569\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2675 - accuracy: 0.8933 - f1_score: 0.8918 - val_loss: 0.3502 - val_accuracy: 0.8535 - val_f1_score: 0.8445\n","Epoch 7/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2336 - accuracy: 0.9073 - f1_score: 0.9060 - val_loss: 0.3358 - val_accuracy: 0.8698 - val_f1_score: 0.8684\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2121 - accuracy: 0.9211 - f1_score: 0.9202 - val_loss: 0.3641 - val_accuracy: 0.8725 - val_f1_score: 0.8764\n","Epoch 9/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.1900 - accuracy: 0.9250 - f1_score: 0.9240 - val_loss: 0.3735 - val_accuracy: 0.8680 - val_f1_score: 0.8699\n","Epoch 10/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.1837 - accuracy: 0.9279 - f1_score: 0.9273 - val_loss: 0.3973 - val_accuracy: 0.8644 - val_f1_score: 0.8700\n","Epoch 11/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1682 - accuracy: 0.9326 - f1_score: 0.9322 - val_loss: 0.3660 - val_accuracy: 0.8797 - val_f1_score: 0.8792\n","Epoch 12/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1423 - accuracy: 0.9430 - f1_score: 0.9427 - val_loss: 0.4244 - val_accuracy: 0.8707 - val_f1_score: 0.8736\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8698 - f1_score: 0.8684\n","Epoch 1/20\n","139/139 [==============================] - 7s 14ms/step - loss: 0.5936 - accuracy: 0.6856 - f1_score: 0.6686 - val_loss: 0.4692 - val_accuracy: 0.7839 - val_f1_score: 0.7789\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4727 - accuracy: 0.7787 - f1_score: 0.7749 - val_loss: 0.4094 - val_accuracy: 0.8210 - val_f1_score: 0.8245\n","Epoch 3/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.4013 - accuracy: 0.8250 - f1_score: 0.8215 - val_loss: 0.3591 - val_accuracy: 0.8499 - val_f1_score: 0.8474\n","Epoch 4/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.3451 - accuracy: 0.8558 - f1_score: 0.8527 - val_loss: 0.3586 - val_accuracy: 0.8454 - val_f1_score: 0.8338\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2998 - accuracy: 0.8705 - f1_score: 0.8680 - val_loss: 0.3250 - val_accuracy: 0.8608 - val_f1_score: 0.8668\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2714 - accuracy: 0.8890 - f1_score: 0.8870 - val_loss: 0.3169 - val_accuracy: 0.8626 - val_f1_score: 0.8616\n","Epoch 7/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2467 - accuracy: 0.8942 - f1_score: 0.8929 - val_loss: 0.3164 - val_accuracy: 0.8653 - val_f1_score: 0.8627\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2035 - accuracy: 0.9189 - f1_score: 0.9181 - val_loss: 0.3252 - val_accuracy: 0.8689 - val_f1_score: 0.8666\n","Epoch 9/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1852 - accuracy: 0.9229 - f1_score: 0.9222 - val_loss: 0.3917 - val_accuracy: 0.8553 - val_f1_score: 0.8628\n","Epoch 10/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1745 - accuracy: 0.9302 - f1_score: 0.9294 - val_loss: 0.3669 - val_accuracy: 0.8617 - val_f1_score: 0.8615\n","Epoch 11/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1589 - accuracy: 0.9406 - f1_score: 0.9401 - val_loss: 0.3941 - val_accuracy: 0.8716 - val_f1_score: 0.8704\n","Epoch 12/20\n","139/139 [==============================] - 1s 7ms/step - loss: 0.1482 - accuracy: 0.9399 - f1_score: 0.9398 - val_loss: 0.3676 - val_accuracy: 0.8779 - val_f1_score: 0.8749\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8653 - f1_score: 0.8627\n","Epoch 1/20\n","139/139 [==============================] - 10s 37ms/step - loss: 0.5673 - accuracy: 0.7134 - f1_score: 0.7057 - val_loss: 0.4933 - val_accuracy: 0.7559 - val_f1_score: 0.7348\n","Epoch 2/20\n","139/139 [==============================] - 3s 19ms/step - loss: 0.4537 - accuracy: 0.7868 - f1_score: 0.7793 - val_loss: 0.4332 - val_accuracy: 0.7939 - val_f1_score: 0.8045\n","Epoch 3/20\n","139/139 [==============================] - 3s 20ms/step - loss: 0.3929 - accuracy: 0.8273 - f1_score: 0.8242 - val_loss: 0.3902 - val_accuracy: 0.8291 - val_f1_score: 0.8268\n","Epoch 4/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.3355 - accuracy: 0.8583 - f1_score: 0.8556 - val_loss: 0.3690 - val_accuracy: 0.8463 - val_f1_score: 0.8468\n","Epoch 5/20\n","139/139 [==============================] - 4s 27ms/step - loss: 0.2964 - accuracy: 0.8770 - f1_score: 0.8749 - val_loss: 0.3660 - val_accuracy: 0.8418 - val_f1_score: 0.8482\n","Epoch 6/20\n","139/139 [==============================] - 3s 19ms/step - loss: 0.2597 - accuracy: 0.8874 - f1_score: 0.8864 - val_loss: 0.3844 - val_accuracy: 0.8400 - val_f1_score: 0.8504\n","Epoch 7/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2356 - accuracy: 0.9057 - f1_score: 0.9051 - val_loss: 0.3534 - val_accuracy: 0.8553 - val_f1_score: 0.8582\n","Epoch 8/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2121 - accuracy: 0.9150 - f1_score: 0.9141 - val_loss: 0.3700 - val_accuracy: 0.8608 - val_f1_score: 0.8613\n","Epoch 9/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1948 - accuracy: 0.9234 - f1_score: 0.9229 - val_loss: 0.3857 - val_accuracy: 0.8635 - val_f1_score: 0.8646\n","Epoch 10/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1712 - accuracy: 0.9313 - f1_score: 0.9310 - val_loss: 0.4020 - val_accuracy: 0.8653 - val_f1_score: 0.8552\n","Epoch 11/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1531 - accuracy: 0.9394 - f1_score: 0.9387 - val_loss: 0.4217 - val_accuracy: 0.8535 - val_f1_score: 0.8599\n","Epoch 12/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1508 - accuracy: 0.9417 - f1_score: 0.9415 - val_loss: 0.4159 - val_accuracy: 0.8635 - val_f1_score: 0.8593\n","35/35 [==============================] - 0s 5ms/step - loss: 0.3534 - accuracy: 0.8553 - f1_score: 0.8582\n","Epoch 1/20\n","139/139 [==============================] - 6s 13ms/step - loss: 0.5839 - accuracy: 0.6946 - f1_score: 0.6850 - val_loss: 0.4786 - val_accuracy: 0.7649 - val_f1_score: 0.7500\n","Epoch 2/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.4556 - accuracy: 0.7887 - f1_score: 0.7824 - val_loss: 0.4214 - val_accuracy: 0.8065 - val_f1_score: 0.8076\n","Epoch 3/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.3825 - accuracy: 0.8305 - f1_score: 0.8267 - val_loss: 0.3595 - val_accuracy: 0.8463 - val_f1_score: 0.8443\n","Epoch 4/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.3302 - accuracy: 0.8590 - f1_score: 0.8569 - val_loss: 0.3604 - val_accuracy: 0.8490 - val_f1_score: 0.8305\n","Epoch 5/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2860 - accuracy: 0.8788 - f1_score: 0.8770 - val_loss: 0.3014 - val_accuracy: 0.8734 - val_f1_score: 0.8684\n","Epoch 6/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2498 - accuracy: 0.8960 - f1_score: 0.8947 - val_loss: 0.3007 - val_accuracy: 0.8770 - val_f1_score: 0.8707\n","Epoch 7/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2285 - accuracy: 0.9069 - f1_score: 0.9054 - val_loss: 0.3035 - val_accuracy: 0.8779 - val_f1_score: 0.8749\n","Epoch 8/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2137 - accuracy: 0.9161 - f1_score: 0.9156 - val_loss: 0.2926 - val_accuracy: 0.8852 - val_f1_score: 0.8805\n","Epoch 9/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1958 - accuracy: 0.9241 - f1_score: 0.9235 - val_loss: 0.3164 - val_accuracy: 0.8861 - val_f1_score: 0.8838\n","Epoch 10/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1736 - accuracy: 0.9329 - f1_score: 0.9326 - val_loss: 0.3095 - val_accuracy: 0.8834 - val_f1_score: 0.8798\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1610 - accuracy: 0.9401 - f1_score: 0.9398 - val_loss: 0.3320 - val_accuracy: 0.8788 - val_f1_score: 0.8806\n","Epoch 12/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.1478 - accuracy: 0.9406 - f1_score: 0.9405 - val_loss: 0.3666 - val_accuracy: 0.8807 - val_f1_score: 0.8800\n","Epoch 13/20\n","139/139 [==============================] - 4s 27ms/step - loss: 0.1308 - accuracy: 0.9471 - f1_score: 0.9469 - val_loss: 0.3467 - val_accuracy: 0.8834 - val_f1_score: 0.8851\n","35/35 [==============================] - 1s 11ms/step - loss: 0.2926 - accuracy: 0.8852 - f1_score: 0.8805\n","Epoch 1/20\n","139/139 [==============================] - 13s 43ms/step - loss: 0.5865 - accuracy: 0.6854 - f1_score: 0.6803 - val_loss: 0.4977 - val_accuracy: 0.7712 - val_f1_score: 0.7537\n","Epoch 2/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.4632 - accuracy: 0.7828 - f1_score: 0.7724 - val_loss: 0.4433 - val_accuracy: 0.7884 - val_f1_score: 0.7911\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4025 - accuracy: 0.8189 - f1_score: 0.8142 - val_loss: 0.4012 - val_accuracy: 0.8210 - val_f1_score: 0.8074\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3474 - accuracy: 0.8499 - f1_score: 0.8452 - val_loss: 0.3848 - val_accuracy: 0.8409 - val_f1_score: 0.8426\n","Epoch 5/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.3145 - accuracy: 0.8660 - f1_score: 0.8624 - val_loss: 0.3574 - val_accuracy: 0.8544 - val_f1_score: 0.8491\n","Epoch 6/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2812 - accuracy: 0.8773 - f1_score: 0.8754 - val_loss: 0.3474 - val_accuracy: 0.8671 - val_f1_score: 0.8640\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2417 - accuracy: 0.9039 - f1_score: 0.9021 - val_loss: 0.3526 - val_accuracy: 0.8544 - val_f1_score: 0.8444\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2152 - accuracy: 0.9130 - f1_score: 0.9117 - val_loss: 0.3460 - val_accuracy: 0.8707 - val_f1_score: 0.8647\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1848 - accuracy: 0.9297 - f1_score: 0.9291 - val_loss: 0.3961 - val_accuracy: 0.8716 - val_f1_score: 0.8637\n","Epoch 10/20\n","139/139 [==============================] - 3s 21ms/step - loss: 0.1770 - accuracy: 0.9283 - f1_score: 0.9275 - val_loss: 0.3656 - val_accuracy: 0.8734 - val_f1_score: 0.8708\n","Epoch 11/20\n","139/139 [==============================] - 4s 26ms/step - loss: 0.1554 - accuracy: 0.9399 - f1_score: 0.9391 - val_loss: 0.3848 - val_accuracy: 0.8599 - val_f1_score: 0.8577\n","Epoch 12/20\n","139/139 [==============================] - 3s 22ms/step - loss: 0.1502 - accuracy: 0.9430 - f1_score: 0.9426 - val_loss: 0.4157 - val_accuracy: 0.8617 - val_f1_score: 0.8628\n","Epoch 13/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1395 - accuracy: 0.9451 - f1_score: 0.9448 - val_loss: 0.4071 - val_accuracy: 0.8617 - val_f1_score: 0.8635\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8707 - f1_score: 0.8647\n","Epoch 1/20\n","139/139 [==============================] - 12s 37ms/step - loss: 0.5633 - accuracy: 0.7050 - f1_score: 0.6945 - val_loss: 0.4843 - val_accuracy: 0.7649 - val_f1_score: 0.7566\n","Epoch 2/20\n","139/139 [==============================] - 3s 20ms/step - loss: 0.4630 - accuracy: 0.7796 - f1_score: 0.7702 - val_loss: 0.4132 - val_accuracy: 0.8228 - val_f1_score: 0.8195\n","Epoch 3/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.3899 - accuracy: 0.8289 - f1_score: 0.8242 - val_loss: 0.3552 - val_accuracy: 0.8490 - val_f1_score: 0.8489\n","Epoch 4/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.3314 - accuracy: 0.8623 - f1_score: 0.8598 - val_loss: 0.3468 - val_accuracy: 0.8508 - val_f1_score: 0.8374\n","Epoch 5/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2798 - accuracy: 0.8822 - f1_score: 0.8798 - val_loss: 0.3042 - val_accuracy: 0.8734 - val_f1_score: 0.8734\n","Epoch 6/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2556 - accuracy: 0.8958 - f1_score: 0.8945 - val_loss: 0.3267 - val_accuracy: 0.8608 - val_f1_score: 0.8675\n","Epoch 7/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2260 - accuracy: 0.9107 - f1_score: 0.9095 - val_loss: 0.3206 - val_accuracy: 0.8788 - val_f1_score: 0.8812\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2124 - accuracy: 0.9177 - f1_score: 0.9167 - val_loss: 0.3384 - val_accuracy: 0.8662 - val_f1_score: 0.8690\n","Epoch 9/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.1903 - accuracy: 0.9236 - f1_score: 0.9230 - val_loss: 0.3674 - val_accuracy: 0.8590 - val_f1_score: 0.8458\n","Epoch 10/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1753 - accuracy: 0.9333 - f1_score: 0.9324 - val_loss: 0.3606 - val_accuracy: 0.8662 - val_f1_score: 0.8702\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8734 - f1_score: 0.8734\n","Epoch 1/20\n","139/139 [==============================] - 6s 21ms/step - loss: 0.5843 - accuracy: 0.6962 - f1_score: 0.6889 - val_loss: 0.4730 - val_accuracy: 0.7622 - val_f1_score: 0.7645\n","Epoch 2/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.4784 - accuracy: 0.7744 - f1_score: 0.7680 - val_loss: 0.4334 - val_accuracy: 0.7812 - val_f1_score: 0.7772\n","Epoch 3/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.4000 - accuracy: 0.8194 - f1_score: 0.8155 - val_loss: 0.3948 - val_accuracy: 0.8165 - val_f1_score: 0.8061\n","Epoch 4/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.3436 - accuracy: 0.8592 - f1_score: 0.8566 - val_loss: 0.3717 - val_accuracy: 0.8264 - val_f1_score: 0.8143\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2982 - accuracy: 0.8718 - f1_score: 0.8688 - val_loss: 0.3784 - val_accuracy: 0.8291 - val_f1_score: 0.8093\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2704 - accuracy: 0.8901 - f1_score: 0.8880 - val_loss: 0.3510 - val_accuracy: 0.8490 - val_f1_score: 0.8447\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2353 - accuracy: 0.9037 - f1_score: 0.9023 - val_loss: 0.3980 - val_accuracy: 0.8436 - val_f1_score: 0.8292\n","Epoch 8/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2183 - accuracy: 0.9193 - f1_score: 0.9179 - val_loss: 0.3641 - val_accuracy: 0.8599 - val_f1_score: 0.8558\n","Epoch 9/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1884 - accuracy: 0.9250 - f1_score: 0.9240 - val_loss: 0.3862 - val_accuracy: 0.8508 - val_f1_score: 0.8403\n","Epoch 10/20\n","139/139 [==============================] - 3s 20ms/step - loss: 0.1695 - accuracy: 0.9365 - f1_score: 0.9356 - val_loss: 0.3901 - val_accuracy: 0.8590 - val_f1_score: 0.8605\n","Epoch 11/20\n","139/139 [==============================] - 3s 18ms/step - loss: 0.1647 - accuracy: 0.9396 - f1_score: 0.9390 - val_loss: 0.3866 - val_accuracy: 0.8553 - val_f1_score: 0.8540\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8490 - f1_score: 0.8447\n","Epoch 1/20\n","139/139 [==============================] - 7s 19ms/step - loss: 0.5831 - accuracy: 0.6899 - f1_score: 0.6863 - val_loss: 0.4989 - val_accuracy: 0.7468 - val_f1_score: 0.7009\n","Epoch 2/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.4768 - accuracy: 0.7712 - f1_score: 0.7621 - val_loss: 0.4308 - val_accuracy: 0.8029 - val_f1_score: 0.7920\n","Epoch 3/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4107 - accuracy: 0.8203 - f1_score: 0.8150 - val_loss: 0.4012 - val_accuracy: 0.8192 - val_f1_score: 0.8152\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3457 - accuracy: 0.8526 - f1_score: 0.8496 - val_loss: 0.3787 - val_accuracy: 0.8327 - val_f1_score: 0.8240\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3047 - accuracy: 0.8757 - f1_score: 0.8734 - val_loss: 0.3947 - val_accuracy: 0.8237 - val_f1_score: 0.8363\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2739 - accuracy: 0.8861 - f1_score: 0.8842 - val_loss: 0.3652 - val_accuracy: 0.8472 - val_f1_score: 0.8448\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2461 - accuracy: 0.8983 - f1_score: 0.8977 - val_loss: 0.3670 - val_accuracy: 0.8508 - val_f1_score: 0.8515\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2216 - accuracy: 0.9127 - f1_score: 0.9117 - val_loss: 0.3582 - val_accuracy: 0.8571 - val_f1_score: 0.8518\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1954 - accuracy: 0.9256 - f1_score: 0.9249 - val_loss: 0.3741 - val_accuracy: 0.8635 - val_f1_score: 0.8606\n","Epoch 10/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1932 - accuracy: 0.9229 - f1_score: 0.9224 - val_loss: 0.3765 - val_accuracy: 0.8580 - val_f1_score: 0.8471\n","Epoch 11/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1628 - accuracy: 0.9351 - f1_score: 0.9344 - val_loss: 0.3958 - val_accuracy: 0.8635 - val_f1_score: 0.8633\n","Epoch 12/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1522 - accuracy: 0.9419 - f1_score: 0.9410 - val_loss: 0.3974 - val_accuracy: 0.8680 - val_f1_score: 0.8661\n","Epoch 13/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1379 - accuracy: 0.9464 - f1_score: 0.9461 - val_loss: 0.4403 - val_accuracy: 0.8571 - val_f1_score: 0.8584\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8571 - f1_score: 0.8518\n","Epoch 1/20\n","139/139 [==============================] - 8s 20ms/step - loss: 0.5704 - accuracy: 0.7057 - f1_score: 0.7096 - val_loss: 0.4564 - val_accuracy: 0.7929 - val_f1_score: 0.7838\n","Epoch 2/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.4569 - accuracy: 0.7866 - f1_score: 0.7820 - val_loss: 0.4019 - val_accuracy: 0.8309 - val_f1_score: 0.8132\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3751 - accuracy: 0.8309 - f1_score: 0.8288 - val_loss: 0.3666 - val_accuracy: 0.8354 - val_f1_score: 0.8412\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3192 - accuracy: 0.8687 - f1_score: 0.8662 - val_loss: 0.3310 - val_accuracy: 0.8707 - val_f1_score: 0.8616\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2937 - accuracy: 0.8791 - f1_score: 0.8771 - val_loss: 0.3198 - val_accuracy: 0.8680 - val_f1_score: 0.8670\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2542 - accuracy: 0.9001 - f1_score: 0.8982 - val_loss: 0.3156 - val_accuracy: 0.8644 - val_f1_score: 0.8601\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2323 - accuracy: 0.9073 - f1_score: 0.9066 - val_loss: 0.3196 - val_accuracy: 0.8671 - val_f1_score: 0.8612\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2163 - accuracy: 0.9157 - f1_score: 0.9145 - val_loss: 0.3178 - val_accuracy: 0.8716 - val_f1_score: 0.8707\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1889 - accuracy: 0.9274 - f1_score: 0.9272 - val_loss: 0.3339 - val_accuracy: 0.8671 - val_f1_score: 0.8645\n","Epoch 10/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1686 - accuracy: 0.9335 - f1_score: 0.9328 - val_loss: 0.3282 - val_accuracy: 0.8779 - val_f1_score: 0.8776\n","Epoch 11/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1729 - accuracy: 0.9374 - f1_score: 0.9370 - val_loss: 0.3366 - val_accuracy: 0.8653 - val_f1_score: 0.8666\n","35/35 [==============================] - 0s 7ms/step - loss: 0.3156 - accuracy: 0.8644 - f1_score: 0.8601\n","Epoch 1/20\n","139/139 [==============================] - 7s 19ms/step - loss: 0.5987 - accuracy: 0.6829 - f1_score: 0.6780 - val_loss: 0.4909 - val_accuracy: 0.7685 - val_f1_score: 0.7475\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4680 - accuracy: 0.7866 - f1_score: 0.7789 - val_loss: 0.4304 - val_accuracy: 0.8020 - val_f1_score: 0.8091\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3943 - accuracy: 0.8296 - f1_score: 0.8260 - val_loss: 0.3863 - val_accuracy: 0.8391 - val_f1_score: 0.8373\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3321 - accuracy: 0.8553 - f1_score: 0.8525 - val_loss: 0.3744 - val_accuracy: 0.8517 - val_f1_score: 0.8479\n","Epoch 5/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2783 - accuracy: 0.8843 - f1_score: 0.8829 - val_loss: 0.3710 - val_accuracy: 0.8553 - val_f1_score: 0.8441\n","Epoch 6/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.2500 - accuracy: 0.8976 - f1_score: 0.8966 - val_loss: 0.3825 - val_accuracy: 0.8608 - val_f1_score: 0.8505\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2277 - accuracy: 0.9073 - f1_score: 0.9063 - val_loss: 0.3569 - val_accuracy: 0.8608 - val_f1_score: 0.8585\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2099 - accuracy: 0.9157 - f1_score: 0.9153 - val_loss: 0.3465 - val_accuracy: 0.8608 - val_f1_score: 0.8637\n","Epoch 9/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1847 - accuracy: 0.9290 - f1_score: 0.9285 - val_loss: 0.3404 - val_accuracy: 0.8725 - val_f1_score: 0.8669\n","Epoch 10/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1762 - accuracy: 0.9290 - f1_score: 0.9286 - val_loss: 0.3486 - val_accuracy: 0.8689 - val_f1_score: 0.8661\n","Epoch 11/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1514 - accuracy: 0.9428 - f1_score: 0.9428 - val_loss: 0.3969 - val_accuracy: 0.8662 - val_f1_score: 0.8590\n","Epoch 12/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1399 - accuracy: 0.9469 - f1_score: 0.9468 - val_loss: 0.3911 - val_accuracy: 0.8653 - val_f1_score: 0.8671\n","Epoch 13/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1422 - accuracy: 0.9437 - f1_score: 0.9435 - val_loss: 0.3765 - val_accuracy: 0.8779 - val_f1_score: 0.8769\n","Epoch 14/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1133 - accuracy: 0.9561 - f1_score: 0.9560 - val_loss: 0.4276 - val_accuracy: 0.8580 - val_f1_score: 0.8626\n","35/35 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8725 - f1_score: 0.8669\n","Epoch 1/20\n","139/139 [==============================] - 6s 14ms/step - loss: 0.5786 - accuracy: 0.6892 - f1_score: 0.6854 - val_loss: 0.4775 - val_accuracy: 0.7712 - val_f1_score: 0.7507\n","Epoch 2/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.4633 - accuracy: 0.7853 - f1_score: 0.7787 - val_loss: 0.4331 - val_accuracy: 0.8056 - val_f1_score: 0.7822\n","Epoch 3/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3867 - accuracy: 0.8262 - f1_score: 0.8219 - val_loss: 0.3882 - val_accuracy: 0.8273 - val_f1_score: 0.8352\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3334 - accuracy: 0.8614 - f1_score: 0.8586 - val_loss: 0.3415 - val_accuracy: 0.8454 - val_f1_score: 0.8455\n","Epoch 5/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2800 - accuracy: 0.8852 - f1_score: 0.8834 - val_loss: 0.3305 - val_accuracy: 0.8662 - val_f1_score: 0.8657\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2500 - accuracy: 0.8969 - f1_score: 0.8960 - val_loss: 0.3406 - val_accuracy: 0.8707 - val_f1_score: 0.8694\n","Epoch 7/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2250 - accuracy: 0.9105 - f1_score: 0.9093 - val_loss: 0.3443 - val_accuracy: 0.8752 - val_f1_score: 0.8717\n","Epoch 8/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2039 - accuracy: 0.9179 - f1_score: 0.9176 - val_loss: 0.3311 - val_accuracy: 0.8716 - val_f1_score: 0.8714\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1849 - accuracy: 0.9299 - f1_score: 0.9293 - val_loss: 0.3601 - val_accuracy: 0.8626 - val_f1_score: 0.8598\n","Epoch 10/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1648 - accuracy: 0.9338 - f1_score: 0.9331 - val_loss: 0.3923 - val_accuracy: 0.8662 - val_f1_score: 0.8645\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8662 - f1_score: 0.8657\n","Epoch 1/20\n","139/139 [==============================] - 5s 14ms/step - loss: 0.5836 - accuracy: 0.6899 - f1_score: 0.6845 - val_loss: 0.4860 - val_accuracy: 0.7794 - val_f1_score: 0.7636\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4762 - accuracy: 0.7744 - f1_score: 0.7666 - val_loss: 0.4259 - val_accuracy: 0.8092 - val_f1_score: 0.8080\n","Epoch 3/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.4017 - accuracy: 0.8210 - f1_score: 0.8189 - val_loss: 0.3685 - val_accuracy: 0.8400 - val_f1_score: 0.8316\n","Epoch 4/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.3355 - accuracy: 0.8596 - f1_score: 0.8559 - val_loss: 0.3430 - val_accuracy: 0.8472 - val_f1_score: 0.8425\n","Epoch 5/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3024 - accuracy: 0.8764 - f1_score: 0.8743 - val_loss: 0.3519 - val_accuracy: 0.8499 - val_f1_score: 0.8579\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2658 - accuracy: 0.8886 - f1_score: 0.8868 - val_loss: 0.3249 - val_accuracy: 0.8725 - val_f1_score: 0.8729\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2347 - accuracy: 0.9100 - f1_score: 0.9086 - val_loss: 0.3282 - val_accuracy: 0.8671 - val_f1_score: 0.8650\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2142 - accuracy: 0.9155 - f1_score: 0.9145 - val_loss: 0.3340 - val_accuracy: 0.8707 - val_f1_score: 0.8689\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1864 - accuracy: 0.9268 - f1_score: 0.9260 - val_loss: 0.3421 - val_accuracy: 0.8725 - val_f1_score: 0.8698\n","Epoch 10/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1781 - accuracy: 0.9349 - f1_score: 0.9341 - val_loss: 0.3705 - val_accuracy: 0.8599 - val_f1_score: 0.8644\n","Epoch 11/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1563 - accuracy: 0.9442 - f1_score: 0.9435 - val_loss: 0.3883 - val_accuracy: 0.8716 - val_f1_score: 0.8616\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3249 - accuracy: 0.8725 - f1_score: 0.8729\n","Epoch 1/20\n","139/139 [==============================] - 6s 14ms/step - loss: 0.5763 - accuracy: 0.6960 - f1_score: 0.6896 - val_loss: 0.4865 - val_accuracy: 0.7685 - val_f1_score: 0.7548\n","Epoch 2/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.4565 - accuracy: 0.7821 - f1_score: 0.7738 - val_loss: 0.4178 - val_accuracy: 0.8047 - val_f1_score: 0.7907\n","Epoch 3/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3912 - accuracy: 0.8262 - f1_score: 0.8202 - val_loss: 0.3745 - val_accuracy: 0.8300 - val_f1_score: 0.8282\n","Epoch 4/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3297 - accuracy: 0.8592 - f1_score: 0.8555 - val_loss: 0.3699 - val_accuracy: 0.8409 - val_f1_score: 0.8453\n","Epoch 5/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2908 - accuracy: 0.8793 - f1_score: 0.8774 - val_loss: 0.3736 - val_accuracy: 0.8472 - val_f1_score: 0.8554\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2495 - accuracy: 0.9003 - f1_score: 0.8995 - val_loss: 0.3531 - val_accuracy: 0.8409 - val_f1_score: 0.8414\n","Epoch 7/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2266 - accuracy: 0.9089 - f1_score: 0.9081 - val_loss: 0.3463 - val_accuracy: 0.8599 - val_f1_score: 0.8579\n","Epoch 8/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1969 - accuracy: 0.9207 - f1_score: 0.9202 - val_loss: 0.3703 - val_accuracy: 0.8499 - val_f1_score: 0.8559\n","Epoch 9/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1856 - accuracy: 0.9252 - f1_score: 0.9247 - val_loss: 0.4153 - val_accuracy: 0.8427 - val_f1_score: 0.8510\n","Epoch 10/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.1697 - accuracy: 0.9354 - f1_score: 0.9354 - val_loss: 0.3812 - val_accuracy: 0.8535 - val_f1_score: 0.8424\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1621 - accuracy: 0.9358 - f1_score: 0.9352 - val_loss: 0.3874 - val_accuracy: 0.8499 - val_f1_score: 0.8523\n","Epoch 12/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1444 - accuracy: 0.9444 - f1_score: 0.9441 - val_loss: 0.3907 - val_accuracy: 0.8490 - val_f1_score: 0.8513\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8599 - f1_score: 0.8579\n","Epoch 1/20\n","139/139 [==============================] - 5s 14ms/step - loss: 0.5773 - accuracy: 0.6960 - f1_score: 0.6824 - val_loss: 0.4534 - val_accuracy: 0.7920 - val_f1_score: 0.7858\n","Epoch 2/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.4645 - accuracy: 0.7801 - f1_score: 0.7716 - val_loss: 0.3837 - val_accuracy: 0.8336 - val_f1_score: 0.8324\n","Epoch 3/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.4072 - accuracy: 0.8153 - f1_score: 0.8103 - val_loss: 0.3535 - val_accuracy: 0.8490 - val_f1_score: 0.8472\n","Epoch 4/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.3571 - accuracy: 0.8465 - f1_score: 0.8433 - val_loss: 0.3221 - val_accuracy: 0.8617 - val_f1_score: 0.8620\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3125 - accuracy: 0.8675 - f1_score: 0.8654 - val_loss: 0.3359 - val_accuracy: 0.8553 - val_f1_score: 0.8419\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2800 - accuracy: 0.8804 - f1_score: 0.8790 - val_loss: 0.2950 - val_accuracy: 0.8797 - val_f1_score: 0.8809\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2477 - accuracy: 0.8990 - f1_score: 0.8976 - val_loss: 0.2866 - val_accuracy: 0.8915 - val_f1_score: 0.8870\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2275 - accuracy: 0.9080 - f1_score: 0.9070 - val_loss: 0.3253 - val_accuracy: 0.8734 - val_f1_score: 0.8619\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1981 - accuracy: 0.9202 - f1_score: 0.9198 - val_loss: 0.2949 - val_accuracy: 0.8951 - val_f1_score: 0.8906\n","Epoch 10/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1805 - accuracy: 0.9288 - f1_score: 0.9280 - val_loss: 0.3201 - val_accuracy: 0.8779 - val_f1_score: 0.8780\n","Epoch 11/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1660 - accuracy: 0.9381 - f1_score: 0.9375 - val_loss: 0.3216 - val_accuracy: 0.8825 - val_f1_score: 0.8785\n","Epoch 12/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1574 - accuracy: 0.9387 - f1_score: 0.9383 - val_loss: 0.3992 - val_accuracy: 0.8445 - val_f1_score: 0.8552\n","35/35 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.8915 - f1_score: 0.8870\n","Epoch 1/20\n","139/139 [==============================] - 6s 14ms/step - loss: 0.5719 - accuracy: 0.7050 - f1_score: 0.7005 - val_loss: 0.4811 - val_accuracy: 0.7694 - val_f1_score: 0.7597\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4561 - accuracy: 0.7916 - f1_score: 0.7850 - val_loss: 0.4352 - val_accuracy: 0.8002 - val_f1_score: 0.7805\n","Epoch 3/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4014 - accuracy: 0.8198 - f1_score: 0.8157 - val_loss: 0.3990 - val_accuracy: 0.8318 - val_f1_score: 0.8357\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3492 - accuracy: 0.8454 - f1_score: 0.8409 - val_loss: 0.3675 - val_accuracy: 0.8391 - val_f1_score: 0.8385\n","Epoch 5/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8653 - f1_score: 0.8629 - val_loss: 0.3669 - val_accuracy: 0.8400 - val_f1_score: 0.8249\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2732 - accuracy: 0.8825 - f1_score: 0.8802 - val_loss: 0.3620 - val_accuracy: 0.8499 - val_f1_score: 0.8320\n","Epoch 7/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2505 - accuracy: 0.8962 - f1_score: 0.8936 - val_loss: 0.3450 - val_accuracy: 0.8716 - val_f1_score: 0.8728\n","Epoch 8/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2162 - accuracy: 0.9089 - f1_score: 0.9076 - val_loss: 0.3370 - val_accuracy: 0.8752 - val_f1_score: 0.8713\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2006 - accuracy: 0.9198 - f1_score: 0.9187 - val_loss: 0.3726 - val_accuracy: 0.8662 - val_f1_score: 0.8650\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1895 - accuracy: 0.9297 - f1_score: 0.9289 - val_loss: 0.3730 - val_accuracy: 0.8725 - val_f1_score: 0.8703\n","Epoch 11/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1771 - accuracy: 0.9259 - f1_score: 0.9253 - val_loss: 0.3584 - val_accuracy: 0.8779 - val_f1_score: 0.8751\n","Epoch 12/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1642 - accuracy: 0.9392 - f1_score: 0.9388 - val_loss: 0.3761 - val_accuracy: 0.8653 - val_f1_score: 0.8639\n","Epoch 13/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1493 - accuracy: 0.9415 - f1_score: 0.9407 - val_loss: 0.4020 - val_accuracy: 0.8680 - val_f1_score: 0.8715\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8752 - f1_score: 0.8713\n","Epoch 1/20\n","139/139 [==============================] - 8s 16ms/step - loss: 0.5854 - accuracy: 0.6926 - f1_score: 0.6863 - val_loss: 0.5040 - val_accuracy: 0.7622 - val_f1_score: 0.7286\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4620 - accuracy: 0.7780 - f1_score: 0.7694 - val_loss: 0.4181 - val_accuracy: 0.8137 - val_f1_score: 0.8141\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3810 - accuracy: 0.8300 - f1_score: 0.8260 - val_loss: 0.4096 - val_accuracy: 0.8255 - val_f1_score: 0.8095\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3249 - accuracy: 0.8599 - f1_score: 0.8571 - val_loss: 0.3481 - val_accuracy: 0.8562 - val_f1_score: 0.8521\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2848 - accuracy: 0.8793 - f1_score: 0.8771 - val_loss: 0.3307 - val_accuracy: 0.8698 - val_f1_score: 0.8672\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2583 - accuracy: 0.8901 - f1_score: 0.8889 - val_loss: 0.3302 - val_accuracy: 0.8734 - val_f1_score: 0.8741\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2306 - accuracy: 0.9069 - f1_score: 0.9050 - val_loss: 0.4113 - val_accuracy: 0.8400 - val_f1_score: 0.8538\n","Epoch 8/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2199 - accuracy: 0.9134 - f1_score: 0.9125 - val_loss: 0.3350 - val_accuracy: 0.8662 - val_f1_score: 0.8604\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1959 - accuracy: 0.9234 - f1_score: 0.9227 - val_loss: 0.3563 - val_accuracy: 0.8698 - val_f1_score: 0.8649\n","Epoch 10/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1769 - accuracy: 0.9311 - f1_score: 0.9302 - val_loss: 0.3761 - val_accuracy: 0.8680 - val_f1_score: 0.8703\n","Epoch 11/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1684 - accuracy: 0.9369 - f1_score: 0.9364 - val_loss: 0.3975 - val_accuracy: 0.8698 - val_f1_score: 0.8689\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8734 - f1_score: 0.8741\n","Epoch 1/20\n","139/139 [==============================] - 6s 19ms/step - loss: 0.5933 - accuracy: 0.6763 - f1_score: 0.6660 - val_loss: 0.4737 - val_accuracy: 0.7712 - val_f1_score: 0.7672\n","Epoch 2/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.4721 - accuracy: 0.7742 - f1_score: 0.7652 - val_loss: 0.4205 - val_accuracy: 0.8201 - val_f1_score: 0.8186\n","Epoch 3/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.4048 - accuracy: 0.8167 - f1_score: 0.8123 - val_loss: 0.3893 - val_accuracy: 0.8318 - val_f1_score: 0.8242\n","Epoch 4/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3455 - accuracy: 0.8476 - f1_score: 0.8453 - val_loss: 0.3742 - val_accuracy: 0.8463 - val_f1_score: 0.8365\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3016 - accuracy: 0.8716 - f1_score: 0.8686 - val_loss: 0.3893 - val_accuracy: 0.8409 - val_f1_score: 0.8236\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2550 - accuracy: 0.8972 - f1_score: 0.8952 - val_loss: 0.3918 - val_accuracy: 0.8490 - val_f1_score: 0.8405\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2430 - accuracy: 0.8992 - f1_score: 0.8972 - val_loss: 0.3891 - val_accuracy: 0.8391 - val_f1_score: 0.8458\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2093 - accuracy: 0.9191 - f1_score: 0.9178 - val_loss: 0.4337 - val_accuracy: 0.8454 - val_f1_score: 0.8527\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1972 - accuracy: 0.9207 - f1_score: 0.9201 - val_loss: 0.3929 - val_accuracy: 0.8562 - val_f1_score: 0.8518\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8463 - f1_score: 0.8365\n","Epoch 1/20\n","139/139 [==============================] - 6s 15ms/step - loss: 0.5849 - accuracy: 0.6917 - f1_score: 0.6791 - val_loss: 0.4924 - val_accuracy: 0.7505 - val_f1_score: 0.7361\n","Epoch 2/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.4683 - accuracy: 0.7862 - f1_score: 0.7806 - val_loss: 0.4339 - val_accuracy: 0.7866 - val_f1_score: 0.7843\n","Epoch 3/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.3953 - accuracy: 0.8271 - f1_score: 0.8235 - val_loss: 0.3968 - val_accuracy: 0.8246 - val_f1_score: 0.8339\n","Epoch 4/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.3352 - accuracy: 0.8553 - f1_score: 0.8521 - val_loss: 0.3540 - val_accuracy: 0.8427 - val_f1_score: 0.8418\n","Epoch 5/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.2967 - accuracy: 0.8757 - f1_score: 0.8736 - val_loss: 0.3399 - val_accuracy: 0.8553 - val_f1_score: 0.8587\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2683 - accuracy: 0.8886 - f1_score: 0.8865 - val_loss: 0.3301 - val_accuracy: 0.8526 - val_f1_score: 0.8431\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2342 - accuracy: 0.9026 - f1_score: 0.9014 - val_loss: 0.3403 - val_accuracy: 0.8499 - val_f1_score: 0.8593\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2215 - accuracy: 0.9080 - f1_score: 0.9069 - val_loss: 0.3067 - val_accuracy: 0.8752 - val_f1_score: 0.8710\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1984 - accuracy: 0.9200 - f1_score: 0.9191 - val_loss: 0.3210 - val_accuracy: 0.8779 - val_f1_score: 0.8804\n","Epoch 10/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1812 - accuracy: 0.9274 - f1_score: 0.9266 - val_loss: 0.3588 - val_accuracy: 0.8680 - val_f1_score: 0.8735\n","Epoch 11/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1688 - accuracy: 0.9315 - f1_score: 0.9309 - val_loss: 0.3419 - val_accuracy: 0.8770 - val_f1_score: 0.8745\n","Epoch 12/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1517 - accuracy: 0.9417 - f1_score: 0.9414 - val_loss: 0.3511 - val_accuracy: 0.8662 - val_f1_score: 0.8697\n","Epoch 13/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1345 - accuracy: 0.9469 - f1_score: 0.9465 - val_loss: 0.3789 - val_accuracy: 0.8770 - val_f1_score: 0.8781\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8752 - f1_score: 0.8710\n","Epoch 1/20\n","139/139 [==============================] - 6s 15ms/step - loss: 0.5662 - accuracy: 0.7039 - f1_score: 0.6956 - val_loss: 0.4784 - val_accuracy: 0.7622 - val_f1_score: 0.7567\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4629 - accuracy: 0.7803 - f1_score: 0.7741 - val_loss: 0.4360 - val_accuracy: 0.7939 - val_f1_score: 0.7720\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3887 - accuracy: 0.8262 - f1_score: 0.8210 - val_loss: 0.3794 - val_accuracy: 0.8146 - val_f1_score: 0.8111\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3422 - accuracy: 0.8481 - f1_score: 0.8454 - val_loss: 0.3584 - val_accuracy: 0.8436 - val_f1_score: 0.8312\n","Epoch 5/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2920 - accuracy: 0.8764 - f1_score: 0.8746 - val_loss: 0.3460 - val_accuracy: 0.8409 - val_f1_score: 0.8367\n","Epoch 6/20\n","139/139 [==============================] - 3s 21ms/step - loss: 0.2526 - accuracy: 0.8958 - f1_score: 0.8938 - val_loss: 0.3385 - val_accuracy: 0.8526 - val_f1_score: 0.8543\n","Epoch 7/20\n","139/139 [==============================] - 4s 28ms/step - loss: 0.2347 - accuracy: 0.9096 - f1_score: 0.9088 - val_loss: 0.3202 - val_accuracy: 0.8617 - val_f1_score: 0.8582\n","Epoch 8/20\n","139/139 [==============================] - 3s 19ms/step - loss: 0.2028 - accuracy: 0.9207 - f1_score: 0.9201 - val_loss: 0.3269 - val_accuracy: 0.8635 - val_f1_score: 0.8585\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1903 - accuracy: 0.9281 - f1_score: 0.9277 - val_loss: 0.3438 - val_accuracy: 0.8698 - val_f1_score: 0.8629\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1669 - accuracy: 0.9360 - f1_score: 0.9355 - val_loss: 0.3798 - val_accuracy: 0.8526 - val_f1_score: 0.8407\n","Epoch 11/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1603 - accuracy: 0.9376 - f1_score: 0.9371 - val_loss: 0.3581 - val_accuracy: 0.8626 - val_f1_score: 0.8613\n","Epoch 12/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1493 - accuracy: 0.9462 - f1_score: 0.9459 - val_loss: 0.3697 - val_accuracy: 0.8653 - val_f1_score: 0.8676\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8617 - f1_score: 0.8582\n","Epoch 1/20\n","139/139 [==============================] - 6s 15ms/step - loss: 0.5771 - accuracy: 0.6980 - f1_score: 0.6894 - val_loss: 0.4936 - val_accuracy: 0.7640 - val_f1_score: 0.7507\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4537 - accuracy: 0.7823 - f1_score: 0.7723 - val_loss: 0.4307 - val_accuracy: 0.8092 - val_f1_score: 0.8008\n","Epoch 3/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.3830 - accuracy: 0.8330 - f1_score: 0.8287 - val_loss: 0.3775 - val_accuracy: 0.8445 - val_f1_score: 0.8431\n","Epoch 4/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.3312 - accuracy: 0.8590 - f1_score: 0.8565 - val_loss: 0.3697 - val_accuracy: 0.8400 - val_f1_score: 0.8332\n","Epoch 5/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2956 - accuracy: 0.8764 - f1_score: 0.8741 - val_loss: 0.3622 - val_accuracy: 0.8454 - val_f1_score: 0.8475\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2658 - accuracy: 0.8933 - f1_score: 0.8914 - val_loss: 0.3467 - val_accuracy: 0.8580 - val_f1_score: 0.8604\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2299 - accuracy: 0.9094 - f1_score: 0.9080 - val_loss: 0.3339 - val_accuracy: 0.8725 - val_f1_score: 0.8693\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2158 - accuracy: 0.9123 - f1_score: 0.9116 - val_loss: 0.3614 - val_accuracy: 0.8599 - val_f1_score: 0.8587\n","Epoch 9/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1883 - accuracy: 0.9283 - f1_score: 0.9278 - val_loss: 0.3528 - val_accuracy: 0.8653 - val_f1_score: 0.8624\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1695 - accuracy: 0.9302 - f1_score: 0.9295 - val_loss: 0.3666 - val_accuracy: 0.8707 - val_f1_score: 0.8684\n","Epoch 11/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1535 - accuracy: 0.9401 - f1_score: 0.9396 - val_loss: 0.4273 - val_accuracy: 0.8571 - val_f1_score: 0.8469\n","Epoch 12/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1519 - accuracy: 0.9390 - f1_score: 0.9384 - val_loss: 0.4026 - val_accuracy: 0.8626 - val_f1_score: 0.8590\n","35/35 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8725 - f1_score: 0.8693\n","Epoch 1/20\n","139/139 [==============================] - 6s 15ms/step - loss: 0.5818 - accuracy: 0.7014 - f1_score: 0.6992 - val_loss: 0.4961 - val_accuracy: 0.7505 - val_f1_score: 0.7500\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4659 - accuracy: 0.7844 - f1_score: 0.7798 - val_loss: 0.4308 - val_accuracy: 0.8156 - val_f1_score: 0.8142\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3977 - accuracy: 0.8280 - f1_score: 0.8238 - val_loss: 0.3785 - val_accuracy: 0.8373 - val_f1_score: 0.8387\n","Epoch 4/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3292 - accuracy: 0.8614 - f1_score: 0.8592 - val_loss: 0.3498 - val_accuracy: 0.8517 - val_f1_score: 0.8536\n","Epoch 5/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2874 - accuracy: 0.8831 - f1_score: 0.8818 - val_loss: 0.3573 - val_accuracy: 0.8481 - val_f1_score: 0.8521\n","Epoch 6/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2698 - accuracy: 0.8856 - f1_score: 0.8846 - val_loss: 0.3507 - val_accuracy: 0.8544 - val_f1_score: 0.8548\n","Epoch 7/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2309 - accuracy: 0.9096 - f1_score: 0.9084 - val_loss: 0.3882 - val_accuracy: 0.8336 - val_f1_score: 0.8459\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2120 - accuracy: 0.9175 - f1_score: 0.9166 - val_loss: 0.3435 - val_accuracy: 0.8635 - val_f1_score: 0.8641\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1863 - accuracy: 0.9243 - f1_score: 0.9236 - val_loss: 0.3651 - val_accuracy: 0.8590 - val_f1_score: 0.8615\n","Epoch 10/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1649 - accuracy: 0.9381 - f1_score: 0.9376 - val_loss: 0.3882 - val_accuracy: 0.8580 - val_f1_score: 0.8574\n","Epoch 11/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.1682 - accuracy: 0.9367 - f1_score: 0.9362 - val_loss: 0.3898 - val_accuracy: 0.8617 - val_f1_score: 0.8598\n","Epoch 12/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9473 - f1_score: 0.9471 - val_loss: 0.4201 - val_accuracy: 0.8562 - val_f1_score: 0.8526\n","Epoch 13/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9394 - f1_score: 0.9393 - val_loss: 0.4315 - val_accuracy: 0.8472 - val_f1_score: 0.8495\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8635 - f1_score: 0.8641\n","Epoch 1/20\n","139/139 [==============================] - 7s 20ms/step - loss: 0.5766 - accuracy: 0.6908 - f1_score: 0.6867 - val_loss: 0.4695 - val_accuracy: 0.7966 - val_f1_score: 0.7863\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4575 - accuracy: 0.7916 - f1_score: 0.7865 - val_loss: 0.4341 - val_accuracy: 0.7966 - val_f1_score: 0.7649\n","Epoch 3/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.3856 - accuracy: 0.8257 - f1_score: 0.8204 - val_loss: 0.3674 - val_accuracy: 0.8445 - val_f1_score: 0.8478\n","Epoch 4/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3193 - accuracy: 0.8678 - f1_score: 0.8649 - val_loss: 0.3490 - val_accuracy: 0.8535 - val_f1_score: 0.8445\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2931 - accuracy: 0.8825 - f1_score: 0.8801 - val_loss: 0.3441 - val_accuracy: 0.8662 - val_f1_score: 0.8650\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2590 - accuracy: 0.8965 - f1_score: 0.8945 - val_loss: 0.3706 - val_accuracy: 0.8553 - val_f1_score: 0.8513\n","Epoch 7/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2284 - accuracy: 0.9098 - f1_score: 0.9084 - val_loss: 0.3732 - val_accuracy: 0.8599 - val_f1_score: 0.8561\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2067 - accuracy: 0.9198 - f1_score: 0.9186 - val_loss: 0.3939 - val_accuracy: 0.8635 - val_f1_score: 0.8574\n","Epoch 9/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1900 - accuracy: 0.9304 - f1_score: 0.9292 - val_loss: 0.3787 - val_accuracy: 0.8608 - val_f1_score: 0.8585\n","Epoch 10/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1734 - accuracy: 0.9344 - f1_score: 0.9337 - val_loss: 0.3954 - val_accuracy: 0.8617 - val_f1_score: 0.8613\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8662 - f1_score: 0.8650\n","Epoch 1/20\n","139/139 [==============================] - 11s 21ms/step - loss: 0.5698 - accuracy: 0.7125 - f1_score: 0.7024 - val_loss: 0.4912 - val_accuracy: 0.7595 - val_f1_score: 0.7382\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4551 - accuracy: 0.7893 - f1_score: 0.7822 - val_loss: 0.4429 - val_accuracy: 0.7803 - val_f1_score: 0.7503\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3892 - accuracy: 0.8291 - f1_score: 0.8247 - val_loss: 0.3989 - val_accuracy: 0.8119 - val_f1_score: 0.8201\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3406 - accuracy: 0.8533 - f1_score: 0.8514 - val_loss: 0.3539 - val_accuracy: 0.8481 - val_f1_score: 0.8464\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2945 - accuracy: 0.8779 - f1_score: 0.8750 - val_loss: 0.3581 - val_accuracy: 0.8363 - val_f1_score: 0.8234\n","Epoch 6/20\n","139/139 [==============================] - 1s 8ms/step - loss: 0.2635 - accuracy: 0.8929 - f1_score: 0.8916 - val_loss: 0.3538 - val_accuracy: 0.8391 - val_f1_score: 0.8479\n","Epoch 7/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2354 - accuracy: 0.9005 - f1_score: 0.8997 - val_loss: 0.3217 - val_accuracy: 0.8626 - val_f1_score: 0.8555\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9109 - f1_score: 0.9100 - val_loss: 0.3241 - val_accuracy: 0.8653 - val_f1_score: 0.8659\n","Epoch 9/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1993 - accuracy: 0.9227 - f1_score: 0.9220 - val_loss: 0.3348 - val_accuracy: 0.8653 - val_f1_score: 0.8696\n","Epoch 10/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1871 - accuracy: 0.9265 - f1_score: 0.9262 - val_loss: 0.3876 - val_accuracy: 0.8526 - val_f1_score: 0.8608\n","Epoch 11/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.1673 - accuracy: 0.9349 - f1_score: 0.9345 - val_loss: 0.4282 - val_accuracy: 0.8472 - val_f1_score: 0.8332\n","Epoch 12/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1573 - accuracy: 0.9403 - f1_score: 0.9401 - val_loss: 0.4049 - val_accuracy: 0.8508 - val_f1_score: 0.8576\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8626 - f1_score: 0.8555\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojraqXmTIYke","executionInfo":{"status":"ok","timestamp":1689754367763,"user_tz":-330,"elapsed":13,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"55e68120-35fa-4f57-aa7a-b3614d86dcd5"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8806509971618652, 0.8571428656578064, 0.8517178893089294, 0.8698011040687561, 0.8698011040687561, 0.865280270576477, 0.8553345203399658, 0.8851717710494995, 0.870705246925354, 0.8734177350997925, 0.849005401134491, 0.8571428656578064, 0.8643761277198792, 0.8725135326385498, 0.8661844730377197, 0.8725135326385498, 0.8598553538322449, 0.8915008902549744, 0.8752260208129883, 0.8734177350997925, 0.8462929725646973, 0.8752260208129883, 0.8616636395454407, 0.8725135326385498, 0.8634719848632812, 0.8661844730377197, 0.8625677824020386]\n","0.8669881423314413\n","0.010353933297072534\n"]}]},{"cell_type":"code","source":["len(accuracies)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvsgOuzJjq0F","executionInfo":{"status":"ok","timestamp":1689760219507,"user_tz":-330,"elapsed":352,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e862e0c3-f08f-4146-9857-17e7ad7adb66"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMxaOdIoLZp5","executionInfo":{"status":"ok","timestamp":1689754367764,"user_tz":-330,"elapsed":12,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d7e4bcb9-4fd4-4619-e548-972258d96bfe"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.4431076943874359, 0.5631454586982727, 0.3621104955673218, 0.32045671343803406, 0.3357580900192261, 0.31643107533454895, 0.3534304201602936, 0.29263103008270264, 0.3460231423377991, 0.30423805117607117, 0.3509593904018402, 0.3582400679588318, 0.3155673146247864, 0.34044772386550903, 0.3305255174636841, 0.3249223232269287, 0.34632089734077454, 0.2865634560585022, 0.33698612451553345, 0.33017274737358093, 0.374165803194046, 0.306731253862381, 0.32015228271484375, 0.333869069814682, 0.3435114324092865, 0.3440817594528198, 0.32168683409690857]\n","0.3445272655398757\n","0.05181645944072147\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4TgmTOeLZst","executionInfo":{"status":"ok","timestamp":1689754367764,"user_tz":-330,"elapsed":8,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"930db377-6301-4c9f-f64e-a25495d78adc"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8730769157409668, 0.8460038304328918, 0.8423076272010803, 0.8693284392356873, 0.8683728575706482, 0.862672746181488, 0.8581559062004089, 0.8805267810821533, 0.8647114038467407, 0.8734177350997925, 0.8446511030197144, 0.8517823815345764, 0.8600745797157288, 0.8668554425239563, 0.8656986355781555, 0.8728583455085754, 0.8579283952713013, 0.887005627155304, 0.8712685704231262, 0.8741006255149841, 0.8365384340286255, 0.8710280060768127, 0.8582019805908203, 0.8693233132362366, 0.864086389541626, 0.8649634718894958, 0.8555132746696472]\n","0.8633501044026127\n","0.011545662643090612\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FuIg5gAeLZvx","executionInfo":{"status":"ok","timestamp":1689754367764,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AID3ymFX_N1K","executionInfo":{"status":"ok","timestamp":1689754367764,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J2hT-DuKKsUa","executionInfo":{"status":"ok","timestamp":1689754367764,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["## LSTM CNN LSTM nothing"],"metadata":{"id":"EggUFlYlLH1S"}},{"cell_type":"code","source":["undersample_seed = [1,2,3,4,5]\n","split_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","\n","for i in undersample_seed:\n","    Xtemp = final_df.drop('label', axis=1)\n","    ytemp = final_df['label']\n","    undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","    X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","    final_df = X_undersampled.copy()\n","    final_df['label'] = y_undersampled\n","    #print(final_df.shape, final_df['label'].value_counts())\n","\n","    for j in split_seed:\n","\n","        X_sentemb = final_df.loc[:, 'sentemb1':'sentemb28']\n","        # putting panic extended feature with liwc features\n","        X_liwc = final_df.loc[:, 'WC':'Emoji']\n","        X_liwc['symptoms_ext_count'] = final_df['symptoms_ext_count']\n","        X_emotions = final_df.loc[:, 'admiration':'neutral']\n","        X_intensity = final_df.loc[:, 'anger_intensity':'trust_intensity']\n","        y = final_df['label']\n","\n","        # train test split with stratification\n","        X_sentemb_train, X_sentemb_test, X_liwc_train, X_liwc_test, X_emotions_train, X_emotions_test, X_intensity_train, X_intensity_test, y_train, y_test = train_test_split(\n","            X_sentemb, X_liwc, X_emotions, X_intensity, y, test_size=0.2, random_state=j, stratify=y)\n","\n","        # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # Standardization of train and test LIWC features\n","        train_scaled_liwc = sc.fit_transform(X_liwc_train)\n","        test_scaled_liwc = sc.fit_transform(X_liwc_test)\n","        liwc_column_names = list(df.loc[:, 'WC':'Emoji'].columns) + ['symptoms_ext_count']\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, LSTM intensity\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=(28,))\n","        lstm_sentemb = LSTM(32)(Reshape((1, 28))(input_sentemb))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","        lstm_intensity = LSTM(32)(Reshape((1, 8))(input_intensity))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=(119,))\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFfMnUlGKsXW","executionInfo":{"status":"ok","timestamp":1689755200855,"user_tz":-330,"elapsed":833095,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d47956e0-032d-4241-94cf-18071d0d6525"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","139/139 [==============================] - 9s 29ms/step - loss: 0.5776 - accuracy: 0.7019 - f1_score: 0.6964 - val_loss: 0.4901 - val_accuracy: 0.7486 - val_f1_score: 0.7616\n","Epoch 2/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.4626 - accuracy: 0.7844 - f1_score: 0.7774 - val_loss: 0.4415 - val_accuracy: 0.8011 - val_f1_score: 0.7704\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3978 - accuracy: 0.8293 - f1_score: 0.8236 - val_loss: 0.3868 - val_accuracy: 0.8165 - val_f1_score: 0.8054\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3361 - accuracy: 0.8526 - f1_score: 0.8491 - val_loss: 0.3709 - val_accuracy: 0.8363 - val_f1_score: 0.8227\n","Epoch 5/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3059 - accuracy: 0.8718 - f1_score: 0.8688 - val_loss: 0.3578 - val_accuracy: 0.8345 - val_f1_score: 0.8426\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2642 - accuracy: 0.8944 - f1_score: 0.8925 - val_loss: 0.3333 - val_accuracy: 0.8490 - val_f1_score: 0.8486\n","Epoch 7/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2439 - accuracy: 0.9003 - f1_score: 0.8987 - val_loss: 0.3093 - val_accuracy: 0.8644 - val_f1_score: 0.8631\n","Epoch 8/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2107 - accuracy: 0.9186 - f1_score: 0.9175 - val_loss: 0.3199 - val_accuracy: 0.8571 - val_f1_score: 0.8556\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1884 - accuracy: 0.9263 - f1_score: 0.9253 - val_loss: 0.3325 - val_accuracy: 0.8680 - val_f1_score: 0.8636\n","Epoch 10/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.1850 - accuracy: 0.9317 - f1_score: 0.9310 - val_loss: 0.4217 - val_accuracy: 0.8599 - val_f1_score: 0.8448\n","Epoch 11/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1596 - accuracy: 0.9408 - f1_score: 0.9403 - val_loss: 0.3517 - val_accuracy: 0.8580 - val_f1_score: 0.8594\n","Epoch 12/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1385 - accuracy: 0.9469 - f1_score: 0.9467 - val_loss: 0.3663 - val_accuracy: 0.8707 - val_f1_score: 0.8650\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8644 - f1_score: 0.8631\n","Epoch 1/20\n","139/139 [==============================] - 8s 22ms/step - loss: 0.5675 - accuracy: 0.7023 - f1_score: 0.7007 - val_loss: 0.5016 - val_accuracy: 0.7550 - val_f1_score: 0.7356\n","Epoch 2/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.4441 - accuracy: 0.7864 - f1_score: 0.7784 - val_loss: 0.4473 - val_accuracy: 0.7929 - val_f1_score: 0.7817\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3877 - accuracy: 0.8253 - f1_score: 0.8214 - val_loss: 0.4211 - val_accuracy: 0.8183 - val_f1_score: 0.8020\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.8556 - f1_score: 0.8520 - val_loss: 0.4128 - val_accuracy: 0.8146 - val_f1_score: 0.8255\n","Epoch 5/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2943 - accuracy: 0.8745 - f1_score: 0.8717 - val_loss: 0.3670 - val_accuracy: 0.8445 - val_f1_score: 0.8478\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2667 - accuracy: 0.8924 - f1_score: 0.8914 - val_loss: 0.3572 - val_accuracy: 0.8535 - val_f1_score: 0.8556\n","Epoch 7/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2404 - accuracy: 0.9048 - f1_score: 0.9037 - val_loss: 0.3390 - val_accuracy: 0.8608 - val_f1_score: 0.8525\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2175 - accuracy: 0.9150 - f1_score: 0.9147 - val_loss: 0.3541 - val_accuracy: 0.8707 - val_f1_score: 0.8662\n","Epoch 9/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1850 - accuracy: 0.9279 - f1_score: 0.9274 - val_loss: 0.3577 - val_accuracy: 0.8788 - val_f1_score: 0.8777\n","Epoch 10/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.1701 - accuracy: 0.9331 - f1_score: 0.9329 - val_loss: 0.3726 - val_accuracy: 0.8725 - val_f1_score: 0.8703\n","Epoch 11/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.1629 - accuracy: 0.9344 - f1_score: 0.9341 - val_loss: 0.3684 - val_accuracy: 0.8680 - val_f1_score: 0.8612\n","Epoch 12/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1474 - accuracy: 0.9455 - f1_score: 0.9450 - val_loss: 0.4099 - val_accuracy: 0.8680 - val_f1_score: 0.8680\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8608 - f1_score: 0.8525\n","Epoch 1/20\n","139/139 [==============================] - 11s 31ms/step - loss: 0.5675 - accuracy: 0.7057 - f1_score: 0.6973 - val_loss: 0.4636 - val_accuracy: 0.7866 - val_f1_score: 0.7731\n","Epoch 2/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.4618 - accuracy: 0.7798 - f1_score: 0.7704 - val_loss: 0.3957 - val_accuracy: 0.8391 - val_f1_score: 0.8340\n","Epoch 3/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.3884 - accuracy: 0.8239 - f1_score: 0.8168 - val_loss: 0.3526 - val_accuracy: 0.8571 - val_f1_score: 0.8574\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3348 - accuracy: 0.8526 - f1_score: 0.8491 - val_loss: 0.3297 - val_accuracy: 0.8635 - val_f1_score: 0.8608\n","Epoch 5/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2874 - accuracy: 0.8816 - f1_score: 0.8793 - val_loss: 0.3248 - val_accuracy: 0.8608 - val_f1_score: 0.8585\n","Epoch 6/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2618 - accuracy: 0.8931 - f1_score: 0.8907 - val_loss: 0.3237 - val_accuracy: 0.8653 - val_f1_score: 0.8649\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.9105 - f1_score: 0.9092 - val_loss: 0.3517 - val_accuracy: 0.8680 - val_f1_score: 0.8719\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2084 - accuracy: 0.9159 - f1_score: 0.9146 - val_loss: 0.3432 - val_accuracy: 0.8680 - val_f1_score: 0.8628\n","Epoch 9/20\n","139/139 [==============================] - 3s 18ms/step - loss: 0.1863 - accuracy: 0.9256 - f1_score: 0.9247 - val_loss: 0.3603 - val_accuracy: 0.8725 - val_f1_score: 0.8751\n","Epoch 10/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.1625 - accuracy: 0.9344 - f1_score: 0.9340 - val_loss: 0.3781 - val_accuracy: 0.8671 - val_f1_score: 0.8689\n","Epoch 11/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1624 - accuracy: 0.9403 - f1_score: 0.9397 - val_loss: 0.3545 - val_accuracy: 0.8698 - val_f1_score: 0.8639\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8653 - f1_score: 0.8649\n","Epoch 1/20\n","139/139 [==============================] - 11s 34ms/step - loss: 0.5680 - accuracy: 0.7084 - f1_score: 0.7024 - val_loss: 0.4618 - val_accuracy: 0.7749 - val_f1_score: 0.7701\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4410 - accuracy: 0.8006 - f1_score: 0.7942 - val_loss: 0.4123 - val_accuracy: 0.8110 - val_f1_score: 0.8045\n","Epoch 3/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.3772 - accuracy: 0.8341 - f1_score: 0.8293 - val_loss: 0.3857 - val_accuracy: 0.8309 - val_f1_score: 0.8302\n","Epoch 4/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3228 - accuracy: 0.8619 - f1_score: 0.8587 - val_loss: 0.3761 - val_accuracy: 0.8400 - val_f1_score: 0.8329\n","Epoch 5/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2810 - accuracy: 0.8779 - f1_score: 0.8768 - val_loss: 0.3535 - val_accuracy: 0.8490 - val_f1_score: 0.8464\n","Epoch 6/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2585 - accuracy: 0.8926 - f1_score: 0.8908 - val_loss: 0.3675 - val_accuracy: 0.8427 - val_f1_score: 0.8281\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2266 - accuracy: 0.9087 - f1_score: 0.9081 - val_loss: 0.3963 - val_accuracy: 0.8499 - val_f1_score: 0.8428\n","Epoch 8/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2093 - accuracy: 0.9137 - f1_score: 0.9127 - val_loss: 0.3646 - val_accuracy: 0.8698 - val_f1_score: 0.8657\n","Epoch 9/20\n","139/139 [==============================] - 2s 18ms/step - loss: 0.1939 - accuracy: 0.9250 - f1_score: 0.9241 - val_loss: 0.3776 - val_accuracy: 0.8662 - val_f1_score: 0.8606\n","Epoch 10/20\n","139/139 [==============================] - 3s 18ms/step - loss: 0.1763 - accuracy: 0.9313 - f1_score: 0.9306 - val_loss: 0.3965 - val_accuracy: 0.8553 - val_f1_score: 0.8462\n","35/35 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8490 - f1_score: 0.8464\n","Epoch 1/20\n","139/139 [==============================] - 17s 59ms/step - loss: 0.5563 - accuracy: 0.7163 - f1_score: 0.7070 - val_loss: 0.4717 - val_accuracy: 0.7794 - val_f1_score: 0.7711\n","Epoch 2/20\n","139/139 [==============================] - 3s 19ms/step - loss: 0.4453 - accuracy: 0.7963 - f1_score: 0.7867 - val_loss: 0.4357 - val_accuracy: 0.8083 - val_f1_score: 0.8015\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3870 - accuracy: 0.8309 - f1_score: 0.8248 - val_loss: 0.4119 - val_accuracy: 0.8183 - val_f1_score: 0.7972\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3223 - accuracy: 0.8601 - f1_score: 0.8560 - val_loss: 0.3739 - val_accuracy: 0.8418 - val_f1_score: 0.8444\n","Epoch 5/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.2787 - accuracy: 0.8854 - f1_score: 0.8836 - val_loss: 0.3690 - val_accuracy: 0.8562 - val_f1_score: 0.8579\n","Epoch 6/20\n","139/139 [==============================] - 3s 18ms/step - loss: 0.2392 - accuracy: 0.9046 - f1_score: 0.9035 - val_loss: 0.3700 - val_accuracy: 0.8635 - val_f1_score: 0.8638\n","Epoch 7/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2116 - accuracy: 0.9195 - f1_score: 0.9191 - val_loss: 0.4071 - val_accuracy: 0.8526 - val_f1_score: 0.8443\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2064 - accuracy: 0.9229 - f1_score: 0.9226 - val_loss: 0.3913 - val_accuracy: 0.8608 - val_f1_score: 0.8623\n","Epoch 9/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1811 - accuracy: 0.9333 - f1_score: 0.9328 - val_loss: 0.3857 - val_accuracy: 0.8662 - val_f1_score: 0.8655\n","Epoch 10/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1657 - accuracy: 0.9392 - f1_score: 0.9388 - val_loss: 0.3940 - val_accuracy: 0.8544 - val_f1_score: 0.8502\n","35/35 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8562 - f1_score: 0.8579\n","Epoch 1/20\n","139/139 [==============================] - 9s 20ms/step - loss: 0.5870 - accuracy: 0.6896 - f1_score: 0.6837 - val_loss: 0.4898 - val_accuracy: 0.7495 - val_f1_score: 0.7461\n","Epoch 2/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.4735 - accuracy: 0.7733 - f1_score: 0.7618 - val_loss: 0.4317 - val_accuracy: 0.7939 - val_f1_score: 0.7901\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4108 - accuracy: 0.8133 - f1_score: 0.8072 - val_loss: 0.4193 - val_accuracy: 0.7929 - val_f1_score: 0.8103\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3609 - accuracy: 0.8486 - f1_score: 0.8448 - val_loss: 0.3476 - val_accuracy: 0.8472 - val_f1_score: 0.8351\n","Epoch 5/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.3157 - accuracy: 0.8648 - f1_score: 0.8620 - val_loss: 0.3405 - val_accuracy: 0.8499 - val_f1_score: 0.8407\n","Epoch 6/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.2747 - accuracy: 0.8847 - f1_score: 0.8831 - val_loss: 0.3145 - val_accuracy: 0.8617 - val_f1_score: 0.8610\n","Epoch 7/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.2462 - accuracy: 0.8992 - f1_score: 0.8976 - val_loss: 0.3245 - val_accuracy: 0.8671 - val_f1_score: 0.8686\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2265 - accuracy: 0.9060 - f1_score: 0.9048 - val_loss: 0.3173 - val_accuracy: 0.8698 - val_f1_score: 0.8664\n","Epoch 9/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2051 - accuracy: 0.9182 - f1_score: 0.9178 - val_loss: 0.3203 - val_accuracy: 0.8653 - val_f1_score: 0.8590\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1848 - accuracy: 0.9311 - f1_score: 0.9305 - val_loss: 0.3193 - val_accuracy: 0.8752 - val_f1_score: 0.8722\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1671 - accuracy: 0.9367 - f1_score: 0.9366 - val_loss: 0.4002 - val_accuracy: 0.8734 - val_f1_score: 0.8606\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8617 - f1_score: 0.8610\n","Epoch 1/20\n","139/139 [==============================] - 11s 21ms/step - loss: 0.5721 - accuracy: 0.7093 - f1_score: 0.7085 - val_loss: 0.4838 - val_accuracy: 0.7703 - val_f1_score: 0.7567\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4645 - accuracy: 0.7740 - f1_score: 0.7668 - val_loss: 0.4323 - val_accuracy: 0.8165 - val_f1_score: 0.8166\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4075 - accuracy: 0.8146 - f1_score: 0.8089 - val_loss: 0.4080 - val_accuracy: 0.8255 - val_f1_score: 0.8311\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3505 - accuracy: 0.8465 - f1_score: 0.8429 - val_loss: 0.3617 - val_accuracy: 0.8418 - val_f1_score: 0.8425\n","Epoch 5/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3001 - accuracy: 0.8736 - f1_score: 0.8714 - val_loss: 0.3412 - val_accuracy: 0.8580 - val_f1_score: 0.8582\n","Epoch 6/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.2654 - accuracy: 0.8886 - f1_score: 0.8867 - val_loss: 0.3391 - val_accuracy: 0.8562 - val_f1_score: 0.8501\n","Epoch 7/20\n","139/139 [==============================] - 2s 18ms/step - loss: 0.2456 - accuracy: 0.9001 - f1_score: 0.8988 - val_loss: 0.3434 - val_accuracy: 0.8571 - val_f1_score: 0.8587\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2062 - accuracy: 0.9191 - f1_score: 0.9181 - val_loss: 0.3470 - val_accuracy: 0.8635 - val_f1_score: 0.8558\n","Epoch 9/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1948 - accuracy: 0.9245 - f1_score: 0.9242 - val_loss: 0.3501 - val_accuracy: 0.8635 - val_f1_score: 0.8677\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1847 - accuracy: 0.9288 - f1_score: 0.9284 - val_loss: 0.3295 - val_accuracy: 0.8725 - val_f1_score: 0.8733\n","Epoch 11/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1586 - accuracy: 0.9415 - f1_score: 0.9412 - val_loss: 0.3586 - val_accuracy: 0.8662 - val_f1_score: 0.8676\n","Epoch 12/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1436 - accuracy: 0.9442 - f1_score: 0.9439 - val_loss: 0.4164 - val_accuracy: 0.8590 - val_f1_score: 0.8458\n","Epoch 13/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1321 - accuracy: 0.9491 - f1_score: 0.9490 - val_loss: 0.4056 - val_accuracy: 0.8680 - val_f1_score: 0.8668\n","Epoch 14/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1262 - accuracy: 0.9509 - f1_score: 0.9507 - val_loss: 0.3760 - val_accuracy: 0.8761 - val_f1_score: 0.8742\n","Epoch 15/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.1120 - accuracy: 0.9577 - f1_score: 0.9576 - val_loss: 0.3911 - val_accuracy: 0.8797 - val_f1_score: 0.8779\n","35/35 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8725 - f1_score: 0.8733\n","Epoch 1/20\n","139/139 [==============================] - 13s 27ms/step - loss: 0.5663 - accuracy: 0.7019 - f1_score: 0.7003 - val_loss: 0.5143 - val_accuracy: 0.7550 - val_f1_score: 0.7552\n","Epoch 2/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.4580 - accuracy: 0.7887 - f1_score: 0.7830 - val_loss: 0.4282 - val_accuracy: 0.8074 - val_f1_score: 0.8079\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3869 - accuracy: 0.8309 - f1_score: 0.8268 - val_loss: 0.3791 - val_accuracy: 0.8345 - val_f1_score: 0.8215\n","Epoch 4/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.3134 - accuracy: 0.8734 - f1_score: 0.8706 - val_loss: 0.3683 - val_accuracy: 0.8562 - val_f1_score: 0.8597\n","Epoch 5/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2789 - accuracy: 0.8811 - f1_score: 0.8796 - val_loss: 0.3793 - val_accuracy: 0.8472 - val_f1_score: 0.8335\n","Epoch 6/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2531 - accuracy: 0.8972 - f1_score: 0.8956 - val_loss: 0.3864 - val_accuracy: 0.8517 - val_f1_score: 0.8367\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2188 - accuracy: 0.9094 - f1_score: 0.9083 - val_loss: 0.3920 - val_accuracy: 0.8680 - val_f1_score: 0.8744\n","Epoch 8/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1956 - accuracy: 0.9263 - f1_score: 0.9256 - val_loss: 0.4034 - val_accuracy: 0.8662 - val_f1_score: 0.8598\n","Epoch 9/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1895 - accuracy: 0.9238 - f1_score: 0.9227 - val_loss: 0.3967 - val_accuracy: 0.8743 - val_f1_score: 0.8738\n","35/35 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.8562 - f1_score: 0.8597\n","Epoch 1/20\n","139/139 [==============================] - 10s 31ms/step - loss: 0.5710 - accuracy: 0.6971 - f1_score: 0.6890 - val_loss: 0.4636 - val_accuracy: 0.7722 - val_f1_score: 0.7645\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4711 - accuracy: 0.7844 - f1_score: 0.7769 - val_loss: 0.4321 - val_accuracy: 0.7893 - val_f1_score: 0.7845\n","Epoch 3/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.4106 - accuracy: 0.8160 - f1_score: 0.8115 - val_loss: 0.4021 - val_accuracy: 0.8083 - val_f1_score: 0.8114\n","Epoch 4/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.3478 - accuracy: 0.8517 - f1_score: 0.8484 - val_loss: 0.3991 - val_accuracy: 0.8192 - val_f1_score: 0.8285\n","Epoch 5/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.3018 - accuracy: 0.8684 - f1_score: 0.8658 - val_loss: 0.3794 - val_accuracy: 0.8336 - val_f1_score: 0.8389\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2673 - accuracy: 0.8951 - f1_score: 0.8933 - val_loss: 0.3704 - val_accuracy: 0.8472 - val_f1_score: 0.8468\n","Epoch 7/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2391 - accuracy: 0.9042 - f1_score: 0.9029 - val_loss: 0.3804 - val_accuracy: 0.8436 - val_f1_score: 0.8325\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2202 - accuracy: 0.9098 - f1_score: 0.9085 - val_loss: 0.3707 - val_accuracy: 0.8535 - val_f1_score: 0.8469\n","Epoch 9/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1864 - accuracy: 0.9231 - f1_score: 0.9226 - val_loss: 0.4004 - val_accuracy: 0.8562 - val_f1_score: 0.8496\n","Epoch 10/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1767 - accuracy: 0.9283 - f1_score: 0.9276 - val_loss: 0.4292 - val_accuracy: 0.8445 - val_f1_score: 0.8478\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1654 - accuracy: 0.9403 - f1_score: 0.9401 - val_loss: 0.4262 - val_accuracy: 0.8499 - val_f1_score: 0.8581\n","35/35 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8472 - f1_score: 0.8468\n","Epoch 1/20\n","139/139 [==============================] - 9s 20ms/step - loss: 0.5699 - accuracy: 0.7014 - f1_score: 0.6954 - val_loss: 0.4772 - val_accuracy: 0.7749 - val_f1_score: 0.7631\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4569 - accuracy: 0.7825 - f1_score: 0.7744 - val_loss: 0.4216 - val_accuracy: 0.8038 - val_f1_score: 0.7931\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3884 - accuracy: 0.8262 - f1_score: 0.8206 - val_loss: 0.4060 - val_accuracy: 0.8137 - val_f1_score: 0.7923\n","Epoch 4/20\n","139/139 [==============================] - 2s 18ms/step - loss: 0.3471 - accuracy: 0.8465 - f1_score: 0.8418 - val_loss: 0.3845 - val_accuracy: 0.8309 - val_f1_score: 0.8143\n","Epoch 5/20\n","139/139 [==============================] - 2s 18ms/step - loss: 0.2970 - accuracy: 0.8793 - f1_score: 0.8772 - val_loss: 0.3548 - val_accuracy: 0.8427 - val_f1_score: 0.8412\n","Epoch 6/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2589 - accuracy: 0.8976 - f1_score: 0.8961 - val_loss: 0.3773 - val_accuracy: 0.8418 - val_f1_score: 0.8430\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2486 - accuracy: 0.9008 - f1_score: 0.8998 - val_loss: 0.3581 - val_accuracy: 0.8544 - val_f1_score: 0.8516\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2128 - accuracy: 0.9168 - f1_score: 0.9159 - val_loss: 0.4215 - val_accuracy: 0.8345 - val_f1_score: 0.8450\n","Epoch 9/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1972 - accuracy: 0.9220 - f1_score: 0.9211 - val_loss: 0.3962 - val_accuracy: 0.8535 - val_f1_score: 0.8576\n","Epoch 10/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1865 - accuracy: 0.9302 - f1_score: 0.9296 - val_loss: 0.4071 - val_accuracy: 0.8553 - val_f1_score: 0.8519\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8427 - f1_score: 0.8412\n","Epoch 1/20\n","139/139 [==============================] - 9s 21ms/step - loss: 0.5801 - accuracy: 0.6899 - f1_score: 0.6876 - val_loss: 0.4785 - val_accuracy: 0.7749 - val_f1_score: 0.7640\n","Epoch 2/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.4553 - accuracy: 0.7920 - f1_score: 0.7870 - val_loss: 0.4092 - val_accuracy: 0.8246 - val_f1_score: 0.8180\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3860 - accuracy: 0.8262 - f1_score: 0.8230 - val_loss: 0.3594 - val_accuracy: 0.8490 - val_f1_score: 0.8444\n","Epoch 4/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.3327 - accuracy: 0.8551 - f1_score: 0.8527 - val_loss: 0.3227 - val_accuracy: 0.8752 - val_f1_score: 0.8729\n","Epoch 5/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.2925 - accuracy: 0.8764 - f1_score: 0.8743 - val_loss: 0.3090 - val_accuracy: 0.8761 - val_f1_score: 0.8753\n","Epoch 6/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2506 - accuracy: 0.9017 - f1_score: 0.9003 - val_loss: 0.3362 - val_accuracy: 0.8517 - val_f1_score: 0.8622\n","Epoch 7/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2386 - accuracy: 0.9014 - f1_score: 0.9007 - val_loss: 0.3106 - val_accuracy: 0.8707 - val_f1_score: 0.8720\n","Epoch 8/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2076 - accuracy: 0.9216 - f1_score: 0.9211 - val_loss: 0.3908 - val_accuracy: 0.8363 - val_f1_score: 0.8510\n","Epoch 9/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1943 - accuracy: 0.9261 - f1_score: 0.9254 - val_loss: 0.3474 - val_accuracy: 0.8707 - val_f1_score: 0.8621\n","Epoch 10/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1783 - accuracy: 0.9299 - f1_score: 0.9293 - val_loss: 0.3413 - val_accuracy: 0.8562 - val_f1_score: 0.8606\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 0.8761 - f1_score: 0.8753\n","Epoch 1/20\n","139/139 [==============================] - 11s 22ms/step - loss: 0.5656 - accuracy: 0.7068 - f1_score: 0.7018 - val_loss: 0.5148 - val_accuracy: 0.7432 - val_f1_score: 0.7589\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4590 - accuracy: 0.7816 - f1_score: 0.7766 - val_loss: 0.4546 - val_accuracy: 0.7902 - val_f1_score: 0.7895\n","Epoch 3/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.3964 - accuracy: 0.8214 - f1_score: 0.8160 - val_loss: 0.4488 - val_accuracy: 0.8011 - val_f1_score: 0.8167\n","Epoch 4/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.3445 - accuracy: 0.8474 - f1_score: 0.8451 - val_loss: 0.4056 - val_accuracy: 0.8282 - val_f1_score: 0.8155\n","Epoch 5/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.2924 - accuracy: 0.8766 - f1_score: 0.8744 - val_loss: 0.3976 - val_accuracy: 0.8327 - val_f1_score: 0.8273\n","Epoch 6/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2535 - accuracy: 0.8962 - f1_score: 0.8954 - val_loss: 0.3797 - val_accuracy: 0.8481 - val_f1_score: 0.8388\n","Epoch 7/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2308 - accuracy: 0.9030 - f1_score: 0.9017 - val_loss: 0.3691 - val_accuracy: 0.8535 - val_f1_score: 0.8525\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2083 - accuracy: 0.9152 - f1_score: 0.9144 - val_loss: 0.4100 - val_accuracy: 0.8490 - val_f1_score: 0.8383\n","Epoch 9/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1893 - accuracy: 0.9207 - f1_score: 0.9201 - val_loss: 0.3851 - val_accuracy: 0.8580 - val_f1_score: 0.8520\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1683 - accuracy: 0.9292 - f1_score: 0.9286 - val_loss: 0.4530 - val_accuracy: 0.8382 - val_f1_score: 0.8194\n","Epoch 11/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1706 - accuracy: 0.9372 - f1_score: 0.9367 - val_loss: 0.4052 - val_accuracy: 0.8653 - val_f1_score: 0.8619\n","Epoch 12/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1308 - accuracy: 0.9487 - f1_score: 0.9485 - val_loss: 0.4585 - val_accuracy: 0.8490 - val_f1_score: 0.8374\n","35/35 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8535 - f1_score: 0.8525\n","Epoch 1/20\n","139/139 [==============================] - 9s 20ms/step - loss: 0.5768 - accuracy: 0.6955 - f1_score: 0.6884 - val_loss: 0.4918 - val_accuracy: 0.7486 - val_f1_score: 0.7214\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4668 - accuracy: 0.7737 - f1_score: 0.7666 - val_loss: 0.4350 - val_accuracy: 0.8020 - val_f1_score: 0.7982\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3977 - accuracy: 0.8201 - f1_score: 0.8159 - val_loss: 0.3898 - val_accuracy: 0.8183 - val_f1_score: 0.8197\n","Epoch 4/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.3418 - accuracy: 0.8538 - f1_score: 0.8516 - val_loss: 0.3628 - val_accuracy: 0.8309 - val_f1_score: 0.8292\n","Epoch 5/20\n","139/139 [==============================] - 2s 18ms/step - loss: 0.2910 - accuracy: 0.8773 - f1_score: 0.8757 - val_loss: 0.3614 - val_accuracy: 0.8499 - val_f1_score: 0.8551\n","Epoch 6/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2544 - accuracy: 0.8947 - f1_score: 0.8931 - val_loss: 0.3437 - val_accuracy: 0.8553 - val_f1_score: 0.8571\n","Epoch 7/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2337 - accuracy: 0.9035 - f1_score: 0.9029 - val_loss: 0.3398 - val_accuracy: 0.8635 - val_f1_score: 0.8653\n","Epoch 8/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2025 - accuracy: 0.9209 - f1_score: 0.9203 - val_loss: 0.3544 - val_accuracy: 0.8481 - val_f1_score: 0.8544\n","Epoch 9/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1823 - accuracy: 0.9304 - f1_score: 0.9300 - val_loss: 0.4058 - val_accuracy: 0.8490 - val_f1_score: 0.8574\n","Epoch 10/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1726 - accuracy: 0.9295 - f1_score: 0.9293 - val_loss: 0.3650 - val_accuracy: 0.8580 - val_f1_score: 0.8626\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1562 - accuracy: 0.9356 - f1_score: 0.9353 - val_loss: 0.4410 - val_accuracy: 0.8508 - val_f1_score: 0.8610\n","Epoch 12/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1338 - accuracy: 0.9489 - f1_score: 0.9488 - val_loss: 0.4022 - val_accuracy: 0.8590 - val_f1_score: 0.8582\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8635 - f1_score: 0.8653\n","Epoch 1/20\n","139/139 [==============================] - 11s 21ms/step - loss: 0.5819 - accuracy: 0.6808 - f1_score: 0.6713 - val_loss: 0.4796 - val_accuracy: 0.7703 - val_f1_score: 0.7343\n","Epoch 2/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.4644 - accuracy: 0.7805 - f1_score: 0.7731 - val_loss: 0.4057 - val_accuracy: 0.8146 - val_f1_score: 0.8015\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3890 - accuracy: 0.8363 - f1_score: 0.8318 - val_loss: 0.3689 - val_accuracy: 0.8382 - val_f1_score: 0.8243\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3282 - accuracy: 0.8587 - f1_score: 0.8556 - val_loss: 0.3481 - val_accuracy: 0.8590 - val_f1_score: 0.8597\n","Epoch 5/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2873 - accuracy: 0.8759 - f1_score: 0.8735 - val_loss: 0.3854 - val_accuracy: 0.8264 - val_f1_score: 0.8021\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2629 - accuracy: 0.8904 - f1_score: 0.8888 - val_loss: 0.3355 - val_accuracy: 0.8698 - val_f1_score: 0.8696\n","Epoch 7/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2384 - accuracy: 0.9069 - f1_score: 0.9055 - val_loss: 0.3270 - val_accuracy: 0.8680 - val_f1_score: 0.8638\n","Epoch 8/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.2095 - accuracy: 0.9179 - f1_score: 0.9171 - val_loss: 0.3400 - val_accuracy: 0.8716 - val_f1_score: 0.8695\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2039 - accuracy: 0.9207 - f1_score: 0.9199 - val_loss: 0.3503 - val_accuracy: 0.8707 - val_f1_score: 0.8639\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1834 - accuracy: 0.9302 - f1_score: 0.9296 - val_loss: 0.3732 - val_accuracy: 0.8599 - val_f1_score: 0.8561\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1696 - accuracy: 0.9320 - f1_score: 0.9316 - val_loss: 0.3466 - val_accuracy: 0.8797 - val_f1_score: 0.8758\n","Epoch 12/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1464 - accuracy: 0.9451 - f1_score: 0.9448 - val_loss: 0.3874 - val_accuracy: 0.8816 - val_f1_score: 0.8827\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8680 - f1_score: 0.8638\n","Epoch 1/20\n","139/139 [==============================] - 10s 21ms/step - loss: 0.5761 - accuracy: 0.6924 - f1_score: 0.6917 - val_loss: 0.4855 - val_accuracy: 0.7640 - val_f1_score: 0.7393\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4588 - accuracy: 0.7832 - f1_score: 0.7759 - val_loss: 0.4265 - val_accuracy: 0.7939 - val_f1_score: 0.7912\n","Epoch 3/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.3840 - accuracy: 0.8232 - f1_score: 0.8172 - val_loss: 0.3754 - val_accuracy: 0.8336 - val_f1_score: 0.8254\n","Epoch 4/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.3389 - accuracy: 0.8542 - f1_score: 0.8511 - val_loss: 0.3518 - val_accuracy: 0.8427 - val_f1_score: 0.8471\n","Epoch 5/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.2935 - accuracy: 0.8759 - f1_score: 0.8736 - val_loss: 0.3235 - val_accuracy: 0.8617 - val_f1_score: 0.8582\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2577 - accuracy: 0.8981 - f1_score: 0.8966 - val_loss: 0.3294 - val_accuracy: 0.8662 - val_f1_score: 0.8652\n","Epoch 7/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.2385 - accuracy: 0.9012 - f1_score: 0.9002 - val_loss: 0.3289 - val_accuracy: 0.8553 - val_f1_score: 0.8596\n","Epoch 8/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.2135 - accuracy: 0.9168 - f1_score: 0.9160 - val_loss: 0.3179 - val_accuracy: 0.8644 - val_f1_score: 0.8593\n","Epoch 9/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2011 - accuracy: 0.9186 - f1_score: 0.9176 - val_loss: 0.3286 - val_accuracy: 0.8716 - val_f1_score: 0.8704\n","Epoch 10/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1798 - accuracy: 0.9306 - f1_score: 0.9297 - val_loss: 0.3300 - val_accuracy: 0.8662 - val_f1_score: 0.8619\n","Epoch 11/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1770 - accuracy: 0.9290 - f1_score: 0.9284 - val_loss: 0.3961 - val_accuracy: 0.8409 - val_f1_score: 0.8516\n","Epoch 12/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1611 - accuracy: 0.9363 - f1_score: 0.9360 - val_loss: 0.3492 - val_accuracy: 0.8535 - val_f1_score: 0.8576\n","Epoch 13/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.1397 - accuracy: 0.9489 - f1_score: 0.9487 - val_loss: 0.3752 - val_accuracy: 0.8535 - val_f1_score: 0.8564\n","35/35 [==============================] - 0s 7ms/step - loss: 0.3179 - accuracy: 0.8644 - f1_score: 0.8593\n","Epoch 1/20\n","139/139 [==============================] - 10s 29ms/step - loss: 0.5753 - accuracy: 0.6951 - f1_score: 0.6962 - val_loss: 0.4905 - val_accuracy: 0.7568 - val_f1_score: 0.7054\n","Epoch 2/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.4593 - accuracy: 0.7810 - f1_score: 0.7722 - val_loss: 0.4069 - val_accuracy: 0.8165 - val_f1_score: 0.8105\n","Epoch 3/20\n","139/139 [==============================] - 3s 18ms/step - loss: 0.3980 - accuracy: 0.8248 - f1_score: 0.8211 - val_loss: 0.3599 - val_accuracy: 0.8418 - val_f1_score: 0.8436\n","Epoch 4/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.3313 - accuracy: 0.8585 - f1_score: 0.8554 - val_loss: 0.3328 - val_accuracy: 0.8562 - val_f1_score: 0.8543\n","Epoch 5/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2958 - accuracy: 0.8800 - f1_score: 0.8780 - val_loss: 0.3110 - val_accuracy: 0.8590 - val_f1_score: 0.8509\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2628 - accuracy: 0.8868 - f1_score: 0.8854 - val_loss: 0.3348 - val_accuracy: 0.8427 - val_f1_score: 0.8508\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2342 - accuracy: 0.9066 - f1_score: 0.9058 - val_loss: 0.2936 - val_accuracy: 0.8707 - val_f1_score: 0.8629\n","Epoch 8/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2200 - accuracy: 0.9150 - f1_score: 0.9145 - val_loss: 0.4156 - val_accuracy: 0.8255 - val_f1_score: 0.7949\n","Epoch 9/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1997 - accuracy: 0.9234 - f1_score: 0.9226 - val_loss: 0.3393 - val_accuracy: 0.8626 - val_f1_score: 0.8530\n","Epoch 10/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1722 - accuracy: 0.9347 - f1_score: 0.9345 - val_loss: 0.3345 - val_accuracy: 0.8698 - val_f1_score: 0.8626\n","Epoch 11/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1534 - accuracy: 0.9399 - f1_score: 0.9396 - val_loss: 0.3819 - val_accuracy: 0.8590 - val_f1_score: 0.8636\n","Epoch 12/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.1465 - accuracy: 0.9442 - f1_score: 0.9439 - val_loss: 0.3557 - val_accuracy: 0.8653 - val_f1_score: 0.8588\n","35/35 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.8707 - f1_score: 0.8629\n","Epoch 1/20\n","139/139 [==============================] - 8s 19ms/step - loss: 0.5718 - accuracy: 0.6996 - f1_score: 0.6910 - val_loss: 0.5048 - val_accuracy: 0.7586 - val_f1_score: 0.7562\n","Epoch 2/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.4579 - accuracy: 0.7891 - f1_score: 0.7813 - val_loss: 0.4523 - val_accuracy: 0.7839 - val_f1_score: 0.7735\n","Epoch 3/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.3948 - accuracy: 0.8203 - f1_score: 0.8158 - val_loss: 0.4109 - val_accuracy: 0.8156 - val_f1_score: 0.8079\n","Epoch 4/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.3286 - accuracy: 0.8642 - f1_score: 0.8603 - val_loss: 0.3945 - val_accuracy: 0.8282 - val_f1_score: 0.8279\n","Epoch 5/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2892 - accuracy: 0.8732 - f1_score: 0.8712 - val_loss: 0.3839 - val_accuracy: 0.8318 - val_f1_score: 0.8194\n","Epoch 6/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2603 - accuracy: 0.8922 - f1_score: 0.8900 - val_loss: 0.3863 - val_accuracy: 0.8345 - val_f1_score: 0.8278\n","Epoch 7/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2402 - accuracy: 0.9028 - f1_score: 0.9015 - val_loss: 0.3936 - val_accuracy: 0.8508 - val_f1_score: 0.8393\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2070 - accuracy: 0.9170 - f1_score: 0.9166 - val_loss: 0.3880 - val_accuracy: 0.8427 - val_f1_score: 0.8349\n","Epoch 9/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1852 - accuracy: 0.9268 - f1_score: 0.9262 - val_loss: 0.4000 - val_accuracy: 0.8508 - val_f1_score: 0.8465\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1773 - accuracy: 0.9272 - f1_score: 0.9266 - val_loss: 0.3894 - val_accuracy: 0.8517 - val_f1_score: 0.8517\n","35/35 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8318 - f1_score: 0.8194\n","Epoch 1/20\n","139/139 [==============================] - 9s 19ms/step - loss: 0.5739 - accuracy: 0.7025 - f1_score: 0.6917 - val_loss: 0.4899 - val_accuracy: 0.7722 - val_f1_score: 0.7701\n","Epoch 2/20\n","139/139 [==============================] - 1s 9ms/step - loss: 0.4563 - accuracy: 0.7846 - f1_score: 0.7780 - val_loss: 0.4393 - val_accuracy: 0.7975 - val_f1_score: 0.7808\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3854 - accuracy: 0.8350 - f1_score: 0.8294 - val_loss: 0.3904 - val_accuracy: 0.8427 - val_f1_score: 0.8389\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3213 - accuracy: 0.8642 - f1_score: 0.8613 - val_loss: 0.3785 - val_accuracy: 0.8454 - val_f1_score: 0.8512\n","Epoch 5/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.2783 - accuracy: 0.8917 - f1_score: 0.8904 - val_loss: 0.3788 - val_accuracy: 0.8490 - val_f1_score: 0.8531\n","Epoch 6/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.2443 - accuracy: 0.9017 - f1_score: 0.9006 - val_loss: 0.3774 - val_accuracy: 0.8707 - val_f1_score: 0.8708\n","Epoch 7/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2157 - accuracy: 0.9139 - f1_score: 0.9131 - val_loss: 0.4116 - val_accuracy: 0.8617 - val_f1_score: 0.8539\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2030 - accuracy: 0.9202 - f1_score: 0.9192 - val_loss: 0.3982 - val_accuracy: 0.8626 - val_f1_score: 0.8676\n","Epoch 9/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1900 - accuracy: 0.9268 - f1_score: 0.9261 - val_loss: 0.3912 - val_accuracy: 0.8644 - val_f1_score: 0.8636\n","Epoch 10/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.1512 - accuracy: 0.9462 - f1_score: 0.9457 - val_loss: 0.5015 - val_accuracy: 0.8571 - val_f1_score: 0.8640\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1623 - accuracy: 0.9424 - f1_score: 0.9421 - val_loss: 0.4526 - val_accuracy: 0.8653 - val_f1_score: 0.8654\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8707 - f1_score: 0.8708\n","Epoch 1/20\n","139/139 [==============================] - 11s 19ms/step - loss: 0.5908 - accuracy: 0.6887 - f1_score: 0.6818 - val_loss: 0.4925 - val_accuracy: 0.7577 - val_f1_score: 0.7624\n","Epoch 2/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.4706 - accuracy: 0.7760 - f1_score: 0.7711 - val_loss: 0.4408 - val_accuracy: 0.7857 - val_f1_score: 0.7930\n","Epoch 3/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.3923 - accuracy: 0.8259 - f1_score: 0.8229 - val_loss: 0.4064 - val_accuracy: 0.8192 - val_f1_score: 0.8084\n","Epoch 4/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.3382 - accuracy: 0.8558 - f1_score: 0.8534 - val_loss: 0.3908 - val_accuracy: 0.8210 - val_f1_score: 0.8242\n","Epoch 5/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.2963 - accuracy: 0.8793 - f1_score: 0.8777 - val_loss: 0.3742 - val_accuracy: 0.8373 - val_f1_score: 0.8324\n","Epoch 6/20\n","139/139 [==============================] - 2s 18ms/step - loss: 0.2568 - accuracy: 0.8940 - f1_score: 0.8923 - val_loss: 0.3740 - val_accuracy: 0.8517 - val_f1_score: 0.8487\n","Epoch 7/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2325 - accuracy: 0.9062 - f1_score: 0.9051 - val_loss: 0.3758 - val_accuracy: 0.8517 - val_f1_score: 0.8520\n","Epoch 8/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2202 - accuracy: 0.9170 - f1_score: 0.9162 - val_loss: 0.3801 - val_accuracy: 0.8427 - val_f1_score: 0.8291\n","Epoch 9/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.1868 - accuracy: 0.9277 - f1_score: 0.9270 - val_loss: 0.3996 - val_accuracy: 0.8436 - val_f1_score: 0.8299\n","Epoch 10/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1703 - accuracy: 0.9360 - f1_score: 0.9354 - val_loss: 0.3770 - val_accuracy: 0.8580 - val_f1_score: 0.8534\n","Epoch 11/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1563 - accuracy: 0.9421 - f1_score: 0.9419 - val_loss: 0.4003 - val_accuracy: 0.8608 - val_f1_score: 0.8550\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8517 - f1_score: 0.8487\n","Epoch 1/20\n","139/139 [==============================] - 9s 29ms/step - loss: 0.5719 - accuracy: 0.7041 - f1_score: 0.6997 - val_loss: 0.4906 - val_accuracy: 0.7468 - val_f1_score: 0.7450\n","Epoch 2/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.4483 - accuracy: 0.7853 - f1_score: 0.7771 - val_loss: 0.4295 - val_accuracy: 0.8065 - val_f1_score: 0.8007\n","Epoch 3/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.3794 - accuracy: 0.8352 - f1_score: 0.8321 - val_loss: 0.3943 - val_accuracy: 0.8146 - val_f1_score: 0.8145\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3193 - accuracy: 0.8682 - f1_score: 0.8650 - val_loss: 0.3666 - val_accuracy: 0.8363 - val_f1_score: 0.8300\n","Epoch 5/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2756 - accuracy: 0.8883 - f1_score: 0.8874 - val_loss: 0.3846 - val_accuracy: 0.8373 - val_f1_score: 0.8282\n","Epoch 6/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2462 - accuracy: 0.8985 - f1_score: 0.8970 - val_loss: 0.3677 - val_accuracy: 0.8454 - val_f1_score: 0.8469\n","Epoch 7/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2189 - accuracy: 0.9127 - f1_score: 0.9119 - val_loss: 0.4104 - val_accuracy: 0.8291 - val_f1_score: 0.8320\n","Epoch 8/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2056 - accuracy: 0.9193 - f1_score: 0.9187 - val_loss: 0.4384 - val_accuracy: 0.8146 - val_f1_score: 0.8246\n","Epoch 9/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1875 - accuracy: 0.9216 - f1_score: 0.9212 - val_loss: 0.4204 - val_accuracy: 0.8427 - val_f1_score: 0.8317\n","35/35 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8363 - f1_score: 0.8300\n","Epoch 1/20\n","139/139 [==============================] - 10s 22ms/step - loss: 0.5642 - accuracy: 0.7016 - f1_score: 0.6950 - val_loss: 0.4771 - val_accuracy: 0.7631 - val_f1_score: 0.7657\n","Epoch 2/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.4505 - accuracy: 0.7963 - f1_score: 0.7918 - val_loss: 0.4334 - val_accuracy: 0.7920 - val_f1_score: 0.7727\n","Epoch 3/20\n","139/139 [==============================] - 3s 18ms/step - loss: 0.3743 - accuracy: 0.8325 - f1_score: 0.8289 - val_loss: 0.3891 - val_accuracy: 0.8273 - val_f1_score: 0.8196\n","Epoch 4/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.3279 - accuracy: 0.8567 - f1_score: 0.8543 - val_loss: 0.3742 - val_accuracy: 0.8454 - val_f1_score: 0.8319\n","Epoch 5/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2810 - accuracy: 0.8770 - f1_score: 0.8752 - val_loss: 0.3495 - val_accuracy: 0.8499 - val_f1_score: 0.8496\n","Epoch 6/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2558 - accuracy: 0.8874 - f1_score: 0.8861 - val_loss: 0.3540 - val_accuracy: 0.8599 - val_f1_score: 0.8473\n","Epoch 7/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2282 - accuracy: 0.9014 - f1_score: 0.9000 - val_loss: 0.3348 - val_accuracy: 0.8635 - val_f1_score: 0.8590\n","Epoch 8/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2025 - accuracy: 0.9186 - f1_score: 0.9179 - val_loss: 0.3272 - val_accuracy: 0.8734 - val_f1_score: 0.8696\n","Epoch 9/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1757 - accuracy: 0.9315 - f1_score: 0.9311 - val_loss: 0.3696 - val_accuracy: 0.8544 - val_f1_score: 0.8450\n","Epoch 10/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1642 - accuracy: 0.9358 - f1_score: 0.9352 - val_loss: 0.3843 - val_accuracy: 0.8481 - val_f1_score: 0.8497\n","Epoch 11/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.1609 - accuracy: 0.9387 - f1_score: 0.9385 - val_loss: 0.4031 - val_accuracy: 0.8363 - val_f1_score: 0.8457\n","Epoch 12/20\n","139/139 [==============================] - 2s 18ms/step - loss: 0.1359 - accuracy: 0.9507 - f1_score: 0.9505 - val_loss: 0.3877 - val_accuracy: 0.8553 - val_f1_score: 0.8561\n","Epoch 13/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.1298 - accuracy: 0.9487 - f1_score: 0.9485 - val_loss: 0.4275 - val_accuracy: 0.8499 - val_f1_score: 0.8541\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8734 - f1_score: 0.8696\n","Epoch 1/20\n","139/139 [==============================] - 9s 29ms/step - loss: 0.5773 - accuracy: 0.7016 - f1_score: 0.6956 - val_loss: 0.4933 - val_accuracy: 0.7703 - val_f1_score: 0.7699\n","Epoch 2/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.4563 - accuracy: 0.7862 - f1_score: 0.7810 - val_loss: 0.4442 - val_accuracy: 0.7966 - val_f1_score: 0.7867\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3905 - accuracy: 0.8244 - f1_score: 0.8198 - val_loss: 0.4198 - val_accuracy: 0.8156 - val_f1_score: 0.7988\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3346 - accuracy: 0.8492 - f1_score: 0.8450 - val_loss: 0.3894 - val_accuracy: 0.8373 - val_f1_score: 0.8413\n","Epoch 5/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2932 - accuracy: 0.8752 - f1_score: 0.8728 - val_loss: 0.3784 - val_accuracy: 0.8481 - val_f1_score: 0.8444\n","Epoch 6/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2606 - accuracy: 0.8922 - f1_score: 0.8904 - val_loss: 0.4006 - val_accuracy: 0.8391 - val_f1_score: 0.8245\n","Epoch 7/20\n","139/139 [==============================] - 1s 10ms/step - loss: 0.2340 - accuracy: 0.9046 - f1_score: 0.9030 - val_loss: 0.3857 - val_accuracy: 0.8553 - val_f1_score: 0.8499\n","Epoch 8/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2042 - accuracy: 0.9114 - f1_score: 0.9101 - val_loss: 0.4290 - val_accuracy: 0.8526 - val_f1_score: 0.8528\n","Epoch 9/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.1918 - accuracy: 0.9229 - f1_score: 0.9224 - val_loss: 0.4003 - val_accuracy: 0.8472 - val_f1_score: 0.8422\n","Epoch 10/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.1861 - accuracy: 0.9279 - f1_score: 0.9273 - val_loss: 0.4359 - val_accuracy: 0.8544 - val_f1_score: 0.8444\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8481 - f1_score: 0.8444\n","Epoch 1/20\n","139/139 [==============================] - 11s 37ms/step - loss: 0.5732 - accuracy: 0.7064 - f1_score: 0.6997 - val_loss: 0.4922 - val_accuracy: 0.7532 - val_f1_score: 0.7422\n","Epoch 2/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.4697 - accuracy: 0.7801 - f1_score: 0.7709 - val_loss: 0.4533 - val_accuracy: 0.7812 - val_f1_score: 0.7910\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3986 - accuracy: 0.8219 - f1_score: 0.8169 - val_loss: 0.4029 - val_accuracy: 0.8128 - val_f1_score: 0.7969\n","Epoch 4/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.3456 - accuracy: 0.8571 - f1_score: 0.8536 - val_loss: 0.3747 - val_accuracy: 0.8354 - val_f1_score: 0.8321\n","Epoch 5/20\n","139/139 [==============================] - 2s 13ms/step - loss: 0.2966 - accuracy: 0.8732 - f1_score: 0.8703 - val_loss: 0.3786 - val_accuracy: 0.8445 - val_f1_score: 0.8462\n","Epoch 6/20\n","139/139 [==============================] - 1s 11ms/step - loss: 0.2657 - accuracy: 0.8920 - f1_score: 0.8909 - val_loss: 0.3858 - val_accuracy: 0.8626 - val_f1_score: 0.8657\n","Epoch 7/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.2266 - accuracy: 0.9132 - f1_score: 0.9120 - val_loss: 0.3910 - val_accuracy: 0.8635 - val_f1_score: 0.8658\n","Epoch 8/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.2124 - accuracy: 0.9103 - f1_score: 0.9093 - val_loss: 0.4065 - val_accuracy: 0.8562 - val_f1_score: 0.8574\n","Epoch 9/20\n","139/139 [==============================] - 3s 21ms/step - loss: 0.1939 - accuracy: 0.9211 - f1_score: 0.9204 - val_loss: 0.4380 - val_accuracy: 0.8644 - val_f1_score: 0.8677\n","35/35 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8354 - f1_score: 0.8321\n","Epoch 1/20\n","139/139 [==============================] - 9s 21ms/step - loss: 0.5657 - accuracy: 0.7066 - f1_score: 0.7017 - val_loss: 0.4749 - val_accuracy: 0.7568 - val_f1_score: 0.7734\n","Epoch 2/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.4582 - accuracy: 0.7882 - f1_score: 0.7831 - val_loss: 0.4215 - val_accuracy: 0.8165 - val_f1_score: 0.8146\n","Epoch 3/20\n","139/139 [==============================] - 2s 14ms/step - loss: 0.3975 - accuracy: 0.8180 - f1_score: 0.8126 - val_loss: 0.3857 - val_accuracy: 0.8327 - val_f1_score: 0.8317\n","Epoch 4/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.3351 - accuracy: 0.8569 - f1_score: 0.8536 - val_loss: 0.3649 - val_accuracy: 0.8517 - val_f1_score: 0.8509\n","Epoch 5/20\n","139/139 [==============================] - 2s 16ms/step - loss: 0.2905 - accuracy: 0.8827 - f1_score: 0.8804 - val_loss: 0.3536 - val_accuracy: 0.8553 - val_f1_score: 0.8524\n","Epoch 6/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2554 - accuracy: 0.8976 - f1_score: 0.8959 - val_loss: 0.3830 - val_accuracy: 0.8436 - val_f1_score: 0.8520\n","Epoch 7/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2302 - accuracy: 0.9094 - f1_score: 0.9083 - val_loss: 0.3513 - val_accuracy: 0.8544 - val_f1_score: 0.8596\n","Epoch 8/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2115 - accuracy: 0.9141 - f1_score: 0.9133 - val_loss: 0.3661 - val_accuracy: 0.8562 - val_f1_score: 0.8548\n","Epoch 9/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1957 - accuracy: 0.9216 - f1_score: 0.9206 - val_loss: 0.3811 - val_accuracy: 0.8644 - val_f1_score: 0.8596\n","Epoch 10/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1713 - accuracy: 0.9363 - f1_score: 0.9356 - val_loss: 0.3732 - val_accuracy: 0.8689 - val_f1_score: 0.8669\n","Epoch 11/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.1670 - accuracy: 0.9367 - f1_score: 0.9363 - val_loss: 0.3857 - val_accuracy: 0.8662 - val_f1_score: 0.8647\n","Epoch 12/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.1524 - accuracy: 0.9387 - f1_score: 0.9383 - val_loss: 0.3746 - val_accuracy: 0.8752 - val_f1_score: 0.8729\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8544 - f1_score: 0.8596\n","Epoch 1/20\n","139/139 [==============================] - 9s 28ms/step - loss: 0.5691 - accuracy: 0.7064 - f1_score: 0.6973 - val_loss: 0.4932 - val_accuracy: 0.7649 - val_f1_score: 0.7461\n","Epoch 2/20\n","139/139 [==============================] - 2s 15ms/step - loss: 0.4596 - accuracy: 0.7923 - f1_score: 0.7856 - val_loss: 0.4575 - val_accuracy: 0.7812 - val_f1_score: 0.7531\n","Epoch 3/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3841 - accuracy: 0.8300 - f1_score: 0.8243 - val_loss: 0.4042 - val_accuracy: 0.8192 - val_f1_score: 0.8000\n","Epoch 4/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.3337 - accuracy: 0.8594 - f1_score: 0.8558 - val_loss: 0.3752 - val_accuracy: 0.8327 - val_f1_score: 0.8304\n","Epoch 5/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2825 - accuracy: 0.8813 - f1_score: 0.8788 - val_loss: 0.3820 - val_accuracy: 0.8418 - val_f1_score: 0.8248\n","Epoch 6/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2577 - accuracy: 0.8910 - f1_score: 0.8893 - val_loss: 0.3551 - val_accuracy: 0.8590 - val_f1_score: 0.8511\n","Epoch 7/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.2320 - accuracy: 0.9087 - f1_score: 0.9075 - val_loss: 0.3662 - val_accuracy: 0.8535 - val_f1_score: 0.8445\n","Epoch 8/20\n","139/139 [==============================] - 2s 11ms/step - loss: 0.2181 - accuracy: 0.9123 - f1_score: 0.9115 - val_loss: 0.3713 - val_accuracy: 0.8571 - val_f1_score: 0.8614\n","Epoch 9/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.1918 - accuracy: 0.9189 - f1_score: 0.9182 - val_loss: 0.3766 - val_accuracy: 0.8590 - val_f1_score: 0.8531\n","Epoch 10/20\n","139/139 [==============================] - 2s 17ms/step - loss: 0.1704 - accuracy: 0.9311 - f1_score: 0.9305 - val_loss: 0.4172 - val_accuracy: 0.8580 - val_f1_score: 0.8587\n","Epoch 11/20\n","139/139 [==============================] - 2s 12ms/step - loss: 0.1677 - accuracy: 0.9342 - f1_score: 0.9336 - val_loss: 0.4561 - val_accuracy: 0.8282 - val_f1_score: 0.8422\n","35/35 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8590 - f1_score: 0.8511\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjABEI6qLr5T","executionInfo":{"status":"ok","timestamp":1689755201312,"user_tz":-330,"elapsed":481,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e4aa2c1b-2b03-4748-991f-4165d0efba34"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8643761277198792, 0.8607594966888428, 0.865280270576477, 0.849005401134491, 0.8562387228012085, 0.8616636395454407, 0.8725135326385498, 0.8562387228012085, 0.8471971154212952, 0.8426762819290161, 0.876130223274231, 0.85352623462677, 0.8634719848632812, 0.8679927587509155, 0.8643761277198792, 0.870705246925354, 0.831826388835907, 0.870705246925354, 0.8517178893089294, 0.836347222328186, 0.8734177350997925, 0.8481012582778931, 0.8354430198669434, 0.8544303774833679, 0.8589511513710022]\n","0.8573236870765686\n","0.012076536348642516\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uiahc2vrLs-u","executionInfo":{"status":"ok","timestamp":1689755201313,"user_tz":-330,"elapsed":6,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"96029e28-b4e6-4918-a975-5f53d43225dc"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.3092760443687439, 0.3389960527420044, 0.3236505091190338, 0.3535382151603699, 0.3690081536769867, 0.31447532773017883, 0.3295382857322693, 0.36832186579704285, 0.37036189436912537, 0.35482439398765564, 0.3089678883552551, 0.36913132667541504, 0.3397783041000366, 0.3270407021045685, 0.3179032802581787, 0.29364603757858276, 0.38387590646743774, 0.3773585855960846, 0.3739812672138214, 0.3665670156478882, 0.32715392112731934, 0.37840840220451355, 0.37466001510620117, 0.35131561756134033, 0.35511690378189087]\n","0.3470758366584778\n","0.025834867749970767\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKqV7KpzLtBK","executionInfo":{"status":"ok","timestamp":1689755201313,"user_tz":-330,"elapsed":5,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"72764116-1b95-44d0-fc97-95f36536c568"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8631386160850525, 0.8524903655052185, 0.8649137616157532, 0.8463660478591919, 0.8579087853431702, 0.8610353469848633, 0.8733153343200684, 0.8596645593643188, 0.8467814326286316, 0.8412408232688904, 0.8753412365913391, 0.8524590134620667, 0.8652988076210022, 0.8638059496879578, 0.8592869639396667, 0.8628954291343689, 0.8194173574447632, 0.8708219528198242, 0.84870845079422, 0.8300468921661377, 0.8696460723876953, 0.8444444537162781, 0.8321032524108887, 0.85963374376297, 0.8511449694633484]\n","0.8548763847351074\n","0.01364361567939674\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"i1C9nlrPM1Y3","executionInfo":{"status":"ok","timestamp":1689755201313,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":58,"outputs":[]}]}