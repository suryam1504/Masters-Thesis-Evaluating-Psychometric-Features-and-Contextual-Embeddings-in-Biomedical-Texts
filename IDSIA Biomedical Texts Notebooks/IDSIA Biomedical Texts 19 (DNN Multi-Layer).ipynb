{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1IYbfZ_1Jz_Zz_Nste8XZVyx-DtbZ6dhC","timestamp":1689251454232}],"collapsed_sections":["tdUDrGzdEl7k","RAx7dPPztUVD"],"gpuType":"T4","authorship_tag":"ABX9TyMmU/U4tAkAOnuIL+vsiWTj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOGWrTXxBSrw","executionInfo":{"status":"ok","timestamp":1689673767005,"user_tz":-330,"elapsed":25916,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"dba03351-baef-40f9-a682-9f334c3b1b14"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle"],"metadata":{"id":"KUCXpS2KBSuR","executionInfo":{"status":"ok","timestamp":1689673767007,"user_tz":-330,"elapsed":11,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/IDSIA Biomedical Texts/AllSource_Intensity_ThirdJuly.csv', low_memory=False)\n","df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"Fw0c27kmBSwz","executionInfo":{"status":"ok","timestamp":1689673769556,"user_tz":-330,"elapsed":2557,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d0597d46-8d31-47ef-8c2c-aa92f77c7e55"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                urls  \\\n","0  https://www.quora.com/What-are-panic-attacks-l...   \n","\n","                                                text source  label   WC  \\\n","0  i have been dealing with these for quite some ...  Quora      1  607   \n","\n","   Analytic  Clout  Authentic  Tone    WPS  ...  \\\n","0     55.22  35.35      48.82   1.0  26.39  ...   \n","\n","                                      all_emo_labels  \\\n","0  ['fear', 'nervousness', 'confusion', 'curiosit...   \n","\n","                                  all_emo_label_rank  anger_intensity  \\\n","0  {'fear': 1, 'nervousness': 2, 'confusion': 3, ...         0.415048   \n","\n","   anticipation_intensity  disgust_intensity  fear_intensity  joy_intensity  \\\n","0                0.553423           0.272333        0.568205         0.4095   \n","\n","   sadness_intensity  surprise_intensity  trust_intensity  \n","0           0.467625              0.4345         0.522773  \n","\n","[1 rows x 165 columns]"],"text/html":["\n","\n","  <div id=\"df-18dadcad-9d68-472c-9556-bdec73996551\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>urls</th>\n","      <th>text</th>\n","      <th>source</th>\n","      <th>label</th>\n","      <th>WC</th>\n","      <th>Analytic</th>\n","      <th>Clout</th>\n","      <th>Authentic</th>\n","      <th>Tone</th>\n","      <th>WPS</th>\n","      <th>...</th>\n","      <th>all_emo_labels</th>\n","      <th>all_emo_label_rank</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.quora.com/What-are-panic-attacks-l...</td>\n","      <td>i have been dealing with these for quite some ...</td>\n","      <td>Quora</td>\n","      <td>1</td>\n","      <td>607</td>\n","      <td>55.22</td>\n","      <td>35.35</td>\n","      <td>48.82</td>\n","      <td>1.0</td>\n","      <td>26.39</td>\n","      <td>...</td>\n","      <td>['fear', 'nervousness', 'confusion', 'curiosit...</td>\n","      <td>{'fear': 1, 'nervousness': 2, 'confusion': 3, ...</td>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.4095</td>\n","      <td>0.467625</td>\n","      <td>0.4345</td>\n","      <td>0.522773</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows Ã— 165 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18dadcad-9d68-472c-9556-bdec73996551')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-36cfae94-cc22-4fc6-ad12-8cd4f50814de\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36cfae94-cc22-4fc6-ad12-8cd4f50814de')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-36cfae94-cc22-4fc6-ad12-8cd4f50814de button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-18dadcad-9d68-472c-9556-bdec73996551 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-18dadcad-9d68-472c-9556-bdec73996551');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":[],"metadata":{"id":"4tkOnPZOb_dV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[['source','label']].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03o1CICyEVSd","executionInfo":{"status":"ok","timestamp":1689673769557,"user_tz":-330,"elapsed":56,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"79a28fc3-8d05-41fe-a6f8-b3db46f6a716"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["source                 label\n","www.nomorepanic.co.uk  1        3815\n","Beyond Blue Forums     0        1040\n","Quora                  0         978\n","                       1         578\n","anxietycommunity       0         489\n","Reddit                 0         258\n","                       1         247\n","dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df[['label']].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rkeu-0nfEqzi","executionInfo":{"status":"ok","timestamp":1689673769558,"user_tz":-330,"elapsed":44,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"5dfd9f2a-1dab-4d9d-f2f3-7e6fb1e61d07"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label\n","1        4640\n","0        2765\n","dtype: int64"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df[df['source'] == 'Reddit']['label'].value_counts()"],"metadata":{"id":"SOpl8glGBSzE","executionInfo":{"status":"ok","timestamp":1689673769559,"user_tz":-330,"elapsed":38,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99894fb8-9f2f-4712-b9f3-7deda39b2ebf"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    258\n","1    247\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["df[df['source'] == 'Quora']['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQFnI9x3D8Hx","executionInfo":{"status":"ok","timestamp":1689673769560,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"00ea3407-eaf8-4e7a-d479-778c58a16717"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    978\n","1    578\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"tMBKb1dBD8LG","executionInfo":{"status":"ok","timestamp":1689673769562,"user_tz":-330,"elapsed":28,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"egSGaO2xD8jP","executionInfo":{"status":"ok","timestamp":1689673769563,"user_tz":-330,"elapsed":27,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0YbifdMFD8nN","executionInfo":{"status":"ok","timestamp":1689673769564,"user_tz":-330,"elapsed":27,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Getting 2 panic features"],"metadata":{"id":"n55rdafbBW4b"}},{"cell_type":"code","source":["import regex as re"],"metadata":{"id":"QRTPOdlpBS1u","executionInfo":{"status":"ok","timestamp":1689673769565,"user_tz":-330,"elapsed":27,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["panic_symptoms = [\"Palpitations\", \"Pounding heart\", \"Accelerated heart rate\", \"Sweating\", \"Trembling\", \"Shaking\", \"Shortness of breath\",\n","\"Smothering\", \"Feelings of choking\", \"Chest pain\", \"Discomfort\", \"Abdominal distress\", \"Nausea\", \"Dizziness\", \"Unsteadiness\", \"Lightheadedness\",\n","\"Faintness\", \"Chills\", \"Heat flashes\", \"Paresthesia\", \"Numbness\", \"Tingling sensations\", \"Derealization\", \"Depersonalization\", \"Fear of losing control\",\n","\"Fear of going crazy\", \"Fear of dying\", \"Mental images of dying\", \"Mental images of collapsing\", \"Agoraphobia\", \"Need to escape\"]\n","\n","\n","panic_symptoms_ext = [\"Palpitations\", \"Pounding heart\", \"Accelerated heart rate\", \"Sweating\", \"Trembling\", \"Shaking\", \"Shortness of breath\",\n","\"Smothering\", \"Feelings of choking\", \"Chest pain\", \"Discomfort\", \"Abdominal distress\", \"Nausea\", \"Dizziness\", \"Unsteadiness\", \"Lightheadedness\",\n","\"Faintness\", \"Chills\", \"Heat flashes\", \"Paresthesia\", \"Numbness\", \"Tingling sensations\", \"Derealization\", \"Depersonalization\", \"Fear of losing control\",\n","\"Fear of going crazy\", \"Fear of dying\", \"Mental images of dying\", \"Mental images of collapsing\", \"Agoraphobia\", \"Need to escape\"\n","\"Sweat\", \"Tremble\", \"Shake\", \"Shortage of breath\",\"Feeling of choking\",\"Dizzy\",\n","\"Faint\",\"Fainted\",\"Chill\",\"Heat flash\", \"Numb\", \"Tingling sensation\",\"Mental image of dying\", \"Mental image of collapsing\"]"],"metadata":{"id":"wKxLD_EfBS4V","executionInfo":{"status":"ok","timestamp":1689673769566,"user_tz":-330,"elapsed":27,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def count_symptoms_in_text(text, panic_list):\n","    if isinstance(text, str):\n","        count = 0\n","        for symptom in panic_list:\n","            match = re.search(r'\\b{}\\b'.format(symptom), text, re.IGNORECASE)\n","            if match:\n","                count += 1\n","        return count"],"metadata":{"id":"dPOEcWfVBS7I","executionInfo":{"status":"ok","timestamp":1689673769568,"user_tz":-330,"elapsed":28,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df['symptoms_count'] = df['text'].apply(lambda x: count_symptoms_in_text(x,panic_symptoms))\n","df['symptoms_ext_count'] = df['text'].apply(lambda x: count_symptoms_in_text(x,panic_symptoms_ext))"],"metadata":{"id":"2uxxE-cYBS9c","executionInfo":{"status":"ok","timestamp":1689673773848,"user_tz":-330,"elapsed":4307,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cyowFaGABS_8","executionInfo":{"status":"ok","timestamp":1689673773849,"user_tz":-330,"elapsed":55,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GYmldp02BTC1","executionInfo":{"status":"ok","timestamp":1689673773850,"user_tz":-330,"elapsed":48,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["pickle_in = open(\"/content/drive/MyDrive/IDSIA Biomedical Texts/Sentence Embeddings/AllSource_alldistilrobertav1_via_UMAP_SHORTembeddings.pickle\", 'rb')\n","sentence_embeddings = pickle.load(pickle_in)\n","sentence_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mn4x-YGKBTE4","executionInfo":{"status":"ok","timestamp":1689673775710,"user_tz":-330,"elapsed":1906,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"5c0b3071-de1f-48dd-b451-34b2dce661a0"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[10.64194  ,  5.0430765,  5.6824026, ...,  4.9058275,  6.8707986,\n","         4.538727 ],\n","       [11.312859 ,  5.364349 ,  4.41365  , ...,  4.92234  ,  6.8475184,\n","         4.5590596],\n","       [10.531799 ,  4.894456 ,  5.387705 , ...,  4.8968716,  6.8360796,\n","         4.530069 ],\n","       ...,\n","       [10.346373 ,  4.4247556,  3.5815325, ...,  5.0401225,  6.552696 ,\n","         4.490976 ],\n","       [10.454275 ,  4.5640407,  3.6035635, ...,  5.0320673,  6.564847 ,\n","         4.4918733],\n","       [11.222271 ,  5.1468487,  4.0054016, ...,  5.079988 ,  6.6341186,\n","         4.5597043]], dtype=float32)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Normalize sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","from sklearn.preprocessing import MinMaxScaler\n","scaling = MinMaxScaler(feature_range=(0,1))  # (0,1) is default"],"metadata":{"id":"Tqr_S89rBfAu","executionInfo":{"status":"ok","timestamp":1689673776669,"user_tz":-330,"elapsed":968,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["sentence_embeddings = scaling.fit_transform(sentence_embeddings.reshape(-1, 1)).reshape(*sentence_embeddings.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","sentence_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4Pv7n7fBieO","executionInfo":{"status":"ok","timestamp":1689673776670,"user_tz":-330,"elapsed":45,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"c64e6e30-b3a3-443b-c414-f0b5a145fc94"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.8199141 , 0.35134387, 0.40484923, ..., 0.33985746, 0.5043063 ,\n","        0.30913472],\n","       [0.8760634 , 0.37823123, 0.298667  , ..., 0.3412394 , 0.502358  ,\n","        0.31083637],\n","       [0.81069636, 0.33890578, 0.3801859 , ..., 0.33910793, 0.5014007 ,\n","        0.30841014],\n","       ...,\n","       [0.795178  , 0.29959643, 0.22902691, ..., 0.35109666, 0.4776843 ,\n","        0.30513844],\n","       [0.80420834, 0.31125325, 0.2308707 , ..., 0.3504225 , 0.4787012 ,\n","        0.30521354],\n","       [0.8684821 , 0.3600286 , 0.26450062, ..., 0.354433  , 0.4844986 ,\n","        0.31089035]], dtype=float32)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["sentence_embeddings.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZ8d8hQeBigj","executionInfo":{"status":"ok","timestamp":1689673776671,"user_tz":-330,"elapsed":41,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"a1ba492a-6a8c-4090-83aa-e6c89e234614"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7405, 28)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":[],"metadata":{"id":"tGf-ARzTBii6","executionInfo":{"status":"ok","timestamp":1689673776672,"user_tz":-330,"elapsed":34,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Standardization of LIWC features\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()"],"metadata":{"id":"xegiJk-oBild","executionInfo":{"status":"ok","timestamp":1689673776673,"user_tz":-330,"elapsed":34,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["standardized_liwc = sc.fit_transform(df.loc[:, 'WC':'Emoji'])"],"metadata":{"id":"pgbSKbCJBinv","executionInfo":{"status":"ok","timestamp":1689673776674,"user_tz":-330,"elapsed":34,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3Sj0mmu6BiqV","executionInfo":{"status":"ok","timestamp":1689673776675,"user_tz":-330,"elapsed":34,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# normalization of 2 panic features\n","normalized_panic_features = scaling.fit_transform(df[['symptoms_count', 'symptoms_ext_count']])"],"metadata":{"id":"VyK43KkhBist","executionInfo":{"status":"ok","timestamp":1689673776677,"user_tz":-330,"elapsed":35,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GDXPenMNBivJ","executionInfo":{"status":"ok","timestamp":1689673776678,"user_tz":-330,"elapsed":35,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["sentence_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ByyugpGzBthi","executionInfo":{"status":"ok","timestamp":1689673776679,"user_tz":-330,"elapsed":36,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"0386fe53-7d00-417c-a04a-673de42f7398"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.8199141 , 0.35134387, 0.40484923, ..., 0.33985746, 0.5043063 ,\n","        0.30913472],\n","       [0.8760634 , 0.37823123, 0.298667  , ..., 0.3412394 , 0.502358  ,\n","        0.31083637],\n","       [0.81069636, 0.33890578, 0.3801859 , ..., 0.33910793, 0.5014007 ,\n","        0.30841014],\n","       ...,\n","       [0.795178  , 0.29959643, 0.22902691, ..., 0.35109666, 0.4776843 ,\n","        0.30513844],\n","       [0.80420834, 0.31125325, 0.2308707 , ..., 0.3504225 , 0.4787012 ,\n","        0.30521354],\n","       [0.8684821 , 0.3600286 , 0.26450062, ..., 0.354433  , 0.4844986 ,\n","        0.31089035]], dtype=float32)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["sentemb_column_names = [\"sentemb\" + str(i+1) for i in range(28)]"],"metadata":{"id":"ACy2ePKvBtkR","executionInfo":{"status":"ok","timestamp":1689673776680,"user_tz":-330,"elapsed":30,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["sentembdf = pd.DataFrame(sentence_embeddings, columns=sentemb_column_names)\n","sentembdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ihnsLempBtmw","executionInfo":{"status":"ok","timestamp":1689673777370,"user_tz":-330,"elapsed":719,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"848f9a11-c6d7-48a3-d62b-65ef66be85f7"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     0.819914  0.351344  0.404849  0.211062  0.258971  0.257296  0.508351   \n","1     0.876063  0.378231  0.298667  0.214494  0.349709  0.284757  0.438802   \n","2     0.810696  0.338906  0.380186  0.207599  0.268363  0.274065  0.500595   \n","3     0.875869  0.375439  0.291701  0.216481  0.355757  0.287865  0.434504   \n","4     0.849092  0.364154  0.345076  0.144952  0.283609  0.274024  0.446017   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","7400  0.808676  0.343545  0.265276  0.106535  0.323924  0.292145  0.382246   \n","7401  0.824678  0.309808  0.225578  0.204305  0.355065  0.360845  0.426495   \n","7402  0.795178  0.299596  0.229027  0.193240  0.349450  0.343462  0.422839   \n","7403  0.804208  0.311253  0.230871  0.186933  0.347010  0.343995  0.420793   \n","7404  0.868482  0.360029  0.264501  0.211487  0.321134  0.380958  0.462207   \n","\n","      sentemb8  sentemb9  sentemb10  ...  sentemb19  sentemb20  sentemb21  \\\n","0     0.079092  0.046841   0.526339  ...   0.494592   0.289889   0.115539   \n","1     0.078256  0.026417   0.481356  ...   0.536341   0.269954   0.126838   \n","2     0.077948  0.052404   0.508967  ...   0.497243   0.285798   0.115411   \n","3     0.078305  0.024242   0.476598  ...   0.540063   0.268896   0.127621   \n","4     0.077871  0.052790   0.488757  ...   0.520263   0.277368   0.124095   \n","...        ...       ...        ...  ...        ...        ...        ...   \n","7400  0.077382  0.073316   0.436193  ...   0.546514   0.260041   0.122214   \n","7401  0.070627  0.067943   0.404500  ...   0.546183   0.259894   0.116986   \n","7402  0.070439  0.078386   0.409807  ...   0.543561   0.260543   0.115634   \n","7403  0.071775  0.076749   0.414172  ...   0.544412   0.260857   0.116057   \n","7404  0.076063  0.055441   0.440022  ...   0.538552   0.271079   0.117871   \n","\n","      sentemb22  sentemb23  sentemb24  sentemb25  sentemb26  sentemb27  \\\n","0      0.196822   0.428880   0.426222   0.362514   0.339857   0.504306   \n","1      0.195539   0.443481   0.403223   0.353871   0.341239   0.502358   \n","2      0.195277   0.431129   0.421081   0.363387   0.339108   0.501401   \n","3      0.195539   0.443904   0.402204   0.353474   0.342344   0.501798   \n","4      0.195726   0.446654   0.415476   0.357244   0.337169   0.496036   \n","...         ...        ...        ...        ...        ...        ...   \n","7400   0.197972   0.459927   0.397550   0.356333   0.341254   0.485487   \n","7401   0.200168   0.441317   0.389815   0.363444   0.354721   0.477989   \n","7402   0.199547   0.446306   0.389455   0.364519   0.351097   0.477684   \n","7403   0.199328   0.447040   0.390905   0.364248   0.350423   0.478701   \n","7404   0.199776   0.435288   0.404733   0.365934   0.354433   0.484499   \n","\n","      sentemb28  \n","0      0.309135  \n","1      0.310836  \n","2      0.308410  \n","3      0.311278  \n","4      0.308303  \n","...         ...  \n","7400   0.303029  \n","7401   0.306945  \n","7402   0.305138  \n","7403   0.305214  \n","7404   0.310890  \n","\n","[7405 rows x 28 columns]"],"text/html":["\n","\n","  <div id=\"df-67039de7-c725-4d84-9db6-c87c5a2026b5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>sentemb19</th>\n","      <th>sentemb20</th>\n","      <th>sentemb21</th>\n","      <th>sentemb22</th>\n","      <th>sentemb23</th>\n","      <th>sentemb24</th>\n","      <th>sentemb25</th>\n","      <th>sentemb26</th>\n","      <th>sentemb27</th>\n","      <th>sentemb28</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.819914</td>\n","      <td>0.351344</td>\n","      <td>0.404849</td>\n","      <td>0.211062</td>\n","      <td>0.258971</td>\n","      <td>0.257296</td>\n","      <td>0.508351</td>\n","      <td>0.079092</td>\n","      <td>0.046841</td>\n","      <td>0.526339</td>\n","      <td>...</td>\n","      <td>0.494592</td>\n","      <td>0.289889</td>\n","      <td>0.115539</td>\n","      <td>0.196822</td>\n","      <td>0.428880</td>\n","      <td>0.426222</td>\n","      <td>0.362514</td>\n","      <td>0.339857</td>\n","      <td>0.504306</td>\n","      <td>0.309135</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.876063</td>\n","      <td>0.378231</td>\n","      <td>0.298667</td>\n","      <td>0.214494</td>\n","      <td>0.349709</td>\n","      <td>0.284757</td>\n","      <td>0.438802</td>\n","      <td>0.078256</td>\n","      <td>0.026417</td>\n","      <td>0.481356</td>\n","      <td>...</td>\n","      <td>0.536341</td>\n","      <td>0.269954</td>\n","      <td>0.126838</td>\n","      <td>0.195539</td>\n","      <td>0.443481</td>\n","      <td>0.403223</td>\n","      <td>0.353871</td>\n","      <td>0.341239</td>\n","      <td>0.502358</td>\n","      <td>0.310836</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.810696</td>\n","      <td>0.338906</td>\n","      <td>0.380186</td>\n","      <td>0.207599</td>\n","      <td>0.268363</td>\n","      <td>0.274065</td>\n","      <td>0.500595</td>\n","      <td>0.077948</td>\n","      <td>0.052404</td>\n","      <td>0.508967</td>\n","      <td>...</td>\n","      <td>0.497243</td>\n","      <td>0.285798</td>\n","      <td>0.115411</td>\n","      <td>0.195277</td>\n","      <td>0.431129</td>\n","      <td>0.421081</td>\n","      <td>0.363387</td>\n","      <td>0.339108</td>\n","      <td>0.501401</td>\n","      <td>0.308410</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.875869</td>\n","      <td>0.375439</td>\n","      <td>0.291701</td>\n","      <td>0.216481</td>\n","      <td>0.355757</td>\n","      <td>0.287865</td>\n","      <td>0.434504</td>\n","      <td>0.078305</td>\n","      <td>0.024242</td>\n","      <td>0.476598</td>\n","      <td>...</td>\n","      <td>0.540063</td>\n","      <td>0.268896</td>\n","      <td>0.127621</td>\n","      <td>0.195539</td>\n","      <td>0.443904</td>\n","      <td>0.402204</td>\n","      <td>0.353474</td>\n","      <td>0.342344</td>\n","      <td>0.501798</td>\n","      <td>0.311278</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.849092</td>\n","      <td>0.364154</td>\n","      <td>0.345076</td>\n","      <td>0.144952</td>\n","      <td>0.283609</td>\n","      <td>0.274024</td>\n","      <td>0.446017</td>\n","      <td>0.077871</td>\n","      <td>0.052790</td>\n","      <td>0.488757</td>\n","      <td>...</td>\n","      <td>0.520263</td>\n","      <td>0.277368</td>\n","      <td>0.124095</td>\n","      <td>0.195726</td>\n","      <td>0.446654</td>\n","      <td>0.415476</td>\n","      <td>0.357244</td>\n","      <td>0.337169</td>\n","      <td>0.496036</td>\n","      <td>0.308303</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.808676</td>\n","      <td>0.343545</td>\n","      <td>0.265276</td>\n","      <td>0.106535</td>\n","      <td>0.323924</td>\n","      <td>0.292145</td>\n","      <td>0.382246</td>\n","      <td>0.077382</td>\n","      <td>0.073316</td>\n","      <td>0.436193</td>\n","      <td>...</td>\n","      <td>0.546514</td>\n","      <td>0.260041</td>\n","      <td>0.122214</td>\n","      <td>0.197972</td>\n","      <td>0.459927</td>\n","      <td>0.397550</td>\n","      <td>0.356333</td>\n","      <td>0.341254</td>\n","      <td>0.485487</td>\n","      <td>0.303029</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.824678</td>\n","      <td>0.309808</td>\n","      <td>0.225578</td>\n","      <td>0.204305</td>\n","      <td>0.355065</td>\n","      <td>0.360845</td>\n","      <td>0.426495</td>\n","      <td>0.070627</td>\n","      <td>0.067943</td>\n","      <td>0.404500</td>\n","      <td>...</td>\n","      <td>0.546183</td>\n","      <td>0.259894</td>\n","      <td>0.116986</td>\n","      <td>0.200168</td>\n","      <td>0.441317</td>\n","      <td>0.389815</td>\n","      <td>0.363444</td>\n","      <td>0.354721</td>\n","      <td>0.477989</td>\n","      <td>0.306945</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.795178</td>\n","      <td>0.299596</td>\n","      <td>0.229027</td>\n","      <td>0.193240</td>\n","      <td>0.349450</td>\n","      <td>0.343462</td>\n","      <td>0.422839</td>\n","      <td>0.070439</td>\n","      <td>0.078386</td>\n","      <td>0.409807</td>\n","      <td>...</td>\n","      <td>0.543561</td>\n","      <td>0.260543</td>\n","      <td>0.115634</td>\n","      <td>0.199547</td>\n","      <td>0.446306</td>\n","      <td>0.389455</td>\n","      <td>0.364519</td>\n","      <td>0.351097</td>\n","      <td>0.477684</td>\n","      <td>0.305138</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.804208</td>\n","      <td>0.311253</td>\n","      <td>0.230871</td>\n","      <td>0.186933</td>\n","      <td>0.347010</td>\n","      <td>0.343995</td>\n","      <td>0.420793</td>\n","      <td>0.071775</td>\n","      <td>0.076749</td>\n","      <td>0.414172</td>\n","      <td>...</td>\n","      <td>0.544412</td>\n","      <td>0.260857</td>\n","      <td>0.116057</td>\n","      <td>0.199328</td>\n","      <td>0.447040</td>\n","      <td>0.390905</td>\n","      <td>0.364248</td>\n","      <td>0.350423</td>\n","      <td>0.478701</td>\n","      <td>0.305214</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.868482</td>\n","      <td>0.360029</td>\n","      <td>0.264501</td>\n","      <td>0.211487</td>\n","      <td>0.321134</td>\n","      <td>0.380958</td>\n","      <td>0.462207</td>\n","      <td>0.076063</td>\n","      <td>0.055441</td>\n","      <td>0.440022</td>\n","      <td>...</td>\n","      <td>0.538552</td>\n","      <td>0.271079</td>\n","      <td>0.117871</td>\n","      <td>0.199776</td>\n","      <td>0.435288</td>\n","      <td>0.404733</td>\n","      <td>0.365934</td>\n","      <td>0.354433</td>\n","      <td>0.484499</td>\n","      <td>0.310890</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 28 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67039de7-c725-4d84-9db6-c87c5a2026b5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-86aff5cc-f60b-4a6f-ae44-f6cf00655927\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86aff5cc-f60b-4a6f-ae44-f6cf00655927')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-86aff5cc-f60b-4a6f-ae44-f6cf00655927 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-67039de7-c725-4d84-9db6-c87c5a2026b5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-67039de7-c725-4d84-9db6-c87c5a2026b5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[],"metadata":{"id":"jrDo5wy0Btpe","executionInfo":{"status":"ok","timestamp":1689673777374,"user_tz":-330,"elapsed":719,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["standardized_liwc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnxD5d_gBtr7","executionInfo":{"status":"ok","timestamp":1689673777376,"user_tz":-330,"elapsed":80,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"7d813192-2fbe-4d85-d601-2c982c1e7e37"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 3.67802528,  0.98063234, -0.11115907, ...,  0.13908545,\n","        -0.12035728,  0.17485002],\n","       [ 2.12422261,  0.93614355, -1.01518881, ..., -0.32861383,\n","        -0.30797786, -0.05320853],\n","       [ 2.46364552, -0.16631989,  1.42946272, ...,  0.82624363,\n","        -0.23487893, -0.05320853],\n","       ...,\n","       [-0.75710077,  0.25671387, -0.96127635, ..., -0.86826685,\n","        -0.30797786, -0.05320853],\n","       [-0.61378887,  0.25671387,  1.36359921, ..., -0.86826685,\n","        -0.30797786,  1.76434898],\n","       [ 0.50253537, -0.1292459 ,  0.3546659 , ..., -0.47971667,\n","        -0.13335265, -0.05320853]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["liwc_column_names = list(df.loc[:, 'WC':'Emoji'].columns)"],"metadata":{"id":"tAKHMDrEBtug","executionInfo":{"status":"ok","timestamp":1689673777377,"user_tz":-330,"elapsed":76,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["stdliwcdf = pd.DataFrame(standardized_liwc, columns=liwc_column_names)\n","stdliwcdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"p6l62oFpBtw9","executionInfo":{"status":"ok","timestamp":1689673777379,"user_tz":-330,"elapsed":77,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"edd97130-9eb1-4e76-c7ae-629b92b53f84"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            WC  Analytic     Clout  Authentic      Tone       WPS  BigWords  \\\n","0     3.678025  0.980632 -0.111159  -0.503463 -0.906085  0.507052  1.316973   \n","1     2.124223  0.936144 -1.015189   0.979755 -0.703811 -0.305294 -0.124287   \n","2     2.463646 -0.166320  1.429463   0.293715 -0.906085 -0.375792  0.031591   \n","3     3.059521  0.021001 -0.971103   0.892855 -0.749503 -0.201164 -0.350683   \n","4     1.535890 -0.332567 -1.023422   0.979755 -0.902879 -0.329225  0.032829   \n","...        ...       ...       ...        ...       ...       ...       ...   \n","7400  0.887215 -0.969850 -0.505012  -0.373113 -0.518371 -0.104795  0.415103   \n","7401 -0.749558  0.374960 -1.023422  -1.102307  1.712520  0.093764  1.210579   \n","7402 -0.757101  0.256714 -0.961276   0.130851  1.712520  0.029087  0.721912   \n","7403 -0.613789  0.256714  1.363599  -0.953040  1.532692  0.029087  0.721912   \n","7404  0.502535 -0.129246  0.354666   0.609689 -0.868944  0.303965  0.046437   \n","\n","           Dic  Linguistic  function  ...    nonflu    filler   AllPunc  \\\n","0     0.342227   -0.601720 -0.018291  ... -0.181918 -0.109396  0.094036   \n","1    -0.340482    0.082425  0.466392  ... -0.181918 -0.109396 -0.338164   \n","2     0.709276    0.143365  0.234690  ... -0.181918 -0.109396 -0.129423   \n","3    -0.186322   -0.087749 -0.128231  ...  2.806013 -0.109396  0.200414   \n","4     0.298182    0.202006  0.394281  ... -0.181918 -0.109396 -0.017025   \n","...        ...         ...       ...  ...       ...       ...       ...   \n","7400  0.252301    0.893050  0.616526  ... -0.181918 -0.109396 -0.561623   \n","7401  0.573468   -1.045551 -2.087060  ... -0.181918 -0.109396 -1.239361   \n","7402  0.525752   -0.047505 -1.215812  ... -0.181918 -0.109396 -1.239361   \n","7403  1.008420   -1.257118 -0.594000  ... -0.181918 -0.109396 -1.063404   \n","7404  1.195615    0.567650  0.493582  ... -0.181918 -0.109396 -0.376299   \n","\n","        Period     Comma     QMark    Exclam   Apostro    OtherP     Emoji  \n","0    -0.364488  1.739462 -0.232106 -0.240709  0.139085 -0.120357  0.174850  \n","1     0.031678  0.330742 -0.184911 -0.271948 -0.328614 -0.307978 -0.053209  \n","2     0.213881 -0.231101 -0.200643 -0.271948  0.826244 -0.234879 -0.053209  \n","3    -0.244134  0.388297  0.281791 -0.271948  1.531390 -0.029390 -0.053209  \n","4     0.055080  0.218374  0.171670 -0.271948  1.024116 -0.257621 -0.053209  \n","...        ...       ...       ...       ...       ...       ...       ...  \n","7400 -0.217388 -0.505171 -0.316007 -0.271948  0.041948 -0.273865 -0.053209  \n","7401 -1.135089 -0.968349 -0.316007 -0.271948 -0.868267 -0.307978 -0.053209  \n","7402 -1.135089 -0.968349 -0.316007 -0.271948 -0.868267 -0.307978 -0.053209  \n","7403 -0.695462 -0.968349 -0.316007 -0.271948 -0.868267 -0.307978  1.764349  \n","7404 -0.506573  0.506147 -0.316007 -0.166515 -0.479717 -0.133353 -0.053209  \n","\n","[7405 rows x 118 columns]"],"text/html":["\n","\n","  <div id=\"df-218cd940-ed54-44a2-9076-db482c19a1e5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>WC</th>\n","      <th>Analytic</th>\n","      <th>Clout</th>\n","      <th>Authentic</th>\n","      <th>Tone</th>\n","      <th>WPS</th>\n","      <th>BigWords</th>\n","      <th>Dic</th>\n","      <th>Linguistic</th>\n","      <th>function</th>\n","      <th>...</th>\n","      <th>nonflu</th>\n","      <th>filler</th>\n","      <th>AllPunc</th>\n","      <th>Period</th>\n","      <th>Comma</th>\n","      <th>QMark</th>\n","      <th>Exclam</th>\n","      <th>Apostro</th>\n","      <th>OtherP</th>\n","      <th>Emoji</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.678025</td>\n","      <td>0.980632</td>\n","      <td>-0.111159</td>\n","      <td>-0.503463</td>\n","      <td>-0.906085</td>\n","      <td>0.507052</td>\n","      <td>1.316973</td>\n","      <td>0.342227</td>\n","      <td>-0.601720</td>\n","      <td>-0.018291</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>0.094036</td>\n","      <td>-0.364488</td>\n","      <td>1.739462</td>\n","      <td>-0.232106</td>\n","      <td>-0.240709</td>\n","      <td>0.139085</td>\n","      <td>-0.120357</td>\n","      <td>0.174850</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.124223</td>\n","      <td>0.936144</td>\n","      <td>-1.015189</td>\n","      <td>0.979755</td>\n","      <td>-0.703811</td>\n","      <td>-0.305294</td>\n","      <td>-0.124287</td>\n","      <td>-0.340482</td>\n","      <td>0.082425</td>\n","      <td>0.466392</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-0.338164</td>\n","      <td>0.031678</td>\n","      <td>0.330742</td>\n","      <td>-0.184911</td>\n","      <td>-0.271948</td>\n","      <td>-0.328614</td>\n","      <td>-0.307978</td>\n","      <td>-0.053209</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.463646</td>\n","      <td>-0.166320</td>\n","      <td>1.429463</td>\n","      <td>0.293715</td>\n","      <td>-0.906085</td>\n","      <td>-0.375792</td>\n","      <td>0.031591</td>\n","      <td>0.709276</td>\n","      <td>0.143365</td>\n","      <td>0.234690</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-0.129423</td>\n","      <td>0.213881</td>\n","      <td>-0.231101</td>\n","      <td>-0.200643</td>\n","      <td>-0.271948</td>\n","      <td>0.826244</td>\n","      <td>-0.234879</td>\n","      <td>-0.053209</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.059521</td>\n","      <td>0.021001</td>\n","      <td>-0.971103</td>\n","      <td>0.892855</td>\n","      <td>-0.749503</td>\n","      <td>-0.201164</td>\n","      <td>-0.350683</td>\n","      <td>-0.186322</td>\n","      <td>-0.087749</td>\n","      <td>-0.128231</td>\n","      <td>...</td>\n","      <td>2.806013</td>\n","      <td>-0.109396</td>\n","      <td>0.200414</td>\n","      <td>-0.244134</td>\n","      <td>0.388297</td>\n","      <td>0.281791</td>\n","      <td>-0.271948</td>\n","      <td>1.531390</td>\n","      <td>-0.029390</td>\n","      <td>-0.053209</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.535890</td>\n","      <td>-0.332567</td>\n","      <td>-1.023422</td>\n","      <td>0.979755</td>\n","      <td>-0.902879</td>\n","      <td>-0.329225</td>\n","      <td>0.032829</td>\n","      <td>0.298182</td>\n","      <td>0.202006</td>\n","      <td>0.394281</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-0.017025</td>\n","      <td>0.055080</td>\n","      <td>0.218374</td>\n","      <td>0.171670</td>\n","      <td>-0.271948</td>\n","      <td>1.024116</td>\n","      <td>-0.257621</td>\n","      <td>-0.053209</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.887215</td>\n","      <td>-0.969850</td>\n","      <td>-0.505012</td>\n","      <td>-0.373113</td>\n","      <td>-0.518371</td>\n","      <td>-0.104795</td>\n","      <td>0.415103</td>\n","      <td>0.252301</td>\n","      <td>0.893050</td>\n","      <td>0.616526</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-0.561623</td>\n","      <td>-0.217388</td>\n","      <td>-0.505171</td>\n","      <td>-0.316007</td>\n","      <td>-0.271948</td>\n","      <td>0.041948</td>\n","      <td>-0.273865</td>\n","      <td>-0.053209</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>-0.749558</td>\n","      <td>0.374960</td>\n","      <td>-1.023422</td>\n","      <td>-1.102307</td>\n","      <td>1.712520</td>\n","      <td>0.093764</td>\n","      <td>1.210579</td>\n","      <td>0.573468</td>\n","      <td>-1.045551</td>\n","      <td>-2.087060</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-1.239361</td>\n","      <td>-1.135089</td>\n","      <td>-0.968349</td>\n","      <td>-0.316007</td>\n","      <td>-0.271948</td>\n","      <td>-0.868267</td>\n","      <td>-0.307978</td>\n","      <td>-0.053209</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>-0.757101</td>\n","      <td>0.256714</td>\n","      <td>-0.961276</td>\n","      <td>0.130851</td>\n","      <td>1.712520</td>\n","      <td>0.029087</td>\n","      <td>0.721912</td>\n","      <td>0.525752</td>\n","      <td>-0.047505</td>\n","      <td>-1.215812</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-1.239361</td>\n","      <td>-1.135089</td>\n","      <td>-0.968349</td>\n","      <td>-0.316007</td>\n","      <td>-0.271948</td>\n","      <td>-0.868267</td>\n","      <td>-0.307978</td>\n","      <td>-0.053209</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>-0.613789</td>\n","      <td>0.256714</td>\n","      <td>1.363599</td>\n","      <td>-0.953040</td>\n","      <td>1.532692</td>\n","      <td>0.029087</td>\n","      <td>0.721912</td>\n","      <td>1.008420</td>\n","      <td>-1.257118</td>\n","      <td>-0.594000</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-1.063404</td>\n","      <td>-0.695462</td>\n","      <td>-0.968349</td>\n","      <td>-0.316007</td>\n","      <td>-0.271948</td>\n","      <td>-0.868267</td>\n","      <td>-0.307978</td>\n","      <td>1.764349</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.502535</td>\n","      <td>-0.129246</td>\n","      <td>0.354666</td>\n","      <td>0.609689</td>\n","      <td>-0.868944</td>\n","      <td>0.303965</td>\n","      <td>0.046437</td>\n","      <td>1.195615</td>\n","      <td>0.567650</td>\n","      <td>0.493582</td>\n","      <td>...</td>\n","      <td>-0.181918</td>\n","      <td>-0.109396</td>\n","      <td>-0.376299</td>\n","      <td>-0.506573</td>\n","      <td>0.506147</td>\n","      <td>-0.316007</td>\n","      <td>-0.166515</td>\n","      <td>-0.479717</td>\n","      <td>-0.133353</td>\n","      <td>-0.053209</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 118 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-218cd940-ed54-44a2-9076-db482c19a1e5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-01f11f1c-24c0-43b6-ada6-d99596024862\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01f11f1c-24c0-43b6-ada6-d99596024862')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-01f11f1c-24c0-43b6-ada6-d99596024862 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-218cd940-ed54-44a2-9076-db482c19a1e5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-218cd940-ed54-44a2-9076-db482c19a1e5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[],"metadata":{"id":"kGo5nnVkBtzT","executionInfo":{"status":"ok","timestamp":1689673777380,"user_tz":-330,"elapsed":75,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["emodf = df.loc[:, 'admiration':'neutral']\n","emodf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"5BPXS01NBt1x","executionInfo":{"status":"ok","timestamp":1689673777381,"user_tz":-330,"elapsed":75,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"51b16ebd-7161-41fe-8d4a-74dedae02746"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      admiration  amusement     anger  annoyance  approval    caring  \\\n","0       0.000016   0.000150  0.000705   0.001447  0.000643  0.009114   \n","1       0.000054   0.167888  0.011522   0.201494  0.000443  0.001504   \n","2       0.000101   0.000596  0.000428   0.001275  0.006295  0.013178   \n","3       0.000054   0.000639  0.043696   0.003672  0.000041  0.007463   \n","4       0.000004   0.000040  0.000176   0.000860  0.000181  0.000255   \n","...          ...        ...       ...        ...       ...       ...   \n","7400    0.000907   0.000017  0.000027   0.000027  0.000360  0.001514   \n","7401    0.000451   0.000075  0.000005   0.000022  0.000736  0.000157   \n","7402    0.000228   0.000024  0.000010   0.000034  0.000405  0.000364   \n","7403    0.000064   0.000080  0.000109   0.000155  0.012040  0.932658   \n","7404    0.003813   0.000036  0.000079   0.000095  0.039129  0.920536   \n","\n","      confusion  curiosity.1    desire  disappointment  ...      love  \\\n","0      0.048850     0.010012  0.000057        0.000440  ...  0.000210   \n","1      0.002532     0.000539  0.000486        0.053486  ...  0.003212   \n","2      0.412494     0.034596  0.000124        0.002020  ...  0.001481   \n","3      0.000333     0.000094  0.000294        0.002422  ...  0.005427   \n","4      0.001674     0.000182  0.000016        0.001535  ...  0.000145   \n","...         ...          ...       ...             ...  ...       ...   \n","7400   0.000162     0.000076  0.000035        0.000038  ...  0.000018   \n","7401   0.000070     0.000227  0.000052        0.000015  ...  0.000010   \n","7402   0.000123     0.000703  0.000040        0.000015  ...  0.000008   \n","7403   0.000593     0.001206  0.000311        0.000126  ...  0.000124   \n","7404   0.000142     0.000082  0.000070        0.000138  ...  0.000231   \n","\n","      nervousness  optimism     pride  realization    relief   remorse  \\\n","0        0.068864  0.000185  0.000041     0.000323  0.001267  0.000330   \n","1        0.013415  0.000246  0.000617     0.022932  0.000231  0.003261   \n","2        0.035853  0.000615  0.000224     0.336612  0.002241  0.001373   \n","3        0.010949  0.000076  0.000740     0.000619  0.000275  0.001561   \n","4        0.079422  0.000020  0.000017     0.000338  0.000211  0.000071   \n","...           ...       ...       ...          ...       ...       ...   \n","7400     0.000038  0.000060  0.000021     0.000021  0.000448  0.000136   \n","7401     0.000004  0.000037  0.000003     0.000018  0.000051  0.000023   \n","7402     0.000007  0.000077  0.000003     0.000009  0.000134  0.000023   \n","7403     0.016793  0.015985  0.000026     0.000285  0.005689  0.000256   \n","7404     0.000211  0.007032  0.000072     0.001102  0.007063  0.000425   \n","\n","       sadness  surprise   neutral  \n","0     0.000575  0.000205  0.000843  \n","1     0.416074  0.001216  0.003240  \n","2     0.007805  0.013074  0.041802  \n","3     0.057985  0.000332  0.000073  \n","4     0.002956  0.000103  0.000174  \n","...        ...       ...       ...  \n","7400  0.000022  0.000016  0.000068  \n","7401  0.000008  0.000011  0.001105  \n","7402  0.000008  0.000013  0.000393  \n","7403  0.000404  0.000174  0.003708  \n","7404  0.000141  0.000089  0.015839  \n","\n","[7405 rows x 28 columns]"],"text/html":["\n","\n","  <div id=\"df-ef6d7ad5-86f3-4220-8e70-fa131f704182\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>admiration</th>\n","      <th>amusement</th>\n","      <th>anger</th>\n","      <th>annoyance</th>\n","      <th>approval</th>\n","      <th>caring</th>\n","      <th>confusion</th>\n","      <th>curiosity.1</th>\n","      <th>desire</th>\n","      <th>disappointment</th>\n","      <th>...</th>\n","      <th>love</th>\n","      <th>nervousness</th>\n","      <th>optimism</th>\n","      <th>pride</th>\n","      <th>realization</th>\n","      <th>relief</th>\n","      <th>remorse</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>neutral</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000016</td>\n","      <td>0.000150</td>\n","      <td>0.000705</td>\n","      <td>0.001447</td>\n","      <td>0.000643</td>\n","      <td>0.009114</td>\n","      <td>0.048850</td>\n","      <td>0.010012</td>\n","      <td>0.000057</td>\n","      <td>0.000440</td>\n","      <td>...</td>\n","      <td>0.000210</td>\n","      <td>0.068864</td>\n","      <td>0.000185</td>\n","      <td>0.000041</td>\n","      <td>0.000323</td>\n","      <td>0.001267</td>\n","      <td>0.000330</td>\n","      <td>0.000575</td>\n","      <td>0.000205</td>\n","      <td>0.000843</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000054</td>\n","      <td>0.167888</td>\n","      <td>0.011522</td>\n","      <td>0.201494</td>\n","      <td>0.000443</td>\n","      <td>0.001504</td>\n","      <td>0.002532</td>\n","      <td>0.000539</td>\n","      <td>0.000486</td>\n","      <td>0.053486</td>\n","      <td>...</td>\n","      <td>0.003212</td>\n","      <td>0.013415</td>\n","      <td>0.000246</td>\n","      <td>0.000617</td>\n","      <td>0.022932</td>\n","      <td>0.000231</td>\n","      <td>0.003261</td>\n","      <td>0.416074</td>\n","      <td>0.001216</td>\n","      <td>0.003240</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000101</td>\n","      <td>0.000596</td>\n","      <td>0.000428</td>\n","      <td>0.001275</td>\n","      <td>0.006295</td>\n","      <td>0.013178</td>\n","      <td>0.412494</td>\n","      <td>0.034596</td>\n","      <td>0.000124</td>\n","      <td>0.002020</td>\n","      <td>...</td>\n","      <td>0.001481</td>\n","      <td>0.035853</td>\n","      <td>0.000615</td>\n","      <td>0.000224</td>\n","      <td>0.336612</td>\n","      <td>0.002241</td>\n","      <td>0.001373</td>\n","      <td>0.007805</td>\n","      <td>0.013074</td>\n","      <td>0.041802</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000054</td>\n","      <td>0.000639</td>\n","      <td>0.043696</td>\n","      <td>0.003672</td>\n","      <td>0.000041</td>\n","      <td>0.007463</td>\n","      <td>0.000333</td>\n","      <td>0.000094</td>\n","      <td>0.000294</td>\n","      <td>0.002422</td>\n","      <td>...</td>\n","      <td>0.005427</td>\n","      <td>0.010949</td>\n","      <td>0.000076</td>\n","      <td>0.000740</td>\n","      <td>0.000619</td>\n","      <td>0.000275</td>\n","      <td>0.001561</td>\n","      <td>0.057985</td>\n","      <td>0.000332</td>\n","      <td>0.000073</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000004</td>\n","      <td>0.000040</td>\n","      <td>0.000176</td>\n","      <td>0.000860</td>\n","      <td>0.000181</td>\n","      <td>0.000255</td>\n","      <td>0.001674</td>\n","      <td>0.000182</td>\n","      <td>0.000016</td>\n","      <td>0.001535</td>\n","      <td>...</td>\n","      <td>0.000145</td>\n","      <td>0.079422</td>\n","      <td>0.000020</td>\n","      <td>0.000017</td>\n","      <td>0.000338</td>\n","      <td>0.000211</td>\n","      <td>0.000071</td>\n","      <td>0.002956</td>\n","      <td>0.000103</td>\n","      <td>0.000174</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.000907</td>\n","      <td>0.000017</td>\n","      <td>0.000027</td>\n","      <td>0.000027</td>\n","      <td>0.000360</td>\n","      <td>0.001514</td>\n","      <td>0.000162</td>\n","      <td>0.000076</td>\n","      <td>0.000035</td>\n","      <td>0.000038</td>\n","      <td>...</td>\n","      <td>0.000018</td>\n","      <td>0.000038</td>\n","      <td>0.000060</td>\n","      <td>0.000021</td>\n","      <td>0.000021</td>\n","      <td>0.000448</td>\n","      <td>0.000136</td>\n","      <td>0.000022</td>\n","      <td>0.000016</td>\n","      <td>0.000068</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.000451</td>\n","      <td>0.000075</td>\n","      <td>0.000005</td>\n","      <td>0.000022</td>\n","      <td>0.000736</td>\n","      <td>0.000157</td>\n","      <td>0.000070</td>\n","      <td>0.000227</td>\n","      <td>0.000052</td>\n","      <td>0.000015</td>\n","      <td>...</td>\n","      <td>0.000010</td>\n","      <td>0.000004</td>\n","      <td>0.000037</td>\n","      <td>0.000003</td>\n","      <td>0.000018</td>\n","      <td>0.000051</td>\n","      <td>0.000023</td>\n","      <td>0.000008</td>\n","      <td>0.000011</td>\n","      <td>0.001105</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.000228</td>\n","      <td>0.000024</td>\n","      <td>0.000010</td>\n","      <td>0.000034</td>\n","      <td>0.000405</td>\n","      <td>0.000364</td>\n","      <td>0.000123</td>\n","      <td>0.000703</td>\n","      <td>0.000040</td>\n","      <td>0.000015</td>\n","      <td>...</td>\n","      <td>0.000008</td>\n","      <td>0.000007</td>\n","      <td>0.000077</td>\n","      <td>0.000003</td>\n","      <td>0.000009</td>\n","      <td>0.000134</td>\n","      <td>0.000023</td>\n","      <td>0.000008</td>\n","      <td>0.000013</td>\n","      <td>0.000393</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.000064</td>\n","      <td>0.000080</td>\n","      <td>0.000109</td>\n","      <td>0.000155</td>\n","      <td>0.012040</td>\n","      <td>0.932658</td>\n","      <td>0.000593</td>\n","      <td>0.001206</td>\n","      <td>0.000311</td>\n","      <td>0.000126</td>\n","      <td>...</td>\n","      <td>0.000124</td>\n","      <td>0.016793</td>\n","      <td>0.015985</td>\n","      <td>0.000026</td>\n","      <td>0.000285</td>\n","      <td>0.005689</td>\n","      <td>0.000256</td>\n","      <td>0.000404</td>\n","      <td>0.000174</td>\n","      <td>0.003708</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.003813</td>\n","      <td>0.000036</td>\n","      <td>0.000079</td>\n","      <td>0.000095</td>\n","      <td>0.039129</td>\n","      <td>0.920536</td>\n","      <td>0.000142</td>\n","      <td>0.000082</td>\n","      <td>0.000070</td>\n","      <td>0.000138</td>\n","      <td>...</td>\n","      <td>0.000231</td>\n","      <td>0.000211</td>\n","      <td>0.007032</td>\n","      <td>0.000072</td>\n","      <td>0.001102</td>\n","      <td>0.007063</td>\n","      <td>0.000425</td>\n","      <td>0.000141</td>\n","      <td>0.000089</td>\n","      <td>0.015839</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 28 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef6d7ad5-86f3-4220-8e70-fa131f704182')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-00114eb4-70af-42d4-a887-d4defe8a2874\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00114eb4-70af-42d4-a887-d4defe8a2874')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-00114eb4-70af-42d4-a887-d4defe8a2874 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ef6d7ad5-86f3-4220-8e70-fa131f704182 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ef6d7ad5-86f3-4220-8e70-fa131f704182');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":[],"metadata":{"id":"ZHyjicb9B2D2","executionInfo":{"status":"ok","timestamp":1689673777383,"user_tz":-330,"elapsed":74,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["intensitydf = df.loc[:, 'anger_intensity':'trust_intensity']\n","intensitydf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"SbUXriXeB2Ge","executionInfo":{"status":"ok","timestamp":1689673777384,"user_tz":-330,"elapsed":74,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d477604a-5ca9-4bbc-8e3c-6ee1baff6913"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      anger_intensity  anticipation_intensity  disgust_intensity  \\\n","0            0.415048                0.553423           0.272333   \n","1            0.530400                0.519750           0.541250   \n","2            0.428600                0.533500           0.228167   \n","3            0.567200                0.533462           0.114667   \n","4            0.487000                0.508000           0.482250   \n","...               ...                     ...                ...   \n","7400         0.396000                0.609000           0.484000   \n","7401         0.000000                0.000000           0.000000   \n","7402         0.000000                0.000000           0.000000   \n","7403         0.344000                0.528667           0.000000   \n","7404         0.376750                0.502500           0.422000   \n","\n","      fear_intensity  joy_intensity  sadness_intensity  surprise_intensity  \\\n","0           0.568205       0.409500           0.467625            0.434500   \n","1           0.432167       0.453429           0.315600            0.247333   \n","2           0.526192       0.413444           0.468533            0.348500   \n","3           0.501952       0.505000           0.522095            0.320500   \n","4           0.624833       0.489167           0.505333            0.000000   \n","...              ...            ...                ...                 ...   \n","7400        0.527500       0.434000           0.591000            0.793000   \n","7401        0.156000       0.000000           0.000000            0.000000   \n","7402        0.156000       0.000000           0.000000            0.000000   \n","7403        0.414000       0.515500           0.500000            0.363500   \n","7404        0.515333       0.431900           0.418800            0.316500   \n","\n","      trust_intensity  \n","0            0.522773  \n","1            0.508875  \n","2            0.504500  \n","3            0.593615  \n","4            0.527167  \n","...               ...  \n","7400         0.540800  \n","7401         0.000000  \n","7402         0.641000  \n","7403         0.613000  \n","7404         0.519286  \n","\n","[7405 rows x 8 columns]"],"text/html":["\n","\n","  <div id=\"df-783ffa70-acfa-4a47-8b9c-043b8d51debd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-783ffa70-acfa-4a47-8b9c-043b8d51debd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-3dcd475b-55be-4abe-a79b-e15e97cf051e\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dcd475b-55be-4abe-a79b-e15e97cf051e')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-3dcd475b-55be-4abe-a79b-e15e97cf051e button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-783ffa70-acfa-4a47-8b9c-043b8d51debd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-783ffa70-acfa-4a47-8b9c-043b8d51debd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":[],"metadata":{"id":"-JVNEj89B2I-","executionInfo":{"status":"ok","timestamp":1689673777385,"user_tz":-330,"elapsed":72,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["final_df = pd.concat([sentembdf, stdliwcdf, emodf, intensitydf, df['symptoms_ext_count']], axis=1)\n","final_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"j5lgm7kTB2LU","executionInfo":{"status":"ok","timestamp":1689673777386,"user_tz":-330,"elapsed":72,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"4fcf20c5-212d-477f-d5b7-9bce67df2948"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     0.819914  0.351344  0.404849  0.211062  0.258971  0.257296  0.508351   \n","1     0.876063  0.378231  0.298667  0.214494  0.349709  0.284757  0.438802   \n","2     0.810696  0.338906  0.380186  0.207599  0.268363  0.274065  0.500595   \n","3     0.875869  0.375439  0.291701  0.216481  0.355757  0.287865  0.434504   \n","4     0.849092  0.364154  0.345076  0.144952  0.283609  0.274024  0.446017   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","7400  0.808676  0.343545  0.265276  0.106535  0.323924  0.292145  0.382246   \n","7401  0.824678  0.309808  0.225578  0.204305  0.355065  0.360845  0.426495   \n","7402  0.795178  0.299596  0.229027  0.193240  0.349450  0.343462  0.422839   \n","7403  0.804208  0.311253  0.230871  0.186933  0.347010  0.343995  0.420793   \n","7404  0.868482  0.360029  0.264501  0.211487  0.321134  0.380958  0.462207   \n","\n","      sentemb8  sentemb9  sentemb10  ...   neutral  anger_intensity  \\\n","0     0.079092  0.046841   0.526339  ...  0.000843         0.415048   \n","1     0.078256  0.026417   0.481356  ...  0.003240         0.530400   \n","2     0.077948  0.052404   0.508967  ...  0.041802         0.428600   \n","3     0.078305  0.024242   0.476598  ...  0.000073         0.567200   \n","4     0.077871  0.052790   0.488757  ...  0.000174         0.487000   \n","...        ...       ...        ...  ...       ...              ...   \n","7400  0.077382  0.073316   0.436193  ...  0.000068         0.396000   \n","7401  0.070627  0.067943   0.404500  ...  0.001105         0.000000   \n","7402  0.070439  0.078386   0.409807  ...  0.000393         0.000000   \n","7403  0.071775  0.076749   0.414172  ...  0.003708         0.344000   \n","7404  0.076063  0.055441   0.440022  ...  0.015839         0.376750   \n","\n","      anticipation_intensity  disgust_intensity  fear_intensity  \\\n","0                   0.553423           0.272333        0.568205   \n","1                   0.519750           0.541250        0.432167   \n","2                   0.533500           0.228167        0.526192   \n","3                   0.533462           0.114667        0.501952   \n","4                   0.508000           0.482250        0.624833   \n","...                      ...                ...             ...   \n","7400                0.609000           0.484000        0.527500   \n","7401                0.000000           0.000000        0.156000   \n","7402                0.000000           0.000000        0.156000   \n","7403                0.528667           0.000000        0.414000   \n","7404                0.502500           0.422000        0.515333   \n","\n","      joy_intensity  sadness_intensity  surprise_intensity  trust_intensity  \\\n","0          0.409500           0.467625            0.434500         0.522773   \n","1          0.453429           0.315600            0.247333         0.508875   \n","2          0.413444           0.468533            0.348500         0.504500   \n","3          0.505000           0.522095            0.320500         0.593615   \n","4          0.489167           0.505333            0.000000         0.527167   \n","...             ...                ...                 ...              ...   \n","7400       0.434000           0.591000            0.793000         0.540800   \n","7401       0.000000           0.000000            0.000000         0.000000   \n","7402       0.000000           0.000000            0.000000         0.641000   \n","7403       0.515500           0.500000            0.363500         0.613000   \n","7404       0.431900           0.418800            0.316500         0.519286   \n","\n","      symptoms_ext_count  \n","0                      8  \n","1                      1  \n","2                      3  \n","3                      1  \n","4                      3  \n","...                  ...  \n","7400                   1  \n","7401                   0  \n","7402                   0  \n","7403                   0  \n","7404                   0  \n","\n","[7405 rows x 183 columns]"],"text/html":["\n","\n","  <div id=\"df-3e34453b-8d55-4112-901a-0b7cb1b92f01\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>neutral</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","      <th>symptoms_ext_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.819914</td>\n","      <td>0.351344</td>\n","      <td>0.404849</td>\n","      <td>0.211062</td>\n","      <td>0.258971</td>\n","      <td>0.257296</td>\n","      <td>0.508351</td>\n","      <td>0.079092</td>\n","      <td>0.046841</td>\n","      <td>0.526339</td>\n","      <td>...</td>\n","      <td>0.000843</td>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.876063</td>\n","      <td>0.378231</td>\n","      <td>0.298667</td>\n","      <td>0.214494</td>\n","      <td>0.349709</td>\n","      <td>0.284757</td>\n","      <td>0.438802</td>\n","      <td>0.078256</td>\n","      <td>0.026417</td>\n","      <td>0.481356</td>\n","      <td>...</td>\n","      <td>0.003240</td>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.810696</td>\n","      <td>0.338906</td>\n","      <td>0.380186</td>\n","      <td>0.207599</td>\n","      <td>0.268363</td>\n","      <td>0.274065</td>\n","      <td>0.500595</td>\n","      <td>0.077948</td>\n","      <td>0.052404</td>\n","      <td>0.508967</td>\n","      <td>...</td>\n","      <td>0.041802</td>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.875869</td>\n","      <td>0.375439</td>\n","      <td>0.291701</td>\n","      <td>0.216481</td>\n","      <td>0.355757</td>\n","      <td>0.287865</td>\n","      <td>0.434504</td>\n","      <td>0.078305</td>\n","      <td>0.024242</td>\n","      <td>0.476598</td>\n","      <td>...</td>\n","      <td>0.000073</td>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.849092</td>\n","      <td>0.364154</td>\n","      <td>0.345076</td>\n","      <td>0.144952</td>\n","      <td>0.283609</td>\n","      <td>0.274024</td>\n","      <td>0.446017</td>\n","      <td>0.077871</td>\n","      <td>0.052790</td>\n","      <td>0.488757</td>\n","      <td>...</td>\n","      <td>0.000174</td>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.808676</td>\n","      <td>0.343545</td>\n","      <td>0.265276</td>\n","      <td>0.106535</td>\n","      <td>0.323924</td>\n","      <td>0.292145</td>\n","      <td>0.382246</td>\n","      <td>0.077382</td>\n","      <td>0.073316</td>\n","      <td>0.436193</td>\n","      <td>...</td>\n","      <td>0.000068</td>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.824678</td>\n","      <td>0.309808</td>\n","      <td>0.225578</td>\n","      <td>0.204305</td>\n","      <td>0.355065</td>\n","      <td>0.360845</td>\n","      <td>0.426495</td>\n","      <td>0.070627</td>\n","      <td>0.067943</td>\n","      <td>0.404500</td>\n","      <td>...</td>\n","      <td>0.001105</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.795178</td>\n","      <td>0.299596</td>\n","      <td>0.229027</td>\n","      <td>0.193240</td>\n","      <td>0.349450</td>\n","      <td>0.343462</td>\n","      <td>0.422839</td>\n","      <td>0.070439</td>\n","      <td>0.078386</td>\n","      <td>0.409807</td>\n","      <td>...</td>\n","      <td>0.000393</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.804208</td>\n","      <td>0.311253</td>\n","      <td>0.230871</td>\n","      <td>0.186933</td>\n","      <td>0.347010</td>\n","      <td>0.343995</td>\n","      <td>0.420793</td>\n","      <td>0.071775</td>\n","      <td>0.076749</td>\n","      <td>0.414172</td>\n","      <td>...</td>\n","      <td>0.003708</td>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.868482</td>\n","      <td>0.360029</td>\n","      <td>0.264501</td>\n","      <td>0.211487</td>\n","      <td>0.321134</td>\n","      <td>0.380958</td>\n","      <td>0.462207</td>\n","      <td>0.076063</td>\n","      <td>0.055441</td>\n","      <td>0.440022</td>\n","      <td>...</td>\n","      <td>0.015839</td>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 183 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e34453b-8d55-4112-901a-0b7cb1b92f01')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-9d320a6e-4720-4a3e-b599-52b925aab3a6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d320a6e-4720-4a3e-b599-52b925aab3a6')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-9d320a6e-4720-4a3e-b599-52b925aab3a6 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3e34453b-8d55-4112-901a-0b7cb1b92f01 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3e34453b-8d55-4112-901a-0b7cb1b92f01');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["df['label']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHJKn6YLB2N5","executionInfo":{"status":"ok","timestamp":1689673777387,"user_tz":-330,"elapsed":70,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"265baf67-b8e7-4173-a269-c83e53df574d"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       1\n","1       1\n","2       1\n","3       1\n","4       1\n","       ..\n","7400    0\n","7401    0\n","7402    0\n","7403    0\n","7404    0\n","Name: label, Length: 7405, dtype: int64"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":[],"metadata":{"id":"WbX60GObB2QC","executionInfo":{"status":"ok","timestamp":1689673777389,"user_tz":-330,"elapsed":63,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["print(list(final_df.columns))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJzg89ekB2SW","executionInfo":{"status":"ok","timestamp":1689673777390,"user_tz":-330,"elapsed":63,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"b796a569-d9ef-48d2-9124-dbc6920fddbd"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["['sentemb1', 'sentemb2', 'sentemb3', 'sentemb4', 'sentemb5', 'sentemb6', 'sentemb7', 'sentemb8', 'sentemb9', 'sentemb10', 'sentemb11', 'sentemb12', 'sentemb13', 'sentemb14', 'sentemb15', 'sentemb16', 'sentemb17', 'sentemb18', 'sentemb19', 'sentemb20', 'sentemb21', 'sentemb22', 'sentemb23', 'sentemb24', 'sentemb25', 'sentemb26', 'sentemb27', 'sentemb28', 'WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'BigWords', 'Dic', 'Linguistic', 'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron', 'det', 'article', 'number', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj', 'quantity', 'Drives', 'affiliation', 'achieve', 'power', 'Cognition', 'allnone', 'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certitude', 'differ', 'memory', 'Affect', 'tone_pos', 'tone_neg', 'emotion', 'emo_pos', 'emo_neg', 'emo_anx', 'emo_anger', 'emo_sad', 'swear', 'Social', 'socbehav', 'prosocial', 'polite', 'conflict', 'moral', 'comm', 'socrefs', 'family', 'friend', 'female', 'male', 'Culture', 'politic', 'ethnicity', 'tech', 'Lifestyle', 'leisure', 'home', 'work', 'money', 'relig', 'Physical', 'health', 'illness', 'wellness', 'mental', 'substances', 'sexual', 'food', 'death', 'need', 'want', 'acquire', 'lack', 'fulfill', 'fatigue', 'reward', 'risk', 'curiosity', 'allure', 'Perception', 'attention', 'motion', 'space', 'visual', 'auditory', 'feeling', 'time', 'focuspast', 'focuspresent', 'focusfuture', 'Conversation', 'netspeak', 'assent', 'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'QMark', 'Exclam', 'Apostro', 'OtherP', 'Emoji', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity.1', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral', 'anger_intensity', 'anticipation_intensity', 'disgust_intensity', 'fear_intensity', 'joy_intensity', 'sadness_intensity', 'surprise_intensity', 'trust_intensity', 'symptoms_ext_count']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XaHqyI_XBt3_","executionInfo":{"status":"ok","timestamp":1689673777391,"user_tz":-330,"elapsed":57,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qHBZ2WU3ElyA","executionInfo":{"status":"ok","timestamp":1689673777392,"user_tz":-330,"elapsed":58,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"479uWboYE0CQ","executionInfo":{"status":"ok","timestamp":1689673787006,"user_tz":-330,"elapsed":9671,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"5406ed93-6a70-4392-92df-1819c751ecb0"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["!pip install keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vh52Mk_JJsaR","executionInfo":{"status":"ok","timestamp":1689673801655,"user_tz":-330,"elapsed":14659,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"edddcb5e-bfcb-44d9-e919-19a155b871f4"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"]}]},{"cell_type":"markdown","source":["## DNN (ignore for this file, see IDSIA Biomedical Texts 18)"],"metadata":{"id":"tdUDrGzdEl7k"}},{"cell_type":"code","source":["# import numpy as np\n","# import pandas as pd\n","# from keras.preprocessing import sequence\n","# from keras.models import Sequential\n","# from keras.layers import Dense, Embedding, Dropout\n","# from keras.layers import LSTM,Bidirectional,GRU,SimpleRNN\n","# from keras.layers import Conv2D, MaxPooling2D\n","# from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPooling1D, AveragePooling1D\n","# # from keras.layers import Input, merge, Dropout  # Merge is not supported in Keras +2. Instead, you need to use Concatenate layer\n","# from keras.layers import Input, Concatenate, Dropout\n","# from keras.models import Model\n","# import tensorflow as tf\n","# #tf.python.control_flow_ops = tf\n","# #from sklearn.cross_validation import train_test_split  # deprecation of cross_validation sub-module\n","# from sklearn.model_selection import train_test_split\n","# from scipy.stats import pearsonr\n","# import timeit"],"metadata":{"id":"f9uYiGq8JP21","executionInfo":{"status":"ok","timestamp":1689673801657,"user_tz":-330,"elapsed":41,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# import tensorflow as tf\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Dense\n","# from tensorflow.keras.layers import Dropout\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import f1_score"],"metadata":{"id":"2QzYazGJExxE","executionInfo":{"status":"ok","timestamp":1689673801657,"user_tz":-330,"elapsed":36,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# X = final_df\n","# y = df['label']"],"metadata":{"id":"YshGAfruEmkE","executionInfo":{"status":"ok","timestamp":1689673801658,"user_tz":-330,"elapsed":35,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"7f4i1Hl4Et2q","executionInfo":{"status":"ok","timestamp":1689673801659,"user_tz":-330,"elapsed":35,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# model = Sequential()"],"metadata":{"id":"auvEfRtGE4lU","executionInfo":{"status":"ok","timestamp":1689673801660,"user_tz":-330,"elapsed":34,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# model.add(Dense(64, activation='relu', input_shape=(183,)))  # Input layer with 64 units\n","# model.add(Dense(128, activation='relu'))  # Hidden layer with 128 units\n","# model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 unit for binary classification (sigmoid activation)"],"metadata":{"id":"BsiG4PXsE784","executionInfo":{"status":"ok","timestamp":1689673801660,"user_tz":-330,"elapsed":33,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"],"metadata":{"id":"RrFu-fpjE_5A","executionInfo":{"status":"ok","timestamp":1689673801660,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"],"metadata":{"id":"yJpUmR8dFBlw","executionInfo":{"status":"ok","timestamp":1689673801661,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# loss, accuracy = model.evaluate(X_test, y_test)\n","# print('Test Loss:', loss)\n","# print('Test Accuracy:', accuracy)"],"metadata":{"id":"-2exuFSYFD3D","executionInfo":{"status":"ok","timestamp":1689673801662,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# predictions = model.predict(X_test)"],"metadata":{"id":"aVuKDJOPFHjr","executionInfo":{"status":"ok","timestamp":1689673801663,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# predictions  # probabilities for postiive class, ie 1 or anxiety"],"metadata":{"id":"ez05uxBrKN7K","executionInfo":{"status":"ok","timestamp":1689673801663,"user_tz":-330,"elapsed":31,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# # make class predictions with the model\n","# predictions1 = (model.predict(X_test) > 0.5).astype(int)\n","# predictions1"],"metadata":{"id":"czkNabZiKPQb","executionInfo":{"status":"ok","timestamp":1689673801664,"user_tz":-330,"elapsed":31,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# # summarize the first 5 cases\n","# for i in range(5):\n","#  #print('%s => %d (expected %d)' % (X.values[i].tolist(), predictions1[i], y[i]))\n","#  print('%d (expected %d)' % (predictions1[i], y[i]))"],"metadata":{"id":"YoMiXIoxrMK2","executionInfo":{"status":"ok","timestamp":1689673801664,"user_tz":-330,"elapsed":29,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l1i7Ri26r5NY","executionInfo":{"status":"ok","timestamp":1689673801665,"user_tz":-330,"elapsed":29,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nTcb6B6btBiS","executionInfo":{"status":"ok","timestamp":1689673801668,"user_tz":-330,"elapsed":31,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["## Adding Dropout layer"],"metadata":{"id":"RAx7dPPztUVD"}},{"cell_type":"code","source":["# X = final_df\n","# y = df['label']\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","# model = Sequential()\n","# model.add(Dense(64, activation='relu', input_shape=(183,)))  # Input layer with 64 units\n","# model.add(Dropout(0.2))\n","# model.add(Dense(128, activation='relu'))  # Hidden layer with 128 units\n","# model.add(Dropout(0.2))\n","# model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 unit for binary classification (sigmoid activation)\n","# model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n","# model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))   # epoch=10 and batch size=32 gives almost the same accuracy of 0.82"],"metadata":{"id":"sbkifv-WtBk5","executionInfo":{"status":"ok","timestamp":1689673801669,"user_tz":-330,"elapsed":31,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# loss, accuracy = model.evaluate(X_test, y_test)\n","# print('Test Loss:', loss)\n","# print('Test Accuracy:', accuracy)"],"metadata":{"id":"hN9A8E8WtMk6","executionInfo":{"status":"ok","timestamp":1689673801669,"user_tz":-330,"elapsed":31,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oHRYT0LmukVG","executionInfo":{"status":"ok","timestamp":1689673801671,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c4MFqf5SxPGw","executionInfo":{"status":"ok","timestamp":1689673801671,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["## Multi-layers"],"metadata":{"id":"Vh0Rm-e-xPOl"}},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Conv1D, Dense, Concatenate, GlobalMaxPooling1D, Reshape, Dropout\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"m_4OpDvLxQxI","executionInfo":{"status":"ok","timestamp":1689673805576,"user_tz":-330,"elapsed":3936,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["final_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"rCyALb6CyS-X","executionInfo":{"status":"ok","timestamp":1689673805577,"user_tz":-330,"elapsed":79,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"40b74d6c-34f0-4c5c-96eb-afebbd0fa6fd"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0     0.819914  0.351344  0.404849  0.211062  0.258971  0.257296  0.508351   \n","1     0.876063  0.378231  0.298667  0.214494  0.349709  0.284757  0.438802   \n","2     0.810696  0.338906  0.380186  0.207599  0.268363  0.274065  0.500595   \n","3     0.875869  0.375439  0.291701  0.216481  0.355757  0.287865  0.434504   \n","4     0.849092  0.364154  0.345076  0.144952  0.283609  0.274024  0.446017   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","7400  0.808676  0.343545  0.265276  0.106535  0.323924  0.292145  0.382246   \n","7401  0.824678  0.309808  0.225578  0.204305  0.355065  0.360845  0.426495   \n","7402  0.795178  0.299596  0.229027  0.193240  0.349450  0.343462  0.422839   \n","7403  0.804208  0.311253  0.230871  0.186933  0.347010  0.343995  0.420793   \n","7404  0.868482  0.360029  0.264501  0.211487  0.321134  0.380958  0.462207   \n","\n","      sentemb8  sentemb9  sentemb10  ...   neutral  anger_intensity  \\\n","0     0.079092  0.046841   0.526339  ...  0.000843         0.415048   \n","1     0.078256  0.026417   0.481356  ...  0.003240         0.530400   \n","2     0.077948  0.052404   0.508967  ...  0.041802         0.428600   \n","3     0.078305  0.024242   0.476598  ...  0.000073         0.567200   \n","4     0.077871  0.052790   0.488757  ...  0.000174         0.487000   \n","...        ...       ...        ...  ...       ...              ...   \n","7400  0.077382  0.073316   0.436193  ...  0.000068         0.396000   \n","7401  0.070627  0.067943   0.404500  ...  0.001105         0.000000   \n","7402  0.070439  0.078386   0.409807  ...  0.000393         0.000000   \n","7403  0.071775  0.076749   0.414172  ...  0.003708         0.344000   \n","7404  0.076063  0.055441   0.440022  ...  0.015839         0.376750   \n","\n","      anticipation_intensity  disgust_intensity  fear_intensity  \\\n","0                   0.553423           0.272333        0.568205   \n","1                   0.519750           0.541250        0.432167   \n","2                   0.533500           0.228167        0.526192   \n","3                   0.533462           0.114667        0.501952   \n","4                   0.508000           0.482250        0.624833   \n","...                      ...                ...             ...   \n","7400                0.609000           0.484000        0.527500   \n","7401                0.000000           0.000000        0.156000   \n","7402                0.000000           0.000000        0.156000   \n","7403                0.528667           0.000000        0.414000   \n","7404                0.502500           0.422000        0.515333   \n","\n","      joy_intensity  sadness_intensity  surprise_intensity  trust_intensity  \\\n","0          0.409500           0.467625            0.434500         0.522773   \n","1          0.453429           0.315600            0.247333         0.508875   \n","2          0.413444           0.468533            0.348500         0.504500   \n","3          0.505000           0.522095            0.320500         0.593615   \n","4          0.489167           0.505333            0.000000         0.527167   \n","...             ...                ...                 ...              ...   \n","7400       0.434000           0.591000            0.793000         0.540800   \n","7401       0.000000           0.000000            0.000000         0.000000   \n","7402       0.000000           0.000000            0.000000         0.641000   \n","7403       0.515500           0.500000            0.363500         0.613000   \n","7404       0.431900           0.418800            0.316500         0.519286   \n","\n","      symptoms_ext_count  \n","0                      8  \n","1                      1  \n","2                      3  \n","3                      1  \n","4                      3  \n","...                  ...  \n","7400                   1  \n","7401                   0  \n","7402                   0  \n","7403                   0  \n","7404                   0  \n","\n","[7405 rows x 183 columns]"],"text/html":["\n","\n","  <div id=\"df-a7e2dcc7-78c0-42fa-8c22-3b9cb7068cf9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>neutral</th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","      <th>symptoms_ext_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.819914</td>\n","      <td>0.351344</td>\n","      <td>0.404849</td>\n","      <td>0.211062</td>\n","      <td>0.258971</td>\n","      <td>0.257296</td>\n","      <td>0.508351</td>\n","      <td>0.079092</td>\n","      <td>0.046841</td>\n","      <td>0.526339</td>\n","      <td>...</td>\n","      <td>0.000843</td>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.876063</td>\n","      <td>0.378231</td>\n","      <td>0.298667</td>\n","      <td>0.214494</td>\n","      <td>0.349709</td>\n","      <td>0.284757</td>\n","      <td>0.438802</td>\n","      <td>0.078256</td>\n","      <td>0.026417</td>\n","      <td>0.481356</td>\n","      <td>...</td>\n","      <td>0.003240</td>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.810696</td>\n","      <td>0.338906</td>\n","      <td>0.380186</td>\n","      <td>0.207599</td>\n","      <td>0.268363</td>\n","      <td>0.274065</td>\n","      <td>0.500595</td>\n","      <td>0.077948</td>\n","      <td>0.052404</td>\n","      <td>0.508967</td>\n","      <td>...</td>\n","      <td>0.041802</td>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.875869</td>\n","      <td>0.375439</td>\n","      <td>0.291701</td>\n","      <td>0.216481</td>\n","      <td>0.355757</td>\n","      <td>0.287865</td>\n","      <td>0.434504</td>\n","      <td>0.078305</td>\n","      <td>0.024242</td>\n","      <td>0.476598</td>\n","      <td>...</td>\n","      <td>0.000073</td>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.849092</td>\n","      <td>0.364154</td>\n","      <td>0.345076</td>\n","      <td>0.144952</td>\n","      <td>0.283609</td>\n","      <td>0.274024</td>\n","      <td>0.446017</td>\n","      <td>0.077871</td>\n","      <td>0.052790</td>\n","      <td>0.488757</td>\n","      <td>...</td>\n","      <td>0.000174</td>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.808676</td>\n","      <td>0.343545</td>\n","      <td>0.265276</td>\n","      <td>0.106535</td>\n","      <td>0.323924</td>\n","      <td>0.292145</td>\n","      <td>0.382246</td>\n","      <td>0.077382</td>\n","      <td>0.073316</td>\n","      <td>0.436193</td>\n","      <td>...</td>\n","      <td>0.000068</td>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.824678</td>\n","      <td>0.309808</td>\n","      <td>0.225578</td>\n","      <td>0.204305</td>\n","      <td>0.355065</td>\n","      <td>0.360845</td>\n","      <td>0.426495</td>\n","      <td>0.070627</td>\n","      <td>0.067943</td>\n","      <td>0.404500</td>\n","      <td>...</td>\n","      <td>0.001105</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.795178</td>\n","      <td>0.299596</td>\n","      <td>0.229027</td>\n","      <td>0.193240</td>\n","      <td>0.349450</td>\n","      <td>0.343462</td>\n","      <td>0.422839</td>\n","      <td>0.070439</td>\n","      <td>0.078386</td>\n","      <td>0.409807</td>\n","      <td>...</td>\n","      <td>0.000393</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.804208</td>\n","      <td>0.311253</td>\n","      <td>0.230871</td>\n","      <td>0.186933</td>\n","      <td>0.347010</td>\n","      <td>0.343995</td>\n","      <td>0.420793</td>\n","      <td>0.071775</td>\n","      <td>0.076749</td>\n","      <td>0.414172</td>\n","      <td>...</td>\n","      <td>0.003708</td>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7404</th>\n","      <td>0.868482</td>\n","      <td>0.360029</td>\n","      <td>0.264501</td>\n","      <td>0.211487</td>\n","      <td>0.321134</td>\n","      <td>0.380958</td>\n","      <td>0.462207</td>\n","      <td>0.076063</td>\n","      <td>0.055441</td>\n","      <td>0.440022</td>\n","      <td>...</td>\n","      <td>0.015839</td>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7405 rows Ã— 183 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7e2dcc7-78c0-42fa-8c22-3b9cb7068cf9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-a13feb39-722f-48eb-bacf-3edf3f936076\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a13feb39-722f-48eb-bacf-3edf3f936076')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-a13feb39-722f-48eb-bacf-3edf3f936076 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a7e2dcc7-78c0-42fa-8c22-3b9cb7068cf9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a7e2dcc7-78c0-42fa-8c22-3b9cb7068cf9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["X_sentemb = final_df.loc[:, 'sentemb1':'sentemb28']\n","X_sentemb.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"YQ12ZTPhyVrD","executionInfo":{"status":"ok","timestamp":1689673805578,"user_tz":-330,"elapsed":75,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"3eaac093-dd4c-4e91-956e-40f235aa606f"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sentemb1  sentemb2  sentemb3  sentemb4  sentemb5  sentemb6  sentemb7  \\\n","0  0.819914  0.351344  0.404849  0.211062  0.258971  0.257296  0.508351   \n","\n","   sentemb8  sentemb9  sentemb10  ...  sentemb19  sentemb20  sentemb21  \\\n","0  0.079092  0.046841   0.526339  ...   0.494592   0.289889   0.115539   \n","\n","   sentemb22  sentemb23  sentemb24  sentemb25  sentemb26  sentemb27  sentemb28  \n","0   0.196822    0.42888   0.426222   0.362514   0.339857   0.504306   0.309135  \n","\n","[1 rows x 28 columns]"],"text/html":["\n","\n","  <div id=\"df-244dd72e-62d4-4dad-b904-6f58e0ad5c72\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentemb1</th>\n","      <th>sentemb2</th>\n","      <th>sentemb3</th>\n","      <th>sentemb4</th>\n","      <th>sentemb5</th>\n","      <th>sentemb6</th>\n","      <th>sentemb7</th>\n","      <th>sentemb8</th>\n","      <th>sentemb9</th>\n","      <th>sentemb10</th>\n","      <th>...</th>\n","      <th>sentemb19</th>\n","      <th>sentemb20</th>\n","      <th>sentemb21</th>\n","      <th>sentemb22</th>\n","      <th>sentemb23</th>\n","      <th>sentemb24</th>\n","      <th>sentemb25</th>\n","      <th>sentemb26</th>\n","      <th>sentemb27</th>\n","      <th>sentemb28</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.819914</td>\n","      <td>0.351344</td>\n","      <td>0.404849</td>\n","      <td>0.211062</td>\n","      <td>0.258971</td>\n","      <td>0.257296</td>\n","      <td>0.508351</td>\n","      <td>0.079092</td>\n","      <td>0.046841</td>\n","      <td>0.526339</td>\n","      <td>...</td>\n","      <td>0.494592</td>\n","      <td>0.289889</td>\n","      <td>0.115539</td>\n","      <td>0.196822</td>\n","      <td>0.42888</td>\n","      <td>0.426222</td>\n","      <td>0.362514</td>\n","      <td>0.339857</td>\n","      <td>0.504306</td>\n","      <td>0.309135</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows Ã— 28 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-244dd72e-62d4-4dad-b904-6f58e0ad5c72')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-2144fc0c-b9d8-4ac2-adf7-abb321cf5d9c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2144fc0c-b9d8-4ac2-adf7-abb321cf5d9c')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-2144fc0c-b9d8-4ac2-adf7-abb321cf5d9c button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-244dd72e-62d4-4dad-b904-6f58e0ad5c72 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-244dd72e-62d4-4dad-b904-6f58e0ad5c72');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["# putting panic extended feature with liwc features\n","X_liwc = final_df.loc[:, 'WC':'Emoji']\n","X_liwc['symptoms_ext_count'] = final_df['symptoms_ext_count']\n","X_liwc.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"p_Pl4Ys2yhRc","executionInfo":{"status":"ok","timestamp":1689673805579,"user_tz":-330,"elapsed":73,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"23a11d2b-1ff9-469d-b795-2516437741e8"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         WC  Analytic     Clout  Authentic      Tone       WPS  BigWords  \\\n","0  3.678025  0.980632 -0.111159  -0.503463 -0.906085  0.507052  1.316973   \n","\n","        Dic  Linguistic  function  ...    filler   AllPunc    Period  \\\n","0  0.342227    -0.60172 -0.018291  ... -0.109396  0.094036 -0.364488   \n","\n","      Comma     QMark    Exclam   Apostro    OtherP    Emoji  \\\n","0  1.739462 -0.232106 -0.240709  0.139085 -0.120357  0.17485   \n","\n","   symptoms_ext_count  \n","0                   8  \n","\n","[1 rows x 119 columns]"],"text/html":["\n","\n","  <div id=\"df-c657c1a3-3102-4683-b9c0-473e60ffb797\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>WC</th>\n","      <th>Analytic</th>\n","      <th>Clout</th>\n","      <th>Authentic</th>\n","      <th>Tone</th>\n","      <th>WPS</th>\n","      <th>BigWords</th>\n","      <th>Dic</th>\n","      <th>Linguistic</th>\n","      <th>function</th>\n","      <th>...</th>\n","      <th>filler</th>\n","      <th>AllPunc</th>\n","      <th>Period</th>\n","      <th>Comma</th>\n","      <th>QMark</th>\n","      <th>Exclam</th>\n","      <th>Apostro</th>\n","      <th>OtherP</th>\n","      <th>Emoji</th>\n","      <th>symptoms_ext_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.678025</td>\n","      <td>0.980632</td>\n","      <td>-0.111159</td>\n","      <td>-0.503463</td>\n","      <td>-0.906085</td>\n","      <td>0.507052</td>\n","      <td>1.316973</td>\n","      <td>0.342227</td>\n","      <td>-0.60172</td>\n","      <td>-0.018291</td>\n","      <td>...</td>\n","      <td>-0.109396</td>\n","      <td>0.094036</td>\n","      <td>-0.364488</td>\n","      <td>1.739462</td>\n","      <td>-0.232106</td>\n","      <td>-0.240709</td>\n","      <td>0.139085</td>\n","      <td>-0.120357</td>\n","      <td>0.17485</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows Ã— 119 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c657c1a3-3102-4683-b9c0-473e60ffb797')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-3d012ba0-d81d-4436-ac54-3fa2de3e249f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d012ba0-d81d-4436-ac54-3fa2de3e249f')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-3d012ba0-d81d-4436-ac54-3fa2de3e249f button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c657c1a3-3102-4683-b9c0-473e60ffb797 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c657c1a3-3102-4683-b9c0-473e60ffb797');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["X_emotions = final_df.loc[:, 'admiration':'neutral']\n","X_emotions.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"vLJNMAinyyPM","executionInfo":{"status":"ok","timestamp":1689673805580,"user_tz":-330,"elapsed":72,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"49cb7394-c15e-4420-9b0b-107794f7ac4a"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   admiration  amusement     anger  annoyance  approval    caring  confusion  \\\n","0    0.000016    0.00015  0.000705   0.001447  0.000643  0.009114    0.04885   \n","\n","   curiosity.1    desire  disappointment  ...     love  nervousness  optimism  \\\n","0     0.010012  0.000057         0.00044  ...  0.00021     0.068864  0.000185   \n","\n","      pride  realization    relief  remorse   sadness  surprise   neutral  \n","0  0.000041     0.000323  0.001267  0.00033  0.000575  0.000205  0.000843  \n","\n","[1 rows x 28 columns]"],"text/html":["\n","\n","  <div id=\"df-43e2abea-6a5d-4703-986b-4ea07519e716\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>admiration</th>\n","      <th>amusement</th>\n","      <th>anger</th>\n","      <th>annoyance</th>\n","      <th>approval</th>\n","      <th>caring</th>\n","      <th>confusion</th>\n","      <th>curiosity.1</th>\n","      <th>desire</th>\n","      <th>disappointment</th>\n","      <th>...</th>\n","      <th>love</th>\n","      <th>nervousness</th>\n","      <th>optimism</th>\n","      <th>pride</th>\n","      <th>realization</th>\n","      <th>relief</th>\n","      <th>remorse</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>neutral</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000016</td>\n","      <td>0.00015</td>\n","      <td>0.000705</td>\n","      <td>0.001447</td>\n","      <td>0.000643</td>\n","      <td>0.009114</td>\n","      <td>0.04885</td>\n","      <td>0.010012</td>\n","      <td>0.000057</td>\n","      <td>0.00044</td>\n","      <td>...</td>\n","      <td>0.00021</td>\n","      <td>0.068864</td>\n","      <td>0.000185</td>\n","      <td>0.000041</td>\n","      <td>0.000323</td>\n","      <td>0.001267</td>\n","      <td>0.00033</td>\n","      <td>0.000575</td>\n","      <td>0.000205</td>\n","      <td>0.000843</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows Ã— 28 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43e2abea-6a5d-4703-986b-4ea07519e716')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-95ccc945-2688-4a92-ad97-08e642258960\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95ccc945-2688-4a92-ad97-08e642258960')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-95ccc945-2688-4a92-ad97-08e642258960 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-43e2abea-6a5d-4703-986b-4ea07519e716 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-43e2abea-6a5d-4703-986b-4ea07519e716');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["X_intensity = final_df.loc[:, 'anger_intensity':'trust_intensity']\n","X_intensity.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"v01ktF_7zN2E","executionInfo":{"status":"ok","timestamp":1689673805580,"user_tz":-330,"elapsed":69,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"465666f0-b1d0-4de0-8831-42b3008cdd32"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   anger_intensity  anticipation_intensity  disgust_intensity  fear_intensity  \\\n","0         0.415048                0.553423           0.272333        0.568205   \n","\n","   joy_intensity  sadness_intensity  surprise_intensity  trust_intensity  \n","0         0.4095           0.467625              0.4345         0.522773  "],"text/html":["\n","\n","  <div id=\"df-090f3fa1-ecaa-478c-8972-c13b8141d2aa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anger_intensity</th>\n","      <th>anticipation_intensity</th>\n","      <th>disgust_intensity</th>\n","      <th>fear_intensity</th>\n","      <th>joy_intensity</th>\n","      <th>sadness_intensity</th>\n","      <th>surprise_intensity</th>\n","      <th>trust_intensity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.4095</td>\n","      <td>0.467625</td>\n","      <td>0.4345</td>\n","      <td>0.522773</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-090f3fa1-ecaa-478c-8972-c13b8141d2aa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-00689c16-9725-4140-ae40-c8a8d28cede6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00689c16-9725-4140-ae40-c8a8d28cede6')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-00689c16-9725-4140-ae40-c8a8d28cede6 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-090f3fa1-ecaa-478c-8972-c13b8141d2aa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-090f3fa1-ecaa-478c-8972-c13b8141d2aa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["y = df['label']"],"metadata":{"id":"to5H00tfzhI0","executionInfo":{"status":"ok","timestamp":1689673805581,"user_tz":-330,"elapsed":68,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["X_sentemb_train, X_sentemb_test, X_liwc_train, X_liwc_test, X_emotions_train, X_emotions_test, X_intensity_train, X_intensity_test, y_train, y_test = train_test_split(\n","    X_sentemb, X_liwc, X_emotions, X_intensity, y, test_size=0.2, random_state=42)"],"metadata":{"id":"Ohf_SHd5zbsY","executionInfo":{"status":"ok","timestamp":1689673805582,"user_tz":-330,"elapsed":68,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["X_sentemb.shape, X_liwc.shape, X_emotions.shape, X_intensity.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqjGxvX_jE2r","executionInfo":{"status":"ok","timestamp":1689673805583,"user_tz":-330,"elapsed":67,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"1f81b192-2df7-449f-d967-808897d25673"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((7405, 28), (7405, 119), (7405, 28), (7405, 8))"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["X_sentemb_train.shape, X_liwc_train.shape, X_emotions_train.shape, X_intensity_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JYb23HkWc1Y","executionInfo":{"status":"ok","timestamp":1689673805585,"user_tz":-330,"elapsed":60,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"0a87e559-f0a7-4afd-bdf0-7c6a04e29ec8"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((5924, 28), (5924, 119), (5924, 28), (5924, 8))"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["X_sentemb_test.shape, X_liwc_test.shape, X_emotions_test.shape, X_intensity_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueKgNUbNW1F5","executionInfo":{"status":"ok","timestamp":1689673805586,"user_tz":-330,"elapsed":55,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"7f0d467b-f0fe-4dd2-e749-107536fceffd"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1481, 28), (1481, 119), (1481, 28), (1481, 8))"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["# # Input for sentemb features\n","# input_sentemb = Input(shape=(28,))\n","# lstm_sentemb = LSTM(64)(input_sentemb)\n","\n","# # Input for LIWC features\n","# input_liwc = Input(shape=(119,))\n","# conv_liwc = Conv1D(128, 3, activation='relu')(input_liwc)\n","# conv_liwc = GlobalMaxPooling1D()(conv_liwc)\n","\n","# # Input for emotions features\n","# input_emotions = Input(shape=(28,))\n","# dense_emotions = Dense(64, activation='relu')(input_emotions)\n","\n","# # Input for intensity features\n","# input_intensity = Input(shape=(8,))\n","# dense_intensity = Dense(32, activation='relu')(input_intensity)\n","\n","# # Concatenate the outputs of all branches\n","# concatenated = Concatenate()([lstm_sentemb, conv_liwc, dense_emotions, dense_intensity])\n","\n","# # Additional Dense layers for further processing\n","# dense1 = Dense(128, activation='relu')(concatenated)\n","# dense2 = Dense(64, activation='relu')(dense1)\n","\n","# # Output layer\n","# output = Dense(1, activation='sigmoid')(dense2)\n","\n","# # Create the model\n","# model = Model(inputs=[input_sentemb, input_liwc, input_emotions, input_intensity], outputs=output)"],"metadata":{"id":"9-2MJee-xk-F","executionInfo":{"status":"ok","timestamp":1689673805588,"user_tz":-330,"elapsed":50,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["X_sentemb_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOkGBVOryqP-","executionInfo":{"status":"ok","timestamp":1689617399553,"user_tz":-330,"elapsed":325,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"305648f3-707f-4655-f0e9-fe94a1c77692"},"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5924, 28)"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["# # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","# # Input for sentemb features\n","# # input_sentemb = Input(shape=(1,28))\n","# # lstm_sentemb = LSTM(64)(input_sentemb)\n","\n","# input_sentemb = Input(shape=(28,))\n","# lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# # Input for emotions features\n","# input_emotions = Input(shape=(28,))\n","# reshaped_emotions = Reshape((28, 1))(input_emotions)\n","# cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","# cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# # # Input for emotions features\n","# # input_emotions = Input(shape=(1,28))\n","# # cnn_emotions = Conv1D(128, 3, activation='relu')(input_emotions)\n","# # cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# # Input for intensity features\n","# input_intensity = Input(shape=(8,))\n","\n","# # Input for LIWC features\n","# input_liwc = Input(shape=(119,))\n","\n","# # Concatenate the outputs of the LSTM and CNN layers\n","# concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","# # Additional Dense layers for further processing\n","# # dense1 = Dense(128, activation='relu')(concatenated)\n","# # dense2 = Dense(64, activation='relu')(dense1)\n","\n","# merged_output = Dense(128, activation='relu')(concatenated)\n","# merged_output = Dropout(rate=0.2)(merged_output)\n","# merged_output = Dense(64, activation='relu')(merged_output)\n","# merged_output = Dense(32, activation='relu')(merged_output)\n","# merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# # Output layer\n","# output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# # Create the model\n","# model = Model(inputs=[lstm_sentemb, cnn_emotions, input_intensity, input_liwc], outputs=output)"],"metadata":{"id":"voT7HnErxZAf","executionInfo":{"status":"ok","timestamp":1689617399554,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":["## LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc"],"metadata":{"id":"gEpnop9w_o7r"}},{"cell_type":"code","source":["# LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# input_emotions = Input(shape=(1, 28))  # Update the input shape to (1, 28)   # this doesnt work\n","# cnn_emotions = Conv1D(128, 3, activation='relu')(input_emotions)\n","# #cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# input_emotions = Input(shape=(28,))\n","# cnn_emotions = Conv1D(128, 3, activation='relu')(Reshape((28, 1))(input_emotions))  # works, same as above working one\n","# cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions"],"metadata":{"id":"8A7mYUnGoefE","executionInfo":{"status":"ok","timestamp":1689664080716,"user_tz":-330,"elapsed":609,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"aVmn_Kx4v9WZ","executionInfo":{"status":"ok","timestamp":1689664082285,"user_tz":-330,"elapsed":336,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# Fit the model\n","history = model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=50, batch_size=10, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-DOlN272BPT","executionInfo":{"status":"ok","timestamp":1689664349177,"user_tz":-330,"elapsed":265287,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"0a9f12ad-51bb-49a1-e0b1-1ad13908c352"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","593/593 [==============================] - 10s 9ms/step - loss: 0.5028 - accuracy: 0.7542 - val_loss: 0.4247 - val_accuracy: 0.8082\n","Epoch 2/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.3670 - accuracy: 0.8376 - val_loss: 0.3783 - val_accuracy: 0.8231\n","Epoch 3/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.2944 - accuracy: 0.8795 - val_loss: 0.3207 - val_accuracy: 0.8656\n","Epoch 4/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.2626 - accuracy: 0.8920 - val_loss: 0.3249 - val_accuracy: 0.8717\n","Epoch 5/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.2359 - accuracy: 0.9053 - val_loss: 0.3190 - val_accuracy: 0.8609\n","Epoch 6/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.2275 - accuracy: 0.9104 - val_loss: 0.3533 - val_accuracy: 0.8656\n","Epoch 7/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.2010 - accuracy: 0.9166 - val_loss: 0.3683 - val_accuracy: 0.8656\n","Epoch 8/50\n","593/593 [==============================] - 9s 15ms/step - loss: 0.1738 - accuracy: 0.9320 - val_loss: 0.3724 - val_accuracy: 0.8663\n","Epoch 9/50\n","593/593 [==============================] - 6s 10ms/step - loss: 0.1651 - accuracy: 0.9359 - val_loss: 0.3765 - val_accuracy: 0.8737\n","Epoch 10/50\n","593/593 [==============================] - 6s 9ms/step - loss: 0.1566 - accuracy: 0.9402 - val_loss: 0.4115 - val_accuracy: 0.8677\n","Epoch 11/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.1407 - accuracy: 0.9456 - val_loss: 0.3875 - val_accuracy: 0.8629\n","Epoch 12/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.1337 - accuracy: 0.9499 - val_loss: 0.4079 - val_accuracy: 0.8602\n","Epoch 13/50\n","593/593 [==============================] - 8s 13ms/step - loss: 0.1165 - accuracy: 0.9554 - val_loss: 0.4650 - val_accuracy: 0.8717\n","Epoch 14/50\n","593/593 [==============================] - 7s 12ms/step - loss: 0.1115 - accuracy: 0.9583 - val_loss: 0.4270 - val_accuracy: 0.8683\n","Epoch 15/50\n","593/593 [==============================] - 6s 11ms/step - loss: 0.1018 - accuracy: 0.9588 - val_loss: 0.5551 - val_accuracy: 0.8460\n","Epoch 16/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0986 - accuracy: 0.9634 - val_loss: 0.4550 - val_accuracy: 0.8731\n","Epoch 17/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0989 - accuracy: 0.9637 - val_loss: 0.4580 - val_accuracy: 0.8663\n","Epoch 18/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0828 - accuracy: 0.9698 - val_loss: 0.5312 - val_accuracy: 0.8704\n","Epoch 19/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0829 - accuracy: 0.9696 - val_loss: 0.5304 - val_accuracy: 0.8798\n","Epoch 20/50\n","593/593 [==============================] - 4s 8ms/step - loss: 0.0778 - accuracy: 0.9732 - val_loss: 0.4890 - val_accuracy: 0.8758\n","Epoch 21/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0776 - accuracy: 0.9720 - val_loss: 0.5329 - val_accuracy: 0.8717\n","Epoch 22/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 0.5461 - val_accuracy: 0.8697\n","Epoch 23/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.5859 - val_accuracy: 0.8663\n","Epoch 24/50\n","593/593 [==============================] - 5s 8ms/step - loss: 0.0629 - accuracy: 0.9767 - val_loss: 0.5670 - val_accuracy: 0.8670\n","Epoch 25/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0680 - accuracy: 0.9772 - val_loss: 0.5531 - val_accuracy: 0.8623\n","Epoch 26/50\n","593/593 [==============================] - 6s 9ms/step - loss: 0.0632 - accuracy: 0.9792 - val_loss: 0.5750 - val_accuracy: 0.8690\n","Epoch 27/50\n","593/593 [==============================] - 4s 8ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.6082 - val_accuracy: 0.8690\n","Epoch 28/50\n","593/593 [==============================] - 5s 8ms/step - loss: 0.0571 - accuracy: 0.9797 - val_loss: 0.6269 - val_accuracy: 0.8650\n","Epoch 29/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0581 - accuracy: 0.9819 - val_loss: 0.6183 - val_accuracy: 0.8670\n","Epoch 30/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0590 - accuracy: 0.9802 - val_loss: 0.5714 - val_accuracy: 0.8758\n","Epoch 31/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0470 - accuracy: 0.9826 - val_loss: 0.6453 - val_accuracy: 0.8623\n","Epoch 32/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 0.7739 - val_accuracy: 0.8791\n","Epoch 33/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.6388 - val_accuracy: 0.8690\n","Epoch 34/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 0.6073 - val_accuracy: 0.8771\n","Epoch 35/50\n","593/593 [==============================] - 6s 9ms/step - loss: 0.0449 - accuracy: 0.9835 - val_loss: 0.6684 - val_accuracy: 0.8656\n","Epoch 36/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0460 - accuracy: 0.9843 - val_loss: 0.6637 - val_accuracy: 0.8724\n","Epoch 37/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0480 - accuracy: 0.9824 - val_loss: 0.6941 - val_accuracy: 0.8670\n","Epoch 38/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 0.6840 - val_accuracy: 0.8670\n","Epoch 39/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0443 - accuracy: 0.9855 - val_loss: 0.7260 - val_accuracy: 0.8528\n","Epoch 40/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0425 - accuracy: 0.9848 - val_loss: 0.7931 - val_accuracy: 0.8683\n","Epoch 41/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 0.7216 - val_accuracy: 0.8737\n","Epoch 42/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.7651 - val_accuracy: 0.8683\n","Epoch 43/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0526 - accuracy: 0.9809 - val_loss: 0.7094 - val_accuracy: 0.8623\n","Epoch 44/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0434 - accuracy: 0.9875 - val_loss: 0.7462 - val_accuracy: 0.8602\n","Epoch 45/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0357 - accuracy: 0.9868 - val_loss: 0.8075 - val_accuracy: 0.8643\n","Epoch 46/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 0.7198 - val_accuracy: 0.8602\n","Epoch 47/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.8863 - val_accuracy: 0.8589\n","Epoch 48/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.7857 - val_accuracy: 0.8690\n","Epoch 49/50\n","593/593 [==============================] - 4s 7ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.7620 - val_accuracy: 0.8602\n","Epoch 50/50\n","593/593 [==============================] - 5s 9ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.8593 - val_accuracy: 0.8663\n"]}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEttvQvhPdp-","executionInfo":{"status":"ok","timestamp":1689664349675,"user_tz":-330,"elapsed":514,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"a2de86c2-c4ea-4b65-e141-103612dc08a5"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 5ms/step - loss: 0.8593 - accuracy: 0.8663\n","Loss: 0.859340488910675\n","Accuracy: 0.8663065433502197\n"]}]},{"cell_type":"code","source":["y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","y_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlbnxM3Lo91l","executionInfo":{"status":"ok","timestamp":1689622286359,"user_tz":-330,"elapsed":246,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"06d93d90-ee54-4c4a-9749-ee892ee3eafe"},"execution_count":163,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 2ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.8511371 ],\n","       [0.27780166],\n","       [0.4806624 ],\n","       ...,\n","       [0.02475166],\n","       [0.00243388],\n","       [1.        ]], dtype=float32)"]},"metadata":{},"execution_count":163}]},{"cell_type":"code","source":["y_pred[:,0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6w1c95aRsJre","executionInfo":{"status":"ok","timestamp":1689622286360,"user_tz":-330,"elapsed":7,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"2416068a-0de5-4b58-eb6f-2337752d3e89"},"execution_count":164,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.8511371 , 0.27780166, 0.4806624 , ..., 0.02475166, 0.00243388,\n","       1.        ], dtype=float32)"]},"metadata":{},"execution_count":164}]},{"cell_type":"code","source":["y_pred_labels = (y_pred > 0.5).astype(int)"],"metadata":{"id":"J1eksCmRHljO","executionInfo":{"status":"ok","timestamp":1689622299049,"user_tz":-330,"elapsed":294,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":165,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","cm = confusion_matrix(y_test, y_pred_labels)\n","cm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCH-v0tWJKPp","executionInfo":{"status":"ok","timestamp":1689622299436,"user_tz":-330,"elapsed":8,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e209bdd2-eb2c-4b5a-c94d-10d2848bb9d9"},"execution_count":166,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[453,  82],\n","       [116, 830]])"]},"metadata":{},"execution_count":166}]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Create a heatmap of the confusion matrix\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","\n","# Set axis labels\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","\n","# Show the plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"eYaPv3YVJK1E","executionInfo":{"status":"ok","timestamp":1689622299715,"user_tz":-330,"elapsed":10,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"8d44a1ae-8198-4195-a841-a48378a532d4"},"execution_count":167,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"pfbw1_feJTLQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YN90DHgVZ5NB","executionInfo":{"status":"ok","timestamp":1689623438499,"user_tz":-330,"elapsed":276,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"b7c0d5c7-e345-4a7b-b598-a6706b782f46"},"execution_count":175,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.8511371 ],\n","       [0.27780166],\n","       [0.4806624 ],\n","       ...,\n","       [0.02475166],\n","       [0.00243388],\n","       [1.        ]], dtype=float32)"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["from scipy.stats import pearsonr\n","pearsonr(y_pred[:,0], y_test)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKV8FfoxVvyy","executionInfo":{"status":"ok","timestamp":1689623457939,"user_tz":-330,"elapsed":258,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6e858a71-e4f1-429c-a2cc-808e8018b68d"},"execution_count":176,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7558254156381256"]},"metadata":{},"execution_count":176}]},{"cell_type":"code","source":[],"metadata":{"id":"Lu4D4908Vv1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ezsOM5-cVv3z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-pr1Ud6DVv6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # to register f1 score separately in Keras (not working)\n","\n","# import tensorflow as tf\n","# from tensorflow.keras import backend as K\n","\n","# def f1_score(y_true, y_pred):\n","#     y_true = K.round(y_true)\n","#     y_pred = K.round(y_pred)\n","\n","#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","\n","#     precision = true_positives / (predicted_positives + K.epsilon())\n","#     recall = true_positives / (possible_positives + K.epsilon())\n","#     f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n","\n","#     return f1\n","\n","# # Register the custom metric\n","# tf.keras.metrics.f1_score = f1_score"],"metadata":{"id":"xelc9fb0TbZc","executionInfo":{"status":"ok","timestamp":1689621765404,"user_tz":-330,"elapsed":233,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["# # to register f1 score separately in Keras (working)\n","\n","# import tensorflow as tf\n","# from tensorflow.keras import backend as K\n","# from tensorflow.keras.metrics import Metric\n","\n","# class F1Score(Metric):\n","#     def __init__(self, name='f1_score', **kwargs):\n","#         super(F1Score, self).__init__(name=name, **kwargs)\n","#         self.true_positives = self.add_weight(name='tp', initializer='zeros')\n","#         self.false_positives = self.add_weight(name='fp', initializer='zeros')\n","#         self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n","\n","#     def update_state(self, y_true, y_pred, sample_weight=None):\n","#         y_true = tf.cast(y_true, tf.float32)\n","#         y_pred = tf.cast(y_pred, tf.float32)\n","\n","#         true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n","#         false_positives = tf.reduce_sum(tf.round(tf.clip_by_value((1 - y_true) * y_pred, 0, 1)))\n","#         false_negatives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * (1 - y_pred), 0, 1)))\n","\n","#         self.true_positives.assign_add(true_positives)\n","#         self.false_positives.assign_add(false_positives)\n","#         self.false_negatives.assign_add(false_negatives)\n","\n","#     def result(self):\n","#         precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n","#         recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n","#         f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n","#         return f1\n","\n","# # Compile the model with 'F1Score' as the metric\n","# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[F1Score()])"],"metadata":{"id":"ZYNe_sd3UnvZ","executionInfo":{"status":"ok","timestamp":1689622053871,"user_tz":-330,"elapsed":278,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["# # running 7 times and getting average\n","# # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","# y_pred = np.zeros(y_test.shape[0])\n","\n","# for i in range(4):\n","\n","#     print('Iteration ',i+1)\n","\n","#     # Input for sentemb features\n","#     input_sentemb = Input(shape=(28,))\n","#     lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","#     # Input for emotions features\n","#     input_emotions = Input(shape=(28,))\n","#     reshaped_emotions = Reshape((28, 1))(input_emotions)\n","#     cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","#     cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","#     # input_emotions = Input(shape=(1, 28))  # Update the input shape to (1, 28)   # this doesnt work\n","#     # cnn_emotions = Conv1D(128, 3, activation='relu')(input_emotions)\n","#     # #cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","#     # input_emotions = Input(shape=(28,))\n","#     # cnn_emotions = Conv1D(128, 3, activation='relu')(Reshape((28, 1))(input_emotions))  # works, same as above working one\n","#     # cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","#     # Input for intensity features\n","#     input_intensity = Input(shape=(8,))\n","\n","#     # Input for LIWC features\n","#     input_liwc = Input(shape=(119,))\n","\n","#     # Concatenate the outputs of the LSTM and CNN layers\n","#     concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","#     # Additional Dense layers for further processing\n","#     merged_output = Dense(128, activation='relu')(concatenated)\n","#     merged_output = Dropout(rate=0.2)(merged_output)\n","#     merged_output = Dense(64, activation='relu')(merged_output)\n","#     merged_output = Dense(32, activation='relu')(merged_output)\n","#     merged_output = Dropout(rate=0.2)(merged_output)\n","\n","#     # Output layer\n","#     output = Dense(1, activation='sigmoid')(merged_output)\n","\n","#     # Create the model\n","#     model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","#     # Compile the model\n","#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","#     model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","#                         epochs=10, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))\n","\n","#     tmp = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","#     y_pred += tmp[:,0]\n","\n","#     print('Iteration ',i+1,' Done')\n","\n","# y_pred = y_pred/4.0    #Final predictions\n","# print('Training DONE')"],"metadata":{"id":"n_6rrVncVvwV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_data = np.array([[[0.1, 0.2], [0.3, 0.4], [0.5, 0.6], [0.7, 0.8], [0.9, 1.0]],\n","  [[1.1, 1.2], [1.3, 1.4], [1.5, 1.6], [1.7, 1.8], [1.9, 2.0]],\n","  [[2.1, 2.2], [2.3, 2.4], [2.5, 2.6], [2.7, 2.8], [2.9, 3.0]]\n","]\n",")\n","GlobalMaxPooling1D()(input_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7iaudlR74MPX","executionInfo":{"status":"ok","timestamp":1689631429172,"user_tz":-330,"elapsed":349,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"60230784-43ba-42ea-e895-4eda55095f68"},"execution_count":181,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.9, 1. ],\n","       [1.9, 2. ],\n","       [2.9, 3. ]], dtype=float32)>"]},"metadata":{},"execution_count":181}]},{"cell_type":"code","source":[],"metadata":{"id":"7ECGhKpI4OGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iZNZVPfW_lfM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNN for sentemb, LSTM for emotions, directly give input for intensity and liwc"],"metadata":{"id":"GKZDZiBXC9YP"}},{"cell_type":"code","source":["input_emotions = Input(shape=(28,))\n","lstm_emotions = LSTM(64)(Reshape((1, 28))(input_emotions))\n","\n","input_sentemb = Input(shape=(28,))\n","reshaped_sentemb = Reshape((28, 1))(input_sentemb)\n","cnn_sentemb = Conv1D(128, 3, activation='relu')(reshaped_sentemb)\n","cnn_sentemb = GlobalMaxPooling1D()(cnn_sentemb)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([cnn_sentemb, lstm_emotions, input_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N77lqlmX_lr6","executionInfo":{"status":"ok","timestamp":1689634786500,"user_tz":-330,"elapsed":21123,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"664e9b7f-e09c-4ffd-b3ef-163f40438a83"},"execution_count":203,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 4s 10ms/step - loss: 0.5376 - accuracy: 0.7262 - val_loss: 0.4658 - val_accuracy: 0.7745\n","Epoch 2/20\n","186/186 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.7941 - val_loss: 0.4311 - val_accuracy: 0.7914\n","Epoch 3/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.3794 - accuracy: 0.8304 - val_loss: 0.3995 - val_accuracy: 0.8157\n","Epoch 4/20\n","186/186 [==============================] - 1s 5ms/step - loss: 0.3249 - accuracy: 0.8547 - val_loss: 0.3909 - val_accuracy: 0.8292\n","Epoch 5/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.8815 - val_loss: 0.3994 - val_accuracy: 0.8393\n","Epoch 6/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.2561 - accuracy: 0.8974 - val_loss: 0.3966 - val_accuracy: 0.8447\n","Epoch 7/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.2321 - accuracy: 0.9080 - val_loss: 0.3997 - val_accuracy: 0.8501\n","Epoch 8/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9202 - val_loss: 0.3983 - val_accuracy: 0.8515\n","Epoch 9/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1969 - accuracy: 0.9225 - val_loss: 0.3741 - val_accuracy: 0.8616\n","Epoch 10/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1730 - accuracy: 0.9308 - val_loss: 0.3968 - val_accuracy: 0.8582\n","Epoch 11/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1527 - accuracy: 0.9413 - val_loss: 0.4072 - val_accuracy: 0.8609\n","Epoch 12/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9453 - val_loss: 0.4067 - val_accuracy: 0.8710\n","Epoch 13/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1244 - accuracy: 0.9502 - val_loss: 0.4409 - val_accuracy: 0.8616\n","Epoch 14/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1066 - accuracy: 0.9600 - val_loss: 0.4732 - val_accuracy: 0.8542\n","Epoch 15/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9620 - val_loss: 0.4837 - val_accuracy: 0.8569\n","Epoch 16/20\n","186/186 [==============================] - 1s 5ms/step - loss: 0.0935 - accuracy: 0.9642 - val_loss: 0.5125 - val_accuracy: 0.8643\n","Epoch 17/20\n","186/186 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9649 - val_loss: 0.5232 - val_accuracy: 0.8629\n","Epoch 18/20\n","186/186 [==============================] - 1s 7ms/step - loss: 0.0991 - accuracy: 0.9634 - val_loss: 0.5394 - val_accuracy: 0.8575\n","Epoch 19/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9610 - val_loss: 0.5249 - val_accuracy: 0.8521\n","Epoch 20/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9710 - val_loss: 0.5703 - val_accuracy: 0.8596\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x79d572b2b490>"]},"metadata":{},"execution_count":203}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLUBQhSXEGp7","executionInfo":{"status":"ok","timestamp":1689634786848,"user_tz":-330,"elapsed":353,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6fcfb2e9-20e2-45d8-bef0-e5194f398a34"},"execution_count":204,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.8596\n","Loss: 0.5702791810035706\n","Accuracy: 0.8595543503761292\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Gttt5gEjEamL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM for sentemb, LSTM for emotions, directly give input for intensity and liwc"],"metadata":{"id":"2XhR6yvBFYCH"}},{"cell_type":"code","source":["input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","input_emotions = Input(shape=(28,))\n","lstm_emotions = LSTM(64)(Reshape((1, 28))(input_emotions))\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, lstm_emotions, input_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tK04EAXLFbJ8","executionInfo":{"status":"ok","timestamp":1689635946604,"user_tz":-330,"elapsed":19687,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"ed629c1c-4b8c-4cd3-c398-dcf946b05355"},"execution_count":229,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 4s 7ms/step - loss: 0.5261 - accuracy: 0.7355 - val_loss: 0.4457 - val_accuracy: 0.7914\n","Epoch 2/20\n","186/186 [==============================] - 1s 5ms/step - loss: 0.4038 - accuracy: 0.8197 - val_loss: 0.3746 - val_accuracy: 0.8258\n","Epoch 3/20\n","186/186 [==============================] - 1s 6ms/step - loss: 0.3208 - accuracy: 0.8597 - val_loss: 0.3511 - val_accuracy: 0.8413\n","Epoch 4/20\n","186/186 [==============================] - 1s 6ms/step - loss: 0.2812 - accuracy: 0.8805 - val_loss: 0.3287 - val_accuracy: 0.8542\n","Epoch 5/20\n","186/186 [==============================] - 1s 5ms/step - loss: 0.2560 - accuracy: 0.8991 - val_loss: 0.3386 - val_accuracy: 0.8481\n","Epoch 6/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.2262 - accuracy: 0.9100 - val_loss: 0.3445 - val_accuracy: 0.8589\n","Epoch 7/20\n","186/186 [==============================] - 1s 3ms/step - loss: 0.2054 - accuracy: 0.9183 - val_loss: 0.3487 - val_accuracy: 0.8609\n","Epoch 8/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9283 - val_loss: 0.3315 - val_accuracy: 0.8744\n","Epoch 9/20\n","186/186 [==============================] - 1s 3ms/step - loss: 0.1746 - accuracy: 0.9320 - val_loss: 0.3557 - val_accuracy: 0.8690\n","Epoch 10/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1585 - accuracy: 0.9391 - val_loss: 0.3875 - val_accuracy: 0.8656\n","Epoch 11/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1509 - accuracy: 0.9394 - val_loss: 0.4200 - val_accuracy: 0.8670\n","Epoch 12/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9429 - val_loss: 0.4324 - val_accuracy: 0.8677\n","Epoch 13/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9519 - val_loss: 0.4776 - val_accuracy: 0.8575\n","Epoch 14/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9566 - val_loss: 0.4553 - val_accuracy: 0.8582\n","Epoch 15/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9622 - val_loss: 0.4633 - val_accuracy: 0.8737\n","Epoch 16/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9624 - val_loss: 0.4501 - val_accuracy: 0.8656\n","Epoch 17/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9666 - val_loss: 0.4970 - val_accuracy: 0.8710\n","Epoch 18/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9652 - val_loss: 0.5198 - val_accuracy: 0.8575\n","Epoch 19/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9684 - val_loss: 0.5569 - val_accuracy: 0.8670\n","Epoch 20/20\n","186/186 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9760 - val_loss: 0.5745 - val_accuracy: 0.8643\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x79d5591f90c0>"]},"metadata":{},"execution_count":229}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHF1Jo6BF_UU","executionInfo":{"status":"ok","timestamp":1689635947058,"user_tz":-330,"elapsed":464,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"cd07a82a-70e3-4af4-e61b-4e373a527fbd"},"execution_count":230,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.8643\n","Loss: 0.574522078037262\n","Accuracy: 0.8642808794975281\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KxI3ZEU0GAfa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNN for sentemb, CNN for emotions, directly give input for intensity and liwc"],"metadata":{"id":"KMeHUkHWH269"}},{"cell_type":"code","source":["input_sentemb = Input(shape=(28,))\n","reshaped_sentemb = Reshape((28, 1))(input_sentemb)\n","cnn_sentemb = Conv1D(128, 3, activation='relu')(reshaped_sentemb)\n","cnn_sentemb = GlobalMaxPooling1D()(cnn_sentemb)\n","\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([cnn_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkV2TCdSH54y","executionInfo":{"status":"ok","timestamp":1689635843302,"user_tz":-330,"elapsed":18566,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d917bffe-4d29-4692-9cf0-18280171d820"},"execution_count":227,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 2s 5ms/step - loss: 0.5283 - accuracy: 0.7286 - val_loss: 0.4537 - val_accuracy: 0.7785\n","Epoch 2/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.4256 - accuracy: 0.8033 - val_loss: 0.4282 - val_accuracy: 0.8042\n","Epoch 3/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.3694 - accuracy: 0.8391 - val_loss: 0.4180 - val_accuracy: 0.8028\n","Epoch 4/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.3267 - accuracy: 0.8547 - val_loss: 0.3938 - val_accuracy: 0.8305\n","Epoch 5/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.2877 - accuracy: 0.8812 - val_loss: 0.3748 - val_accuracy: 0.8488\n","Epoch 6/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.2460 - accuracy: 0.9001 - val_loss: 0.3450 - val_accuracy: 0.8575\n","Epoch 7/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9124 - val_loss: 0.3758 - val_accuracy: 0.8508\n","Epoch 8/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1969 - accuracy: 0.9227 - val_loss: 0.3761 - val_accuracy: 0.8643\n","Epoch 9/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1863 - accuracy: 0.9256 - val_loss: 0.3783 - val_accuracy: 0.8535\n","Epoch 10/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9365 - val_loss: 0.3905 - val_accuracy: 0.8616\n","Epoch 11/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1619 - accuracy: 0.9409 - val_loss: 0.3969 - val_accuracy: 0.8616\n","Epoch 12/20\n","186/186 [==============================] - 1s 6ms/step - loss: 0.1342 - accuracy: 0.9485 - val_loss: 0.4369 - val_accuracy: 0.8737\n","Epoch 13/20\n","186/186 [==============================] - 1s 6ms/step - loss: 0.1347 - accuracy: 0.9504 - val_loss: 0.4526 - val_accuracy: 0.8535\n","Epoch 14/20\n","186/186 [==============================] - 1s 7ms/step - loss: 0.1201 - accuracy: 0.9564 - val_loss: 0.4264 - val_accuracy: 0.8670\n","Epoch 15/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1160 - accuracy: 0.9570 - val_loss: 0.4733 - val_accuracy: 0.8643\n","Epoch 16/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9603 - val_loss: 0.5063 - val_accuracy: 0.8629\n","Epoch 17/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9656 - val_loss: 0.5431 - val_accuracy: 0.8575\n","Epoch 18/20\n","186/186 [==============================] - 1s 5ms/step - loss: 0.0853 - accuracy: 0.9694 - val_loss: 0.5421 - val_accuracy: 0.8602\n","Epoch 19/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.5165 - val_accuracy: 0.8677\n","Epoch 20/20\n","186/186 [==============================] - 1s 4ms/step - loss: 0.0761 - accuracy: 0.9705 - val_loss: 0.5323 - val_accuracy: 0.8650\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x79d55d184130>"]},"metadata":{},"execution_count":227}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3huDVmQKIIjc","executionInfo":{"status":"ok","timestamp":1689635843674,"user_tz":-330,"elapsed":391,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"80be1db1-e520-4e6c-c91e-75b77cfcb6be"},"execution_count":228,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.8650\n","Loss: 0.5323306322097778\n","Accuracy: 0.8649561405181885\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ptEEE5OVIdtl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"72VQozJoMSQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OJG2ctU7MSSX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A31OIyyRMSVA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM for sentemb, CNN for emotions, LSTM intensity and CNN liwc"],"metadata":{"id":"nBgiuo-2LTV3"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","lstm_intensity = LSTM(64)(Reshape((1, 8))(input_intensity))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","reshaped_liwc = Reshape((119, 1))(input_liwc)\n","cnn_liwc = Conv1D(128, 3, activation='relu')(reshaped_liwc)\n","cnn_liwc = GlobalMaxPooling1D()(cnn_liwc)\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, cnn_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=10, batch_size=64, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEEOod66LhB8","executionInfo":{"status":"ok","timestamp":1689665170232,"user_tz":-330,"elapsed":26991,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"3cce292d-ec68-4976-803b-4b0c6c12f446"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","93/93 [==============================] - 9s 19ms/step - loss: 0.6490 - accuracy: 0.6345 - val_loss: 0.5918 - val_accuracy: 0.6597\n","Epoch 2/10\n","93/93 [==============================] - 1s 9ms/step - loss: 0.5297 - accuracy: 0.7270 - val_loss: 0.4704 - val_accuracy: 0.7502\n","Epoch 3/10\n","93/93 [==============================] - 1s 10ms/step - loss: 0.4605 - accuracy: 0.7687 - val_loss: 0.4091 - val_accuracy: 0.7920\n","Epoch 4/10\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3901 - accuracy: 0.8275 - val_loss: 0.3839 - val_accuracy: 0.8265\n","Epoch 5/10\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3639 - accuracy: 0.8412 - val_loss: 0.3344 - val_accuracy: 0.8494\n","Epoch 6/10\n","93/93 [==============================] - 1s 13ms/step - loss: 0.3460 - accuracy: 0.8545 - val_loss: 0.3861 - val_accuracy: 0.8386\n","Epoch 7/10\n","93/93 [==============================] - 1s 15ms/step - loss: 0.3441 - accuracy: 0.8542 - val_loss: 0.3186 - val_accuracy: 0.8589\n","Epoch 8/10\n","93/93 [==============================] - 1s 14ms/step - loss: 0.3324 - accuracy: 0.8560 - val_loss: 0.3154 - val_accuracy: 0.8663\n","Epoch 9/10\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3273 - accuracy: 0.8594 - val_loss: 0.3196 - val_accuracy: 0.8636\n","Epoch 10/10\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3288 - accuracy: 0.8601 - val_loss: 0.3134 - val_accuracy: 0.8650\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f12b0632bf0>"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0F8PsGUMMXV","executionInfo":{"status":"ok","timestamp":1689665170601,"user_tz":-330,"elapsed":372,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"c21ebc98-6ffd-4fd4-8d29-e81ed2c83a32"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8650\n","Loss: 0.31335359811782837\n","Accuracy: 0.8649561405181885\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cI6cZapCMUUr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM for sentemb, CNN for emotions, CNN intensity and LSTM liwc"],"metadata":{"id":"gyUlEvt1M_qr"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","reshaped_intensity = Reshape((8, 1))(input_intensity)\n","cnn_intensity = Conv1D(128, 3, activation='relu')(reshaped_intensity)\n","cnn_intensity = GlobalMaxPooling1D()(cnn_intensity)\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","lstm_liwc = LSTM(64)(Reshape((1, 119))(input_liwc))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, cnn_intensity, lstm_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=64, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2w3qyecNcI2","executionInfo":{"status":"ok","timestamp":1689664013668,"user_tz":-330,"elapsed":38004,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"c166d60f-3121-4a74-dd88-4c07ce2b6ffb"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","93/93 [==============================] - 11s 29ms/step - loss: 0.5389 - accuracy: 0.7164 - val_loss: 0.4391 - val_accuracy: 0.7880\n","Epoch 2/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3741 - accuracy: 0.8315 - val_loss: 0.3564 - val_accuracy: 0.8440\n","Epoch 3/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.2967 - accuracy: 0.8736 - val_loss: 0.3473 - val_accuracy: 0.8481\n","Epoch 4/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.2456 - accuracy: 0.9018 - val_loss: 0.3377 - val_accuracy: 0.8589\n","Epoch 5/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.2030 - accuracy: 0.9217 - val_loss: 0.3689 - val_accuracy: 0.8535\n","Epoch 6/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.1778 - accuracy: 0.9350 - val_loss: 0.3885 - val_accuracy: 0.8582\n","Epoch 7/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.1365 - accuracy: 0.9504 - val_loss: 0.4115 - val_accuracy: 0.8609\n","Epoch 8/20\n","93/93 [==============================] - 2s 22ms/step - loss: 0.1100 - accuracy: 0.9620 - val_loss: 0.4642 - val_accuracy: 0.8589\n","Epoch 9/20\n","93/93 [==============================] - 2s 23ms/step - loss: 0.0980 - accuracy: 0.9649 - val_loss: 0.4982 - val_accuracy: 0.8555\n","Epoch 10/20\n","93/93 [==============================] - 2s 20ms/step - loss: 0.0820 - accuracy: 0.9701 - val_loss: 0.5955 - val_accuracy: 0.8501\n","Epoch 11/20\n","93/93 [==============================] - 2s 20ms/step - loss: 0.0754 - accuracy: 0.9710 - val_loss: 0.6223 - val_accuracy: 0.8508\n","Epoch 12/20\n","93/93 [==============================] - 2s 20ms/step - loss: 0.0522 - accuracy: 0.9838 - val_loss: 0.6620 - val_accuracy: 0.8548\n","Epoch 13/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0436 - accuracy: 0.9855 - val_loss: 0.7373 - val_accuracy: 0.8542\n","Epoch 14/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0514 - accuracy: 0.9813 - val_loss: 0.7463 - val_accuracy: 0.8440\n","Epoch 15/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.0538 - accuracy: 0.9801 - val_loss: 0.7972 - val_accuracy: 0.8460\n","Epoch 16/20\n","93/93 [==============================] - 1s 14ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.8197 - val_accuracy: 0.8542\n","Epoch 17/20\n","93/93 [==============================] - 2s 16ms/step - loss: 0.0270 - accuracy: 0.9904 - val_loss: 0.8992 - val_accuracy: 0.8575\n","Epoch 18/20\n","93/93 [==============================] - 3s 28ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 1.0315 - val_accuracy: 0.8413\n","Epoch 19/20\n","93/93 [==============================] - 1s 15ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 1.0602 - val_accuracy: 0.8562\n","Epoch 20/20\n","93/93 [==============================] - 1s 14ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 1.0896 - val_accuracy: 0.8508\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f13843e1840>"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGSUXwkxO3ji","executionInfo":{"status":"ok","timestamp":1689664014038,"user_tz":-330,"elapsed":376,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"9eeeaba1-9c8c-4f59-e603-b5edc8917a43"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 4ms/step - loss: 1.0896 - accuracy: 0.8508\n","Loss: 1.0895622968673706\n","Accuracy: 0.8507764935493469\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1tl0h6wfPAps"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM for sentemb, CNN for emotions, LSTM intensity and LSTM liwc"],"metadata":{"id":"UgxX0AIgz3YJ"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","lstm_intensity = LSTM(64)(Reshape((1, 8))(input_intensity))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","lstm_liwc = LSTM(64)(Reshape((1, 119))(input_liwc))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, lstm_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fek1XSGcz7z8","executionInfo":{"status":"ok","timestamp":1689664779030,"user_tz":-330,"elapsed":90130,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"2f80481d-0272-444c-8e0a-b431c4b55561"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 13s 25ms/step - loss: 0.5055 - accuracy: 0.7348 - val_loss: 0.4016 - val_accuracy: 0.8204\n","Epoch 2/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.3422 - accuracy: 0.8491 - val_loss: 0.4189 - val_accuracy: 0.8015\n","Epoch 3/20\n","186/186 [==============================] - 5s 28ms/step - loss: 0.2646 - accuracy: 0.8891 - val_loss: 0.3435 - val_accuracy: 0.8501\n","Epoch 4/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.2160 - accuracy: 0.9127 - val_loss: 0.3561 - val_accuracy: 0.8609\n","Epoch 5/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.1756 - accuracy: 0.9316 - val_loss: 0.4207 - val_accuracy: 0.8710\n","Epoch 6/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1452 - accuracy: 0.9453 - val_loss: 0.4057 - val_accuracy: 0.8710\n","Epoch 7/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.1138 - accuracy: 0.9578 - val_loss: 0.4939 - val_accuracy: 0.8569\n","Epoch 8/20\n","186/186 [==============================] - 4s 21ms/step - loss: 0.1028 - accuracy: 0.9615 - val_loss: 0.5623 - val_accuracy: 0.8521\n","Epoch 9/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.0833 - accuracy: 0.9703 - val_loss: 0.5811 - val_accuracy: 0.8636\n","Epoch 10/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.0659 - accuracy: 0.9775 - val_loss: 0.6140 - val_accuracy: 0.8602\n","Epoch 11/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.0524 - accuracy: 0.9806 - val_loss: 0.7165 - val_accuracy: 0.8413\n","Epoch 12/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.0612 - accuracy: 0.9802 - val_loss: 0.6757 - val_accuracy: 0.8542\n","Epoch 13/20\n","186/186 [==============================] - 4s 19ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 0.7721 - val_accuracy: 0.8481\n","Epoch 14/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.0561 - accuracy: 0.9799 - val_loss: 0.7632 - val_accuracy: 0.8542\n","Epoch 15/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.8368 - val_accuracy: 0.8521\n","Epoch 16/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.8656 - val_accuracy: 0.8420\n","Epoch 17/20\n","186/186 [==============================] - 3s 16ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.9620 - val_accuracy: 0.8494\n","Epoch 18/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.9027 - val_accuracy: 0.8447\n","Epoch 19/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.9958 - val_accuracy: 0.8521\n","Epoch 20/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 1.0444 - val_accuracy: 0.8467\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f13857bdcc0>"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVpv4y7x1GE_","executionInfo":{"status":"ok","timestamp":1689664779380,"user_tz":-330,"elapsed":358,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e880a931-a3bf-4d50-8ec4-ce3edd9412e3"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 4ms/step - loss: 1.0444 - accuracy: 0.8467\n","Loss: 1.044447660446167\n","Accuracy: 0.8467251658439636\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Yy8nFHCl1GkE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM for sentemb, CNN for emotions, CNN intensity and CNN liwc"],"metadata":{"id":"P8H_G8BX1GqX"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","reshaped_intensity = Reshape((8, 1))(input_intensity)\n","cnn_intensity = Conv1D(128, 3, activation='relu')(reshaped_intensity)\n","cnn_intensity = GlobalMaxPooling1D()(cnn_intensity)\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","reshaped_liwc = Reshape((119, 1))(input_liwc)\n","cnn_liwc = Conv1D(128, 3, activation='relu')(reshaped_liwc)\n","cnn_liwc = GlobalMaxPooling1D()(cnn_liwc)\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, cnn_intensity, cnn_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=64, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PvNYEi7g1KEA","executionInfo":{"status":"ok","timestamp":1689664941878,"user_tz":-330,"elapsed":26910,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6de66126-aaf4-4a45-895a-67303933330c"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","93/93 [==============================] - 7s 18ms/step - loss: 0.6522 - accuracy: 0.6210 - val_loss: 0.6377 - val_accuracy: 0.6793\n","Epoch 2/20\n","93/93 [==============================] - 1s 13ms/step - loss: 0.5302 - accuracy: 0.7289 - val_loss: 0.4869 - val_accuracy: 0.7441\n","Epoch 3/20\n","93/93 [==============================] - 1s 13ms/step - loss: 0.4736 - accuracy: 0.7687 - val_loss: 0.4336 - val_accuracy: 0.7589\n","Epoch 4/20\n","93/93 [==============================] - 1s 15ms/step - loss: 0.4219 - accuracy: 0.8030 - val_loss: 0.4047 - val_accuracy: 0.7839\n","Epoch 5/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3813 - accuracy: 0.8248 - val_loss: 0.3491 - val_accuracy: 0.8332\n","Epoch 6/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3573 - accuracy: 0.8467 - val_loss: 0.3373 - val_accuracy: 0.8515\n","Epoch 7/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3407 - accuracy: 0.8508 - val_loss: 0.3317 - val_accuracy: 0.8596\n","Epoch 8/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3318 - accuracy: 0.8597 - val_loss: 0.3227 - val_accuracy: 0.8589\n","Epoch 9/20\n","93/93 [==============================] - 2s 17ms/step - loss: 0.3339 - accuracy: 0.8599 - val_loss: 0.3245 - val_accuracy: 0.8582\n","Epoch 10/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3245 - accuracy: 0.8589 - val_loss: 0.3149 - val_accuracy: 0.8643\n","Epoch 11/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3285 - accuracy: 0.8589 - val_loss: 0.3104 - val_accuracy: 0.8683\n","Epoch 12/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3255 - accuracy: 0.8629 - val_loss: 0.3293 - val_accuracy: 0.8616\n","Epoch 13/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3156 - accuracy: 0.8650 - val_loss: 0.3192 - val_accuracy: 0.8623\n","Epoch 14/20\n","93/93 [==============================] - 1s 10ms/step - loss: 0.3188 - accuracy: 0.8675 - val_loss: 0.3117 - val_accuracy: 0.8596\n","Epoch 15/20\n","93/93 [==============================] - 1s 13ms/step - loss: 0.3120 - accuracy: 0.8690 - val_loss: 0.3044 - val_accuracy: 0.8724\n","Epoch 16/20\n","93/93 [==============================] - 1s 13ms/step - loss: 0.3161 - accuracy: 0.8655 - val_loss: 0.3068 - val_accuracy: 0.8731\n","Epoch 17/20\n","93/93 [==============================] - 1s 13ms/step - loss: 0.3148 - accuracy: 0.8680 - val_loss: 0.3055 - val_accuracy: 0.8656\n","Epoch 18/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3157 - accuracy: 0.8697 - val_loss: 0.3809 - val_accuracy: 0.8413\n","Epoch 19/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3217 - accuracy: 0.8673 - val_loss: 0.3044 - val_accuracy: 0.8717\n","Epoch 20/20\n","93/93 [==============================] - 1s 9ms/step - loss: 0.3110 - accuracy: 0.8700 - val_loss: 0.3032 - val_accuracy: 0.8690\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f13001c1660>"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUQVjzgQ3e68","executionInfo":{"status":"ok","timestamp":1689664942216,"user_tz":-330,"elapsed":351,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6b209b39-a5c5-4265-c9b6-ee8d5483e9c3"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8690\n","Loss: 0.3031615912914276\n","Accuracy: 0.869007408618927\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"T785Nkz43pSg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"FUGikFROCRd2"}},{"cell_type":"code","source":["# LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])   # concatenated.shape = TensorShape([None, 319])\n","\n","# Additional Dense layers for further processing\n","\n","reshaped_concatenated = Reshape((319, 1))(concatenated)\n","merged_output = Conv1D(128, 3, activation='relu')(reshaped_concatenated)\n","merged_output = GlobalMaxPooling1D()(merged_output)\n","\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions"],"metadata":{"id":"omDI3GQtCSlv","executionInfo":{"status":"ok","timestamp":1689667786751,"user_tz":-330,"elapsed":640,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgb1Fht0DHTQ","executionInfo":{"status":"ok","timestamp":1689667929270,"user_tz":-330,"elapsed":85308,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"94285f40-3c90-48ba-ae88-293bff71fafb"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 17s 14ms/step - loss: 0.5341 - accuracy: 0.7245 - val_loss: 0.4735 - val_accuracy: 0.7643\n","Epoch 2/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.4222 - accuracy: 0.8054 - val_loss: 0.4196 - val_accuracy: 0.8082\n","Epoch 3/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.3444 - accuracy: 0.8442 - val_loss: 0.3726 - val_accuracy: 0.8400\n","Epoch 4/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.2933 - accuracy: 0.8756 - val_loss: 0.3385 - val_accuracy: 0.8501\n","Epoch 5/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.2631 - accuracy: 0.8898 - val_loss: 0.3741 - val_accuracy: 0.8447\n","Epoch 6/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.2370 - accuracy: 0.9014 - val_loss: 0.3224 - val_accuracy: 0.8677\n","Epoch 7/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.2089 - accuracy: 0.9168 - val_loss: 0.3331 - val_accuracy: 0.8650\n","Epoch 8/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.2022 - accuracy: 0.9223 - val_loss: 0.3695 - val_accuracy: 0.8575\n","Epoch 9/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.1780 - accuracy: 0.9320 - val_loss: 0.3590 - val_accuracy: 0.8670\n","Epoch 10/20\n","186/186 [==============================] - 2s 13ms/step - loss: 0.1624 - accuracy: 0.9364 - val_loss: 0.3963 - val_accuracy: 0.8555\n","Epoch 11/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.1599 - accuracy: 0.9350 - val_loss: 0.3795 - val_accuracy: 0.8683\n","Epoch 12/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.1349 - accuracy: 0.9485 - val_loss: 0.3971 - val_accuracy: 0.8704\n","Epoch 13/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.1248 - accuracy: 0.9510 - val_loss: 0.6020 - val_accuracy: 0.8373\n","Epoch 14/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1322 - accuracy: 0.9460 - val_loss: 0.4522 - val_accuracy: 0.8623\n","Epoch 15/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.1022 - accuracy: 0.9632 - val_loss: 0.4981 - val_accuracy: 0.8704\n","Epoch 16/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.1149 - accuracy: 0.9585 - val_loss: 0.4480 - val_accuracy: 0.8710\n","Epoch 17/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.0934 - accuracy: 0.9664 - val_loss: 0.5344 - val_accuracy: 0.8643\n","Epoch 18/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.0812 - accuracy: 0.9676 - val_loss: 0.5456 - val_accuracy: 0.8724\n","Epoch 19/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.0834 - accuracy: 0.9689 - val_loss: 0.5284 - val_accuracy: 0.8636\n","Epoch 20/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.0716 - accuracy: 0.9732 - val_loss: 0.6063 - val_accuracy: 0.8677\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7e430009f040>"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cB1C3UODHY8","executionInfo":{"status":"ok","timestamp":1689667929272,"user_tz":-330,"elapsed":50,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"2ae59e47-f1f1-45ea-e75e-640f1fdaf38b"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 6ms/step - loss: 0.6063 - accuracy: 0.8677\n","Loss: 0.6063438653945923\n","Accuracy: 0.8676570057868958\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rby20EbyDHbI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to check shape of concatenated tensor\n","\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])"],"metadata":{"id":"3GE_m9q5C03j","executionInfo":{"status":"ok","timestamp":1689667726429,"user_tz":-330,"elapsed":3912,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["concatenated.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAPyeXUNCgHE","executionInfo":{"status":"ok","timestamp":1689667726431,"user_tz":-330,"elapsed":18,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"59e93f5e-9ce4-4819-f065-9ee38160d0fa"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([None, 319])"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":[],"metadata":{"id":"6tCi3OMMChA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZeSvHeJtJurb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM sentemb, CNN emotions, LSTM intensity, liwc directly input"],"metadata":{"id":"0A8mWF2tK9rR"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(64)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","lstm_intensity = LSTM(64)(Reshape((1, 8))(input_intensity))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=64, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cg6d4oZDJuuv","executionInfo":{"status":"ok","timestamp":1689670223968,"user_tz":-330,"elapsed":40542,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"83d8514e-70d4-417f-a88d-d0df44254cd3"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","93/93 [==============================] - 11s 32ms/step - loss: 0.5374 - accuracy: 0.7220 - val_loss: 0.4670 - val_accuracy: 0.7569\n","Epoch 2/20\n","93/93 [==============================] - 2s 17ms/step - loss: 0.4303 - accuracy: 0.8013 - val_loss: 0.4096 - val_accuracy: 0.8130\n","Epoch 3/20\n","93/93 [==============================] - 2s 17ms/step - loss: 0.3668 - accuracy: 0.8358 - val_loss: 0.3727 - val_accuracy: 0.8332\n","Epoch 4/20\n","93/93 [==============================] - 2s 23ms/step - loss: 0.3178 - accuracy: 0.8602 - val_loss: 0.3572 - val_accuracy: 0.8528\n","Epoch 5/20\n","93/93 [==============================] - 2s 22ms/step - loss: 0.2835 - accuracy: 0.8822 - val_loss: 0.3443 - val_accuracy: 0.8555\n","Epoch 6/20\n","93/93 [==============================] - 2s 24ms/step - loss: 0.2510 - accuracy: 0.9001 - val_loss: 0.3342 - val_accuracy: 0.8636\n","Epoch 7/20\n","93/93 [==============================] - 2s 23ms/step - loss: 0.2216 - accuracy: 0.9136 - val_loss: 0.3345 - val_accuracy: 0.8602\n","Epoch 8/20\n","93/93 [==============================] - 1s 12ms/step - loss: 0.2007 - accuracy: 0.9212 - val_loss: 0.3523 - val_accuracy: 0.8616\n","Epoch 9/20\n","93/93 [==============================] - 1s 11ms/step - loss: 0.1944 - accuracy: 0.9223 - val_loss: 0.3456 - val_accuracy: 0.8683\n","Epoch 10/20\n","93/93 [==============================] - 1s 11ms/step - loss: 0.1754 - accuracy: 0.9311 - val_loss: 0.3708 - val_accuracy: 0.8602\n","Epoch 11/20\n","93/93 [==============================] - 2s 18ms/step - loss: 0.1612 - accuracy: 0.9377 - val_loss: 0.4076 - val_accuracy: 0.8508\n","Epoch 12/20\n","93/93 [==============================] - 2s 21ms/step - loss: 0.1551 - accuracy: 0.9397 - val_loss: 0.4090 - val_accuracy: 0.8704\n","Epoch 13/20\n","93/93 [==============================] - 1s 12ms/step - loss: 0.1359 - accuracy: 0.9478 - val_loss: 0.4166 - val_accuracy: 0.8670\n","Epoch 14/20\n","93/93 [==============================] - 1s 12ms/step - loss: 0.1328 - accuracy: 0.9478 - val_loss: 0.4434 - val_accuracy: 0.8562\n","Epoch 15/20\n","93/93 [==============================] - 1s 13ms/step - loss: 0.1292 - accuracy: 0.9504 - val_loss: 0.4259 - val_accuracy: 0.8731\n","Epoch 16/20\n","93/93 [==============================] - 2s 19ms/step - loss: 0.1097 - accuracy: 0.9595 - val_loss: 0.4883 - val_accuracy: 0.8582\n","Epoch 17/20\n","93/93 [==============================] - 2s 17ms/step - loss: 0.1154 - accuracy: 0.9571 - val_loss: 0.4520 - val_accuracy: 0.8737\n","Epoch 18/20\n","93/93 [==============================] - 1s 14ms/step - loss: 0.1081 - accuracy: 0.9568 - val_loss: 0.4741 - val_accuracy: 0.8663\n","Epoch 19/20\n","93/93 [==============================] - 1s 12ms/step - loss: 0.0877 - accuracy: 0.9667 - val_loss: 0.4944 - val_accuracy: 0.8636\n","Epoch 20/20\n","93/93 [==============================] - 1s 11ms/step - loss: 0.0820 - accuracy: 0.9708 - val_loss: 0.4928 - val_accuracy: 0.8704\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7e4259f6bee0>"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-89cQbdOJ5V7","executionInfo":{"status":"ok","timestamp":1689670224587,"user_tz":-330,"elapsed":636,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"c1fc8fdc-85e3-484e-b42b-ae1a5e78a9d9"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.8704\n","Loss: 0.4928414821624756\n","Accuracy: 0.870357871055603\n"]}]},{"cell_type":"markdown","source":["20 32 - 0.871/0.544 <br>\n","20 64 - 0.870/0.492"],"metadata":{"id":"GmsGfvSYMQyP"}},{"cell_type":"code","source":[],"metadata":{"id":"hI5KptxqKHOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM (with lstm layer having 32 neurons, not 64) sentemb, CNN emotions, LSTM(32) intensity, liwc directly input"],"metadata":{"id":"deEEGs8CMpab"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(32)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","lstm_intensity = LSTM(32)(Reshape((1, 8))(input_intensity))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1lsejVKMp0e","executionInfo":{"status":"ok","timestamp":1689670413043,"user_tz":-330,"elapsed":87104,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"cb00aa10-ebed-4ff7-c884-9520c2a2efe9"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 15s 33ms/step - loss: 0.5291 - accuracy: 0.7357 - val_loss: 0.4566 - val_accuracy: 0.7738\n","Epoch 2/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.4060 - accuracy: 0.8131 - val_loss: 0.3979 - val_accuracy: 0.8177\n","Epoch 3/20\n","186/186 [==============================] - 3s 19ms/step - loss: 0.3423 - accuracy: 0.8520 - val_loss: 0.3550 - val_accuracy: 0.8393\n","Epoch 4/20\n","186/186 [==============================] - 4s 22ms/step - loss: 0.2941 - accuracy: 0.8732 - val_loss: 0.3361 - val_accuracy: 0.8636\n","Epoch 5/20\n","186/186 [==============================] - 3s 17ms/step - loss: 0.2601 - accuracy: 0.8948 - val_loss: 0.3464 - val_accuracy: 0.8508\n","Epoch 6/20\n","186/186 [==============================] - 3s 17ms/step - loss: 0.2335 - accuracy: 0.9060 - val_loss: 0.3945 - val_accuracy: 0.8427\n","Epoch 7/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.2186 - accuracy: 0.9112 - val_loss: 0.3520 - val_accuracy: 0.8569\n","Epoch 8/20\n","186/186 [==============================] - 6s 31ms/step - loss: 0.1992 - accuracy: 0.9222 - val_loss: 0.3721 - val_accuracy: 0.8629\n","Epoch 9/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.1817 - accuracy: 0.9293 - val_loss: 0.3802 - val_accuracy: 0.8643\n","Epoch 10/20\n","186/186 [==============================] - 4s 22ms/step - loss: 0.1678 - accuracy: 0.9342 - val_loss: 0.3799 - val_accuracy: 0.8596\n","Epoch 11/20\n","186/186 [==============================] - 5s 28ms/step - loss: 0.1572 - accuracy: 0.9396 - val_loss: 0.4001 - val_accuracy: 0.8629\n","Epoch 12/20\n","186/186 [==============================] - 4s 22ms/step - loss: 0.1393 - accuracy: 0.9450 - val_loss: 0.4046 - val_accuracy: 0.8717\n","Epoch 13/20\n","186/186 [==============================] - 2s 13ms/step - loss: 0.1348 - accuracy: 0.9480 - val_loss: 0.4128 - val_accuracy: 0.8616\n","Epoch 14/20\n","186/186 [==============================] - 4s 22ms/step - loss: 0.1199 - accuracy: 0.9549 - val_loss: 0.4419 - val_accuracy: 0.8650\n","Epoch 15/20\n","186/186 [==============================] - 4s 19ms/step - loss: 0.1129 - accuracy: 0.9544 - val_loss: 0.4830 - val_accuracy: 0.8670\n","Epoch 16/20\n","186/186 [==============================] - 3s 16ms/step - loss: 0.1147 - accuracy: 0.9564 - val_loss: 0.4452 - val_accuracy: 0.8690\n","Epoch 17/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.0971 - accuracy: 0.9676 - val_loss: 0.4869 - val_accuracy: 0.8751\n","Epoch 18/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.1020 - accuracy: 0.9646 - val_loss: 0.4875 - val_accuracy: 0.8690\n","Epoch 19/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.0849 - accuracy: 0.9694 - val_loss: 0.5217 - val_accuracy: 0.8710\n","Epoch 20/20\n","186/186 [==============================] - 5s 24ms/step - loss: 0.0769 - accuracy: 0.9711 - val_loss: 0.4959 - val_accuracy: 0.8751\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7e425822fdc0>"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7iJ7X2XMxE9","executionInfo":{"status":"ok","timestamp":1689670413584,"user_tz":-330,"elapsed":597,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"61560622-d41d-4776-cf99-ff4ba735c846"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 7ms/step - loss: 0.4959 - accuracy: 0.8751\n","Loss: 0.49585771560668945\n","Accuracy: 0.875084400177002\n"]}]},{"cell_type":"markdown","source":["20 32 - 0.875/0.495"],"metadata":{"id":"LeD8IgPlNDms"}},{"cell_type":"code","source":[],"metadata":{"id":"3mv82DOVMyvF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM (32) for sentemb, CNN for emotions, directly give input for intensity and liwc"],"metadata":{"id":"rG_j9iznNSIF"}},{"cell_type":"code","source":["# LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(32)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVYi2cVtNRF0","executionInfo":{"status":"ok","timestamp":1689670604144,"user_tz":-330,"elapsed":52271,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"caaeb88a-feff-4ce9-999d-be2c85b6ffab"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 12s 20ms/step - loss: 0.5505 - accuracy: 0.7154 - val_loss: 0.4533 - val_accuracy: 0.7799\n","Epoch 2/20\n","186/186 [==============================] - 3s 17ms/step - loss: 0.4254 - accuracy: 0.8017 - val_loss: 0.4218 - val_accuracy: 0.7927\n","Epoch 3/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.3548 - accuracy: 0.8332 - val_loss: 0.3765 - val_accuracy: 0.8319\n","Epoch 4/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.2959 - accuracy: 0.8778 - val_loss: 0.3502 - val_accuracy: 0.8400\n","Epoch 5/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.2718 - accuracy: 0.8867 - val_loss: 0.3546 - val_accuracy: 0.8460\n","Epoch 6/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.2353 - accuracy: 0.9051 - val_loss: 0.3485 - val_accuracy: 0.8569\n","Epoch 7/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.2142 - accuracy: 0.9141 - val_loss: 0.3567 - val_accuracy: 0.8656\n","Epoch 8/20\n","186/186 [==============================] - 2s 9ms/step - loss: 0.2015 - accuracy: 0.9203 - val_loss: 0.3709 - val_accuracy: 0.8616\n","Epoch 9/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1782 - accuracy: 0.9328 - val_loss: 0.3650 - val_accuracy: 0.8656\n","Epoch 10/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.1661 - accuracy: 0.9348 - val_loss: 0.3624 - val_accuracy: 0.8609\n","Epoch 11/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1533 - accuracy: 0.9440 - val_loss: 0.3778 - val_accuracy: 0.8663\n","Epoch 12/20\n","186/186 [==============================] - 2s 10ms/step - loss: 0.1408 - accuracy: 0.9440 - val_loss: 0.3923 - val_accuracy: 0.8602\n","Epoch 13/20\n","186/186 [==============================] - 2s 9ms/step - loss: 0.1321 - accuracy: 0.9483 - val_loss: 0.4238 - val_accuracy: 0.8656\n","Epoch 14/20\n","186/186 [==============================] - 2s 9ms/step - loss: 0.1248 - accuracy: 0.9517 - val_loss: 0.4263 - val_accuracy: 0.8562\n","Epoch 15/20\n","186/186 [==============================] - 2s 9ms/step - loss: 0.1149 - accuracy: 0.9566 - val_loss: 0.4375 - val_accuracy: 0.8663\n","Epoch 16/20\n","186/186 [==============================] - 2s 9ms/step - loss: 0.0950 - accuracy: 0.9632 - val_loss: 0.4974 - val_accuracy: 0.8629\n","Epoch 17/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.0963 - accuracy: 0.9622 - val_loss: 0.4863 - val_accuracy: 0.8569\n","Epoch 18/20\n","186/186 [==============================] - 2s 13ms/step - loss: 0.0883 - accuracy: 0.9678 - val_loss: 0.5886 - val_accuracy: 0.8474\n","Epoch 19/20\n","186/186 [==============================] - 2s 9ms/step - loss: 0.0998 - accuracy: 0.9613 - val_loss: 0.4620 - val_accuracy: 0.8704\n","Epoch 20/20\n","186/186 [==============================] - 2s 9ms/step - loss: 0.0740 - accuracy: 0.9725 - val_loss: 0.5010 - val_accuracy: 0.8623\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7e4234799d20>"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FEuLWyxNoKA","executionInfo":{"status":"ok","timestamp":1689670663128,"user_tz":-330,"elapsed":1622,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"862ec893-1d80-4c1b-f97a-8f6189559c05"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.8623\n","Loss: 0.5009584426879883\n","Accuracy: 0.8622552156448364\n"]}]},{"cell_type":"markdown","source":["20 32 - 0.862/0.500"],"metadata":{"id":"QVMJ49-lNqLZ"}},{"cell_type":"code","source":[],"metadata":{"id":"eEtGjWbOOhuG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM (16) sentemb, CNN emotions, LSTM(16) intensity, liwc directly input"],"metadata":{"id":"is4U1u-hOtw2"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(16)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","lstm_intensity = LSTM(16)(Reshape((1, 8))(input_intensity))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvXPgFK8OosS","executionInfo":{"status":"ok","timestamp":1689671086008,"user_tz":-330,"elapsed":55461,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d6763282-7c9f-4e77-c5f0-9c2de4e6833a"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 10s 17ms/step - loss: 0.5330 - accuracy: 0.7270 - val_loss: 0.4512 - val_accuracy: 0.7772\n","Epoch 2/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.4134 - accuracy: 0.8148 - val_loss: 0.4230 - val_accuracy: 0.8015\n","Epoch 3/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.3520 - accuracy: 0.8450 - val_loss: 0.3765 - val_accuracy: 0.8346\n","Epoch 4/20\n","186/186 [==============================] - 3s 17ms/step - loss: 0.2990 - accuracy: 0.8700 - val_loss: 0.3547 - val_accuracy: 0.8413\n","Epoch 5/20\n","186/186 [==============================] - 2s 13ms/step - loss: 0.2649 - accuracy: 0.8861 - val_loss: 0.3465 - val_accuracy: 0.8467\n","Epoch 6/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.2389 - accuracy: 0.9006 - val_loss: 0.3677 - val_accuracy: 0.8589\n","Epoch 7/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.2133 - accuracy: 0.9148 - val_loss: 0.3670 - val_accuracy: 0.8562\n","Epoch 8/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.1949 - accuracy: 0.9208 - val_loss: 0.3404 - val_accuracy: 0.8717\n","Epoch 9/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.1778 - accuracy: 0.9313 - val_loss: 0.3821 - val_accuracy: 0.8569\n","Epoch 10/20\n","186/186 [==============================] - 3s 17ms/step - loss: 0.1565 - accuracy: 0.9367 - val_loss: 0.3851 - val_accuracy: 0.8521\n","Epoch 11/20\n","186/186 [==============================] - 3s 14ms/step - loss: 0.1511 - accuracy: 0.9389 - val_loss: 0.3779 - val_accuracy: 0.8751\n","Epoch 12/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1433 - accuracy: 0.9429 - val_loss: 0.3926 - val_accuracy: 0.8697\n","Epoch 13/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1266 - accuracy: 0.9499 - val_loss: 0.4598 - val_accuracy: 0.8521\n","Epoch 14/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1157 - accuracy: 0.9563 - val_loss: 0.4370 - val_accuracy: 0.8650\n","Epoch 15/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.1065 - accuracy: 0.9612 - val_loss: 0.4441 - val_accuracy: 0.8677\n","Epoch 16/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.0960 - accuracy: 0.9664 - val_loss: 0.4594 - val_accuracy: 0.8629\n","Epoch 17/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.0891 - accuracy: 0.9656 - val_loss: 0.4955 - val_accuracy: 0.8542\n","Epoch 18/20\n","186/186 [==============================] - 2s 12ms/step - loss: 0.0853 - accuracy: 0.9678 - val_loss: 0.4655 - val_accuracy: 0.8663\n","Epoch 19/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.0800 - accuracy: 0.9715 - val_loss: 0.5282 - val_accuracy: 0.8643\n","Epoch 20/20\n","186/186 [==============================] - 2s 11ms/step - loss: 0.0771 - accuracy: 0.9721 - val_loss: 0.5084 - val_accuracy: 0.8663\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7e42242da950>"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FBECjAMNO2qh","executionInfo":{"status":"ok","timestamp":1689671086589,"user_tz":-330,"elapsed":630,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e222beef-7ae4-4e3d-eb22-d95d05b307f7"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.8663\n","Loss: 0.508393406867981\n","Accuracy: 0.8663065433502197\n"]}]},{"cell_type":"markdown","source":["20 32 - 0.866/0.504"],"metadata":{"id":"mu18XLGNO7Wr"}},{"cell_type":"code","source":[""],"metadata":{"id":"3qWmU_ACO6DB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM (32) sentemb, CNN + LSTM (32) emotions, LSTM(32) intensity, liwc directly input"],"metadata":{"id":"QDVz3cp5ZDc0"}},{"cell_type":"code","source":["# Input for sentemb features\n","input_sentemb = Input(shape=(28,))\n","lstm_sentemb = LSTM(32)(Reshape((1, 28))(input_sentemb))\n","\n","# Input for emotions features\n","input_emotions = Input(shape=(28,))\n","reshaped_emotions = Reshape((28, 1))(input_emotions)\n","cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","cnn_emotions = GlobalMaxPooling1D()(cnn_emotions)\n","# + LSTM\n","cnn_lstm_emotions = LSTM(32)(Reshape((1, 128))(cnn_emotions))  # cnn_emotions returns length 128\n","\n","# Input for intensity features\n","input_intensity = Input(shape=(8,))\n","lstm_intensity = LSTM(32)(Reshape((1, 8))(input_intensity))\n","\n","# Input for LIWC features\n","input_liwc = Input(shape=(119,))\n","\n","# Concatenate the outputs of the LSTM and CNN layers\n","concatenated = Concatenate()([lstm_sentemb, cnn_lstm_emotions, lstm_intensity, input_liwc])\n","\n","# Additional Dense layers for further processing\n","merged_output = Dense(128, activation='relu')(concatenated)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","merged_output = Dense(64, activation='relu')(merged_output)\n","merged_output = Dense(32, activation='relu')(merged_output)\n","merged_output = Dropout(rate=0.2)(merged_output)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(merged_output)\n","\n","# Create the model\n","model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                    epochs=20, batch_size=32, validation_data=([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eGCx7-wGZK0I","executionInfo":{"status":"ok","timestamp":1689674235629,"user_tz":-330,"elapsed":89749,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"a27cf165-741b-4703-deb3-282ee7700d84"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","186/186 [==============================] - 14s 23ms/step - loss: 0.5459 - accuracy: 0.7120 - val_loss: 0.4658 - val_accuracy: 0.7664\n","Epoch 2/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.4334 - accuracy: 0.7961 - val_loss: 0.4060 - val_accuracy: 0.8170\n","Epoch 3/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.3528 - accuracy: 0.8430 - val_loss: 0.3802 - val_accuracy: 0.8332\n","Epoch 4/20\n","186/186 [==============================] - 4s 20ms/step - loss: 0.3134 - accuracy: 0.8673 - val_loss: 0.3503 - val_accuracy: 0.8413\n","Epoch 5/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.2632 - accuracy: 0.8931 - val_loss: 0.3516 - val_accuracy: 0.8609\n","Epoch 6/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.2425 - accuracy: 0.9016 - val_loss: 0.3545 - val_accuracy: 0.8555\n","Epoch 7/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.2250 - accuracy: 0.9094 - val_loss: 0.3546 - val_accuracy: 0.8575\n","Epoch 8/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.1972 - accuracy: 0.9210 - val_loss: 0.4094 - val_accuracy: 0.8454\n","Epoch 9/20\n","186/186 [==============================] - 4s 22ms/step - loss: 0.1887 - accuracy: 0.9254 - val_loss: 0.3655 - val_accuracy: 0.8656\n","Epoch 10/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.1624 - accuracy: 0.9380 - val_loss: 0.3842 - val_accuracy: 0.8575\n","Epoch 11/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.1590 - accuracy: 0.9382 - val_loss: 0.4291 - val_accuracy: 0.8528\n","Epoch 12/20\n","186/186 [==============================] - 3s 16ms/step - loss: 0.1540 - accuracy: 0.9419 - val_loss: 0.4058 - val_accuracy: 0.8656\n","Epoch 13/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.1439 - accuracy: 0.9472 - val_loss: 0.3974 - val_accuracy: 0.8683\n","Epoch 14/20\n","186/186 [==============================] - 4s 19ms/step - loss: 0.1191 - accuracy: 0.9578 - val_loss: 0.4636 - val_accuracy: 0.8575\n","Epoch 15/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.1258 - accuracy: 0.9532 - val_loss: 0.4253 - val_accuracy: 0.8609\n","Epoch 16/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.1144 - accuracy: 0.9539 - val_loss: 0.4622 - val_accuracy: 0.8542\n","Epoch 17/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.1019 - accuracy: 0.9629 - val_loss: 0.4874 - val_accuracy: 0.8650\n","Epoch 18/20\n","186/186 [==============================] - 4s 20ms/step - loss: 0.1020 - accuracy: 0.9607 - val_loss: 0.5018 - val_accuracy: 0.8683\n","Epoch 19/20\n","186/186 [==============================] - 3s 18ms/step - loss: 0.0825 - accuracy: 0.9678 - val_loss: 0.5384 - val_accuracy: 0.8616\n","Epoch 20/20\n","186/186 [==============================] - 3s 15ms/step - loss: 0.0873 - accuracy: 0.9674 - val_loss: 0.4829 - val_accuracy: 0.8616\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x795c2ad8dae0>"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_5a-c7eaqYh","executionInfo":{"status":"ok","timestamp":1689674235630,"user_tz":-330,"elapsed":50,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"156c251a-431e-433c-be86-0b6bdc0534f0"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.8616\n","Loss: 0.48293250799179077\n","Accuracy: 0.8615800142288208\n"]}]},{"cell_type":"markdown","source":["20 32 - 0.861/0.48"],"metadata":{"id":"I4QUzQMFa354"}},{"cell_type":"code","source":[],"metadata":{"id":"L4bwEKYwZl0W"},"execution_count":null,"outputs":[]}]}