{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["36JvKgMx0BUW","KA8k_DIQw-CZ","QQQp6VDqYZDq"],"authorship_tag":"ABX9TyPbkWMADkgzUuItumFuuYDB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"PVZ9CtoBdqqK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697714297923,"user_tz":-330,"elapsed":23230,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"7181cd04-3c22-4d23-8e3c-bd91c56ba45e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle"],"metadata":{"id":"62y4wcx6dzJL","executionInfo":{"status":"ok","timestamp":1697714298687,"user_tz":-330,"elapsed":777,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/IDSIA Biomedical Texts/final_ds.csv', low_memory=False)\n","df.head(1)"],"metadata":{"id":"j28R0ui-dzLm","colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"status":"ok","timestamp":1697714306647,"user_tz":-330,"elapsed":7965,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e6c6c1f3-8e18-44b0-bb4b-bd670b40aeb4"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        A_1       A_2       A_3       A_4       A_5       A_6       A_7  \\\n","0 -0.019143  0.014779  0.039521 -0.010309  0.049008  0.025026 -0.056692   \n","\n","        A_8       A_9      A_10  ...     I_759   I_760     I_761     I_762  \\\n","0 -0.023111 -0.046817  0.000515  ...  0.078821 -0.0939 -0.287797  0.092244   \n","\n","      I_763     I_764     I_765     I_766     I_767     I_768  \n","0 -0.086249  0.062891  0.165077  0.159807  0.062507 -0.047195  \n","\n","[1 rows x 2922 columns]"],"text/html":["\n","  <div id=\"df-b8cf0678-7417-43aa-b4ff-b57b40abdfd1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A_1</th>\n","      <th>A_2</th>\n","      <th>A_3</th>\n","      <th>A_4</th>\n","      <th>A_5</th>\n","      <th>A_6</th>\n","      <th>A_7</th>\n","      <th>A_8</th>\n","      <th>A_9</th>\n","      <th>A_10</th>\n","      <th>...</th>\n","      <th>I_759</th>\n","      <th>I_760</th>\n","      <th>I_761</th>\n","      <th>I_762</th>\n","      <th>I_763</th>\n","      <th>I_764</th>\n","      <th>I_765</th>\n","      <th>I_766</th>\n","      <th>I_767</th>\n","      <th>I_768</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.019143</td>\n","      <td>0.014779</td>\n","      <td>0.039521</td>\n","      <td>-0.010309</td>\n","      <td>0.049008</td>\n","      <td>0.025026</td>\n","      <td>-0.056692</td>\n","      <td>-0.023111</td>\n","      <td>-0.046817</td>\n","      <td>0.000515</td>\n","      <td>...</td>\n","      <td>0.078821</td>\n","      <td>-0.0939</td>\n","      <td>-0.287797</td>\n","      <td>0.092244</td>\n","      <td>-0.086249</td>\n","      <td>0.062891</td>\n","      <td>0.165077</td>\n","      <td>0.159807</td>\n","      <td>0.062507</td>\n","      <td>-0.047195</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 2922 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8cf0678-7417-43aa-b4ff-b57b40abdfd1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b8cf0678-7417-43aa-b4ff-b57b40abdfd1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b8cf0678-7417-43aa-b4ff-b57b40abdfd1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"z0-Sbx1odzNt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697714306648,"user_tz":-330,"elapsed":63,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"0d27db46-3283-494a-e406-ad5668af8e29"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['A_1', 'A_2', 'A_3', 'A_4', 'A_5', 'A_6', 'A_7', 'A_8', 'A_9', 'A_10',\n","       ...\n","       'I_759', 'I_760', 'I_761', 'I_762', 'I_763', 'I_764', 'I_765', 'I_766',\n","       'I_767', 'I_768'],\n","      dtype='object', length=2922)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"S40TMVXG_yS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697714306648,"user_tz":-330,"elapsed":55,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e6a750cd-b416-47e5-ea59-fb030f9b8a1b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7411"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df.duplicated().sum()"],"metadata":{"id":"49vxkPxhQHJg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697714307456,"user_tz":-330,"elapsed":858,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"9afcce0d-8e76-4b6b-a16e-d08b3e1fed5a"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["df[df.duplicated() == True]"],"metadata":{"id":"nO0mjuNDQRxa","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1697714308802,"user_tz":-330,"elapsed":1353,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d652a387-57a2-45a0-9c0a-77c4edf29c01"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           A_1       A_2       A_3       A_4       A_5       A_6       A_7  \\\n","114  -0.019981 -0.006418  0.021737 -0.011297  0.017683  0.067064 -0.013877   \n","116  -0.019981 -0.006418  0.021737 -0.011297  0.017683  0.067064 -0.013877   \n","478   0.014510  0.026111  0.009168  0.009326  0.004685 -0.034664 -0.035343   \n","480   0.014510  0.026111  0.009168  0.009326  0.004685 -0.034664 -0.035343   \n","1484  0.028640  0.014297  0.034310 -0.008341 -0.031866 -0.049014 -0.024636   \n","1485  0.028640  0.014297  0.034310 -0.008341 -0.031866 -0.049014 -0.024636   \n","1486  0.028640  0.014297  0.034310 -0.008341 -0.031866 -0.049014 -0.024636   \n","\n","           A_8       A_9      A_10  ...     I_759     I_760     I_761  \\\n","114  -0.005313  0.030635 -0.014966  ...  0.108200 -0.068662  0.119337   \n","116  -0.005313  0.030635 -0.014966  ...  0.108200 -0.068662  0.119337   \n","478  -0.026033  0.007001 -0.009977  ... -0.102348  0.017713 -0.329996   \n","480  -0.026033  0.007001 -0.009977  ... -0.102348  0.017713 -0.329996   \n","1484 -0.041997  0.018234  0.063375  ... -0.231205 -0.025784  0.025897   \n","1485 -0.041997  0.018234  0.063375  ... -0.231205 -0.025784  0.025897   \n","1486 -0.041997  0.018234  0.063375  ... -0.231205 -0.025784  0.025897   \n","\n","         I_762     I_763     I_764     I_765     I_766     I_767     I_768  \n","114   0.148479 -0.230278  0.248709  0.073005 -0.084308  0.130383 -0.157570  \n","116   0.148479 -0.230278  0.248709  0.073005 -0.084308  0.130383 -0.157570  \n","478   0.031990 -0.017869  0.065587  0.076549  0.175816  0.099023  0.211595  \n","480   0.031990 -0.017869  0.065587  0.076549  0.175816  0.099023  0.211595  \n","1484  0.053830  0.283645  0.195133 -0.151477  0.012942  0.218365  0.247659  \n","1485  0.053830  0.283645  0.195133 -0.151477  0.012942  0.218365  0.247659  \n","1486  0.053830  0.283645  0.195133 -0.151477  0.012942  0.218365  0.247659  \n","\n","[7 rows x 2922 columns]"],"text/html":["\n","  <div id=\"df-e7960404-a99e-464d-9b45-aa2891550ca2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A_1</th>\n","      <th>A_2</th>\n","      <th>A_3</th>\n","      <th>A_4</th>\n","      <th>A_5</th>\n","      <th>A_6</th>\n","      <th>A_7</th>\n","      <th>A_8</th>\n","      <th>A_9</th>\n","      <th>A_10</th>\n","      <th>...</th>\n","      <th>I_759</th>\n","      <th>I_760</th>\n","      <th>I_761</th>\n","      <th>I_762</th>\n","      <th>I_763</th>\n","      <th>I_764</th>\n","      <th>I_765</th>\n","      <th>I_766</th>\n","      <th>I_767</th>\n","      <th>I_768</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>114</th>\n","      <td>-0.019981</td>\n","      <td>-0.006418</td>\n","      <td>0.021737</td>\n","      <td>-0.011297</td>\n","      <td>0.017683</td>\n","      <td>0.067064</td>\n","      <td>-0.013877</td>\n","      <td>-0.005313</td>\n","      <td>0.030635</td>\n","      <td>-0.014966</td>\n","      <td>...</td>\n","      <td>0.108200</td>\n","      <td>-0.068662</td>\n","      <td>0.119337</td>\n","      <td>0.148479</td>\n","      <td>-0.230278</td>\n","      <td>0.248709</td>\n","      <td>0.073005</td>\n","      <td>-0.084308</td>\n","      <td>0.130383</td>\n","      <td>-0.157570</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>-0.019981</td>\n","      <td>-0.006418</td>\n","      <td>0.021737</td>\n","      <td>-0.011297</td>\n","      <td>0.017683</td>\n","      <td>0.067064</td>\n","      <td>-0.013877</td>\n","      <td>-0.005313</td>\n","      <td>0.030635</td>\n","      <td>-0.014966</td>\n","      <td>...</td>\n","      <td>0.108200</td>\n","      <td>-0.068662</td>\n","      <td>0.119337</td>\n","      <td>0.148479</td>\n","      <td>-0.230278</td>\n","      <td>0.248709</td>\n","      <td>0.073005</td>\n","      <td>-0.084308</td>\n","      <td>0.130383</td>\n","      <td>-0.157570</td>\n","    </tr>\n","    <tr>\n","      <th>478</th>\n","      <td>0.014510</td>\n","      <td>0.026111</td>\n","      <td>0.009168</td>\n","      <td>0.009326</td>\n","      <td>0.004685</td>\n","      <td>-0.034664</td>\n","      <td>-0.035343</td>\n","      <td>-0.026033</td>\n","      <td>0.007001</td>\n","      <td>-0.009977</td>\n","      <td>...</td>\n","      <td>-0.102348</td>\n","      <td>0.017713</td>\n","      <td>-0.329996</td>\n","      <td>0.031990</td>\n","      <td>-0.017869</td>\n","      <td>0.065587</td>\n","      <td>0.076549</td>\n","      <td>0.175816</td>\n","      <td>0.099023</td>\n","      <td>0.211595</td>\n","    </tr>\n","    <tr>\n","      <th>480</th>\n","      <td>0.014510</td>\n","      <td>0.026111</td>\n","      <td>0.009168</td>\n","      <td>0.009326</td>\n","      <td>0.004685</td>\n","      <td>-0.034664</td>\n","      <td>-0.035343</td>\n","      <td>-0.026033</td>\n","      <td>0.007001</td>\n","      <td>-0.009977</td>\n","      <td>...</td>\n","      <td>-0.102348</td>\n","      <td>0.017713</td>\n","      <td>-0.329996</td>\n","      <td>0.031990</td>\n","      <td>-0.017869</td>\n","      <td>0.065587</td>\n","      <td>0.076549</td>\n","      <td>0.175816</td>\n","      <td>0.099023</td>\n","      <td>0.211595</td>\n","    </tr>\n","    <tr>\n","      <th>1484</th>\n","      <td>0.028640</td>\n","      <td>0.014297</td>\n","      <td>0.034310</td>\n","      <td>-0.008341</td>\n","      <td>-0.031866</td>\n","      <td>-0.049014</td>\n","      <td>-0.024636</td>\n","      <td>-0.041997</td>\n","      <td>0.018234</td>\n","      <td>0.063375</td>\n","      <td>...</td>\n","      <td>-0.231205</td>\n","      <td>-0.025784</td>\n","      <td>0.025897</td>\n","      <td>0.053830</td>\n","      <td>0.283645</td>\n","      <td>0.195133</td>\n","      <td>-0.151477</td>\n","      <td>0.012942</td>\n","      <td>0.218365</td>\n","      <td>0.247659</td>\n","    </tr>\n","    <tr>\n","      <th>1485</th>\n","      <td>0.028640</td>\n","      <td>0.014297</td>\n","      <td>0.034310</td>\n","      <td>-0.008341</td>\n","      <td>-0.031866</td>\n","      <td>-0.049014</td>\n","      <td>-0.024636</td>\n","      <td>-0.041997</td>\n","      <td>0.018234</td>\n","      <td>0.063375</td>\n","      <td>...</td>\n","      <td>-0.231205</td>\n","      <td>-0.025784</td>\n","      <td>0.025897</td>\n","      <td>0.053830</td>\n","      <td>0.283645</td>\n","      <td>0.195133</td>\n","      <td>-0.151477</td>\n","      <td>0.012942</td>\n","      <td>0.218365</td>\n","      <td>0.247659</td>\n","    </tr>\n","    <tr>\n","      <th>1486</th>\n","      <td>0.028640</td>\n","      <td>0.014297</td>\n","      <td>0.034310</td>\n","      <td>-0.008341</td>\n","      <td>-0.031866</td>\n","      <td>-0.049014</td>\n","      <td>-0.024636</td>\n","      <td>-0.041997</td>\n","      <td>0.018234</td>\n","      <td>0.063375</td>\n","      <td>...</td>\n","      <td>-0.231205</td>\n","      <td>-0.025784</td>\n","      <td>0.025897</td>\n","      <td>0.053830</td>\n","      <td>0.283645</td>\n","      <td>0.195133</td>\n","      <td>-0.151477</td>\n","      <td>0.012942</td>\n","      <td>0.218365</td>\n","      <td>0.247659</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7 rows × 2922 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7960404-a99e-464d-9b45-aa2891550ca2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e7960404-a99e-464d-9b45-aa2891550ca2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e7960404-a99e-464d-9b45-aa2891550ca2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6d5d70b1-703f-4187-b910-bd251aea7770\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d5d70b1-703f-4187-b910-bd251aea7770')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6d5d70b1-703f-4187-b910-bd251aea7770 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df.drop_duplicates(inplace=True)"],"metadata":{"id":"F6I5z8A-_yVB","executionInfo":{"status":"ok","timestamp":1697714309924,"user_tz":-330,"elapsed":1130,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df[df.duplicated() == True]"],"metadata":{"id":"WKAgE0WHQCov","colab":{"base_uri":"https://localhost:8080/","height":79},"executionInfo":{"status":"ok","timestamp":1697714311225,"user_tz":-330,"elapsed":1304,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"8c53f8f8-46a6-4fc7-8cb6-7f214a3a22ad"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [A_1, A_2, A_3, A_4, A_5, A_6, A_7, A_8, A_9, A_10, A_11, A_12, A_13, A_14, A_15, A_16, A_17, A_18, A_19, A_20, A_21, A_22, A_23, A_24, A_25, A_26, A_27, A_28, A_29, A_30, A_31, A_32, A_33, A_34, A_35, A_36, A_37, A_38, A_39, A_40, A_41, A_42, A_43, A_44, A_45, A_46, A_47, A_48, A_49, A_50, A_51, A_52, A_53, A_54, A_55, A_56, A_57, A_58, A_59, A_60, A_61, A_62, A_63, A_64, A_65, A_66, A_67, A_68, A_69, A_70, A_71, A_72, A_73, A_74, A_75, A_76, A_77, A_78, A_79, A_80, A_81, A_82, A_83, A_84, A_85, A_86, A_87, A_88, A_89, A_90, A_91, A_92, A_93, A_94, A_95, A_96, A_97, A_98, A_99, A_100, ...]\n","Index: []\n","\n","[0 rows x 2922 columns]"],"text/html":["\n","  <div id=\"df-bf6498e9-e115-485c-879a-ca0ec1e3bab4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A_1</th>\n","      <th>A_2</th>\n","      <th>A_3</th>\n","      <th>A_4</th>\n","      <th>A_5</th>\n","      <th>A_6</th>\n","      <th>A_7</th>\n","      <th>A_8</th>\n","      <th>A_9</th>\n","      <th>A_10</th>\n","      <th>...</th>\n","      <th>I_759</th>\n","      <th>I_760</th>\n","      <th>I_761</th>\n","      <th>I_762</th>\n","      <th>I_763</th>\n","      <th>I_764</th>\n","      <th>I_765</th>\n","      <th>I_766</th>\n","      <th>I_767</th>\n","      <th>I_768</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","<p>0 rows × 2922 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf6498e9-e115-485c-879a-ca0ec1e3bab4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bf6498e9-e115-485c-879a-ca0ec1e3bab4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bf6498e9-e115-485c-879a-ca0ec1e3bab4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df.duplicated().sum()"],"metadata":{"id":"eL4K9gB6QCq3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697714312376,"user_tz":-330,"elapsed":1160,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"f148e6fc-2731-4bb3-f55a-90006f4acd22"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"_A9zi_XwQCsy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697714312376,"user_tz":-330,"elapsed":58,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"62fca7d1-91dc-4e5b-9f2f-e9a180502092"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7404"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["df.reset_index(drop=True, inplace=True)"],"metadata":{"id":"YMGaZr7MQCwK","executionInfo":{"status":"ok","timestamp":1697714312377,"user_tz":-330,"elapsed":54,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LIOoFXL2_yYe","executionInfo":{"status":"ok","timestamp":1697714312377,"user_tz":-330,"elapsed":53,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["1. A_1 to A_768 (768) (Emb) (no need to normalize it this time?) <br>\n","2. B_WC to B_Emoji (118) (LIWC) (needs normalizing (so that it gets treated as rest of the features)) <br>\n","3. C_admiration to C_neutral (28) (Emotion Probabilities) <br>\n","4. D_anger_intensity to D_trust_intensity (8) (Intensity Scores) <br>\n","5. F_symptoms_count (0 to 17, so normalize?) and F_symptom_1_indicator to F_symptom_44_indicator (45) (symptom features) (combine these) <br>\n","6. E_1 to E_384 (384) (Emb) <br>\n","7. H_1 to H_768 (768) (Emb) <br>\n","8. I_1 to I_768 (768) (Emb) <br>\n","\n"],"metadata":{"id":"FcC2EQo4epcu"}},{"cell_type":"code","source":[],"metadata":{"id":"7iSjrMCXdzSU","executionInfo":{"status":"ok","timestamp":1697714312378,"user_tz":-330,"elapsed":53,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["sentembdf = df.loc[:, 'A_1':'A_768']\n","sentembdf"],"metadata":{"id":"rCIiypQGdzUz","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1697714312378,"user_tz":-330,"elapsed":52,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"bf412d1d-85e9-46b9-89a6-b750121e281a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           A_1       A_2       A_3       A_4       A_5       A_6       A_7  \\\n","0    -0.019143  0.014779  0.039521 -0.010309  0.049008  0.025026 -0.056692   \n","1     0.010327 -0.017366  0.037534  0.020887  0.070232  0.060259 -0.020957   \n","2    -0.048175  0.037344  0.056609  0.035632  0.034589  0.009242 -0.033765   \n","3    -0.025639 -0.012544  0.004850  0.003161  0.068372  0.020812 -0.023470   \n","4    -0.004646  0.029859  0.027000  0.009553  0.061528  0.015759  0.015545   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","7399  0.004537  0.004089 -0.001497  0.029067 -0.010354  0.060507 -0.057212   \n","7400  0.058352  0.083199  0.026844  0.018507  0.040248 -0.046760 -0.004367   \n","7401  0.040878  0.051785  0.012076  0.003620  0.052075 -0.037816  0.024597   \n","7402  0.056155  0.062430 -0.006433  0.014363 -0.037829 -0.023952 -0.031864   \n","7403  0.042712  0.040786  0.058618  0.017743 -0.004685  0.032968 -0.026134   \n","\n","           A_8       A_9      A_10  ...     A_759     A_760     A_761  \\\n","0    -0.023111 -0.046817  0.000515  ...  0.008046  0.003752  0.010078   \n","1     0.041326  0.010001 -0.012280  ...  0.008371  0.041797 -0.001600   \n","2    -0.051093 -0.030799 -0.026486  ... -0.025529  0.038435 -0.024716   \n","3     0.020670 -0.006528 -0.011151  ... -0.031360  0.086882 -0.014112   \n","4     0.006237 -0.013028 -0.004326  ... -0.002027  0.037794 -0.019592   \n","...        ...       ...       ...  ...       ...       ...       ...   \n","7399  0.000164  0.008451  0.057407  ... -0.038596  0.002155 -0.023819   \n","7400 -0.002714  0.034234  0.015911  ... -0.044591 -0.044029  0.021687   \n","7401  0.018865  0.051135  0.046981  ... -0.044072  0.001522  0.006487   \n","7402  0.038622 -0.003138  0.030964  ... -0.050429 -0.011246  0.022960   \n","7403 -0.009570 -0.014374  0.049005  ... -0.039912  0.006624  0.019066   \n","\n","         A_762     A_763     A_764     A_765     A_766     A_767     A_768  \n","0     0.039703  0.015814 -0.027510 -0.036636 -0.008065  0.039512  0.002816  \n","1     0.005443 -0.046287 -0.015238 -0.013136  0.001611 -0.021068 -0.022256  \n","2     0.013199  0.032277 -0.060235 -0.014266  0.012649  0.059875  0.011108  \n","3    -0.023503 -0.020573  0.008945 -0.030735 -0.041017 -0.053785 -0.021591  \n","4     0.007031  0.005945 -0.039767 -0.079558  0.015854  0.030582  0.006756  \n","...        ...       ...       ...       ...       ...       ...       ...  \n","7399  0.001184 -0.016418 -0.023391 -0.076088  0.011812 -0.050905  0.003696  \n","7400  0.042343  0.018476 -0.014512 -0.056334  0.021098 -0.026808  0.008442  \n","7401  0.056962  0.024643 -0.017065  0.053320 -0.006796 -0.010665 -0.014575  \n","7402  0.025358 -0.026356 -0.025079  0.047665 -0.013113  0.012966 -0.014514  \n","7403  0.055368 -0.014706 -0.015744 -0.070712 -0.036133  0.049234 -0.021455  \n","\n","[7404 rows x 768 columns]"],"text/html":["\n","  <div id=\"df-929694cf-abab-40f4-a8f9-91140c525139\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A_1</th>\n","      <th>A_2</th>\n","      <th>A_3</th>\n","      <th>A_4</th>\n","      <th>A_5</th>\n","      <th>A_6</th>\n","      <th>A_7</th>\n","      <th>A_8</th>\n","      <th>A_9</th>\n","      <th>A_10</th>\n","      <th>...</th>\n","      <th>A_759</th>\n","      <th>A_760</th>\n","      <th>A_761</th>\n","      <th>A_762</th>\n","      <th>A_763</th>\n","      <th>A_764</th>\n","      <th>A_765</th>\n","      <th>A_766</th>\n","      <th>A_767</th>\n","      <th>A_768</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.019143</td>\n","      <td>0.014779</td>\n","      <td>0.039521</td>\n","      <td>-0.010309</td>\n","      <td>0.049008</td>\n","      <td>0.025026</td>\n","      <td>-0.056692</td>\n","      <td>-0.023111</td>\n","      <td>-0.046817</td>\n","      <td>0.000515</td>\n","      <td>...</td>\n","      <td>0.008046</td>\n","      <td>0.003752</td>\n","      <td>0.010078</td>\n","      <td>0.039703</td>\n","      <td>0.015814</td>\n","      <td>-0.027510</td>\n","      <td>-0.036636</td>\n","      <td>-0.008065</td>\n","      <td>0.039512</td>\n","      <td>0.002816</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.010327</td>\n","      <td>-0.017366</td>\n","      <td>0.037534</td>\n","      <td>0.020887</td>\n","      <td>0.070232</td>\n","      <td>0.060259</td>\n","      <td>-0.020957</td>\n","      <td>0.041326</td>\n","      <td>0.010001</td>\n","      <td>-0.012280</td>\n","      <td>...</td>\n","      <td>0.008371</td>\n","      <td>0.041797</td>\n","      <td>-0.001600</td>\n","      <td>0.005443</td>\n","      <td>-0.046287</td>\n","      <td>-0.015238</td>\n","      <td>-0.013136</td>\n","      <td>0.001611</td>\n","      <td>-0.021068</td>\n","      <td>-0.022256</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.048175</td>\n","      <td>0.037344</td>\n","      <td>0.056609</td>\n","      <td>0.035632</td>\n","      <td>0.034589</td>\n","      <td>0.009242</td>\n","      <td>-0.033765</td>\n","      <td>-0.051093</td>\n","      <td>-0.030799</td>\n","      <td>-0.026486</td>\n","      <td>...</td>\n","      <td>-0.025529</td>\n","      <td>0.038435</td>\n","      <td>-0.024716</td>\n","      <td>0.013199</td>\n","      <td>0.032277</td>\n","      <td>-0.060235</td>\n","      <td>-0.014266</td>\n","      <td>0.012649</td>\n","      <td>0.059875</td>\n","      <td>0.011108</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.025639</td>\n","      <td>-0.012544</td>\n","      <td>0.004850</td>\n","      <td>0.003161</td>\n","      <td>0.068372</td>\n","      <td>0.020812</td>\n","      <td>-0.023470</td>\n","      <td>0.020670</td>\n","      <td>-0.006528</td>\n","      <td>-0.011151</td>\n","      <td>...</td>\n","      <td>-0.031360</td>\n","      <td>0.086882</td>\n","      <td>-0.014112</td>\n","      <td>-0.023503</td>\n","      <td>-0.020573</td>\n","      <td>0.008945</td>\n","      <td>-0.030735</td>\n","      <td>-0.041017</td>\n","      <td>-0.053785</td>\n","      <td>-0.021591</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.004646</td>\n","      <td>0.029859</td>\n","      <td>0.027000</td>\n","      <td>0.009553</td>\n","      <td>0.061528</td>\n","      <td>0.015759</td>\n","      <td>0.015545</td>\n","      <td>0.006237</td>\n","      <td>-0.013028</td>\n","      <td>-0.004326</td>\n","      <td>...</td>\n","      <td>-0.002027</td>\n","      <td>0.037794</td>\n","      <td>-0.019592</td>\n","      <td>0.007031</td>\n","      <td>0.005945</td>\n","      <td>-0.039767</td>\n","      <td>-0.079558</td>\n","      <td>0.015854</td>\n","      <td>0.030582</td>\n","      <td>0.006756</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7399</th>\n","      <td>0.004537</td>\n","      <td>0.004089</td>\n","      <td>-0.001497</td>\n","      <td>0.029067</td>\n","      <td>-0.010354</td>\n","      <td>0.060507</td>\n","      <td>-0.057212</td>\n","      <td>0.000164</td>\n","      <td>0.008451</td>\n","      <td>0.057407</td>\n","      <td>...</td>\n","      <td>-0.038596</td>\n","      <td>0.002155</td>\n","      <td>-0.023819</td>\n","      <td>0.001184</td>\n","      <td>-0.016418</td>\n","      <td>-0.023391</td>\n","      <td>-0.076088</td>\n","      <td>0.011812</td>\n","      <td>-0.050905</td>\n","      <td>0.003696</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.058352</td>\n","      <td>0.083199</td>\n","      <td>0.026844</td>\n","      <td>0.018507</td>\n","      <td>0.040248</td>\n","      <td>-0.046760</td>\n","      <td>-0.004367</td>\n","      <td>-0.002714</td>\n","      <td>0.034234</td>\n","      <td>0.015911</td>\n","      <td>...</td>\n","      <td>-0.044591</td>\n","      <td>-0.044029</td>\n","      <td>0.021687</td>\n","      <td>0.042343</td>\n","      <td>0.018476</td>\n","      <td>-0.014512</td>\n","      <td>-0.056334</td>\n","      <td>0.021098</td>\n","      <td>-0.026808</td>\n","      <td>0.008442</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.040878</td>\n","      <td>0.051785</td>\n","      <td>0.012076</td>\n","      <td>0.003620</td>\n","      <td>0.052075</td>\n","      <td>-0.037816</td>\n","      <td>0.024597</td>\n","      <td>0.018865</td>\n","      <td>0.051135</td>\n","      <td>0.046981</td>\n","      <td>...</td>\n","      <td>-0.044072</td>\n","      <td>0.001522</td>\n","      <td>0.006487</td>\n","      <td>0.056962</td>\n","      <td>0.024643</td>\n","      <td>-0.017065</td>\n","      <td>0.053320</td>\n","      <td>-0.006796</td>\n","      <td>-0.010665</td>\n","      <td>-0.014575</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.056155</td>\n","      <td>0.062430</td>\n","      <td>-0.006433</td>\n","      <td>0.014363</td>\n","      <td>-0.037829</td>\n","      <td>-0.023952</td>\n","      <td>-0.031864</td>\n","      <td>0.038622</td>\n","      <td>-0.003138</td>\n","      <td>0.030964</td>\n","      <td>...</td>\n","      <td>-0.050429</td>\n","      <td>-0.011246</td>\n","      <td>0.022960</td>\n","      <td>0.025358</td>\n","      <td>-0.026356</td>\n","      <td>-0.025079</td>\n","      <td>0.047665</td>\n","      <td>-0.013113</td>\n","      <td>0.012966</td>\n","      <td>-0.014514</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.042712</td>\n","      <td>0.040786</td>\n","      <td>0.058618</td>\n","      <td>0.017743</td>\n","      <td>-0.004685</td>\n","      <td>0.032968</td>\n","      <td>-0.026134</td>\n","      <td>-0.009570</td>\n","      <td>-0.014374</td>\n","      <td>0.049005</td>\n","      <td>...</td>\n","      <td>-0.039912</td>\n","      <td>0.006624</td>\n","      <td>0.019066</td>\n","      <td>0.055368</td>\n","      <td>-0.014706</td>\n","      <td>-0.015744</td>\n","      <td>-0.070712</td>\n","      <td>-0.036133</td>\n","      <td>0.049234</td>\n","      <td>-0.021455</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7404 rows × 768 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-929694cf-abab-40f4-a8f9-91140c525139')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-929694cf-abab-40f4-a8f9-91140c525139 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-929694cf-abab-40f4-a8f9-91140c525139');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e877734d-5236-431b-9ec3-2e7e9e67b995\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e877734d-5236-431b-9ec3-2e7e9e67b995')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e877734d-5236-431b-9ec3-2e7e9e67b995 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["stdliwcdf = df.loc[:, 'B_WC':'B_Emoji'].join(df.loc[:, 'F_symptom_1_indicator':'F_symptom_44_indicator'])\n","stdliwcdf"],"metadata":{"id":"bJ4_toY6dzXA","colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"status":"ok","timestamp":1697714312379,"user_tz":-330,"elapsed":51,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"27e8e8bb-992b-4268-9ce5-38791a7a1e81"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      B_WC  B_Analytic  B_Clout  B_Authentic  B_Tone  B_WPS  B_BigWords  \\\n","0      607       55.22    35.35        48.82    1.00  26.39       25.86   \n","1      401       54.08     1.31        99.00    8.57  13.83       14.21   \n","2      446       25.83    93.36        75.79    1.00  12.74       15.47   \n","3      525       30.63     2.97        96.06    6.86  15.44       12.38   \n","4      323       21.57     1.00        99.00    1.12  13.46       15.48   \n","...    ...         ...      ...          ...     ...    ...         ...   \n","7399   237        5.24    20.52        53.23   15.51  16.93       18.57   \n","7400    20       39.70     1.00        28.56   99.00  20.00       25.00   \n","7401    19       36.67     3.34        70.28   99.00  19.00       21.05   \n","7402    38       36.67    90.88        33.61   92.27  19.00       21.05   \n","7403   186       26.78    52.89        86.48    2.39  23.25       15.59   \n","\n","      B_Dic  B_Linguistic  B_function  ...  F_symptom_35_indicator  \\\n","0     93.74         68.86       57.50  ...                       0   \n","1     90.02         74.81       61.60  ...                       0   \n","2     95.74         75.34       59.64  ...                       0   \n","3     90.86         73.33       56.57  ...                       0   \n","4     93.50         75.85       60.99  ...                       0   \n","...     ...           ...         ...  ...                     ...   \n","7399  93.25         81.86       62.87  ...                       0   \n","7400  95.00         65.00       40.00  ...                       0   \n","7401  94.74         73.68       47.37  ...                       0   \n","7402  97.37         63.16       52.63  ...                       0   \n","7403  98.39         79.03       61.83  ...                       0   \n","\n","      F_symptom_36_indicator  F_symptom_37_indicator  F_symptom_38_indicator  \\\n","0                          0                       0                       0   \n","1                          0                       0                       0   \n","2                          1                       0                       0   \n","3                          0                       0                       0   \n","4                          0                       1                       0   \n","...                      ...                     ...                     ...   \n","7399                       0                       0                       0   \n","7400                       0                       0                       0   \n","7401                       0                       0                       0   \n","7402                       0                       0                       0   \n","7403                       0                       0                       0   \n","\n","      F_symptom_39_indicator  F_symptom_40_indicator  F_symptom_41_indicator  \\\n","0                          0                       0                       0   \n","1                          0                       0                       0   \n","2                          0                       0                       0   \n","3                          0                       0                       0   \n","4                          0                       0                       0   \n","...                      ...                     ...                     ...   \n","7399                       0                       0                       0   \n","7400                       0                       0                       0   \n","7401                       0                       0                       0   \n","7402                       0                       0                       0   \n","7403                       0                       0                       0   \n","\n","      F_symptom_42_indicator  F_symptom_43_indicator  F_symptom_44_indicator  \n","0                          0                       0                       0  \n","1                          0                       0                       0  \n","2                          0                       0                       0  \n","3                          0                       0                       0  \n","4                          0                       0                       0  \n","...                      ...                     ...                     ...  \n","7399                       0                       0                       0  \n","7400                       0                       0                       0  \n","7401                       0                       0                       0  \n","7402                       0                       0                       0  \n","7403                       0                       0                       0  \n","\n","[7404 rows x 162 columns]"],"text/html":["\n","  <div id=\"df-a4ad628e-1c06-4abe-b27b-1763496648e6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>B_WC</th>\n","      <th>B_Analytic</th>\n","      <th>B_Clout</th>\n","      <th>B_Authentic</th>\n","      <th>B_Tone</th>\n","      <th>B_WPS</th>\n","      <th>B_BigWords</th>\n","      <th>B_Dic</th>\n","      <th>B_Linguistic</th>\n","      <th>B_function</th>\n","      <th>...</th>\n","      <th>F_symptom_35_indicator</th>\n","      <th>F_symptom_36_indicator</th>\n","      <th>F_symptom_37_indicator</th>\n","      <th>F_symptom_38_indicator</th>\n","      <th>F_symptom_39_indicator</th>\n","      <th>F_symptom_40_indicator</th>\n","      <th>F_symptom_41_indicator</th>\n","      <th>F_symptom_42_indicator</th>\n","      <th>F_symptom_43_indicator</th>\n","      <th>F_symptom_44_indicator</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>607</td>\n","      <td>55.22</td>\n","      <td>35.35</td>\n","      <td>48.82</td>\n","      <td>1.00</td>\n","      <td>26.39</td>\n","      <td>25.86</td>\n","      <td>93.74</td>\n","      <td>68.86</td>\n","      <td>57.50</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>401</td>\n","      <td>54.08</td>\n","      <td>1.31</td>\n","      <td>99.00</td>\n","      <td>8.57</td>\n","      <td>13.83</td>\n","      <td>14.21</td>\n","      <td>90.02</td>\n","      <td>74.81</td>\n","      <td>61.60</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>446</td>\n","      <td>25.83</td>\n","      <td>93.36</td>\n","      <td>75.79</td>\n","      <td>1.00</td>\n","      <td>12.74</td>\n","      <td>15.47</td>\n","      <td>95.74</td>\n","      <td>75.34</td>\n","      <td>59.64</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>525</td>\n","      <td>30.63</td>\n","      <td>2.97</td>\n","      <td>96.06</td>\n","      <td>6.86</td>\n","      <td>15.44</td>\n","      <td>12.38</td>\n","      <td>90.86</td>\n","      <td>73.33</td>\n","      <td>56.57</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>323</td>\n","      <td>21.57</td>\n","      <td>1.00</td>\n","      <td>99.00</td>\n","      <td>1.12</td>\n","      <td>13.46</td>\n","      <td>15.48</td>\n","      <td>93.50</td>\n","      <td>75.85</td>\n","      <td>60.99</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7399</th>\n","      <td>237</td>\n","      <td>5.24</td>\n","      <td>20.52</td>\n","      <td>53.23</td>\n","      <td>15.51</td>\n","      <td>16.93</td>\n","      <td>18.57</td>\n","      <td>93.25</td>\n","      <td>81.86</td>\n","      <td>62.87</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>20</td>\n","      <td>39.70</td>\n","      <td>1.00</td>\n","      <td>28.56</td>\n","      <td>99.00</td>\n","      <td>20.00</td>\n","      <td>25.00</td>\n","      <td>95.00</td>\n","      <td>65.00</td>\n","      <td>40.00</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>19</td>\n","      <td>36.67</td>\n","      <td>3.34</td>\n","      <td>70.28</td>\n","      <td>99.00</td>\n","      <td>19.00</td>\n","      <td>21.05</td>\n","      <td>94.74</td>\n","      <td>73.68</td>\n","      <td>47.37</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>38</td>\n","      <td>36.67</td>\n","      <td>90.88</td>\n","      <td>33.61</td>\n","      <td>92.27</td>\n","      <td>19.00</td>\n","      <td>21.05</td>\n","      <td>97.37</td>\n","      <td>63.16</td>\n","      <td>52.63</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>186</td>\n","      <td>26.78</td>\n","      <td>52.89</td>\n","      <td>86.48</td>\n","      <td>2.39</td>\n","      <td>23.25</td>\n","      <td>15.59</td>\n","      <td>98.39</td>\n","      <td>79.03</td>\n","      <td>61.83</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7404 rows × 162 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4ad628e-1c06-4abe-b27b-1763496648e6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a4ad628e-1c06-4abe-b27b-1763496648e6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a4ad628e-1c06-4abe-b27b-1763496648e6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cf49113d-8b86-40a9-a5eb-a39b53406add\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf49113d-8b86-40a9-a5eb-a39b53406add')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cf49113d-8b86-40a9-a5eb-a39b53406add button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["emodf = df.loc[:, 'C_admiration':'C_neutral']\n","emodf"],"metadata":{"id":"09_Ktf1QdzeN","colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"status":"ok","timestamp":1697714312379,"user_tz":-330,"elapsed":48,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"c9aa8fef-446d-481b-bd32-a31529cacb0c"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      C_admiration  C_amusement   C_anger  C_annoyance  C_approval  C_caring  \\\n","0         0.000016     0.000150  0.000705     0.001447    0.000643  0.009114   \n","1         0.000054     0.167888  0.011522     0.201494    0.000443  0.001504   \n","2         0.000101     0.000596  0.000428     0.001275    0.006295  0.013178   \n","3         0.000054     0.000639  0.043696     0.003672    0.000041  0.007463   \n","4         0.000004     0.000040  0.000176     0.000860    0.000181  0.000255   \n","...            ...          ...       ...          ...         ...       ...   \n","7399      0.000907     0.000017  0.000027     0.000027    0.000360  0.001514   \n","7400      0.000451     0.000075  0.000005     0.000022    0.000736  0.000157   \n","7401      0.000228     0.000024  0.000010     0.000034    0.000405  0.000364   \n","7402      0.000064     0.000080  0.000109     0.000155    0.012040  0.932658   \n","7403      0.003813     0.000036  0.000079     0.000095    0.039129  0.920536   \n","\n","      C_confusion  C_curiosity.1  C_desire  C_disappointment  ...    C_love  \\\n","0        0.048850       0.010012  0.000057          0.000440  ...  0.000210   \n","1        0.002532       0.000539  0.000486          0.053486  ...  0.003212   \n","2        0.412494       0.034596  0.000124          0.002020  ...  0.001481   \n","3        0.000333       0.000094  0.000294          0.002422  ...  0.005427   \n","4        0.001674       0.000182  0.000016          0.001535  ...  0.000145   \n","...           ...            ...       ...               ...  ...       ...   \n","7399     0.000162       0.000076  0.000035          0.000038  ...  0.000018   \n","7400     0.000070       0.000227  0.000052          0.000015  ...  0.000010   \n","7401     0.000123       0.000703  0.000040          0.000015  ...  0.000008   \n","7402     0.000593       0.001206  0.000311          0.000126  ...  0.000124   \n","7403     0.000142       0.000082  0.000070          0.000138  ...  0.000231   \n","\n","      C_nervousness  C_optimism   C_pride  C_realization  C_relief  C_remorse  \\\n","0          0.068864    0.000185  0.000041       0.000323  0.001267   0.000330   \n","1          0.013415    0.000246  0.000617       0.022932  0.000231   0.003261   \n","2          0.035853    0.000615  0.000224       0.336612  0.002241   0.001373   \n","3          0.010949    0.000076  0.000740       0.000619  0.000275   0.001561   \n","4          0.079422    0.000020  0.000017       0.000338  0.000211   0.000071   \n","...             ...         ...       ...            ...       ...        ...   \n","7399       0.000038    0.000060  0.000021       0.000021  0.000448   0.000136   \n","7400       0.000004    0.000037  0.000003       0.000018  0.000051   0.000023   \n","7401       0.000007    0.000077  0.000003       0.000009  0.000134   0.000023   \n","7402       0.016793    0.015985  0.000026       0.000285  0.005689   0.000256   \n","7403       0.000211    0.007032  0.000072       0.001102  0.007063   0.000425   \n","\n","      C_sadness  C_surprise  C_neutral  \n","0      0.000575    0.000205   0.000843  \n","1      0.416074    0.001216   0.003240  \n","2      0.007805    0.013074   0.041802  \n","3      0.057985    0.000332   0.000073  \n","4      0.002956    0.000103   0.000174  \n","...         ...         ...        ...  \n","7399   0.000022    0.000016   0.000068  \n","7400   0.000008    0.000011   0.001105  \n","7401   0.000008    0.000013   0.000393  \n","7402   0.000404    0.000174   0.003708  \n","7403   0.000141    0.000089   0.015839  \n","\n","[7404 rows x 28 columns]"],"text/html":["\n","  <div id=\"df-a1c44aa5-31de-4d9c-911c-1310dacda5b6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>C_admiration</th>\n","      <th>C_amusement</th>\n","      <th>C_anger</th>\n","      <th>C_annoyance</th>\n","      <th>C_approval</th>\n","      <th>C_caring</th>\n","      <th>C_confusion</th>\n","      <th>C_curiosity.1</th>\n","      <th>C_desire</th>\n","      <th>C_disappointment</th>\n","      <th>...</th>\n","      <th>C_love</th>\n","      <th>C_nervousness</th>\n","      <th>C_optimism</th>\n","      <th>C_pride</th>\n","      <th>C_realization</th>\n","      <th>C_relief</th>\n","      <th>C_remorse</th>\n","      <th>C_sadness</th>\n","      <th>C_surprise</th>\n","      <th>C_neutral</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000016</td>\n","      <td>0.000150</td>\n","      <td>0.000705</td>\n","      <td>0.001447</td>\n","      <td>0.000643</td>\n","      <td>0.009114</td>\n","      <td>0.048850</td>\n","      <td>0.010012</td>\n","      <td>0.000057</td>\n","      <td>0.000440</td>\n","      <td>...</td>\n","      <td>0.000210</td>\n","      <td>0.068864</td>\n","      <td>0.000185</td>\n","      <td>0.000041</td>\n","      <td>0.000323</td>\n","      <td>0.001267</td>\n","      <td>0.000330</td>\n","      <td>0.000575</td>\n","      <td>0.000205</td>\n","      <td>0.000843</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000054</td>\n","      <td>0.167888</td>\n","      <td>0.011522</td>\n","      <td>0.201494</td>\n","      <td>0.000443</td>\n","      <td>0.001504</td>\n","      <td>0.002532</td>\n","      <td>0.000539</td>\n","      <td>0.000486</td>\n","      <td>0.053486</td>\n","      <td>...</td>\n","      <td>0.003212</td>\n","      <td>0.013415</td>\n","      <td>0.000246</td>\n","      <td>0.000617</td>\n","      <td>0.022932</td>\n","      <td>0.000231</td>\n","      <td>0.003261</td>\n","      <td>0.416074</td>\n","      <td>0.001216</td>\n","      <td>0.003240</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000101</td>\n","      <td>0.000596</td>\n","      <td>0.000428</td>\n","      <td>0.001275</td>\n","      <td>0.006295</td>\n","      <td>0.013178</td>\n","      <td>0.412494</td>\n","      <td>0.034596</td>\n","      <td>0.000124</td>\n","      <td>0.002020</td>\n","      <td>...</td>\n","      <td>0.001481</td>\n","      <td>0.035853</td>\n","      <td>0.000615</td>\n","      <td>0.000224</td>\n","      <td>0.336612</td>\n","      <td>0.002241</td>\n","      <td>0.001373</td>\n","      <td>0.007805</td>\n","      <td>0.013074</td>\n","      <td>0.041802</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000054</td>\n","      <td>0.000639</td>\n","      <td>0.043696</td>\n","      <td>0.003672</td>\n","      <td>0.000041</td>\n","      <td>0.007463</td>\n","      <td>0.000333</td>\n","      <td>0.000094</td>\n","      <td>0.000294</td>\n","      <td>0.002422</td>\n","      <td>...</td>\n","      <td>0.005427</td>\n","      <td>0.010949</td>\n","      <td>0.000076</td>\n","      <td>0.000740</td>\n","      <td>0.000619</td>\n","      <td>0.000275</td>\n","      <td>0.001561</td>\n","      <td>0.057985</td>\n","      <td>0.000332</td>\n","      <td>0.000073</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000004</td>\n","      <td>0.000040</td>\n","      <td>0.000176</td>\n","      <td>0.000860</td>\n","      <td>0.000181</td>\n","      <td>0.000255</td>\n","      <td>0.001674</td>\n","      <td>0.000182</td>\n","      <td>0.000016</td>\n","      <td>0.001535</td>\n","      <td>...</td>\n","      <td>0.000145</td>\n","      <td>0.079422</td>\n","      <td>0.000020</td>\n","      <td>0.000017</td>\n","      <td>0.000338</td>\n","      <td>0.000211</td>\n","      <td>0.000071</td>\n","      <td>0.002956</td>\n","      <td>0.000103</td>\n","      <td>0.000174</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7399</th>\n","      <td>0.000907</td>\n","      <td>0.000017</td>\n","      <td>0.000027</td>\n","      <td>0.000027</td>\n","      <td>0.000360</td>\n","      <td>0.001514</td>\n","      <td>0.000162</td>\n","      <td>0.000076</td>\n","      <td>0.000035</td>\n","      <td>0.000038</td>\n","      <td>...</td>\n","      <td>0.000018</td>\n","      <td>0.000038</td>\n","      <td>0.000060</td>\n","      <td>0.000021</td>\n","      <td>0.000021</td>\n","      <td>0.000448</td>\n","      <td>0.000136</td>\n","      <td>0.000022</td>\n","      <td>0.000016</td>\n","      <td>0.000068</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.000451</td>\n","      <td>0.000075</td>\n","      <td>0.000005</td>\n","      <td>0.000022</td>\n","      <td>0.000736</td>\n","      <td>0.000157</td>\n","      <td>0.000070</td>\n","      <td>0.000227</td>\n","      <td>0.000052</td>\n","      <td>0.000015</td>\n","      <td>...</td>\n","      <td>0.000010</td>\n","      <td>0.000004</td>\n","      <td>0.000037</td>\n","      <td>0.000003</td>\n","      <td>0.000018</td>\n","      <td>0.000051</td>\n","      <td>0.000023</td>\n","      <td>0.000008</td>\n","      <td>0.000011</td>\n","      <td>0.001105</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.000228</td>\n","      <td>0.000024</td>\n","      <td>0.000010</td>\n","      <td>0.000034</td>\n","      <td>0.000405</td>\n","      <td>0.000364</td>\n","      <td>0.000123</td>\n","      <td>0.000703</td>\n","      <td>0.000040</td>\n","      <td>0.000015</td>\n","      <td>...</td>\n","      <td>0.000008</td>\n","      <td>0.000007</td>\n","      <td>0.000077</td>\n","      <td>0.000003</td>\n","      <td>0.000009</td>\n","      <td>0.000134</td>\n","      <td>0.000023</td>\n","      <td>0.000008</td>\n","      <td>0.000013</td>\n","      <td>0.000393</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.000064</td>\n","      <td>0.000080</td>\n","      <td>0.000109</td>\n","      <td>0.000155</td>\n","      <td>0.012040</td>\n","      <td>0.932658</td>\n","      <td>0.000593</td>\n","      <td>0.001206</td>\n","      <td>0.000311</td>\n","      <td>0.000126</td>\n","      <td>...</td>\n","      <td>0.000124</td>\n","      <td>0.016793</td>\n","      <td>0.015985</td>\n","      <td>0.000026</td>\n","      <td>0.000285</td>\n","      <td>0.005689</td>\n","      <td>0.000256</td>\n","      <td>0.000404</td>\n","      <td>0.000174</td>\n","      <td>0.003708</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.003813</td>\n","      <td>0.000036</td>\n","      <td>0.000079</td>\n","      <td>0.000095</td>\n","      <td>0.039129</td>\n","      <td>0.920536</td>\n","      <td>0.000142</td>\n","      <td>0.000082</td>\n","      <td>0.000070</td>\n","      <td>0.000138</td>\n","      <td>...</td>\n","      <td>0.000231</td>\n","      <td>0.000211</td>\n","      <td>0.007032</td>\n","      <td>0.000072</td>\n","      <td>0.001102</td>\n","      <td>0.007063</td>\n","      <td>0.000425</td>\n","      <td>0.000141</td>\n","      <td>0.000089</td>\n","      <td>0.015839</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7404 rows × 28 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1c44aa5-31de-4d9c-911c-1310dacda5b6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a1c44aa5-31de-4d9c-911c-1310dacda5b6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a1c44aa5-31de-4d9c-911c-1310dacda5b6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a1bd4aa0-a053-437c-9bdf-cc172389e1e5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1bd4aa0-a053-437c-9bdf-cc172389e1e5')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a1bd4aa0-a053-437c-9bdf-cc172389e1e5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["intensitydf = df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","intensitydf"],"metadata":{"id":"65iE2Gl-dzg2","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1697714312379,"user_tz":-330,"elapsed":45,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"20f44998-3e00-4907-a15b-a264f7f4204e"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      D_anger_intensity  D_anticipation_intensity  D_disgust_intensity  \\\n","0              0.415048                  0.553423             0.272333   \n","1              0.530400                  0.519750             0.541250   \n","2              0.428600                  0.533500             0.228167   \n","3              0.567200                  0.533462             0.114667   \n","4              0.487000                  0.508000             0.482250   \n","...                 ...                       ...                  ...   \n","7399           0.396000                  0.609000             0.484000   \n","7400           0.000000                  0.000000             0.000000   \n","7401           0.000000                  0.000000             0.000000   \n","7402           0.344000                  0.528667             0.000000   \n","7403           0.376750                  0.502500             0.422000   \n","\n","      D_fear_intensity  D_joy_intensity  D_sadness_intensity  \\\n","0             0.568205         0.409500             0.467625   \n","1             0.432167         0.453429             0.315600   \n","2             0.526192         0.413444             0.468533   \n","3             0.501952         0.505000             0.522095   \n","4             0.624833         0.489167             0.505333   \n","...                ...              ...                  ...   \n","7399          0.527500         0.434000             0.591000   \n","7400          0.156000         0.000000             0.000000   \n","7401          0.156000         0.000000             0.000000   \n","7402          0.414000         0.515500             0.500000   \n","7403          0.515333         0.431900             0.418800   \n","\n","      D_surprise_intensity  D_trust_intensity  \n","0                 0.434500           0.522773  \n","1                 0.247333           0.508875  \n","2                 0.348500           0.504500  \n","3                 0.320500           0.593615  \n","4                 0.000000           0.527167  \n","...                    ...                ...  \n","7399              0.793000           0.540800  \n","7400              0.000000           0.000000  \n","7401              0.000000           0.641000  \n","7402              0.363500           0.613000  \n","7403              0.316500           0.519286  \n","\n","[7404 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-91621706-afce-4419-a2ed-5c08539023a8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>D_anger_intensity</th>\n","      <th>D_anticipation_intensity</th>\n","      <th>D_disgust_intensity</th>\n","      <th>D_fear_intensity</th>\n","      <th>D_joy_intensity</th>\n","      <th>D_sadness_intensity</th>\n","      <th>D_surprise_intensity</th>\n","      <th>D_trust_intensity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7399</th>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7404 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91621706-afce-4419-a2ed-5c08539023a8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-91621706-afce-4419-a2ed-5c08539023a8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-91621706-afce-4419-a2ed-5c08539023a8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ed3cb27f-23e8-4a8e-bf93-c737af5f49a5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed3cb27f-23e8-4a8e-bf93-c737af5f49a5')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ed3cb27f-23e8-4a8e-bf93-c737af5f49a5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["final_df = pd.concat([sentembdf, stdliwcdf, emodf, intensitydf], axis=1)\n","final_df['label'] = df['label']\n","final_df"],"metadata":{"id":"BV6tFi7qdzjX","colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"status":"ok","timestamp":1697714312380,"user_tz":-330,"elapsed":43,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"18fdecb3-0fe9-4b8f-ded8-9d4616be078d"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           A_1       A_2       A_3       A_4       A_5       A_6       A_7  \\\n","0    -0.019143  0.014779  0.039521 -0.010309  0.049008  0.025026 -0.056692   \n","1     0.010327 -0.017366  0.037534  0.020887  0.070232  0.060259 -0.020957   \n","2    -0.048175  0.037344  0.056609  0.035632  0.034589  0.009242 -0.033765   \n","3    -0.025639 -0.012544  0.004850  0.003161  0.068372  0.020812 -0.023470   \n","4    -0.004646  0.029859  0.027000  0.009553  0.061528  0.015759  0.015545   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","7399  0.004537  0.004089 -0.001497  0.029067 -0.010354  0.060507 -0.057212   \n","7400  0.058352  0.083199  0.026844  0.018507  0.040248 -0.046760 -0.004367   \n","7401  0.040878  0.051785  0.012076  0.003620  0.052075 -0.037816  0.024597   \n","7402  0.056155  0.062430 -0.006433  0.014363 -0.037829 -0.023952 -0.031864   \n","7403  0.042712  0.040786  0.058618  0.017743 -0.004685  0.032968 -0.026134   \n","\n","           A_8       A_9      A_10  ...  C_neutral  D_anger_intensity  \\\n","0    -0.023111 -0.046817  0.000515  ...   0.000843           0.415048   \n","1     0.041326  0.010001 -0.012280  ...   0.003240           0.530400   \n","2    -0.051093 -0.030799 -0.026486  ...   0.041802           0.428600   \n","3     0.020670 -0.006528 -0.011151  ...   0.000073           0.567200   \n","4     0.006237 -0.013028 -0.004326  ...   0.000174           0.487000   \n","...        ...       ...       ...  ...        ...                ...   \n","7399  0.000164  0.008451  0.057407  ...   0.000068           0.396000   \n","7400 -0.002714  0.034234  0.015911  ...   0.001105           0.000000   \n","7401  0.018865  0.051135  0.046981  ...   0.000393           0.000000   \n","7402  0.038622 -0.003138  0.030964  ...   0.003708           0.344000   \n","7403 -0.009570 -0.014374  0.049005  ...   0.015839           0.376750   \n","\n","      D_anticipation_intensity  D_disgust_intensity  D_fear_intensity  \\\n","0                     0.553423             0.272333          0.568205   \n","1                     0.519750             0.541250          0.432167   \n","2                     0.533500             0.228167          0.526192   \n","3                     0.533462             0.114667          0.501952   \n","4                     0.508000             0.482250          0.624833   \n","...                        ...                  ...               ...   \n","7399                  0.609000             0.484000          0.527500   \n","7400                  0.000000             0.000000          0.156000   \n","7401                  0.000000             0.000000          0.156000   \n","7402                  0.528667             0.000000          0.414000   \n","7403                  0.502500             0.422000          0.515333   \n","\n","      D_joy_intensity  D_sadness_intensity  D_surprise_intensity  \\\n","0            0.409500             0.467625              0.434500   \n","1            0.453429             0.315600              0.247333   \n","2            0.413444             0.468533              0.348500   \n","3            0.505000             0.522095              0.320500   \n","4            0.489167             0.505333              0.000000   \n","...               ...                  ...                   ...   \n","7399         0.434000             0.591000              0.793000   \n","7400         0.000000             0.000000              0.000000   \n","7401         0.000000             0.000000              0.000000   \n","7402         0.515500             0.500000              0.363500   \n","7403         0.431900             0.418800              0.316500   \n","\n","      D_trust_intensity  label  \n","0              0.522773      1  \n","1              0.508875      1  \n","2              0.504500      1  \n","3              0.593615      1  \n","4              0.527167      1  \n","...                 ...    ...  \n","7399           0.540800      0  \n","7400           0.000000      0  \n","7401           0.641000      0  \n","7402           0.613000      0  \n","7403           0.519286      0  \n","\n","[7404 rows x 967 columns]"],"text/html":["\n","  <div id=\"df-f1ce292b-bc56-4918-94cd-0903a0ed8169\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A_1</th>\n","      <th>A_2</th>\n","      <th>A_3</th>\n","      <th>A_4</th>\n","      <th>A_5</th>\n","      <th>A_6</th>\n","      <th>A_7</th>\n","      <th>A_8</th>\n","      <th>A_9</th>\n","      <th>A_10</th>\n","      <th>...</th>\n","      <th>C_neutral</th>\n","      <th>D_anger_intensity</th>\n","      <th>D_anticipation_intensity</th>\n","      <th>D_disgust_intensity</th>\n","      <th>D_fear_intensity</th>\n","      <th>D_joy_intensity</th>\n","      <th>D_sadness_intensity</th>\n","      <th>D_surprise_intensity</th>\n","      <th>D_trust_intensity</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.019143</td>\n","      <td>0.014779</td>\n","      <td>0.039521</td>\n","      <td>-0.010309</td>\n","      <td>0.049008</td>\n","      <td>0.025026</td>\n","      <td>-0.056692</td>\n","      <td>-0.023111</td>\n","      <td>-0.046817</td>\n","      <td>0.000515</td>\n","      <td>...</td>\n","      <td>0.000843</td>\n","      <td>0.415048</td>\n","      <td>0.553423</td>\n","      <td>0.272333</td>\n","      <td>0.568205</td>\n","      <td>0.409500</td>\n","      <td>0.467625</td>\n","      <td>0.434500</td>\n","      <td>0.522773</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.010327</td>\n","      <td>-0.017366</td>\n","      <td>0.037534</td>\n","      <td>0.020887</td>\n","      <td>0.070232</td>\n","      <td>0.060259</td>\n","      <td>-0.020957</td>\n","      <td>0.041326</td>\n","      <td>0.010001</td>\n","      <td>-0.012280</td>\n","      <td>...</td>\n","      <td>0.003240</td>\n","      <td>0.530400</td>\n","      <td>0.519750</td>\n","      <td>0.541250</td>\n","      <td>0.432167</td>\n","      <td>0.453429</td>\n","      <td>0.315600</td>\n","      <td>0.247333</td>\n","      <td>0.508875</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.048175</td>\n","      <td>0.037344</td>\n","      <td>0.056609</td>\n","      <td>0.035632</td>\n","      <td>0.034589</td>\n","      <td>0.009242</td>\n","      <td>-0.033765</td>\n","      <td>-0.051093</td>\n","      <td>-0.030799</td>\n","      <td>-0.026486</td>\n","      <td>...</td>\n","      <td>0.041802</td>\n","      <td>0.428600</td>\n","      <td>0.533500</td>\n","      <td>0.228167</td>\n","      <td>0.526192</td>\n","      <td>0.413444</td>\n","      <td>0.468533</td>\n","      <td>0.348500</td>\n","      <td>0.504500</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.025639</td>\n","      <td>-0.012544</td>\n","      <td>0.004850</td>\n","      <td>0.003161</td>\n","      <td>0.068372</td>\n","      <td>0.020812</td>\n","      <td>-0.023470</td>\n","      <td>0.020670</td>\n","      <td>-0.006528</td>\n","      <td>-0.011151</td>\n","      <td>...</td>\n","      <td>0.000073</td>\n","      <td>0.567200</td>\n","      <td>0.533462</td>\n","      <td>0.114667</td>\n","      <td>0.501952</td>\n","      <td>0.505000</td>\n","      <td>0.522095</td>\n","      <td>0.320500</td>\n","      <td>0.593615</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.004646</td>\n","      <td>0.029859</td>\n","      <td>0.027000</td>\n","      <td>0.009553</td>\n","      <td>0.061528</td>\n","      <td>0.015759</td>\n","      <td>0.015545</td>\n","      <td>0.006237</td>\n","      <td>-0.013028</td>\n","      <td>-0.004326</td>\n","      <td>...</td>\n","      <td>0.000174</td>\n","      <td>0.487000</td>\n","      <td>0.508000</td>\n","      <td>0.482250</td>\n","      <td>0.624833</td>\n","      <td>0.489167</td>\n","      <td>0.505333</td>\n","      <td>0.000000</td>\n","      <td>0.527167</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7399</th>\n","      <td>0.004537</td>\n","      <td>0.004089</td>\n","      <td>-0.001497</td>\n","      <td>0.029067</td>\n","      <td>-0.010354</td>\n","      <td>0.060507</td>\n","      <td>-0.057212</td>\n","      <td>0.000164</td>\n","      <td>0.008451</td>\n","      <td>0.057407</td>\n","      <td>...</td>\n","      <td>0.000068</td>\n","      <td>0.396000</td>\n","      <td>0.609000</td>\n","      <td>0.484000</td>\n","      <td>0.527500</td>\n","      <td>0.434000</td>\n","      <td>0.591000</td>\n","      <td>0.793000</td>\n","      <td>0.540800</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7400</th>\n","      <td>0.058352</td>\n","      <td>0.083199</td>\n","      <td>0.026844</td>\n","      <td>0.018507</td>\n","      <td>0.040248</td>\n","      <td>-0.046760</td>\n","      <td>-0.004367</td>\n","      <td>-0.002714</td>\n","      <td>0.034234</td>\n","      <td>0.015911</td>\n","      <td>...</td>\n","      <td>0.001105</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7401</th>\n","      <td>0.040878</td>\n","      <td>0.051785</td>\n","      <td>0.012076</td>\n","      <td>0.003620</td>\n","      <td>0.052075</td>\n","      <td>-0.037816</td>\n","      <td>0.024597</td>\n","      <td>0.018865</td>\n","      <td>0.051135</td>\n","      <td>0.046981</td>\n","      <td>...</td>\n","      <td>0.000393</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.641000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7402</th>\n","      <td>0.056155</td>\n","      <td>0.062430</td>\n","      <td>-0.006433</td>\n","      <td>0.014363</td>\n","      <td>-0.037829</td>\n","      <td>-0.023952</td>\n","      <td>-0.031864</td>\n","      <td>0.038622</td>\n","      <td>-0.003138</td>\n","      <td>0.030964</td>\n","      <td>...</td>\n","      <td>0.003708</td>\n","      <td>0.344000</td>\n","      <td>0.528667</td>\n","      <td>0.000000</td>\n","      <td>0.414000</td>\n","      <td>0.515500</td>\n","      <td>0.500000</td>\n","      <td>0.363500</td>\n","      <td>0.613000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7403</th>\n","      <td>0.042712</td>\n","      <td>0.040786</td>\n","      <td>0.058618</td>\n","      <td>0.017743</td>\n","      <td>-0.004685</td>\n","      <td>0.032968</td>\n","      <td>-0.026134</td>\n","      <td>-0.009570</td>\n","      <td>-0.014374</td>\n","      <td>0.049005</td>\n","      <td>...</td>\n","      <td>0.015839</td>\n","      <td>0.376750</td>\n","      <td>0.502500</td>\n","      <td>0.422000</td>\n","      <td>0.515333</td>\n","      <td>0.431900</td>\n","      <td>0.418800</td>\n","      <td>0.316500</td>\n","      <td>0.519286</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7404 rows × 967 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1ce292b-bc56-4918-94cd-0903a0ed8169')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f1ce292b-bc56-4918-94cd-0903a0ed8169 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f1ce292b-bc56-4918-94cd-0903a0ed8169');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7c3d979a-0eca-4bbb-a47a-92a5310e5e79\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c3d979a-0eca-4bbb-a47a-92a5310e5e79')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7c3d979a-0eca-4bbb-a47a-92a5310e5e79 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[],"metadata":{"id":"Fhzij9Yadzm2","executionInfo":{"status":"ok","timestamp":1697714312380,"user_tz":-330,"elapsed":39,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"CxkzY-KOg1Kz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697714318246,"user_tz":-330,"elapsed":5904,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"dffbae13-abd0-4a19-8cd4-f06f92d61270"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import matthews_corrcoef"],"metadata":{"id":"3NCNXMeEg1M6","executionInfo":{"status":"ok","timestamp":1697714319026,"user_tz":-330,"elapsed":792,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Conv1D, Dense, Concatenate, GlobalMaxPooling1D, Reshape, Dropout, MaxPooling1D, MaxPooling2D, MaxPooling3D, RepeatVector, Flatten\n","from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"1jdsbgQ1g1PD","executionInfo":{"status":"ok","timestamp":1697714321492,"user_tz":-330,"elapsed":2473,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from imblearn.under_sampling import RandomUnderSampler"],"metadata":{"id":"5UxFvXmAg1cB","executionInfo":{"status":"ok","timestamp":1697714322160,"user_tz":-330,"elapsed":673,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["scaling = MinMaxScaler(feature_range=(0,1))  # (0,1) is default\n","sc = StandardScaler()"],"metadata":{"id":"_tHCdn2pg1Rh","executionInfo":{"status":"ok","timestamp":1697714322161,"user_tz":-330,"elapsed":23,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DUvS8xVWg1Ts","executionInfo":{"status":"ok","timestamp":1697714322162,"user_tz":-330,"elapsed":23,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# to register f1 score separately in Keras (working)\n","\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.metrics import Metric\n","\n","class F1Score(Metric):\n","    def __init__(self, name='f1_score', **kwargs):\n","        super(F1Score, self).__init__(name=name, **kwargs)\n","        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n","        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n","        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_true = tf.cast(y_true, tf.float32)\n","        y_pred = tf.cast(y_pred, tf.float32)\n","\n","        true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n","        false_positives = tf.reduce_sum(tf.round(tf.clip_by_value((1 - y_true) * y_pred, 0, 1)))\n","        false_negatives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * (1 - y_pred), 0, 1)))\n","\n","        self.true_positives.assign_add(true_positives)\n","        self.false_positives.assign_add(false_positives)\n","        self.false_negatives.assign_add(false_negatives)\n","\n","    def result(self):\n","        precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n","        recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n","        f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n","        return f1"],"metadata":{"id":"m4W7TPpig1Vw","executionInfo":{"status":"ok","timestamp":1697714322162,"user_tz":-330,"elapsed":22,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Note - as of now MCC is calculated separately as evaluate() doesnt inherently have mcc as an evaluation metric, but it can be made by defining a function like this\n","\n","\n","# from tensorflow.keras import backend as K\n","\n","# # Define a custom MCC metric\n","# def matthews_correlation_coefficient(y_true, y_pred):\n","#     y_pred_binary = K.round(y_pred)\n","#     TP = K.sum(K.round(y_true) * y_pred_binary)\n","#     TN = K.sum((1 - K.round(y_true)) * (1 - y_pred_binary))\n","#     FP = K.sum((1 - K.round(y_true)) * y_pred_binary)\n","#     FN = K.sum(K.round(y_true) * (1 - y_pred_binary))\n","\n","#     numerator = (TP * TN - FP * FN)\n","#     denominator = K.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n","\n","#     return numerator / (denominator + K.epsilon())\n","\n","# and then make these changes in the end\n","\n","# # Compile the model using the custom metric\n","# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score(), matthews_correlation_coefficient])\n","\n","# # During evaluation, you can retrieve MCC as follows\n","# loss, accuracy, f1, mcc = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)"],"metadata":{"id":"KvROOHKAEMof","executionInfo":{"status":"ok","timestamp":1697714322163,"user_tz":-330,"elapsed":23,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zemzTJH9EMqs","executionInfo":{"status":"ok","timestamp":1697714322164,"user_tz":-330,"elapsed":23,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["### Change A,E,H,I accordingly"],"metadata":{"id":"mcETqQsO96XC"}},{"cell_type":"code","source":["# sentembdf = df.loc[:, 'A_1':'A_768']\n","# sentembdf = df.loc[:, 'E_1':'E_384']\n","# sentembdf = df.loc[:, 'H_1':'H_768']\n","sentembdf = df.loc[:, 'I_1':'I_768']\n","\n","stdliwcdf = df.loc[:, 'B_WC':'B_Emoji'].join(df.loc[:, 'F_symptom_1_indicator':'F_symptom_44_indicator'])\n","emodf = df.loc[:, 'C_admiration':'C_neutral']\n","intensitydf = df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","final_df = pd.concat([sentembdf, stdliwcdf, emodf, intensitydf], axis=1)\n","final_df['label'] = df['label']"],"metadata":{"id":"_N_j5dNOg1Xz","executionInfo":{"status":"ok","timestamp":1697718681538,"user_tz":-330,"elapsed":466,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# X_sentemb = final_df.loc[:, 'A_1':'A_768']\n","# sentemb_column_names = [\"A_\" + str(i+1) for i in range(768)]\n","# X_sentemb = final_df.loc[:, 'E_1':'E_384']\n","# sentemb_column_names = [\"E_\" + str(i+1) for i in range(384)]\n","# X_sentemb = final_df.loc[:, 'H_1':'H_768']\n","# sentemb_column_names = [\"H_\" + str(i+1) for i in range(768)]\n","X_sentemb = final_df.loc[:, 'I_1':'I_768']\n","sentemb_column_names = [\"I_\" + str(i+1) for i in range(768)]\n","\n","X_liwc = final_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","X_emotions = final_df.loc[:, 'C_admiration':'C_neutral']\n","X_intensity = final_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","y = final_df['label']"],"metadata":{"id":"_47EGr1qg1aC","executionInfo":{"status":"ok","timestamp":1697718681967,"user_tz":-330,"elapsed":1,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["sentemb_column_names[-1]"],"metadata":{"id":"N6-m5KyA-ujm","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1697714322165,"user_tz":-330,"elapsed":22,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e0fc6b7a-0055-4576-8502-dfc32bc1c480"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'A_768'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":[],"metadata":{"id":"-Nv6FvxMlNhu","executionInfo":{"status":"ok","timestamp":1697570247711,"user_tz":-330,"elapsed":7,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Yh85xFpl0A_X","executionInfo":{"status":"ok","timestamp":1697570247711,"user_tz":-330,"elapsed":6,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["## CNN layer to emotions with maxpooling (pool size 5 and stride 2) (without additional LSTM layer in emotions)"],"metadata":{"id":"36JvKgMx0BUW"}},{"cell_type":"code","source":["# LSTM CNN nothing nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=5, strides=2)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        #cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))  # cnn_emotions returns length 3072, ie cnn_emotions.shape[1] = 3072\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"id":"1TL8pPMRg1fk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697570645920,"user_tz":-330,"elapsed":397316,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"05ad258a-cb38-4b22-bd9b-457e1927b61d"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4707 - accuracy: 0.7684 - f1_score: 0.7648 - val_loss: 0.3530 - val_accuracy: 0.8454 - val_f1_score: 0.8469\n","Epoch 2/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.3107 - accuracy: 0.8682 - f1_score: 0.8685 - val_loss: 0.3375 - val_accuracy: 0.8472 - val_f1_score: 0.8392\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2600 - accuracy: 0.8972 - f1_score: 0.8961 - val_loss: 0.3341 - val_accuracy: 0.8653 - val_f1_score: 0.8598\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2106 - accuracy: 0.9198 - f1_score: 0.9198 - val_loss: 0.3410 - val_accuracy: 0.8671 - val_f1_score: 0.8599\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1676 - accuracy: 0.9373 - f1_score: 0.9366 - val_loss: 0.3459 - val_accuracy: 0.8644 - val_f1_score: 0.8644\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1360 - accuracy: 0.9493 - f1_score: 0.9491 - val_loss: 0.3668 - val_accuracy: 0.8671 - val_f1_score: 0.8607\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1067 - accuracy: 0.9620 - f1_score: 0.9618 - val_loss: 0.5017 - val_accuracy: 0.8535 - val_f1_score: 0.8370\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0867 - accuracy: 0.9677 - f1_score: 0.9675 - val_loss: 0.5165 - val_accuracy: 0.8635 - val_f1_score: 0.8598\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8616 - f1_score: 0.8825\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4808 - accuracy: 0.7615 - f1_score: 0.7617 - val_loss: 0.3596 - val_accuracy: 0.8409 - val_f1_score: 0.8516\n","Epoch 2/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.3067 - accuracy: 0.8727 - f1_score: 0.8733 - val_loss: 0.3476 - val_accuracy: 0.8617 - val_f1_score: 0.8516\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2629 - accuracy: 0.8981 - f1_score: 0.8975 - val_loss: 0.3114 - val_accuracy: 0.8662 - val_f1_score: 0.8669\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2153 - accuracy: 0.9147 - f1_score: 0.9144 - val_loss: 0.3149 - val_accuracy: 0.8770 - val_f1_score: 0.8736\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1857 - accuracy: 0.9273 - f1_score: 0.9271 - val_loss: 0.3782 - val_accuracy: 0.8725 - val_f1_score: 0.8653\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1472 - accuracy: 0.9457 - f1_score: 0.9458 - val_loss: 0.4062 - val_accuracy: 0.8653 - val_f1_score: 0.8523\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1057 - accuracy: 0.9626 - f1_score: 0.9627 - val_loss: 0.3994 - val_accuracy: 0.8843 - val_f1_score: 0.8795\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9759 - f1_score: 0.9759 - val_loss: 0.5034 - val_accuracy: 0.8816 - val_f1_score: 0.8746\n","47/47 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8717 - f1_score: 0.8955\n","47/47 [==============================] - 0s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 19ms/step - loss: 0.5029 - accuracy: 0.7437 - f1_score: 0.7478 - val_loss: 0.3548 - val_accuracy: 0.8382 - val_f1_score: 0.8326\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3269 - accuracy: 0.8604 - f1_score: 0.8593 - val_loss: 0.3299 - val_accuracy: 0.8463 - val_f1_score: 0.8514\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2675 - accuracy: 0.8938 - f1_score: 0.8935 - val_loss: 0.2967 - val_accuracy: 0.8707 - val_f1_score: 0.8684\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2166 - accuracy: 0.9159 - f1_score: 0.9155 - val_loss: 0.3031 - val_accuracy: 0.8752 - val_f1_score: 0.8748\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1659 - accuracy: 0.9334 - f1_score: 0.9330 - val_loss: 0.3331 - val_accuracy: 0.8725 - val_f1_score: 0.8661\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1496 - accuracy: 0.9424 - f1_score: 0.9420 - val_loss: 0.3538 - val_accuracy: 0.8752 - val_f1_score: 0.8720\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1033 - accuracy: 0.9581 - f1_score: 0.9578 - val_loss: 0.4343 - val_accuracy: 0.8698 - val_f1_score: 0.8667\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0719 - accuracy: 0.9738 - f1_score: 0.9736 - val_loss: 0.5116 - val_accuracy: 0.8608 - val_f1_score: 0.8525\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8690 - f1_score: 0.8900\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 20ms/step - loss: 0.5066 - accuracy: 0.7494 - f1_score: 0.7276 - val_loss: 0.3530 - val_accuracy: 0.8544 - val_f1_score: 0.8553\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3289 - accuracy: 0.8607 - f1_score: 0.8616 - val_loss: 0.3218 - val_accuracy: 0.8608 - val_f1_score: 0.8613\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2634 - accuracy: 0.8914 - f1_score: 0.8915 - val_loss: 0.2960 - val_accuracy: 0.8734 - val_f1_score: 0.8727\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2166 - accuracy: 0.9189 - f1_score: 0.9190 - val_loss: 0.2889 - val_accuracy: 0.8825 - val_f1_score: 0.8825\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9328 - f1_score: 0.9327 - val_loss: 0.3176 - val_accuracy: 0.8743 - val_f1_score: 0.8680\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1376 - accuracy: 0.9454 - f1_score: 0.9455 - val_loss: 0.3740 - val_accuracy: 0.8807 - val_f1_score: 0.8782\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0956 - accuracy: 0.9665 - f1_score: 0.9667 - val_loss: 0.3940 - val_accuracy: 0.8825 - val_f1_score: 0.8837\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0740 - accuracy: 0.9750 - f1_score: 0.9749 - val_loss: 0.4652 - val_accuracy: 0.8834 - val_f1_score: 0.8839\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0681 - accuracy: 0.9774 - f1_score: 0.9773 - val_loss: 0.5183 - val_accuracy: 0.8843 - val_f1_score: 0.8813\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8751 - f1_score: 0.8961\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 19ms/step - loss: 0.4873 - accuracy: 0.7660 - f1_score: 0.7658 - val_loss: 0.3448 - val_accuracy: 0.8454 - val_f1_score: 0.8403\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3126 - accuracy: 0.8661 - f1_score: 0.8660 - val_loss: 0.3152 - val_accuracy: 0.8544 - val_f1_score: 0.8505\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2541 - accuracy: 0.8978 - f1_score: 0.8984 - val_loss: 0.3007 - val_accuracy: 0.8635 - val_f1_score: 0.8613\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2165 - accuracy: 0.9168 - f1_score: 0.9166 - val_loss: 0.2973 - val_accuracy: 0.8653 - val_f1_score: 0.8654\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1677 - accuracy: 0.9370 - f1_score: 0.9368 - val_loss: 0.3752 - val_accuracy: 0.8580 - val_f1_score: 0.8664\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1336 - accuracy: 0.9505 - f1_score: 0.9503 - val_loss: 0.3545 - val_accuracy: 0.8761 - val_f1_score: 0.8758\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0987 - accuracy: 0.9656 - f1_score: 0.9655 - val_loss: 0.4421 - val_accuracy: 0.8752 - val_f1_score: 0.8743\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0807 - accuracy: 0.9704 - f1_score: 0.9703 - val_loss: 0.5144 - val_accuracy: 0.8445 - val_f1_score: 0.8562\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0766 - accuracy: 0.9726 - f1_score: 0.9724 - val_loss: 0.4072 - val_accuracy: 0.8671 - val_f1_score: 0.8640\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.8758 - f1_score: 0.8956\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 19ms/step - loss: 0.4879 - accuracy: 0.7554 - f1_score: 0.7474 - val_loss: 0.3760 - val_accuracy: 0.8255 - val_f1_score: 0.8388\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3047 - accuracy: 0.8706 - f1_score: 0.8698 - val_loss: 0.3180 - val_accuracy: 0.8571 - val_f1_score: 0.8534\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2447 - accuracy: 0.9044 - f1_score: 0.9034 - val_loss: 0.3446 - val_accuracy: 0.8644 - val_f1_score: 0.8634\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1996 - accuracy: 0.9189 - f1_score: 0.9181 - val_loss: 0.3429 - val_accuracy: 0.8562 - val_f1_score: 0.8579\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1586 - accuracy: 0.9409 - f1_score: 0.9405 - val_loss: 0.3708 - val_accuracy: 0.8608 - val_f1_score: 0.8577\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1233 - accuracy: 0.9560 - f1_score: 0.9557 - val_loss: 0.3884 - val_accuracy: 0.8635 - val_f1_score: 0.8658\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0910 - accuracy: 0.9698 - f1_score: 0.9697 - val_loss: 0.4512 - val_accuracy: 0.8571 - val_f1_score: 0.8545\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8379 - f1_score: 0.8629\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 19ms/step - loss: 0.4823 - accuracy: 0.7684 - f1_score: 0.7543 - val_loss: 0.3884 - val_accuracy: 0.8264 - val_f1_score: 0.8206\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3092 - accuracy: 0.8736 - f1_score: 0.8740 - val_loss: 0.3470 - val_accuracy: 0.8526 - val_f1_score: 0.8581\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2538 - accuracy: 0.8960 - f1_score: 0.8961 - val_loss: 0.3202 - val_accuracy: 0.8599 - val_f1_score: 0.8569\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1962 - accuracy: 0.9228 - f1_score: 0.9225 - val_loss: 0.3515 - val_accuracy: 0.8698 - val_f1_score: 0.8662\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1580 - accuracy: 0.9397 - f1_score: 0.9396 - val_loss: 0.3471 - val_accuracy: 0.8463 - val_f1_score: 0.8564\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1294 - accuracy: 0.9478 - f1_score: 0.9476 - val_loss: 0.3690 - val_accuracy: 0.8680 - val_f1_score: 0.8661\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0857 - accuracy: 0.9710 - f1_score: 0.9709 - val_loss: 0.5341 - val_accuracy: 0.8508 - val_f1_score: 0.8622\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0648 - accuracy: 0.9759 - f1_score: 0.9759 - val_loss: 0.6048 - val_accuracy: 0.8635 - val_f1_score: 0.8579\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8562 - f1_score: 0.8795\n","47/47 [==============================] - 1s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 20ms/step - loss: 0.4841 - accuracy: 0.7642 - f1_score: 0.7579 - val_loss: 0.3632 - val_accuracy: 0.8354 - val_f1_score: 0.8273\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3093 - accuracy: 0.8721 - f1_score: 0.8710 - val_loss: 0.3485 - val_accuracy: 0.8544 - val_f1_score: 0.8601\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2575 - accuracy: 0.8945 - f1_score: 0.8936 - val_loss: 0.3143 - val_accuracy: 0.8626 - val_f1_score: 0.8616\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2113 - accuracy: 0.9192 - f1_score: 0.9184 - val_loss: 0.3605 - val_accuracy: 0.8599 - val_f1_score: 0.8590\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1716 - accuracy: 0.9337 - f1_score: 0.9330 - val_loss: 0.3365 - val_accuracy: 0.8599 - val_f1_score: 0.8625\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1435 - accuracy: 0.9493 - f1_score: 0.9487 - val_loss: 0.4064 - val_accuracy: 0.8671 - val_f1_score: 0.8689\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1056 - accuracy: 0.9617 - f1_score: 0.9614 - val_loss: 0.3882 - val_accuracy: 0.8752 - val_f1_score: 0.8763\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0843 - accuracy: 0.9704 - f1_score: 0.9702 - val_loss: 0.5078 - val_accuracy: 0.8580 - val_f1_score: 0.8622\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8569 - f1_score: 0.8820\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 20ms/step - loss: 0.5020 - accuracy: 0.7584 - f1_score: 0.7620 - val_loss: 0.3670 - val_accuracy: 0.8382 - val_f1_score: 0.8243\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3201 - accuracy: 0.8640 - f1_score: 0.8616 - val_loss: 0.3095 - val_accuracy: 0.8716 - val_f1_score: 0.8707\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2613 - accuracy: 0.8926 - f1_score: 0.8928 - val_loss: 0.2951 - val_accuracy: 0.8816 - val_f1_score: 0.8758\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2181 - accuracy: 0.9119 - f1_score: 0.9105 - val_loss: 0.3079 - val_accuracy: 0.8888 - val_f1_score: 0.8889\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1767 - accuracy: 0.9252 - f1_score: 0.9242 - val_loss: 0.3069 - val_accuracy: 0.8843 - val_f1_score: 0.8790\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9478 - f1_score: 0.9473 - val_loss: 0.3505 - val_accuracy: 0.8770 - val_f1_score: 0.8692\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1075 - accuracy: 0.9617 - f1_score: 0.9617 - val_loss: 0.3747 - val_accuracy: 0.8933 - val_f1_score: 0.8893\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0850 - accuracy: 0.9710 - f1_score: 0.9710 - val_loss: 0.4940 - val_accuracy: 0.8716 - val_f1_score: 0.8613\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8528 - f1_score: 0.8761\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 20ms/step - loss: 0.4742 - accuracy: 0.7729 - f1_score: 0.7752 - val_loss: 0.3542 - val_accuracy: 0.8517 - val_f1_score: 0.8479\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.8703 - f1_score: 0.8683 - val_loss: 0.3217 - val_accuracy: 0.8671 - val_f1_score: 0.8580\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2605 - accuracy: 0.8902 - f1_score: 0.8887 - val_loss: 0.3181 - val_accuracy: 0.8743 - val_f1_score: 0.8677\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2248 - accuracy: 0.9044 - f1_score: 0.9030 - val_loss: 0.2993 - val_accuracy: 0.8915 - val_f1_score: 0.8887\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1730 - accuracy: 0.9352 - f1_score: 0.9344 - val_loss: 0.3125 - val_accuracy: 0.8888 - val_f1_score: 0.8879\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1425 - accuracy: 0.9469 - f1_score: 0.9465 - val_loss: 0.4460 - val_accuracy: 0.8472 - val_f1_score: 0.8593\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1203 - accuracy: 0.9557 - f1_score: 0.9555 - val_loss: 0.4236 - val_accuracy: 0.8770 - val_f1_score: 0.8741\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0798 - accuracy: 0.9729 - f1_score: 0.9727 - val_loss: 0.4173 - val_accuracy: 0.8843 - val_f1_score: 0.8790\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9771 - f1_score: 0.9770 - val_loss: 0.4419 - val_accuracy: 0.8734 - val_f1_score: 0.8696\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8690 - f1_score: 0.8917\n","47/47 [==============================] - 0s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4973 - accuracy: 0.7603 - f1_score: 0.7656 - val_loss: 0.3454 - val_accuracy: 0.8472 - val_f1_score: 0.8407\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3285 - accuracy: 0.8601 - f1_score: 0.8596 - val_loss: 0.2996 - val_accuracy: 0.8743 - val_f1_score: 0.8726\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2762 - accuracy: 0.8881 - f1_score: 0.8876 - val_loss: 0.2916 - val_accuracy: 0.8816 - val_f1_score: 0.8810\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2405 - accuracy: 0.9050 - f1_score: 0.9052 - val_loss: 0.2848 - val_accuracy: 0.8807 - val_f1_score: 0.8716\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1978 - accuracy: 0.9195 - f1_score: 0.9188 - val_loss: 0.2902 - val_accuracy: 0.8879 - val_f1_score: 0.8839\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1558 - accuracy: 0.9415 - f1_score: 0.9411 - val_loss: 0.3229 - val_accuracy: 0.8843 - val_f1_score: 0.8804\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1332 - accuracy: 0.9478 - f1_score: 0.9473 - val_loss: 0.3181 - val_accuracy: 0.8834 - val_f1_score: 0.8807\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0945 - accuracy: 0.9677 - f1_score: 0.9675 - val_loss: 0.4218 - val_accuracy: 0.8734 - val_f1_score: 0.8776\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9744 - f1_score: 0.9741 - val_loss: 0.4426 - val_accuracy: 0.8797 - val_f1_score: 0.8816\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8535 - f1_score: 0.8729\n","47/47 [==============================] - 0s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 19ms/step - loss: 0.4922 - accuracy: 0.7545 - f1_score: 0.7495 - val_loss: 0.3631 - val_accuracy: 0.8363 - val_f1_score: 0.8368\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3147 - accuracy: 0.8667 - f1_score: 0.8673 - val_loss: 0.3426 - val_accuracy: 0.8391 - val_f1_score: 0.8255\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2690 - accuracy: 0.8905 - f1_score: 0.8906 - val_loss: 0.3200 - val_accuracy: 0.8716 - val_f1_score: 0.8739\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2241 - accuracy: 0.9095 - f1_score: 0.9087 - val_loss: 0.3199 - val_accuracy: 0.8698 - val_f1_score: 0.8700\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1850 - accuracy: 0.9264 - f1_score: 0.9260 - val_loss: 0.3363 - val_accuracy: 0.8671 - val_f1_score: 0.8718\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1454 - accuracy: 0.9466 - f1_score: 0.9462 - val_loss: 0.3650 - val_accuracy: 0.8671 - val_f1_score: 0.8707\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1096 - accuracy: 0.9602 - f1_score: 0.9600 - val_loss: 0.4506 - val_accuracy: 0.8680 - val_f1_score: 0.8633\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0844 - accuracy: 0.9680 - f1_score: 0.9678 - val_loss: 0.4634 - val_accuracy: 0.8743 - val_f1_score: 0.8749\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0665 - accuracy: 0.9771 - f1_score: 0.9770 - val_loss: 0.6098 - val_accuracy: 0.8580 - val_f1_score: 0.8438\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.8839 - f1_score: 0.9054\n","47/47 [==============================] - 0s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 19ms/step - loss: 0.4872 - accuracy: 0.7657 - f1_score: 0.7582 - val_loss: 0.3956 - val_accuracy: 0.8309 - val_f1_score: 0.8347\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3236 - accuracy: 0.8700 - f1_score: 0.8693 - val_loss: 0.3617 - val_accuracy: 0.8454 - val_f1_score: 0.8450\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2639 - accuracy: 0.8951 - f1_score: 0.8947 - val_loss: 0.3568 - val_accuracy: 0.8580 - val_f1_score: 0.8629\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2234 - accuracy: 0.9113 - f1_score: 0.9109 - val_loss: 0.3330 - val_accuracy: 0.8626 - val_f1_score: 0.8636\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1791 - accuracy: 0.9297 - f1_score: 0.9297 - val_loss: 0.3651 - val_accuracy: 0.8662 - val_f1_score: 0.8640\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1446 - accuracy: 0.9418 - f1_score: 0.9415 - val_loss: 0.3828 - val_accuracy: 0.8626 - val_f1_score: 0.8650\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1166 - accuracy: 0.9527 - f1_score: 0.9524 - val_loss: 0.4097 - val_accuracy: 0.8608 - val_f1_score: 0.8539\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0941 - accuracy: 0.9659 - f1_score: 0.9657 - val_loss: 0.5720 - val_accuracy: 0.8562 - val_f1_score: 0.8556\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0702 - accuracy: 0.9753 - f1_score: 0.9751 - val_loss: 0.5134 - val_accuracy: 0.8680 - val_f1_score: 0.8646\n","47/47 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8791 - f1_score: 0.9015\n","47/47 [==============================] - 0s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 16ms/step - loss: 0.4917 - accuracy: 0.7615 - f1_score: 0.7433 - val_loss: 0.3739 - val_accuracy: 0.8418 - val_f1_score: 0.8500\n","Epoch 2/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.3242 - accuracy: 0.8631 - f1_score: 0.8628 - val_loss: 0.3141 - val_accuracy: 0.8590 - val_f1_score: 0.8600\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2675 - accuracy: 0.8863 - f1_score: 0.8850 - val_loss: 0.3126 - val_accuracy: 0.8626 - val_f1_score: 0.8552\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2256 - accuracy: 0.9089 - f1_score: 0.9075 - val_loss: 0.3021 - val_accuracy: 0.8743 - val_f1_score: 0.8690\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1841 - accuracy: 0.9309 - f1_score: 0.9299 - val_loss: 0.2935 - val_accuracy: 0.8671 - val_f1_score: 0.8588\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1425 - accuracy: 0.9460 - f1_score: 0.9451 - val_loss: 0.3325 - val_accuracy: 0.8770 - val_f1_score: 0.8770\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1180 - accuracy: 0.9557 - f1_score: 0.9552 - val_loss: 0.3739 - val_accuracy: 0.8508 - val_f1_score: 0.8358\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0842 - accuracy: 0.9674 - f1_score: 0.9672 - val_loss: 0.3766 - val_accuracy: 0.8852 - val_f1_score: 0.8847\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0745 - accuracy: 0.9741 - f1_score: 0.9739 - val_loss: 0.4585 - val_accuracy: 0.8626 - val_f1_score: 0.8645\n","Epoch 10/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0502 - accuracy: 0.9843 - f1_score: 0.9842 - val_loss: 0.5000 - val_accuracy: 0.8716 - val_f1_score: 0.8683\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8764 - f1_score: 0.8948\n","47/47 [==============================] - 0s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 19ms/step - loss: 0.4875 - accuracy: 0.7545 - f1_score: 0.7422 - val_loss: 0.3331 - val_accuracy: 0.8571 - val_f1_score: 0.8624\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3331 - accuracy: 0.8649 - f1_score: 0.8655 - val_loss: 0.2875 - val_accuracy: 0.8707 - val_f1_score: 0.8715\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2754 - accuracy: 0.8872 - f1_score: 0.8865 - val_loss: 0.2870 - val_accuracy: 0.8788 - val_f1_score: 0.8733\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2251 - accuracy: 0.9122 - f1_score: 0.9113 - val_loss: 0.3111 - val_accuracy: 0.8770 - val_f1_score: 0.8692\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1857 - accuracy: 0.9297 - f1_score: 0.9284 - val_loss: 0.3147 - val_accuracy: 0.8816 - val_f1_score: 0.8825\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1488 - accuracy: 0.9445 - f1_score: 0.9439 - val_loss: 0.3219 - val_accuracy: 0.8761 - val_f1_score: 0.8723\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1100 - accuracy: 0.9608 - f1_score: 0.9604 - val_loss: 0.3470 - val_accuracy: 0.8816 - val_f1_score: 0.8786\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0893 - accuracy: 0.9683 - f1_score: 0.9681 - val_loss: 0.4597 - val_accuracy: 0.8671 - val_f1_score: 0.8707\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8731 - f1_score: 0.8928\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 19ms/step - loss: 0.4700 - accuracy: 0.7817 - f1_score: 0.7770 - val_loss: 0.3449 - val_accuracy: 0.8508 - val_f1_score: 0.8518\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3212 - accuracy: 0.8724 - f1_score: 0.8716 - val_loss: 0.3325 - val_accuracy: 0.8463 - val_f1_score: 0.8540\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2623 - accuracy: 0.8960 - f1_score: 0.8956 - val_loss: 0.3303 - val_accuracy: 0.8653 - val_f1_score: 0.8535\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2184 - accuracy: 0.9159 - f1_score: 0.9153 - val_loss: 0.3207 - val_accuracy: 0.8725 - val_f1_score: 0.8653\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1732 - accuracy: 0.9321 - f1_score: 0.9318 - val_loss: 0.3392 - val_accuracy: 0.8807 - val_f1_score: 0.8738\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1331 - accuracy: 0.9527 - f1_score: 0.9523 - val_loss: 0.3860 - val_accuracy: 0.8716 - val_f1_score: 0.8716\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1069 - accuracy: 0.9629 - f1_score: 0.9627 - val_loss: 0.3991 - val_accuracy: 0.8689 - val_f1_score: 0.8690\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0893 - accuracy: 0.9692 - f1_score: 0.9691 - val_loss: 0.4120 - val_accuracy: 0.8752 - val_f1_score: 0.8715\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0605 - accuracy: 0.9783 - f1_score: 0.9782 - val_loss: 0.4540 - val_accuracy: 0.8734 - val_f1_score: 0.8689\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8481 - f1_score: 0.8700\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 17ms/step - loss: 0.4933 - accuracy: 0.7497 - f1_score: 0.7321 - val_loss: 0.3403 - val_accuracy: 0.8571 - val_f1_score: 0.8518\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3162 - accuracy: 0.8676 - f1_score: 0.8659 - val_loss: 0.3038 - val_accuracy: 0.8807 - val_f1_score: 0.8796\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2648 - accuracy: 0.8875 - f1_score: 0.8858 - val_loss: 0.2989 - val_accuracy: 0.8707 - val_f1_score: 0.8670\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2140 - accuracy: 0.9165 - f1_score: 0.9148 - val_loss: 0.2963 - val_accuracy: 0.8906 - val_f1_score: 0.8911\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1712 - accuracy: 0.9334 - f1_score: 0.9322 - val_loss: 0.3161 - val_accuracy: 0.8897 - val_f1_score: 0.8875\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1307 - accuracy: 0.9514 - f1_score: 0.9511 - val_loss: 0.3420 - val_accuracy: 0.8825 - val_f1_score: 0.8810\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1070 - accuracy: 0.9641 - f1_score: 0.9638 - val_loss: 0.3563 - val_accuracy: 0.8915 - val_f1_score: 0.8889\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0771 - accuracy: 0.9738 - f1_score: 0.9736 - val_loss: 0.4177 - val_accuracy: 0.8807 - val_f1_score: 0.8826\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0598 - accuracy: 0.9786 - f1_score: 0.9785 - val_loss: 0.4821 - val_accuracy: 0.8788 - val_f1_score: 0.8816\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8596 - f1_score: 0.8848\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 19ms/step - loss: 0.4830 - accuracy: 0.7615 - f1_score: 0.7598 - val_loss: 0.3566 - val_accuracy: 0.8418 - val_f1_score: 0.8428\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3090 - accuracy: 0.8712 - f1_score: 0.8699 - val_loss: 0.3227 - val_accuracy: 0.8626 - val_f1_score: 0.8621\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2598 - accuracy: 0.8978 - f1_score: 0.8965 - val_loss: 0.3728 - val_accuracy: 0.8363 - val_f1_score: 0.8510\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2146 - accuracy: 0.9168 - f1_score: 0.9160 - val_loss: 0.3429 - val_accuracy: 0.8635 - val_f1_score: 0.8663\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1787 - accuracy: 0.9285 - f1_score: 0.9279 - val_loss: 0.3282 - val_accuracy: 0.8743 - val_f1_score: 0.8738\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1304 - accuracy: 0.9502 - f1_score: 0.9498 - val_loss: 0.3516 - val_accuracy: 0.8797 - val_f1_score: 0.8774\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9677 - f1_score: 0.9675 - val_loss: 0.3746 - val_accuracy: 0.8761 - val_f1_score: 0.8740\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8629 - f1_score: 0.8886\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 20ms/step - loss: 0.4828 - accuracy: 0.7633 - f1_score: 0.7467 - val_loss: 0.3728 - val_accuracy: 0.8300 - val_f1_score: 0.8182\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3019 - accuracy: 0.8767 - f1_score: 0.8754 - val_loss: 0.3653 - val_accuracy: 0.8427 - val_f1_score: 0.8284\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2671 - accuracy: 0.8917 - f1_score: 0.8895 - val_loss: 0.3280 - val_accuracy: 0.8617 - val_f1_score: 0.8519\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2085 - accuracy: 0.9171 - f1_score: 0.9153 - val_loss: 0.3244 - val_accuracy: 0.8544 - val_f1_score: 0.8468\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1723 - accuracy: 0.9312 - f1_score: 0.9309 - val_loss: 0.3400 - val_accuracy: 0.8743 - val_f1_score: 0.8702\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1289 - accuracy: 0.9517 - f1_score: 0.9512 - val_loss: 0.3987 - val_accuracy: 0.8707 - val_f1_score: 0.8665\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0993 - accuracy: 0.9611 - f1_score: 0.9608 - val_loss: 0.4174 - val_accuracy: 0.8716 - val_f1_score: 0.8704\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0819 - accuracy: 0.9704 - f1_score: 0.9702 - val_loss: 0.4776 - val_accuracy: 0.8770 - val_f1_score: 0.8752\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0519 - accuracy: 0.9825 - f1_score: 0.9824 - val_loss: 0.5675 - val_accuracy: 0.8635 - val_f1_score: 0.8611\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8589 - f1_score: 0.8825\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 14ms/step - loss: 0.4757 - accuracy: 0.7759 - f1_score: 0.7729 - val_loss: 0.3554 - val_accuracy: 0.8490 - val_f1_score: 0.8472\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8613 - f1_score: 0.8613 - val_loss: 0.3250 - val_accuracy: 0.8617 - val_f1_score: 0.8579\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2534 - accuracy: 0.8935 - f1_score: 0.8925 - val_loss: 0.3173 - val_accuracy: 0.8680 - val_f1_score: 0.8680\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2087 - accuracy: 0.9153 - f1_score: 0.9150 - val_loss: 0.3394 - val_accuracy: 0.8662 - val_f1_score: 0.8693\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1633 - accuracy: 0.9331 - f1_score: 0.9327 - val_loss: 0.4003 - val_accuracy: 0.8716 - val_f1_score: 0.8702\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1311 - accuracy: 0.9502 - f1_score: 0.9501 - val_loss: 0.3447 - val_accuracy: 0.8761 - val_f1_score: 0.8696\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0978 - accuracy: 0.9644 - f1_score: 0.9643 - val_loss: 0.4588 - val_accuracy: 0.8834 - val_f1_score: 0.8815\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0645 - accuracy: 0.9774 - f1_score: 0.9774 - val_loss: 0.5116 - val_accuracy: 0.8743 - val_f1_score: 0.8777\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8629 - f1_score: 0.8865\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 13ms/step - loss: 0.4763 - accuracy: 0.7699 - f1_score: 0.7797 - val_loss: 0.3605 - val_accuracy: 0.8309 - val_f1_score: 0.8280\n","Epoch 2/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.3203 - accuracy: 0.8664 - f1_score: 0.8664 - val_loss: 0.3384 - val_accuracy: 0.8590 - val_f1_score: 0.8646\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2580 - accuracy: 0.8941 - f1_score: 0.8938 - val_loss: 0.3060 - val_accuracy: 0.8716 - val_f1_score: 0.8690\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2142 - accuracy: 0.9131 - f1_score: 0.9122 - val_loss: 0.3054 - val_accuracy: 0.8671 - val_f1_score: 0.8607\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1657 - accuracy: 0.9340 - f1_score: 0.9336 - val_loss: 0.3195 - val_accuracy: 0.8716 - val_f1_score: 0.8624\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9517 - f1_score: 0.9512 - val_loss: 0.3477 - val_accuracy: 0.8816 - val_f1_score: 0.8788\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0935 - accuracy: 0.9653 - f1_score: 0.9652 - val_loss: 0.3675 - val_accuracy: 0.8870 - val_f1_score: 0.8869\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0624 - accuracy: 0.9792 - f1_score: 0.9791 - val_loss: 0.4852 - val_accuracy: 0.8816 - val_f1_score: 0.8799\n","Epoch 9/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9849 - f1_score: 0.9849 - val_loss: 0.5845 - val_accuracy: 0.8544 - val_f1_score: 0.8456\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8663 - f1_score: 0.8883\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4637 - accuracy: 0.7829 - f1_score: 0.7814 - val_loss: 0.3792 - val_accuracy: 0.8309 - val_f1_score: 0.8227\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3121 - accuracy: 0.8688 - f1_score: 0.8678 - val_loss: 0.3318 - val_accuracy: 0.8526 - val_f1_score: 0.8472\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2688 - accuracy: 0.8926 - f1_score: 0.8919 - val_loss: 0.3107 - val_accuracy: 0.8626 - val_f1_score: 0.8555\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2168 - accuracy: 0.9104 - f1_score: 0.9099 - val_loss: 0.3700 - val_accuracy: 0.8490 - val_f1_score: 0.8355\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1796 - accuracy: 0.9270 - f1_score: 0.9266 - val_loss: 0.3119 - val_accuracy: 0.8797 - val_f1_score: 0.8842\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1349 - accuracy: 0.9475 - f1_score: 0.9471 - val_loss: 0.3765 - val_accuracy: 0.8698 - val_f1_score: 0.8788\n","Epoch 7/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1061 - accuracy: 0.9593 - f1_score: 0.9591 - val_loss: 0.4134 - val_accuracy: 0.8761 - val_f1_score: 0.8767\n","Epoch 8/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0923 - accuracy: 0.9644 - f1_score: 0.9643 - val_loss: 0.4459 - val_accuracy: 0.8816 - val_f1_score: 0.8825\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8481 - f1_score: 0.8683\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 12ms/step - loss: 0.4924 - accuracy: 0.7636 - f1_score: 0.7574 - val_loss: 0.3530 - val_accuracy: 0.8535 - val_f1_score: 0.8643\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3237 - accuracy: 0.8643 - f1_score: 0.8630 - val_loss: 0.3079 - val_accuracy: 0.8834 - val_f1_score: 0.8873\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2737 - accuracy: 0.8845 - f1_score: 0.8828 - val_loss: 0.2767 - val_accuracy: 0.8788 - val_f1_score: 0.8768\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2227 - accuracy: 0.9113 - f1_score: 0.9107 - val_loss: 0.2781 - val_accuracy: 0.8825 - val_f1_score: 0.8762\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1939 - accuracy: 0.9243 - f1_score: 0.9231 - val_loss: 0.2739 - val_accuracy: 0.8987 - val_f1_score: 0.9004\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1488 - accuracy: 0.9415 - f1_score: 0.9410 - val_loss: 0.2966 - val_accuracy: 0.8933 - val_f1_score: 0.8937\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1108 - accuracy: 0.9614 - f1_score: 0.9611 - val_loss: 0.3229 - val_accuracy: 0.8870 - val_f1_score: 0.8837\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0883 - accuracy: 0.9677 - f1_score: 0.9675 - val_loss: 0.4347 - val_accuracy: 0.8761 - val_f1_score: 0.8826\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.9701 - f1_score: 0.9700 - val_loss: 0.4100 - val_accuracy: 0.8897 - val_f1_score: 0.8893\n","Epoch 10/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0470 - accuracy: 0.9840 - f1_score: 0.9839 - val_loss: 0.4611 - val_accuracy: 0.8879 - val_f1_score: 0.8877\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8798 - f1_score: 0.9010\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4734 - accuracy: 0.7759 - f1_score: 0.7768 - val_loss: 0.3372 - val_accuracy: 0.8590 - val_f1_score: 0.8629\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8718 - f1_score: 0.8711 - val_loss: 0.2961 - val_accuracy: 0.8761 - val_f1_score: 0.8751\n","Epoch 3/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2576 - accuracy: 0.8941 - f1_score: 0.8931 - val_loss: 0.2853 - val_accuracy: 0.8788 - val_f1_score: 0.8806\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2148 - accuracy: 0.9113 - f1_score: 0.9111 - val_loss: 0.2915 - val_accuracy: 0.8807 - val_f1_score: 0.8852\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1768 - accuracy: 0.9291 - f1_score: 0.9285 - val_loss: 0.2828 - val_accuracy: 0.8852 - val_f1_score: 0.8859\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1431 - accuracy: 0.9448 - f1_score: 0.9448 - val_loss: 0.3689 - val_accuracy: 0.8834 - val_f1_score: 0.8837\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1116 - accuracy: 0.9578 - f1_score: 0.9577 - val_loss: 0.3301 - val_accuracy: 0.8888 - val_f1_score: 0.8856\n","Epoch 8/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0880 - accuracy: 0.9662 - f1_score: 0.9661 - val_loss: 0.4286 - val_accuracy: 0.8852 - val_f1_score: 0.8857\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0614 - accuracy: 0.9768 - f1_score: 0.9767 - val_loss: 0.5281 - val_accuracy: 0.8626 - val_f1_score: 0.8710\n","Epoch 10/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0469 - accuracy: 0.9843 - f1_score: 0.9843 - val_loss: 0.5211 - val_accuracy: 0.8834 - val_f1_score: 0.8865\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8717 - f1_score: 0.8936\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4915 - accuracy: 0.7536 - f1_score: 0.7372 - val_loss: 0.3456 - val_accuracy: 0.8535 - val_f1_score: 0.8466\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3183 - accuracy: 0.8634 - f1_score: 0.8626 - val_loss: 0.3289 - val_accuracy: 0.8626 - val_f1_score: 0.8710\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2600 - accuracy: 0.8869 - f1_score: 0.8865 - val_loss: 0.3170 - val_accuracy: 0.8698 - val_f1_score: 0.8756\n","Epoch 4/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.2190 - accuracy: 0.9116 - f1_score: 0.9108 - val_loss: 0.3342 - val_accuracy: 0.8779 - val_f1_score: 0.8825\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1764 - accuracy: 0.9276 - f1_score: 0.9269 - val_loss: 0.3567 - val_accuracy: 0.8626 - val_f1_score: 0.8504\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1503 - accuracy: 0.9412 - f1_score: 0.9406 - val_loss: 0.4084 - val_accuracy: 0.8517 - val_f1_score: 0.8320\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1265 - accuracy: 0.9530 - f1_score: 0.9526 - val_loss: 0.3890 - val_accuracy: 0.8779 - val_f1_score: 0.8756\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0904 - accuracy: 0.9680 - f1_score: 0.9678 - val_loss: 0.3798 - val_accuracy: 0.8752 - val_f1_score: 0.8713\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8771 - f1_score: 0.9012\n","47/47 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"id":"RFrGqQKVAMZE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697570645920,"user_tz":-330,"elapsed":37,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"919386a0-613b-4955-f8f7-3a48becf367e"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8615800142288208, 0.871708333492279, 0.869007408618927, 0.875084400177002, 0.8757596015930176, 0.8379473090171814, 0.8561782836914062, 0.8568534851074219, 0.8528021574020386, 0.869007408618927, 0.8534773588180542, 0.8838622570037842, 0.8791357278823853, 0.876434862613678, 0.8730587363243103, 0.8480756282806396, 0.8595543503761292, 0.8629304766654968, 0.8588791489601135, 0.8629304766654968, 0.8663065433502197, 0.8480756282806396, 0.8798109292984009, 0.871708333492279, 0.8771100640296936]\n","0.8650911569595336\n","0.011447710012997462\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"id":"KN9BQqh1GvjX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697570645920,"user_tz":-330,"elapsed":20,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"eed8c2c3-6529-4cac-d153-fdca6c7a59b6"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.3272606432437897, 0.2927084267139435, 0.3115938901901245, 0.29943612217903137, 0.2919321656227112, 0.35074880719184875, 0.3359774649143219, 0.3301825523376465, 0.33752480149269104, 0.32805660367012024, 0.32082632184028625, 0.3089374303817749, 0.2988288998603821, 0.30989548563957214, 0.31069648265838623, 0.3673247694969177, 0.3191393315792084, 0.3161396086215973, 0.325526624917984, 0.32601016759872437, 0.30442193150520325, 0.34123289585113525, 0.29198646545410156, 0.30916205048561096, 0.2939026951789856]\n","0.31797810554504397\n","0.018986146446826856\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"id":"w5sehaIzGvl8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697570645920,"user_tz":-330,"elapsed":17,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"9d7625fd-a7de-4e3f-94c5-e26dc7c2c6a5"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.882521390914917, 0.895489513874054, 0.8900226950645447, 0.8961257338523865, 0.8955731987953186, 0.8628571033477783, 0.8794566988945007, 0.8819599151611328, 0.8761363625526428, 0.8917409777641296, 0.8728763461112976, 0.9053905010223389, 0.9014858603477478, 0.8947671055793762, 0.8928163647651672, 0.8700172305107117, 0.8848282694816589, 0.8886449933052063, 0.8825181722640991, 0.886528730392456, 0.8882617950439453, 0.8683440089225769, 0.9010010957717896, 0.8936169147491455, 0.9011942744255066]\n","0.8873670101165771\n","0.010971086484176256\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"id":"HrOFFmqEGvn-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697570645920,"user_tz":-330,"elapsed":15,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"a155a930-c596-4483-e4cc-0f6c0ffc9d64"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.7243563024156432, 0.7306626760151943, 0.7352602553329761, 0.7443144869334913, 0.7497872194823397, 0.6739500439712437, 0.7078270250935638, 0.7031844110609773, 0.702414535529159, 0.7294394890083401, 0.7181321058504, 0.7563176908687206, 0.7464901992558246, 0.7567491911438577, 0.7460196938880121, 0.7000081791906348, 0.7070274437971508, 0.7113581805741422, 0.7108380918470052, 0.717280815358309, 0.7278532817737687, 0.7063437170625493, 0.751010773359198, 0.7362555335563378, 0.7388684253425957]\n","0.7252699907084573\n","0.020703031633658733\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"t5Iak4xKGvqM","executionInfo":{"status":"ok","timestamp":1697570645920,"user_tz":-330,"elapsed":14,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# LSTM CNN LSTM nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=5, strides=2)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        #cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))  # cnn_emotions returns length 3072, ie cnn_emotions.shape[1] = 3072\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","        lstm_intensity = LSTM(32)(Reshape((1, 8))(input_intensity))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"id":"5_zVc1VR1a-h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697571160878,"user_tz":-330,"elapsed":514971,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"b2b3bfe3-9607-4b72-c771-776b06b73536"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 7s 16ms/step - loss: 0.4968 - accuracy: 0.7491 - f1_score: 0.7442 - val_loss: 0.3554 - val_accuracy: 0.8490 - val_f1_score: 0.8529\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3135 - accuracy: 0.8667 - f1_score: 0.8663 - val_loss: 0.3384 - val_accuracy: 0.8599 - val_f1_score: 0.8632\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2616 - accuracy: 0.8951 - f1_score: 0.8952 - val_loss: 0.3244 - val_accuracy: 0.8562 - val_f1_score: 0.8566\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2113 - accuracy: 0.9189 - f1_score: 0.9187 - val_loss: 0.3253 - val_accuracy: 0.8617 - val_f1_score: 0.8579\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1695 - accuracy: 0.9300 - f1_score: 0.9294 - val_loss: 0.4053 - val_accuracy: 0.8599 - val_f1_score: 0.8630\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1331 - accuracy: 0.9563 - f1_score: 0.9561 - val_loss: 0.3663 - val_accuracy: 0.8671 - val_f1_score: 0.8617\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9653 - f1_score: 0.9651 - val_loss: 0.4541 - val_accuracy: 0.8644 - val_f1_score: 0.8603\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0814 - accuracy: 0.9707 - f1_score: 0.9707 - val_loss: 0.5303 - val_accuracy: 0.8653 - val_f1_score: 0.8582\n","47/47 [==============================] - 0s 6ms/step - loss: 0.2827 - accuracy: 0.8758 - f1_score: 0.8976\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4639 - accuracy: 0.7820 - f1_score: 0.7867 - val_loss: 0.3492 - val_accuracy: 0.8499 - val_f1_score: 0.8502\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3091 - accuracy: 0.8667 - f1_score: 0.8668 - val_loss: 0.3449 - val_accuracy: 0.8562 - val_f1_score: 0.8452\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2612 - accuracy: 0.8929 - f1_score: 0.8925 - val_loss: 0.3423 - val_accuracy: 0.8653 - val_f1_score: 0.8538\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2196 - accuracy: 0.9168 - f1_score: 0.9167 - val_loss: 0.3067 - val_accuracy: 0.8743 - val_f1_score: 0.8705\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1817 - accuracy: 0.9300 - f1_score: 0.9299 - val_loss: 0.3601 - val_accuracy: 0.8779 - val_f1_score: 0.8737\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1460 - accuracy: 0.9475 - f1_score: 0.9472 - val_loss: 0.3517 - val_accuracy: 0.8734 - val_f1_score: 0.8720\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1147 - accuracy: 0.9563 - f1_score: 0.9561 - val_loss: 0.3478 - val_accuracy: 0.8743 - val_f1_score: 0.8747\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0784 - accuracy: 0.9738 - f1_score: 0.9737 - val_loss: 0.4746 - val_accuracy: 0.8779 - val_f1_score: 0.8718\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0597 - accuracy: 0.9789 - f1_score: 0.9789 - val_loss: 0.6003 - val_accuracy: 0.8743 - val_f1_score: 0.8670\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8663 - f1_score: 0.8869\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 25ms/step - loss: 0.4876 - accuracy: 0.7711 - f1_score: 0.7703 - val_loss: 0.3373 - val_accuracy: 0.8590 - val_f1_score: 0.8587\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3128 - accuracy: 0.8685 - f1_score: 0.8671 - val_loss: 0.3146 - val_accuracy: 0.8626 - val_f1_score: 0.8603\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2589 - accuracy: 0.8978 - f1_score: 0.8970 - val_loss: 0.3207 - val_accuracy: 0.8571 - val_f1_score: 0.8445\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2091 - accuracy: 0.9144 - f1_score: 0.9134 - val_loss: 0.3126 - val_accuracy: 0.8680 - val_f1_score: 0.8617\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1709 - accuracy: 0.9364 - f1_score: 0.9359 - val_loss: 0.3335 - val_accuracy: 0.8671 - val_f1_score: 0.8571\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1318 - accuracy: 0.9508 - f1_score: 0.9503 - val_loss: 0.3560 - val_accuracy: 0.8797 - val_f1_score: 0.8772\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1016 - accuracy: 0.9665 - f1_score: 0.9664 - val_loss: 0.4563 - val_accuracy: 0.8716 - val_f1_score: 0.8632\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0662 - accuracy: 0.9756 - f1_score: 0.9755 - val_loss: 0.4535 - val_accuracy: 0.8680 - val_f1_score: 0.8636\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0587 - accuracy: 0.9822 - f1_score: 0.9822 - val_loss: 0.5353 - val_accuracy: 0.8743 - val_f1_score: 0.8670\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8569 - f1_score: 0.8766\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.4901 - accuracy: 0.7578 - f1_score: 0.7527 - val_loss: 0.3511 - val_accuracy: 0.8481 - val_f1_score: 0.8467\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3120 - accuracy: 0.8658 - f1_score: 0.8649 - val_loss: 0.3280 - val_accuracy: 0.8544 - val_f1_score: 0.8453\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2548 - accuracy: 0.9002 - f1_score: 0.8988 - val_loss: 0.3592 - val_accuracy: 0.8608 - val_f1_score: 0.8496\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2161 - accuracy: 0.9116 - f1_score: 0.9111 - val_loss: 0.3009 - val_accuracy: 0.8752 - val_f1_score: 0.8713\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1748 - accuracy: 0.9334 - f1_score: 0.9329 - val_loss: 0.3406 - val_accuracy: 0.8725 - val_f1_score: 0.8758\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1395 - accuracy: 0.9466 - f1_score: 0.9462 - val_loss: 0.3805 - val_accuracy: 0.8725 - val_f1_score: 0.8738\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9635 - f1_score: 0.9634 - val_loss: 0.4453 - val_accuracy: 0.8707 - val_f1_score: 0.8660\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0747 - accuracy: 0.9698 - f1_score: 0.9698 - val_loss: 0.4589 - val_accuracy: 0.8707 - val_f1_score: 0.8711\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0607 - accuracy: 0.9756 - f1_score: 0.9755 - val_loss: 0.5498 - val_accuracy: 0.8734 - val_f1_score: 0.8739\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8643 - f1_score: 0.8837\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4747 - accuracy: 0.7729 - f1_score: 0.7664 - val_loss: 0.3437 - val_accuracy: 0.8409 - val_f1_score: 0.8388\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3101 - accuracy: 0.8706 - f1_score: 0.8712 - val_loss: 0.3281 - val_accuracy: 0.8571 - val_f1_score: 0.8597\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2582 - accuracy: 0.8914 - f1_score: 0.8915 - val_loss: 0.3017 - val_accuracy: 0.8644 - val_f1_score: 0.8691\n","Epoch 4/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.2115 - accuracy: 0.9186 - f1_score: 0.9186 - val_loss: 0.3355 - val_accuracy: 0.8680 - val_f1_score: 0.8708\n","Epoch 5/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1687 - accuracy: 0.9315 - f1_score: 0.9314 - val_loss: 0.3580 - val_accuracy: 0.8626 - val_f1_score: 0.8707\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1301 - accuracy: 0.9560 - f1_score: 0.9558 - val_loss: 0.3766 - val_accuracy: 0.8752 - val_f1_score: 0.8736\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1002 - accuracy: 0.9644 - f1_score: 0.9643 - val_loss: 0.4733 - val_accuracy: 0.8635 - val_f1_score: 0.8686\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0866 - accuracy: 0.9717 - f1_score: 0.9716 - val_loss: 0.4530 - val_accuracy: 0.8689 - val_f1_score: 0.8656\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8778 - f1_score: 0.8993\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4949 - accuracy: 0.7518 - f1_score: 0.7501 - val_loss: 0.3577 - val_accuracy: 0.8363 - val_f1_score: 0.8391\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3112 - accuracy: 0.8703 - f1_score: 0.8698 - val_loss: 0.3390 - val_accuracy: 0.8499 - val_f1_score: 0.8539\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2537 - accuracy: 0.8966 - f1_score: 0.8954 - val_loss: 0.3501 - val_accuracy: 0.8617 - val_f1_score: 0.8642\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2074 - accuracy: 0.9207 - f1_score: 0.9205 - val_loss: 0.3079 - val_accuracy: 0.8707 - val_f1_score: 0.8731\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1621 - accuracy: 0.9388 - f1_score: 0.9383 - val_loss: 0.4185 - val_accuracy: 0.8508 - val_f1_score: 0.8610\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1210 - accuracy: 0.9545 - f1_score: 0.9543 - val_loss: 0.4389 - val_accuracy: 0.8544 - val_f1_score: 0.8655\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0908 - accuracy: 0.9686 - f1_score: 0.9684 - val_loss: 0.4669 - val_accuracy: 0.8617 - val_f1_score: 0.8605\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0732 - accuracy: 0.9729 - f1_score: 0.9729 - val_loss: 0.5132 - val_accuracy: 0.8608 - val_f1_score: 0.8574\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0565 - accuracy: 0.9807 - f1_score: 0.9807 - val_loss: 0.5270 - val_accuracy: 0.8562 - val_f1_score: 0.8640\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8643 - f1_score: 0.8900\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 16ms/step - loss: 0.4959 - accuracy: 0.7545 - f1_score: 0.7669 - val_loss: 0.3858 - val_accuracy: 0.8309 - val_f1_score: 0.8387\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3104 - accuracy: 0.8658 - f1_score: 0.8643 - val_loss: 0.3311 - val_accuracy: 0.8580 - val_f1_score: 0.8587\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2534 - accuracy: 0.8938 - f1_score: 0.8926 - val_loss: 0.3324 - val_accuracy: 0.8544 - val_f1_score: 0.8511\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2061 - accuracy: 0.9174 - f1_score: 0.9169 - val_loss: 0.3808 - val_accuracy: 0.8599 - val_f1_score: 0.8644\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1642 - accuracy: 0.9367 - f1_score: 0.9364 - val_loss: 0.3537 - val_accuracy: 0.8617 - val_f1_score: 0.8487\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1257 - accuracy: 0.9539 - f1_score: 0.9535 - val_loss: 0.4266 - val_accuracy: 0.8671 - val_f1_score: 0.8725\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0955 - accuracy: 0.9644 - f1_score: 0.9643 - val_loss: 0.4397 - val_accuracy: 0.8580 - val_f1_score: 0.8650\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8542 - f1_score: 0.8807\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4847 - accuracy: 0.7518 - f1_score: 0.7513 - val_loss: 0.3875 - val_accuracy: 0.8336 - val_f1_score: 0.8425\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3102 - accuracy: 0.8727 - f1_score: 0.8709 - val_loss: 0.3411 - val_accuracy: 0.8562 - val_f1_score: 0.8558\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2559 - accuracy: 0.8975 - f1_score: 0.8960 - val_loss: 0.3413 - val_accuracy: 0.8553 - val_f1_score: 0.8482\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2024 - accuracy: 0.9225 - f1_score: 0.9219 - val_loss: 0.3273 - val_accuracy: 0.8626 - val_f1_score: 0.8643\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1672 - accuracy: 0.9409 - f1_score: 0.9403 - val_loss: 0.3343 - val_accuracy: 0.8553 - val_f1_score: 0.8513\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1333 - accuracy: 0.9563 - f1_score: 0.9560 - val_loss: 0.4697 - val_accuracy: 0.8499 - val_f1_score: 0.8395\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1164 - accuracy: 0.9590 - f1_score: 0.9587 - val_loss: 0.4030 - val_accuracy: 0.8770 - val_f1_score: 0.8759\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0849 - accuracy: 0.9683 - f1_score: 0.9681 - val_loss: 0.5068 - val_accuracy: 0.8599 - val_f1_score: 0.8536\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9753 - f1_score: 0.9751 - val_loss: 0.5074 - val_accuracy: 0.8671 - val_f1_score: 0.8686\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8575 - f1_score: 0.8849\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.5011 - accuracy: 0.7461 - f1_score: 0.7420 - val_loss: 0.3516 - val_accuracy: 0.8427 - val_f1_score: 0.8377\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3193 - accuracy: 0.8664 - f1_score: 0.8651 - val_loss: 0.3472 - val_accuracy: 0.8445 - val_f1_score: 0.8287\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2523 - accuracy: 0.8908 - f1_score: 0.8893 - val_loss: 0.3274 - val_accuracy: 0.8653 - val_f1_score: 0.8543\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2168 - accuracy: 0.9083 - f1_score: 0.9074 - val_loss: 0.3280 - val_accuracy: 0.8825 - val_f1_score: 0.8755\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1742 - accuracy: 0.9318 - f1_score: 0.9306 - val_loss: 0.3143 - val_accuracy: 0.8770 - val_f1_score: 0.8796\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1423 - accuracy: 0.9463 - f1_score: 0.9460 - val_loss: 0.3484 - val_accuracy: 0.8861 - val_f1_score: 0.8811\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9653 - f1_score: 0.9651 - val_loss: 0.4335 - val_accuracy: 0.8743 - val_f1_score: 0.8771\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0897 - accuracy: 0.9641 - f1_score: 0.9640 - val_loss: 0.5813 - val_accuracy: 0.8626 - val_f1_score: 0.8489\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0710 - accuracy: 0.9735 - f1_score: 0.9733 - val_loss: 0.4996 - val_accuracy: 0.8879 - val_f1_score: 0.8832\n","Epoch 10/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0515 - accuracy: 0.9813 - f1_score: 0.9813 - val_loss: 0.5056 - val_accuracy: 0.8906 - val_f1_score: 0.8885\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8697 - f1_score: 0.8970\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 17ms/step - loss: 0.4849 - accuracy: 0.7590 - f1_score: 0.7509 - val_loss: 0.3690 - val_accuracy: 0.8418 - val_f1_score: 0.8495\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3112 - accuracy: 0.8670 - f1_score: 0.8662 - val_loss: 0.3165 - val_accuracy: 0.8707 - val_f1_score: 0.8642\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2565 - accuracy: 0.8941 - f1_score: 0.8933 - val_loss: 0.3054 - val_accuracy: 0.8843 - val_f1_score: 0.8845\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2152 - accuracy: 0.9110 - f1_score: 0.9106 - val_loss: 0.3571 - val_accuracy: 0.8508 - val_f1_score: 0.8355\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1747 - accuracy: 0.9300 - f1_score: 0.9299 - val_loss: 0.3083 - val_accuracy: 0.8888 - val_f1_score: 0.8845\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1285 - accuracy: 0.9517 - f1_score: 0.9516 - val_loss: 0.4065 - val_accuracy: 0.8761 - val_f1_score: 0.8686\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.9608 - f1_score: 0.9607 - val_loss: 0.4069 - val_accuracy: 0.8743 - val_f1_score: 0.8740\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0756 - accuracy: 0.9720 - f1_score: 0.9719 - val_loss: 0.4493 - val_accuracy: 0.8743 - val_f1_score: 0.8697\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8717 - f1_score: 0.8967\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4996 - accuracy: 0.7512 - f1_score: 0.7346 - val_loss: 0.3452 - val_accuracy: 0.8562 - val_f1_score: 0.8558\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3286 - accuracy: 0.8613 - f1_score: 0.8621 - val_loss: 0.2969 - val_accuracy: 0.8779 - val_f1_score: 0.8760\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2788 - accuracy: 0.8872 - f1_score: 0.8871 - val_loss: 0.2836 - val_accuracy: 0.8852 - val_f1_score: 0.8821\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2323 - accuracy: 0.9113 - f1_score: 0.9111 - val_loss: 0.2979 - val_accuracy: 0.8788 - val_f1_score: 0.8816\n","Epoch 5/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1950 - accuracy: 0.9273 - f1_score: 0.9275 - val_loss: 0.2868 - val_accuracy: 0.8852 - val_f1_score: 0.8778\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1425 - accuracy: 0.9457 - f1_score: 0.9455 - val_loss: 0.3617 - val_accuracy: 0.8861 - val_f1_score: 0.8800\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1070 - accuracy: 0.9623 - f1_score: 0.9622 - val_loss: 0.3697 - val_accuracy: 0.8807 - val_f1_score: 0.8776\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0915 - accuracy: 0.9698 - f1_score: 0.9698 - val_loss: 0.3882 - val_accuracy: 0.8807 - val_f1_score: 0.8844\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8717 - f1_score: 0.8939\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 23ms/step - loss: 0.4925 - accuracy: 0.7569 - f1_score: 0.7491 - val_loss: 0.3717 - val_accuracy: 0.8345 - val_f1_score: 0.8285\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3152 - accuracy: 0.8730 - f1_score: 0.8723 - val_loss: 0.3414 - val_accuracy: 0.8553 - val_f1_score: 0.8623\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2698 - accuracy: 0.8872 - f1_score: 0.8871 - val_loss: 0.3311 - val_accuracy: 0.8535 - val_f1_score: 0.8448\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2271 - accuracy: 0.9035 - f1_score: 0.9026 - val_loss: 0.3641 - val_accuracy: 0.8427 - val_f1_score: 0.8217\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1840 - accuracy: 0.9246 - f1_score: 0.9240 - val_loss: 0.3434 - val_accuracy: 0.8743 - val_f1_score: 0.8728\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1543 - accuracy: 0.9385 - f1_score: 0.9382 - val_loss: 0.3326 - val_accuracy: 0.8671 - val_f1_score: 0.8612\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1247 - accuracy: 0.9484 - f1_score: 0.9478 - val_loss: 0.4578 - val_accuracy: 0.8698 - val_f1_score: 0.8752\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9620 - f1_score: 0.9619 - val_loss: 0.3967 - val_accuracy: 0.8770 - val_f1_score: 0.8761\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8562 - f1_score: 0.8772\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.5092 - accuracy: 0.7440 - f1_score: 0.7349 - val_loss: 0.3732 - val_accuracy: 0.8363 - val_f1_score: 0.8374\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3225 - accuracy: 0.8643 - f1_score: 0.8651 - val_loss: 0.3370 - val_accuracy: 0.8481 - val_f1_score: 0.8462\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2699 - accuracy: 0.8908 - f1_score: 0.8902 - val_loss: 0.3281 - val_accuracy: 0.8580 - val_f1_score: 0.8561\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2211 - accuracy: 0.9147 - f1_score: 0.9143 - val_loss: 0.3597 - val_accuracy: 0.8580 - val_f1_score: 0.8483\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1792 - accuracy: 0.9294 - f1_score: 0.9287 - val_loss: 0.3780 - val_accuracy: 0.8580 - val_f1_score: 0.8629\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1465 - accuracy: 0.9442 - f1_score: 0.9439 - val_loss: 0.3814 - val_accuracy: 0.8734 - val_f1_score: 0.8677\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1078 - accuracy: 0.9605 - f1_score: 0.9603 - val_loss: 0.5069 - val_accuracy: 0.8517 - val_f1_score: 0.8383\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1016 - accuracy: 0.9635 - f1_score: 0.9634 - val_loss: 0.4395 - val_accuracy: 0.8770 - val_f1_score: 0.8738\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8744 - f1_score: 0.8964\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.4883 - accuracy: 0.7603 - f1_score: 0.7561 - val_loss: 0.3823 - val_accuracy: 0.8183 - val_f1_score: 0.8027\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3172 - accuracy: 0.8703 - f1_score: 0.8695 - val_loss: 0.3279 - val_accuracy: 0.8635 - val_f1_score: 0.8585\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2759 - accuracy: 0.8920 - f1_score: 0.8916 - val_loss: 0.3063 - val_accuracy: 0.8725 - val_f1_score: 0.8753\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2325 - accuracy: 0.9047 - f1_score: 0.9040 - val_loss: 0.2899 - val_accuracy: 0.8797 - val_f1_score: 0.8801\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1899 - accuracy: 0.9300 - f1_score: 0.9295 - val_loss: 0.3048 - val_accuracy: 0.8807 - val_f1_score: 0.8802\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1491 - accuracy: 0.9442 - f1_score: 0.9437 - val_loss: 0.3339 - val_accuracy: 0.8626 - val_f1_score: 0.8550\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1150 - accuracy: 0.9563 - f1_score: 0.9558 - val_loss: 0.3802 - val_accuracy: 0.8761 - val_f1_score: 0.8751\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0851 - accuracy: 0.9701 - f1_score: 0.9700 - val_loss: 0.4004 - val_accuracy: 0.8797 - val_f1_score: 0.8796\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0630 - accuracy: 0.9759 - f1_score: 0.9758 - val_loss: 0.4965 - val_accuracy: 0.8734 - val_f1_score: 0.8699\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.8731 - f1_score: 0.8961\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 28ms/step - loss: 0.5086 - accuracy: 0.7542 - f1_score: 0.7696 - val_loss: 0.3416 - val_accuracy: 0.8617 - val_f1_score: 0.8571\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3301 - accuracy: 0.8604 - f1_score: 0.8591 - val_loss: 0.3127 - val_accuracy: 0.8788 - val_f1_score: 0.8857\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2713 - accuracy: 0.8884 - f1_score: 0.8881 - val_loss: 0.2951 - val_accuracy: 0.8788 - val_f1_score: 0.8780\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2317 - accuracy: 0.9065 - f1_score: 0.9063 - val_loss: 0.2957 - val_accuracy: 0.8807 - val_f1_score: 0.8782\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1907 - accuracy: 0.9306 - f1_score: 0.9296 - val_loss: 0.3242 - val_accuracy: 0.8788 - val_f1_score: 0.8795\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1528 - accuracy: 0.9463 - f1_score: 0.9457 - val_loss: 0.4103 - val_accuracy: 0.8626 - val_f1_score: 0.8501\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1230 - accuracy: 0.9527 - f1_score: 0.9521 - val_loss: 0.3642 - val_accuracy: 0.8807 - val_f1_score: 0.8804\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0949 - accuracy: 0.9629 - f1_score: 0.9626 - val_loss: 0.4716 - val_accuracy: 0.8761 - val_f1_score: 0.8726\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8798 - f1_score: 0.9008\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4964 - accuracy: 0.7548 - f1_score: 0.7420 - val_loss: 0.3555 - val_accuracy: 0.8553 - val_f1_score: 0.8584\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3226 - accuracy: 0.8646 - f1_score: 0.8626 - val_loss: 0.3187 - val_accuracy: 0.8653 - val_f1_score: 0.8566\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2620 - accuracy: 0.8920 - f1_score: 0.8905 - val_loss: 0.2986 - val_accuracy: 0.8680 - val_f1_score: 0.8612\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2136 - accuracy: 0.9159 - f1_score: 0.9146 - val_loss: 0.3447 - val_accuracy: 0.8834 - val_f1_score: 0.8807\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1758 - accuracy: 0.9328 - f1_score: 0.9321 - val_loss: 0.3468 - val_accuracy: 0.8590 - val_f1_score: 0.8440\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1326 - accuracy: 0.9548 - f1_score: 0.9543 - val_loss: 0.3442 - val_accuracy: 0.8788 - val_f1_score: 0.8784\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1045 - accuracy: 0.9596 - f1_score: 0.9592 - val_loss: 0.3860 - val_accuracy: 0.8834 - val_f1_score: 0.8773\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0992 - accuracy: 0.9638 - f1_score: 0.9635 - val_loss: 0.3896 - val_accuracy: 0.8761 - val_f1_score: 0.8787\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8420 - f1_score: 0.8646\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 17ms/step - loss: 0.4859 - accuracy: 0.7584 - f1_score: 0.7672 - val_loss: 0.3393 - val_accuracy: 0.8608 - val_f1_score: 0.8661\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3074 - accuracy: 0.8697 - f1_score: 0.8689 - val_loss: 0.2991 - val_accuracy: 0.8788 - val_f1_score: 0.8808\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2642 - accuracy: 0.8884 - f1_score: 0.8869 - val_loss: 0.2891 - val_accuracy: 0.8825 - val_f1_score: 0.8848\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2147 - accuracy: 0.9113 - f1_score: 0.9098 - val_loss: 0.3063 - val_accuracy: 0.8933 - val_f1_score: 0.8961\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1667 - accuracy: 0.9340 - f1_score: 0.9333 - val_loss: 0.3040 - val_accuracy: 0.8897 - val_f1_score: 0.8883\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1276 - accuracy: 0.9536 - f1_score: 0.9532 - val_loss: 0.3331 - val_accuracy: 0.8915 - val_f1_score: 0.8899\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1006 - accuracy: 0.9644 - f1_score: 0.9640 - val_loss: 0.4254 - val_accuracy: 0.8897 - val_f1_score: 0.8926\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0858 - accuracy: 0.9689 - f1_score: 0.9686 - val_loss: 0.4175 - val_accuracy: 0.8861 - val_f1_score: 0.8902\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8650 - f1_score: 0.8907\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4860 - accuracy: 0.7639 - f1_score: 0.7627 - val_loss: 0.3741 - val_accuracy: 0.8318 - val_f1_score: 0.8309\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3132 - accuracy: 0.8703 - f1_score: 0.8694 - val_loss: 0.3501 - val_accuracy: 0.8463 - val_f1_score: 0.8511\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2478 - accuracy: 0.8999 - f1_score: 0.8986 - val_loss: 0.3334 - val_accuracy: 0.8644 - val_f1_score: 0.8606\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2121 - accuracy: 0.9174 - f1_score: 0.9165 - val_loss: 0.3488 - val_accuracy: 0.8734 - val_f1_score: 0.8662\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1714 - accuracy: 0.9328 - f1_score: 0.9324 - val_loss: 0.3469 - val_accuracy: 0.8716 - val_f1_score: 0.8658\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1329 - accuracy: 0.9548 - f1_score: 0.9542 - val_loss: 0.3695 - val_accuracy: 0.8807 - val_f1_score: 0.8830\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.9680 - f1_score: 0.9678 - val_loss: 0.4256 - val_accuracy: 0.8653 - val_f1_score: 0.8588\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0704 - accuracy: 0.9756 - f1_score: 0.9754 - val_loss: 0.5392 - val_accuracy: 0.8752 - val_f1_score: 0.8708\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8589 - f1_score: 0.8823\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4679 - accuracy: 0.7762 - f1_score: 0.7796 - val_loss: 0.3951 - val_accuracy: 0.8237 - val_f1_score: 0.8235\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3062 - accuracy: 0.8742 - f1_score: 0.8724 - val_loss: 0.3611 - val_accuracy: 0.8517 - val_f1_score: 0.8447\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2576 - accuracy: 0.8920 - f1_score: 0.8906 - val_loss: 0.3692 - val_accuracy: 0.8300 - val_f1_score: 0.8038\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2133 - accuracy: 0.9177 - f1_score: 0.9162 - val_loss: 0.3359 - val_accuracy: 0.8608 - val_f1_score: 0.8553\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1736 - accuracy: 0.9391 - f1_score: 0.9383 - val_loss: 0.4056 - val_accuracy: 0.8599 - val_f1_score: 0.8520\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1297 - accuracy: 0.9524 - f1_score: 0.9517 - val_loss: 0.4080 - val_accuracy: 0.8617 - val_f1_score: 0.8558\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0988 - accuracy: 0.9662 - f1_score: 0.9659 - val_loss: 0.4342 - val_accuracy: 0.8689 - val_f1_score: 0.8669\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0813 - accuracy: 0.9723 - f1_score: 0.9721 - val_loss: 0.4809 - val_accuracy: 0.8662 - val_f1_score: 0.8637\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0765 - accuracy: 0.9717 - f1_score: 0.9714 - val_loss: 0.4353 - val_accuracy: 0.8716 - val_f1_score: 0.8635\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3444 - accuracy: 0.8569 - f1_score: 0.8810\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 16ms/step - loss: 0.4694 - accuracy: 0.7666 - f1_score: 0.7695 - val_loss: 0.3621 - val_accuracy: 0.8490 - val_f1_score: 0.8411\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3091 - accuracy: 0.8694 - f1_score: 0.8683 - val_loss: 0.3227 - val_accuracy: 0.8644 - val_f1_score: 0.8661\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2522 - accuracy: 0.8914 - f1_score: 0.8910 - val_loss: 0.3206 - val_accuracy: 0.8707 - val_f1_score: 0.8722\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.9171 - f1_score: 0.9158 - val_loss: 0.3207 - val_accuracy: 0.8671 - val_f1_score: 0.8612\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1610 - accuracy: 0.9379 - f1_score: 0.9373 - val_loss: 0.3245 - val_accuracy: 0.8752 - val_f1_score: 0.8759\n","Epoch 6/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1241 - accuracy: 0.9578 - f1_score: 0.9575 - val_loss: 0.3879 - val_accuracy: 0.8816 - val_f1_score: 0.8821\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0953 - accuracy: 0.9632 - f1_score: 0.9630 - val_loss: 0.4148 - val_accuracy: 0.8779 - val_f1_score: 0.8756\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0690 - accuracy: 0.9750 - f1_score: 0.9748 - val_loss: 0.5241 - val_accuracy: 0.8644 - val_f1_score: 0.8585\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8589 - f1_score: 0.8836\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4912 - accuracy: 0.7584 - f1_score: 0.7395 - val_loss: 0.3619 - val_accuracy: 0.8409 - val_f1_score: 0.8491\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3191 - accuracy: 0.8688 - f1_score: 0.8701 - val_loss: 0.3314 - val_accuracy: 0.8508 - val_f1_score: 0.8421\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2555 - accuracy: 0.8978 - f1_score: 0.8972 - val_loss: 0.3281 - val_accuracy: 0.8635 - val_f1_score: 0.8626\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2140 - accuracy: 0.9125 - f1_score: 0.9120 - val_loss: 0.3204 - val_accuracy: 0.8671 - val_f1_score: 0.8622\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1726 - accuracy: 0.9346 - f1_score: 0.9339 - val_loss: 0.3815 - val_accuracy: 0.8535 - val_f1_score: 0.8406\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1310 - accuracy: 0.9514 - f1_score: 0.9512 - val_loss: 0.3866 - val_accuracy: 0.8698 - val_f1_score: 0.8703\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0995 - accuracy: 0.9611 - f1_score: 0.9611 - val_loss: 0.4790 - val_accuracy: 0.8644 - val_f1_score: 0.8529\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0731 - accuracy: 0.9744 - f1_score: 0.9743 - val_loss: 0.4962 - val_accuracy: 0.8680 - val_f1_score: 0.8620\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9846 - f1_score: 0.9846 - val_loss: 0.5920 - val_accuracy: 0.8770 - val_f1_score: 0.8768\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.8663 - f1_score: 0.8881\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 20ms/step - loss: 0.4785 - accuracy: 0.7636 - f1_score: 0.7607 - val_loss: 0.3633 - val_accuracy: 0.8327 - val_f1_score: 0.8276\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3084 - accuracy: 0.8634 - f1_score: 0.8614 - val_loss: 0.3282 - val_accuracy: 0.8617 - val_f1_score: 0.8673\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2497 - accuracy: 0.8929 - f1_score: 0.8924 - val_loss: 0.2957 - val_accuracy: 0.8725 - val_f1_score: 0.8726\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2029 - accuracy: 0.9204 - f1_score: 0.9198 - val_loss: 0.3442 - val_accuracy: 0.8716 - val_f1_score: 0.8754\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1699 - accuracy: 0.9318 - f1_score: 0.9316 - val_loss: 0.3193 - val_accuracy: 0.8788 - val_f1_score: 0.8784\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1339 - accuracy: 0.9484 - f1_score: 0.9481 - val_loss: 0.3230 - val_accuracy: 0.8788 - val_f1_score: 0.8748\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0975 - accuracy: 0.9638 - f1_score: 0.9637 - val_loss: 0.4045 - val_accuracy: 0.8671 - val_f1_score: 0.8682\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0704 - accuracy: 0.9735 - f1_score: 0.9734 - val_loss: 0.4030 - val_accuracy: 0.8653 - val_f1_score: 0.8617\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8643 - f1_score: 0.8864\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.5017 - accuracy: 0.7551 - f1_score: 0.7511 - val_loss: 0.3425 - val_accuracy: 0.8599 - val_f1_score: 0.8653\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3286 - accuracy: 0.8649 - f1_score: 0.8636 - val_loss: 0.2910 - val_accuracy: 0.8752 - val_f1_score: 0.8732\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2690 - accuracy: 0.8827 - f1_score: 0.8803 - val_loss: 0.2882 - val_accuracy: 0.8888 - val_f1_score: 0.8881\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2321 - accuracy: 0.9044 - f1_score: 0.9030 - val_loss: 0.2743 - val_accuracy: 0.8843 - val_f1_score: 0.8828\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1809 - accuracy: 0.9273 - f1_score: 0.9260 - val_loss: 0.3091 - val_accuracy: 0.8797 - val_f1_score: 0.8850\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1532 - accuracy: 0.9400 - f1_score: 0.9395 - val_loss: 0.3221 - val_accuracy: 0.8906 - val_f1_score: 0.8868\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1098 - accuracy: 0.9599 - f1_score: 0.9594 - val_loss: 0.3569 - val_accuracy: 0.8924 - val_f1_score: 0.8883\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0939 - accuracy: 0.9653 - f1_score: 0.9651 - val_loss: 0.3723 - val_accuracy: 0.8915 - val_f1_score: 0.8934\n","Epoch 9/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0711 - accuracy: 0.9750 - f1_score: 0.9748 - val_loss: 0.6345 - val_accuracy: 0.8698 - val_f1_score: 0.8800\n","47/47 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8724 - f1_score: 0.8927\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4604 - accuracy: 0.7744 - f1_score: 0.7732 - val_loss: 0.3448 - val_accuracy: 0.8463 - val_f1_score: 0.8488\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3040 - accuracy: 0.8721 - f1_score: 0.8718 - val_loss: 0.3017 - val_accuracy: 0.8752 - val_f1_score: 0.8736\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2575 - accuracy: 0.8935 - f1_score: 0.8928 - val_loss: 0.2905 - val_accuracy: 0.8816 - val_f1_score: 0.8838\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2031 - accuracy: 0.9189 - f1_score: 0.9184 - val_loss: 0.2894 - val_accuracy: 0.8779 - val_f1_score: 0.8723\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1679 - accuracy: 0.9315 - f1_score: 0.9312 - val_loss: 0.3116 - val_accuracy: 0.8689 - val_f1_score: 0.8762\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1383 - accuracy: 0.9472 - f1_score: 0.9470 - val_loss: 0.3056 - val_accuracy: 0.8861 - val_f1_score: 0.8881\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1020 - accuracy: 0.9656 - f1_score: 0.9656 - val_loss: 0.3044 - val_accuracy: 0.8861 - val_f1_score: 0.8877\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0695 - accuracy: 0.9765 - f1_score: 0.9765 - val_loss: 0.3714 - val_accuracy: 0.8933 - val_f1_score: 0.8909\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0523 - accuracy: 0.9828 - f1_score: 0.9828 - val_loss: 0.4194 - val_accuracy: 0.8906 - val_f1_score: 0.8901\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8413 - f1_score: 0.8617\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.5010 - accuracy: 0.7503 - f1_score: 0.7563 - val_loss: 0.3329 - val_accuracy: 0.8571 - val_f1_score: 0.8587\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3151 - accuracy: 0.8709 - f1_score: 0.8698 - val_loss: 0.2990 - val_accuracy: 0.8680 - val_f1_score: 0.8724\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2571 - accuracy: 0.8911 - f1_score: 0.8902 - val_loss: 0.3023 - val_accuracy: 0.8662 - val_f1_score: 0.8706\n","Epoch 4/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2126 - accuracy: 0.9116 - f1_score: 0.9118 - val_loss: 0.3310 - val_accuracy: 0.8662 - val_f1_score: 0.8741\n","Epoch 5/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1765 - accuracy: 0.9334 - f1_score: 0.9330 - val_loss: 0.3188 - val_accuracy: 0.8734 - val_f1_score: 0.8723\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1310 - accuracy: 0.9548 - f1_score: 0.9548 - val_loss: 0.3373 - val_accuracy: 0.8770 - val_f1_score: 0.8811\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1020 - accuracy: 0.9638 - f1_score: 0.9637 - val_loss: 0.3484 - val_accuracy: 0.8897 - val_f1_score: 0.8851\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8656 - f1_score: 0.8910\n","47/47 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"id":"oX6mU_Wv1bA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697571160878,"user_tz":-330,"elapsed":31,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"8603f3ed-d48e-4a0c-92ae-751e260b0afe"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8757596015930176, 0.8663065433502197, 0.8568534851074219, 0.8642808794975281, 0.8777852654457092, 0.8642808794975281, 0.8541526198387146, 0.8575286865234375, 0.8696826696395874, 0.871708333492279, 0.871708333492279, 0.8561782836914062, 0.8744091987609863, 0.8730587363243103, 0.8798109292984009, 0.8419986367225647, 0.8649561405181885, 0.8588791489601135, 0.8568534851074219, 0.8588791489601135, 0.8663065433502197, 0.8642808794975281, 0.8723835349082947, 0.8413234353065491, 0.8656313419342041]\n","0.864199869632721\n","0.009708743534499062\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"id":"X8gWEDLy2Qjs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697571160878,"user_tz":-330,"elapsed":18,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"dcd6805c-a354-4191-f30d-e19299891d42"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.28273478150367737, 0.31288060545921326, 0.34567850828170776, 0.31890425086021423, 0.2978297472000122, 0.3162073493003845, 0.33429771661758423, 0.33842626214027405, 0.33314192295074463, 0.31106916069984436, 0.3137189447879791, 0.3188532292842865, 0.30043691396713257, 0.2807988226413727, 0.3063645362854004, 0.3334631323814392, 0.3091433346271515, 0.3340449035167694, 0.34440648555755615, 0.32432085275650024, 0.32336074113845825, 0.2967500388622284, 0.302021861076355, 0.36369872093200684, 0.31427526473999023]\n","0.31827312350273135\n","0.019392812999529302\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"id":"uxV3HD7Z2QnQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697571160878,"user_tz":-330,"elapsed":16,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6cfb7b77-3520-488b-bae8-619f0e3ad3c9"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8975500464439392, 0.8868571519851685, 0.8766006827354431, 0.8837476968765259, 0.8992765545845032, 0.8899835348129272, 0.8806629776954651, 0.8848881125450134, 0.8969566822052002, 0.8967390656471252, 0.8938546180725098, 0.8772333860397339, 0.8964364528656006, 0.8961325287818909, 0.9007803201675415, 0.8645833134651184, 0.8907102942466736, 0.8822534680366516, 0.8810324668884277, 0.8835654258728027, 0.888135552406311, 0.8863764405250549, 0.8926745057106018, 0.861683189868927, 0.890958845615387]\n","0.8871869325637818\n","0.009815934503712922\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"id":"iQDwhN9B1bEb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697571160878,"user_tz":-330,"elapsed":15,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"38286550-8d29-4308-bfcb-f0a94ba93ce8"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.7428630202218336, 0.7329374343718179, 0.7218670610871358, 0.7341740595583146, 0.7469351884227906, 0.7136194865069325, 0.6949563403391906, 0.6984526555311125, 0.7199890146610854, 0.7276241629541996, 0.7354815422873108, 0.7157396769474571, 0.740028833853201, 0.7347761185429561, 0.7517258636691895, 0.6882327047463918, 0.7146188907652706, 0.711692053740208, 0.7059730804374406, 0.7076256300950358, 0.728289561524553, 0.7242827485273817, 0.7429795290933081, 0.6954519458762116, 0.7167698793480257]\n","0.7218834593243342\n","0.01707704819419851\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ltt-jGQBXDk1","executionInfo":{"status":"ok","timestamp":1697571160879,"user_tz":-330,"elapsed":14,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["Emb A\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.871/0.006\n","2. Loss - 0.300/0.017\n","3. F1 score - 0.893/0.005\n","4. MCC - 0.736/0.011\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.869/0.007\n","2. Loss - 0.302/0.015\n","3. F1 score - 0.891/0.006\n","4. MCC - 0.734/0.013"],"metadata":{"id":"49IpoRO-zNNV"}},{"cell_type":"markdown","source":["Emb E\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.852/0.007\n","2. Loss - 0.338/0.011\n","3. F1 score - 0.877/0.006\n","4. MCC - 0.696/0.013\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.850/0.009\n","2. Loss - 0.343/0.017\n","3. F1 score - 0.874/0.009\n","4. MCC - 0.695/0.014"],"metadata":{"id":"tliHRGY8-lPl"}},{"cell_type":"markdown","source":["Emb H\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.857/0.016\n","2. Loss - 0.323/0.023\n","3. F1 score - 0.880/0.016\n","4. MCC - 0.712/0.025\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.856/0.015\n","2. Loss - 0.331/0.026\n","3. F1 score - 0.878/0.016\n","4. MCC - 0.712/0.022"],"metadata":{"id":"h86gQV4aHmhe"}},{"cell_type":"markdown","source":["Emb I\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.865/0.011\n","2. Loss - 0.317/0.018\n","3. F1 score - 0.887/0.010\n","4. MCC - 0.725/0.020\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.864/0.009\n","2. Loss - 0.318/0.019\n","3. F1 score - 0.887/0.009\n","4. MCC - 0.721/0.017"],"metadata":{"id":"UUpaqxgjMkTQ"}},{"cell_type":"code","source":[],"metadata":{"id":"Ti0cUJ4QGvtE","executionInfo":{"status":"ok","timestamp":1697568725367,"user_tz":-330,"elapsed":13,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UDxGX0LTANyM","executionInfo":{"status":"ok","timestamp":1697568725368,"user_tz":-330,"elapsed":14,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["## CNN layer to emotions with maxpooling (pool size 5 and stride 2) (with additional LSTM layer in emotions)"],"metadata":{"id":"KA8k_DIQw-CZ"}},{"cell_type":"code","source":["# LSTM CNN nothing nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=5, strides=2)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_lstm_emotions, input_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fc7yjgK8xCc6","executionInfo":{"status":"ok","timestamp":1697624197117,"user_tz":-330,"elapsed":533483,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"74f8e46a-0563-45e1-9baa-7864aef39de7"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4795 - accuracy: 0.7648 - f1_score: 0.7770 - val_loss: 0.3420 - val_accuracy: 0.8490 - val_f1_score: 0.8469\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2973 - accuracy: 0.8758 - f1_score: 0.8766 - val_loss: 0.3790 - val_accuracy: 0.8373 - val_f1_score: 0.8193\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2511 - accuracy: 0.8951 - f1_score: 0.8945 - val_loss: 0.3078 - val_accuracy: 0.8599 - val_f1_score: 0.8553\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1974 - accuracy: 0.9222 - f1_score: 0.9223 - val_loss: 0.3417 - val_accuracy: 0.8707 - val_f1_score: 0.8731\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1593 - accuracy: 0.9442 - f1_score: 0.9440 - val_loss: 0.3739 - val_accuracy: 0.8797 - val_f1_score: 0.8758\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1266 - accuracy: 0.9536 - f1_score: 0.9534 - val_loss: 0.3972 - val_accuracy: 0.8580 - val_f1_score: 0.8526\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1082 - accuracy: 0.9578 - f1_score: 0.9577 - val_loss: 0.3668 - val_accuracy: 0.8752 - val_f1_score: 0.8750\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0748 - accuracy: 0.9689 - f1_score: 0.9690 - val_loss: 0.4804 - val_accuracy: 0.8644 - val_f1_score: 0.8571\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.8731 - f1_score: 0.8938\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4810 - accuracy: 0.7684 - f1_score: 0.7743 - val_loss: 0.3451 - val_accuracy: 0.8571 - val_f1_score: 0.8594\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3097 - accuracy: 0.8709 - f1_score: 0.8714 - val_loss: 0.3084 - val_accuracy: 0.8671 - val_f1_score: 0.8665\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2515 - accuracy: 0.9023 - f1_score: 0.9025 - val_loss: 0.3101 - val_accuracy: 0.8743 - val_f1_score: 0.8695\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1994 - accuracy: 0.9237 - f1_score: 0.9235 - val_loss: 0.3205 - val_accuracy: 0.8752 - val_f1_score: 0.8698\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1625 - accuracy: 0.9361 - f1_score: 0.9359 - val_loss: 0.3513 - val_accuracy: 0.8644 - val_f1_score: 0.8689\n","Epoch 6/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1235 - accuracy: 0.9539 - f1_score: 0.9538 - val_loss: 0.3427 - val_accuracy: 0.8788 - val_f1_score: 0.8757\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0980 - accuracy: 0.9656 - f1_score: 0.9655 - val_loss: 0.3963 - val_accuracy: 0.8779 - val_f1_score: 0.8720\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3014 - accuracy: 0.8663 - f1_score: 0.8896\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 20ms/step - loss: 0.4661 - accuracy: 0.7811 - f1_score: 0.7754 - val_loss: 0.3395 - val_accuracy: 0.8445 - val_f1_score: 0.8401\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3024 - accuracy: 0.8718 - f1_score: 0.8723 - val_loss: 0.3173 - val_accuracy: 0.8662 - val_f1_score: 0.8630\n","Epoch 3/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.2466 - accuracy: 0.9005 - f1_score: 0.9001 - val_loss: 0.3022 - val_accuracy: 0.8743 - val_f1_score: 0.8702\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2123 - accuracy: 0.9116 - f1_score: 0.9110 - val_loss: 0.3457 - val_accuracy: 0.8689 - val_f1_score: 0.8704\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1662 - accuracy: 0.9373 - f1_score: 0.9369 - val_loss: 0.3667 - val_accuracy: 0.8608 - val_f1_score: 0.8511\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1331 - accuracy: 0.9487 - f1_score: 0.9483 - val_loss: 0.3715 - val_accuracy: 0.8752 - val_f1_score: 0.8732\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1258 - accuracy: 0.9499 - f1_score: 0.9496 - val_loss: 0.4109 - val_accuracy: 0.8752 - val_f1_score: 0.8741\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0829 - accuracy: 0.9695 - f1_score: 0.9694 - val_loss: 0.4503 - val_accuracy: 0.8698 - val_f1_score: 0.8636\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8569 - f1_score: 0.8759\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.4820 - accuracy: 0.7657 - f1_score: 0.7738 - val_loss: 0.3462 - val_accuracy: 0.8544 - val_f1_score: 0.8559\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3132 - accuracy: 0.8718 - f1_score: 0.8710 - val_loss: 0.3154 - val_accuracy: 0.8680 - val_f1_score: 0.8689\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2559 - accuracy: 0.8972 - f1_score: 0.8977 - val_loss: 0.3251 - val_accuracy: 0.8770 - val_f1_score: 0.8811\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2087 - accuracy: 0.9128 - f1_score: 0.9131 - val_loss: 0.3123 - val_accuracy: 0.8743 - val_f1_score: 0.8705\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1687 - accuracy: 0.9331 - f1_score: 0.9326 - val_loss: 0.3619 - val_accuracy: 0.8843 - val_f1_score: 0.8845\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.9469 - f1_score: 0.9469 - val_loss: 0.3479 - val_accuracy: 0.8788 - val_f1_score: 0.8782\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0996 - accuracy: 0.9629 - f1_score: 0.9629 - val_loss: 0.4164 - val_accuracy: 0.8825 - val_f1_score: 0.8787\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0684 - accuracy: 0.9753 - f1_score: 0.9752 - val_loss: 0.4700 - val_accuracy: 0.8797 - val_f1_score: 0.8779\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0584 - accuracy: 0.9789 - f1_score: 0.9789 - val_loss: 0.4905 - val_accuracy: 0.8752 - val_f1_score: 0.8755\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8670 - f1_score: 0.8861\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4840 - accuracy: 0.7627 - f1_score: 0.7523 - val_loss: 0.3353 - val_accuracy: 0.8472 - val_f1_score: 0.8495\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3053 - accuracy: 0.8788 - f1_score: 0.8788 - val_loss: 0.3245 - val_accuracy: 0.8535 - val_f1_score: 0.8574\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2526 - accuracy: 0.8966 - f1_score: 0.8962 - val_loss: 0.3117 - val_accuracy: 0.8653 - val_f1_score: 0.8708\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2042 - accuracy: 0.9192 - f1_score: 0.9193 - val_loss: 0.3039 - val_accuracy: 0.8725 - val_f1_score: 0.8693\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1680 - accuracy: 0.9340 - f1_score: 0.9339 - val_loss: 0.3463 - val_accuracy: 0.8689 - val_f1_score: 0.8725\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1322 - accuracy: 0.9466 - f1_score: 0.9463 - val_loss: 0.3918 - val_accuracy: 0.8626 - val_f1_score: 0.8681\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0948 - accuracy: 0.9641 - f1_score: 0.9640 - val_loss: 0.4555 - val_accuracy: 0.8707 - val_f1_score: 0.8749\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0854 - accuracy: 0.9656 - f1_score: 0.9655 - val_loss: 0.4336 - val_accuracy: 0.8761 - val_f1_score: 0.8782\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0505 - accuracy: 0.9816 - f1_score: 0.9815 - val_loss: 0.6102 - val_accuracy: 0.8707 - val_f1_score: 0.8749\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8670 - f1_score: 0.8862\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4775 - accuracy: 0.7693 - f1_score: 0.7671 - val_loss: 0.3502 - val_accuracy: 0.8454 - val_f1_score: 0.8499\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3039 - accuracy: 0.8761 - f1_score: 0.8755 - val_loss: 0.3172 - val_accuracy: 0.8553 - val_f1_score: 0.8556\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2463 - accuracy: 0.8975 - f1_score: 0.8958 - val_loss: 0.3710 - val_accuracy: 0.8571 - val_f1_score: 0.8650\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2005 - accuracy: 0.9231 - f1_score: 0.9225 - val_loss: 0.3520 - val_accuracy: 0.8698 - val_f1_score: 0.8748\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1538 - accuracy: 0.9448 - f1_score: 0.9445 - val_loss: 0.3353 - val_accuracy: 0.8662 - val_f1_score: 0.8637\n","Epoch 6/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1339 - accuracy: 0.9505 - f1_score: 0.9501 - val_loss: 0.4017 - val_accuracy: 0.8662 - val_f1_score: 0.8688\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1044 - accuracy: 0.9623 - f1_score: 0.9620 - val_loss: 0.5030 - val_accuracy: 0.8617 - val_f1_score: 0.8698\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8494 - f1_score: 0.8755\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4670 - accuracy: 0.7771 - f1_score: 0.7723 - val_loss: 0.3978 - val_accuracy: 0.8228 - val_f1_score: 0.8310\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3177 - accuracy: 0.8670 - f1_score: 0.8666 - val_loss: 0.3817 - val_accuracy: 0.8246 - val_f1_score: 0.8420\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2629 - accuracy: 0.8935 - f1_score: 0.8929 - val_loss: 0.3409 - val_accuracy: 0.8544 - val_f1_score: 0.8581\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2040 - accuracy: 0.9252 - f1_score: 0.9250 - val_loss: 0.3412 - val_accuracy: 0.8599 - val_f1_score: 0.8663\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1815 - accuracy: 0.9285 - f1_score: 0.9279 - val_loss: 0.3579 - val_accuracy: 0.8698 - val_f1_score: 0.8631\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1333 - accuracy: 0.9527 - f1_score: 0.9523 - val_loss: 0.4078 - val_accuracy: 0.8553 - val_f1_score: 0.8441\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1002 - accuracy: 0.9632 - f1_score: 0.9630 - val_loss: 0.3912 - val_accuracy: 0.8698 - val_f1_score: 0.8647\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0772 - accuracy: 0.9732 - f1_score: 0.9732 - val_loss: 0.4320 - val_accuracy: 0.8680 - val_f1_score: 0.8730\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8602 - f1_score: 0.8879\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 21ms/step - loss: 0.4857 - accuracy: 0.7600 - f1_score: 0.7592 - val_loss: 0.3536 - val_accuracy: 0.8363 - val_f1_score: 0.8319\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3060 - accuracy: 0.8770 - f1_score: 0.8752 - val_loss: 0.3382 - val_accuracy: 0.8571 - val_f1_score: 0.8487\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2518 - accuracy: 0.8993 - f1_score: 0.8980 - val_loss: 0.3755 - val_accuracy: 0.8599 - val_f1_score: 0.8665\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2075 - accuracy: 0.9189 - f1_score: 0.9182 - val_loss: 0.3221 - val_accuracy: 0.8644 - val_f1_score: 0.8656\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1651 - accuracy: 0.9352 - f1_score: 0.9345 - val_loss: 0.3541 - val_accuracy: 0.8653 - val_f1_score: 0.8606\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1291 - accuracy: 0.9548 - f1_score: 0.9544 - val_loss: 0.4024 - val_accuracy: 0.8571 - val_f1_score: 0.8548\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0993 - accuracy: 0.9665 - f1_score: 0.9664 - val_loss: 0.4823 - val_accuracy: 0.8544 - val_f1_score: 0.8411\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0829 - accuracy: 0.9698 - f1_score: 0.9696 - val_loss: 0.4941 - val_accuracy: 0.8671 - val_f1_score: 0.8604\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0533 - accuracy: 0.9825 - f1_score: 0.9824 - val_loss: 0.5895 - val_accuracy: 0.8662 - val_f1_score: 0.8695\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8683 - f1_score: 0.8922\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 26ms/step - loss: 0.4763 - accuracy: 0.7744 - f1_score: 0.7780 - val_loss: 0.3931 - val_accuracy: 0.8382 - val_f1_score: 0.8527\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3019 - accuracy: 0.8682 - f1_score: 0.8661 - val_loss: 0.3193 - val_accuracy: 0.8535 - val_f1_score: 0.8591\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2407 - accuracy: 0.8993 - f1_score: 0.8979 - val_loss: 0.3349 - val_accuracy: 0.8680 - val_f1_score: 0.8607\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2089 - accuracy: 0.9174 - f1_score: 0.9161 - val_loss: 0.3147 - val_accuracy: 0.8825 - val_f1_score: 0.8745\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1672 - accuracy: 0.9346 - f1_score: 0.9338 - val_loss: 0.3865 - val_accuracy: 0.8626 - val_f1_score: 0.8474\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1229 - accuracy: 0.9521 - f1_score: 0.9517 - val_loss: 0.4376 - val_accuracy: 0.8788 - val_f1_score: 0.8702\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1055 - accuracy: 0.9611 - f1_score: 0.9606 - val_loss: 0.4786 - val_accuracy: 0.8626 - val_f1_score: 0.8474\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0867 - accuracy: 0.9689 - f1_score: 0.9688 - val_loss: 0.4173 - val_accuracy: 0.8843 - val_f1_score: 0.8830\n","Epoch 9/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0705 - accuracy: 0.9735 - f1_score: 0.9734 - val_loss: 0.4562 - val_accuracy: 0.8951 - val_f1_score: 0.8899\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8562 - f1_score: 0.8785\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 18ms/step - loss: 0.4906 - accuracy: 0.7660 - f1_score: 0.7599 - val_loss: 0.3629 - val_accuracy: 0.8400 - val_f1_score: 0.8270\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3170 - accuracy: 0.8676 - f1_score: 0.8665 - val_loss: 0.3302 - val_accuracy: 0.8571 - val_f1_score: 0.8484\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2538 - accuracy: 0.8905 - f1_score: 0.8894 - val_loss: 0.3215 - val_accuracy: 0.8743 - val_f1_score: 0.8719\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2068 - accuracy: 0.9147 - f1_score: 0.9139 - val_loss: 0.3262 - val_accuracy: 0.8834 - val_f1_score: 0.8800\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1634 - accuracy: 0.9328 - f1_score: 0.9323 - val_loss: 0.3383 - val_accuracy: 0.8716 - val_f1_score: 0.8629\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1220 - accuracy: 0.9542 - f1_score: 0.9537 - val_loss: 0.3273 - val_accuracy: 0.8924 - val_f1_score: 0.8907\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0938 - accuracy: 0.9680 - f1_score: 0.9677 - val_loss: 0.4299 - val_accuracy: 0.8779 - val_f1_score: 0.8718\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0750 - accuracy: 0.9726 - f1_score: 0.9724 - val_loss: 0.4458 - val_accuracy: 0.8843 - val_f1_score: 0.8792\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8677 - f1_score: 0.8915\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.4831 - accuracy: 0.7672 - f1_score: 0.7696 - val_loss: 0.3340 - val_accuracy: 0.8590 - val_f1_score: 0.8561\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3344 - accuracy: 0.8631 - f1_score: 0.8639 - val_loss: 0.3081 - val_accuracy: 0.8617 - val_f1_score: 0.8645\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2742 - accuracy: 0.8866 - f1_score: 0.8863 - val_loss: 0.2942 - val_accuracy: 0.8834 - val_f1_score: 0.8756\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2379 - accuracy: 0.9056 - f1_score: 0.9056 - val_loss: 0.3572 - val_accuracy: 0.8562 - val_f1_score: 0.8369\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1872 - accuracy: 0.9328 - f1_score: 0.9322 - val_loss: 0.2968 - val_accuracy: 0.8897 - val_f1_score: 0.8838\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1566 - accuracy: 0.9415 - f1_score: 0.9409 - val_loss: 0.3166 - val_accuracy: 0.8779 - val_f1_score: 0.8706\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1201 - accuracy: 0.9548 - f1_score: 0.9546 - val_loss: 0.3028 - val_accuracy: 0.8933 - val_f1_score: 0.8939\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0894 - accuracy: 0.9659 - f1_score: 0.9658 - val_loss: 0.3937 - val_accuracy: 0.8861 - val_f1_score: 0.8840\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3250 - accuracy: 0.8704 - f1_score: 0.8907\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4787 - accuracy: 0.7720 - f1_score: 0.7753 - val_loss: 0.3699 - val_accuracy: 0.8264 - val_f1_score: 0.8161\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3061 - accuracy: 0.8724 - f1_score: 0.8714 - val_loss: 0.3324 - val_accuracy: 0.8580 - val_f1_score: 0.8500\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2514 - accuracy: 0.8987 - f1_score: 0.8980 - val_loss: 0.3320 - val_accuracy: 0.8689 - val_f1_score: 0.8709\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2206 - accuracy: 0.9131 - f1_score: 0.9122 - val_loss: 0.3434 - val_accuracy: 0.8680 - val_f1_score: 0.8680\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1825 - accuracy: 0.9294 - f1_score: 0.9288 - val_loss: 0.3507 - val_accuracy: 0.8680 - val_f1_score: 0.8699\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1538 - accuracy: 0.9424 - f1_score: 0.9418 - val_loss: 0.3604 - val_accuracy: 0.8644 - val_f1_score: 0.8614\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1132 - accuracy: 0.9596 - f1_score: 0.9593 - val_loss: 0.3854 - val_accuracy: 0.8662 - val_f1_score: 0.8622\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0994 - accuracy: 0.9650 - f1_score: 0.9649 - val_loss: 0.3962 - val_accuracy: 0.8662 - val_f1_score: 0.8619\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8683 - f1_score: 0.8951\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 24ms/step - loss: 0.4819 - accuracy: 0.7636 - f1_score: 0.7555 - val_loss: 0.3835 - val_accuracy: 0.8309 - val_f1_score: 0.8292\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3048 - accuracy: 0.8782 - f1_score: 0.8780 - val_loss: 0.3561 - val_accuracy: 0.8454 - val_f1_score: 0.8364\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2532 - accuracy: 0.8975 - f1_score: 0.8977 - val_loss: 0.3333 - val_accuracy: 0.8608 - val_f1_score: 0.8561\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2134 - accuracy: 0.9147 - f1_score: 0.9136 - val_loss: 0.3284 - val_accuracy: 0.8626 - val_f1_score: 0.8574\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1724 - accuracy: 0.9346 - f1_score: 0.9339 - val_loss: 0.4002 - val_accuracy: 0.8608 - val_f1_score: 0.8508\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1501 - accuracy: 0.9436 - f1_score: 0.9429 - val_loss: 0.3708 - val_accuracy: 0.8481 - val_f1_score: 0.8330\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1177 - accuracy: 0.9563 - f1_score: 0.9559 - val_loss: 0.4180 - val_accuracy: 0.8770 - val_f1_score: 0.8752\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0768 - accuracy: 0.9704 - f1_score: 0.9704 - val_loss: 0.5102 - val_accuracy: 0.8734 - val_f1_score: 0.8689\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0677 - accuracy: 0.9786 - f1_score: 0.9785 - val_loss: 0.5243 - val_accuracy: 0.8716 - val_f1_score: 0.8711\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2989 - accuracy: 0.8764 - f1_score: 0.8976\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 24ms/step - loss: 0.4714 - accuracy: 0.7753 - f1_score: 0.7720 - val_loss: 0.3431 - val_accuracy: 0.8472 - val_f1_score: 0.8479\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3175 - accuracy: 0.8646 - f1_score: 0.8632 - val_loss: 0.3384 - val_accuracy: 0.8490 - val_f1_score: 0.8452\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2621 - accuracy: 0.8887 - f1_score: 0.8877 - val_loss: 0.3161 - val_accuracy: 0.8409 - val_f1_score: 0.8295\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2237 - accuracy: 0.9110 - f1_score: 0.9096 - val_loss: 0.3328 - val_accuracy: 0.8626 - val_f1_score: 0.8603\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1843 - accuracy: 0.9309 - f1_score: 0.9299 - val_loss: 0.3460 - val_accuracy: 0.8599 - val_f1_score: 0.8508\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1449 - accuracy: 0.9439 - f1_score: 0.9432 - val_loss: 0.3253 - val_accuracy: 0.8662 - val_f1_score: 0.8612\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1125 - accuracy: 0.9632 - f1_score: 0.9629 - val_loss: 0.4305 - val_accuracy: 0.8571 - val_f1_score: 0.8475\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9735 - f1_score: 0.9733 - val_loss: 0.4407 - val_accuracy: 0.8725 - val_f1_score: 0.8758\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8636 - f1_score: 0.8839\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4715 - accuracy: 0.7708 - f1_score: 0.7735 - val_loss: 0.3294 - val_accuracy: 0.8635 - val_f1_score: 0.8569\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3206 - accuracy: 0.8685 - f1_score: 0.8674 - val_loss: 0.2947 - val_accuracy: 0.8743 - val_f1_score: 0.8784\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2656 - accuracy: 0.8890 - f1_score: 0.8886 - val_loss: 0.3541 - val_accuracy: 0.8481 - val_f1_score: 0.8293\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2250 - accuracy: 0.9086 - f1_score: 0.9078 - val_loss: 0.3332 - val_accuracy: 0.8617 - val_f1_score: 0.8487\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1875 - accuracy: 0.9255 - f1_score: 0.9243 - val_loss: 0.3143 - val_accuracy: 0.8752 - val_f1_score: 0.8796\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1472 - accuracy: 0.9448 - f1_score: 0.9444 - val_loss: 0.3573 - val_accuracy: 0.8716 - val_f1_score: 0.8655\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1153 - accuracy: 0.9602 - f1_score: 0.9600 - val_loss: 0.3926 - val_accuracy: 0.8870 - val_f1_score: 0.8877\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8758 - f1_score: 0.9006\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 20ms/step - loss: 0.4810 - accuracy: 0.7756 - f1_score: 0.7750 - val_loss: 0.3387 - val_accuracy: 0.8472 - val_f1_score: 0.8521\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3058 - accuracy: 0.8773 - f1_score: 0.8771 - val_loss: 0.3088 - val_accuracy: 0.8635 - val_f1_score: 0.8633\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2589 - accuracy: 0.8993 - f1_score: 0.8978 - val_loss: 0.3046 - val_accuracy: 0.8635 - val_f1_score: 0.8595\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2152 - accuracy: 0.9107 - f1_score: 0.9100 - val_loss: 0.3215 - val_accuracy: 0.8662 - val_f1_score: 0.8543\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1662 - accuracy: 0.9346 - f1_score: 0.9340 - val_loss: 0.3429 - val_accuracy: 0.8761 - val_f1_score: 0.8784\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1357 - accuracy: 0.9548 - f1_score: 0.9544 - val_loss: 0.3615 - val_accuracy: 0.8770 - val_f1_score: 0.8766\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1058 - accuracy: 0.9599 - f1_score: 0.9596 - val_loss: 0.3682 - val_accuracy: 0.8797 - val_f1_score: 0.8781\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0916 - accuracy: 0.9662 - f1_score: 0.9660 - val_loss: 0.4320 - val_accuracy: 0.8562 - val_f1_score: 0.8455\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3250 - accuracy: 0.8569 - f1_score: 0.8802\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4624 - accuracy: 0.7765 - f1_score: 0.7707 - val_loss: 0.3333 - val_accuracy: 0.8698 - val_f1_score: 0.8652\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3190 - accuracy: 0.8628 - f1_score: 0.8622 - val_loss: 0.3037 - val_accuracy: 0.8761 - val_f1_score: 0.8749\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2607 - accuracy: 0.8963 - f1_score: 0.8950 - val_loss: 0.2813 - val_accuracy: 0.8816 - val_f1_score: 0.8777\n","Epoch 4/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2130 - accuracy: 0.9116 - f1_score: 0.9105 - val_loss: 0.3226 - val_accuracy: 0.8635 - val_f1_score: 0.8566\n","Epoch 5/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1709 - accuracy: 0.9321 - f1_score: 0.9316 - val_loss: 0.2931 - val_accuracy: 0.8816 - val_f1_score: 0.8758\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1256 - accuracy: 0.9536 - f1_score: 0.9530 - val_loss: 0.3885 - val_accuracy: 0.8743 - val_f1_score: 0.8670\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1066 - accuracy: 0.9602 - f1_score: 0.9600 - val_loss: 0.3996 - val_accuracy: 0.8807 - val_f1_score: 0.8773\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0654 - accuracy: 0.9795 - f1_score: 0.9794 - val_loss: 0.4801 - val_accuracy: 0.8852 - val_f1_score: 0.8808\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8542 - f1_score: 0.8780\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 25ms/step - loss: 0.4730 - accuracy: 0.7729 - f1_score: 0.7750 - val_loss: 0.4075 - val_accuracy: 0.8363 - val_f1_score: 0.8356\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3074 - accuracy: 0.8736 - f1_score: 0.8729 - val_loss: 0.3397 - val_accuracy: 0.8508 - val_f1_score: 0.8528\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2512 - accuracy: 0.9002 - f1_score: 0.9002 - val_loss: 0.3148 - val_accuracy: 0.8671 - val_f1_score: 0.8627\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2075 - accuracy: 0.9201 - f1_score: 0.9194 - val_loss: 0.3102 - val_accuracy: 0.8779 - val_f1_score: 0.8737\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1560 - accuracy: 0.9382 - f1_score: 0.9377 - val_loss: 0.3308 - val_accuracy: 0.8770 - val_f1_score: 0.8712\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1161 - accuracy: 0.9632 - f1_score: 0.9630 - val_loss: 0.3813 - val_accuracy: 0.8779 - val_f1_score: 0.8706\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1016 - accuracy: 0.9620 - f1_score: 0.9619 - val_loss: 0.4181 - val_accuracy: 0.8707 - val_f1_score: 0.8629\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0686 - accuracy: 0.9762 - f1_score: 0.9761 - val_loss: 0.4833 - val_accuracy: 0.8743 - val_f1_score: 0.8662\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0556 - accuracy: 0.9822 - f1_score: 0.9821 - val_loss: 0.5003 - val_accuracy: 0.8843 - val_f1_score: 0.8799\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8562 - f1_score: 0.8800\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 19ms/step - loss: 0.4601 - accuracy: 0.7771 - f1_score: 0.7723 - val_loss: 0.3633 - val_accuracy: 0.8309 - val_f1_score: 0.8347\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3017 - accuracy: 0.8806 - f1_score: 0.8793 - val_loss: 0.3433 - val_accuracy: 0.8472 - val_f1_score: 0.8539\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2432 - accuracy: 0.8987 - f1_score: 0.8979 - val_loss: 0.3462 - val_accuracy: 0.8553 - val_f1_score: 0.8450\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1992 - accuracy: 0.9231 - f1_score: 0.9223 - val_loss: 0.3686 - val_accuracy: 0.8553 - val_f1_score: 0.8513\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1563 - accuracy: 0.9436 - f1_score: 0.9430 - val_loss: 0.3568 - val_accuracy: 0.8635 - val_f1_score: 0.8558\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1199 - accuracy: 0.9587 - f1_score: 0.9583 - val_loss: 0.3736 - val_accuracy: 0.8599 - val_f1_score: 0.8536\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0860 - accuracy: 0.9689 - f1_score: 0.9687 - val_loss: 0.4905 - val_accuracy: 0.8653 - val_f1_score: 0.8582\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3165 - accuracy: 0.8643 - f1_score: 0.8934\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.4716 - accuracy: 0.7696 - f1_score: 0.7679 - val_loss: 0.3512 - val_accuracy: 0.8535 - val_f1_score: 0.8489\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3041 - accuracy: 0.8727 - f1_score: 0.8708 - val_loss: 0.3670 - val_accuracy: 0.8354 - val_f1_score: 0.8488\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2454 - accuracy: 0.8981 - f1_score: 0.8968 - val_loss: 0.3252 - val_accuracy: 0.8671 - val_f1_score: 0.8686\n","Epoch 4/20\n","104/104 [==============================] - 2s 17ms/step - loss: 0.2093 - accuracy: 0.9201 - f1_score: 0.9192 - val_loss: 0.3380 - val_accuracy: 0.8635 - val_f1_score: 0.8533\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1626 - accuracy: 0.9361 - f1_score: 0.9356 - val_loss: 0.3432 - val_accuracy: 0.8725 - val_f1_score: 0.8779\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1224 - accuracy: 0.9542 - f1_score: 0.9539 - val_loss: 0.3544 - val_accuracy: 0.8834 - val_f1_score: 0.8813\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0923 - accuracy: 0.9683 - f1_score: 0.9681 - val_loss: 0.3657 - val_accuracy: 0.8816 - val_f1_score: 0.8812\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0667 - accuracy: 0.9765 - f1_score: 0.9764 - val_loss: 0.4919 - val_accuracy: 0.8770 - val_f1_score: 0.8748\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8602 - f1_score: 0.8852\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.4643 - accuracy: 0.7750 - f1_score: 0.7689 - val_loss: 0.3552 - val_accuracy: 0.8463 - val_f1_score: 0.8381\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3089 - accuracy: 0.8691 - f1_score: 0.8690 - val_loss: 0.3192 - val_accuracy: 0.8553 - val_f1_score: 0.8470\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2544 - accuracy: 0.8935 - f1_score: 0.8940 - val_loss: 0.3738 - val_accuracy: 0.8418 - val_f1_score: 0.8231\n","Epoch 4/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2043 - accuracy: 0.9168 - f1_score: 0.9163 - val_loss: 0.3277 - val_accuracy: 0.8743 - val_f1_score: 0.8667\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1570 - accuracy: 0.9321 - f1_score: 0.9316 - val_loss: 0.3346 - val_accuracy: 0.8861 - val_f1_score: 0.8846\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1203 - accuracy: 0.9524 - f1_score: 0.9522 - val_loss: 0.3649 - val_accuracy: 0.8816 - val_f1_score: 0.8799\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1021 - accuracy: 0.9653 - f1_score: 0.9652 - val_loss: 0.4201 - val_accuracy: 0.8725 - val_f1_score: 0.8705\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3363 - accuracy: 0.8474 - f1_score: 0.8703\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4803 - accuracy: 0.7669 - f1_score: 0.7692 - val_loss: 0.3605 - val_accuracy: 0.8418 - val_f1_score: 0.8416\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3005 - accuracy: 0.8767 - f1_score: 0.8756 - val_loss: 0.3301 - val_accuracy: 0.8562 - val_f1_score: 0.8470\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2524 - accuracy: 0.8945 - f1_score: 0.8943 - val_loss: 0.3056 - val_accuracy: 0.8689 - val_f1_score: 0.8661\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2081 - accuracy: 0.9168 - f1_score: 0.9164 - val_loss: 0.3152 - val_accuracy: 0.8770 - val_f1_score: 0.8786\n","Epoch 5/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1742 - accuracy: 0.9328 - f1_score: 0.9326 - val_loss: 0.2985 - val_accuracy: 0.8761 - val_f1_score: 0.8737\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1340 - accuracy: 0.9454 - f1_score: 0.9450 - val_loss: 0.3355 - val_accuracy: 0.8797 - val_f1_score: 0.8828\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1267 - accuracy: 0.9530 - f1_score: 0.9527 - val_loss: 0.3712 - val_accuracy: 0.8770 - val_f1_score: 0.8700\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0736 - accuracy: 0.9744 - f1_score: 0.9743 - val_loss: 0.3947 - val_accuracy: 0.8743 - val_f1_score: 0.8756\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0671 - accuracy: 0.9765 - f1_score: 0.9764 - val_loss: 0.4471 - val_accuracy: 0.8626 - val_f1_score: 0.8524\n","Epoch 10/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0464 - accuracy: 0.9858 - f1_score: 0.9858 - val_loss: 0.5777 - val_accuracy: 0.8752 - val_f1_score: 0.8772\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8704 - f1_score: 0.8915\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 18ms/step - loss: 0.4723 - accuracy: 0.7699 - f1_score: 0.7684 - val_loss: 0.3479 - val_accuracy: 0.8427 - val_f1_score: 0.8270\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3147 - accuracy: 0.8667 - f1_score: 0.8643 - val_loss: 0.2804 - val_accuracy: 0.8761 - val_f1_score: 0.8726\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2483 - accuracy: 0.8975 - f1_score: 0.8961 - val_loss: 0.2719 - val_accuracy: 0.8807 - val_f1_score: 0.8817\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2142 - accuracy: 0.9116 - f1_score: 0.9105 - val_loss: 0.2748 - val_accuracy: 0.8788 - val_f1_score: 0.8712\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1689 - accuracy: 0.9300 - f1_score: 0.9291 - val_loss: 0.2987 - val_accuracy: 0.8924 - val_f1_score: 0.8948\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1254 - accuracy: 0.9502 - f1_score: 0.9500 - val_loss: 0.3661 - val_accuracy: 0.8897 - val_f1_score: 0.8887\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1000 - accuracy: 0.9617 - f1_score: 0.9616 - val_loss: 0.3779 - val_accuracy: 0.8897 - val_f1_score: 0.8901\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0700 - accuracy: 0.9741 - f1_score: 0.9739 - val_loss: 0.4543 - val_accuracy: 0.8825 - val_f1_score: 0.8856\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8825 - f1_score: 0.9040\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.4611 - accuracy: 0.7777 - f1_score: 0.7761 - val_loss: 0.3230 - val_accuracy: 0.8626 - val_f1_score: 0.8671\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3105 - accuracy: 0.8682 - f1_score: 0.8682 - val_loss: 0.3009 - val_accuracy: 0.8761 - val_f1_score: 0.8728\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2597 - accuracy: 0.8899 - f1_score: 0.8888 - val_loss: 0.2869 - val_accuracy: 0.8689 - val_f1_score: 0.8731\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2122 - accuracy: 0.9080 - f1_score: 0.9082 - val_loss: 0.2992 - val_accuracy: 0.8834 - val_f1_score: 0.8845\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1704 - accuracy: 0.9288 - f1_score: 0.9289 - val_loss: 0.2920 - val_accuracy: 0.8788 - val_f1_score: 0.8741\n","Epoch 6/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.1346 - accuracy: 0.9463 - f1_score: 0.9462 - val_loss: 0.3022 - val_accuracy: 0.8843 - val_f1_score: 0.8855\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1051 - accuracy: 0.9551 - f1_score: 0.9550 - val_loss: 0.3351 - val_accuracy: 0.8870 - val_f1_score: 0.8826\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0814 - accuracy: 0.9723 - f1_score: 0.9723 - val_loss: 0.3988 - val_accuracy: 0.8761 - val_f1_score: 0.8795\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8758 - f1_score: 0.8999\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 21ms/step - loss: 0.4781 - accuracy: 0.7669 - f1_score: 0.7613 - val_loss: 0.3242 - val_accuracy: 0.8617 - val_f1_score: 0.8625\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3036 - accuracy: 0.8682 - f1_score: 0.8666 - val_loss: 0.2864 - val_accuracy: 0.8788 - val_f1_score: 0.8791\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2450 - accuracy: 0.8996 - f1_score: 0.8998 - val_loss: 0.3358 - val_accuracy: 0.8571 - val_f1_score: 0.8445\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2191 - accuracy: 0.9092 - f1_score: 0.9084 - val_loss: 0.2939 - val_accuracy: 0.8825 - val_f1_score: 0.8875\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1658 - accuracy: 0.9349 - f1_score: 0.9343 - val_loss: 0.2899 - val_accuracy: 0.8870 - val_f1_score: 0.8854\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1310 - accuracy: 0.9530 - f1_score: 0.9529 - val_loss: 0.3154 - val_accuracy: 0.8888 - val_f1_score: 0.8885\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0999 - accuracy: 0.9650 - f1_score: 0.9649 - val_loss: 0.3591 - val_accuracy: 0.8834 - val_f1_score: 0.8845\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8636 - f1_score: 0.8861\n","47/47 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcOLU-VYxJJ7","executionInfo":{"status":"ok","timestamp":1697624197117,"user_tz":-330,"elapsed":99,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"34b07d06-ecb7-4575-d42a-696108803240"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8730587363243103, 0.8663065433502197, 0.8568534851074219, 0.8669817447662354, 0.8669817447662354, 0.8494260907173157, 0.8602295517921448, 0.8683322072029114, 0.8561782836914062, 0.8676570057868958, 0.870357871055603, 0.8683322072029114, 0.876434862613678, 0.8636056780815125, 0.8757596015930176, 0.8568534851074219, 0.8541526198387146, 0.8561782836914062, 0.8642808794975281, 0.8602295517921448, 0.847400426864624, 0.870357871055603, 0.8825117945671082, 0.8757596015930176, 0.8636056780815125]\n","0.864713032245636\n","0.00857050171182748\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaIFztYExJUk","executionInfo":{"status":"ok","timestamp":1697624197118,"user_tz":-330,"elapsed":67,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6a97ef46-7860-4cbc-d2e4-f1eff3d298d9"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.29246872663497925, 0.3014252185821533, 0.32109034061431885, 0.3208305835723877, 0.32922375202178955, 0.33816224336624146, 0.331108421087265, 0.3314656913280487, 0.3486522138118744, 0.3430574834346771, 0.3250468373298645, 0.3034771680831909, 0.298939049243927, 0.3165706694126129, 0.2923447787761688, 0.32495129108428955, 0.3139958381652832, 0.33102717995643616, 0.3165014684200287, 0.327340692281723, 0.3362579345703125, 0.3328031301498413, 0.2951224446296692, 0.29181110858917236, 0.30920112133026123]\n","0.31891501545906065\n","0.016520417703303588\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDMt0uWgxJev","executionInfo":{"status":"ok","timestamp":1697624197118,"user_tz":-330,"elapsed":62,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"66166159-d5ce-43b9-ca45-6836ca818b4e"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8937852382659912, 0.889631986618042, 0.8758781552314758, 0.8860612511634827, 0.8861929178237915, 0.8754885196685791, 0.8879262804985046, 0.8922055959701538, 0.8784939646720886, 0.8914728164672852, 0.8906605243682861, 0.8951048254966736, 0.8975936770439148, 0.8839079737663269, 0.9006478786468506, 0.8802259564399719, 0.877966046333313, 0.8799999356269836, 0.8933686017990112, 0.8851913213729858, 0.8702640533447266, 0.891525387763977, 0.9039734601974487, 0.8998910784721375, 0.8861330151557922]\n","0.8877436184883117\n","0.008438651298600571\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05vVYNXHxJoC","executionInfo":{"status":"ok","timestamp":1697624197119,"user_tz":-330,"elapsed":59,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"f31bd7a6-bf41-48da-c541-f780c1c240c3"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.7423818665314498, 0.7233974666184498, 0.7248189606344054, 0.7397765069362032, 0.7392341698755605, 0.6885821252972749, 0.7023466930174276, 0.7249878065754328, 0.7111306069376961, 0.7240750671316549, 0.7399233373712395, 0.7183223054421928, 0.7459591225564207, 0.7298458065950576, 0.7348964513256167, 0.7085603345148975, 0.7029234125121389, 0.706049675885461, 0.7074936602398452, 0.7089810699427017, 0.6956617030498063, 0.7367449445286911, 0.7543728724048134, 0.7364767060590329, 0.7217809268718284]\n","0.722748943954212\n","0.016903269054719176\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1olOBWFSxJzB","executionInfo":{"status":"ok","timestamp":1697624197119,"user_tz":-330,"elapsed":54,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# LSTM CNN LSTM nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=5, strides=2)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","        lstm_intensity = LSTM(32)(Reshape((1, 8))(input_intensity))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_lstm_emotions, lstm_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woZqyrrCxJ9E","executionInfo":{"status":"ok","timestamp":1697624867159,"user_tz":-330,"elapsed":670093,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"56ad9656-8263-44d5-afdd-dee14349921c"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 11s 23ms/step - loss: 0.4742 - accuracy: 0.7696 - f1_score: 0.7639 - val_loss: 0.3599 - val_accuracy: 0.8481 - val_f1_score: 0.8453\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3027 - accuracy: 0.8685 - f1_score: 0.8696 - val_loss: 0.3356 - val_accuracy: 0.8544 - val_f1_score: 0.8532\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2464 - accuracy: 0.8984 - f1_score: 0.8984 - val_loss: 0.3330 - val_accuracy: 0.8599 - val_f1_score: 0.8607\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1937 - accuracy: 0.9276 - f1_score: 0.9276 - val_loss: 0.3716 - val_accuracy: 0.8553 - val_f1_score: 0.8444\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1499 - accuracy: 0.9424 - f1_score: 0.9423 - val_loss: 0.4127 - val_accuracy: 0.8608 - val_f1_score: 0.8644\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1158 - accuracy: 0.9554 - f1_score: 0.9554 - val_loss: 0.4044 - val_accuracy: 0.8671 - val_f1_score: 0.8601\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0860 - accuracy: 0.9698 - f1_score: 0.9698 - val_loss: 0.5190 - val_accuracy: 0.8653 - val_f1_score: 0.8560\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0615 - accuracy: 0.9765 - f1_score: 0.9765 - val_loss: 0.6692 - val_accuracy: 0.8562 - val_f1_score: 0.8430\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2856 - accuracy: 0.8785 - f1_score: 0.9004\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 22ms/step - loss: 0.4877 - accuracy: 0.7627 - f1_score: 0.7665 - val_loss: 0.3398 - val_accuracy: 0.8553 - val_f1_score: 0.8574\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3185 - accuracy: 0.8646 - f1_score: 0.8636 - val_loss: 0.3578 - val_accuracy: 0.8445 - val_f1_score: 0.8263\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2552 - accuracy: 0.8957 - f1_score: 0.8957 - val_loss: 0.2972 - val_accuracy: 0.8689 - val_f1_score: 0.8671\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2134 - accuracy: 0.9168 - f1_score: 0.9168 - val_loss: 0.3375 - val_accuracy: 0.8698 - val_f1_score: 0.8607\n","Epoch 5/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.1677 - accuracy: 0.9397 - f1_score: 0.9396 - val_loss: 0.3292 - val_accuracy: 0.8779 - val_f1_score: 0.8747\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1246 - accuracy: 0.9521 - f1_score: 0.9519 - val_loss: 0.3954 - val_accuracy: 0.8816 - val_f1_score: 0.8737\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0982 - accuracy: 0.9680 - f1_score: 0.9679 - val_loss: 0.3615 - val_accuracy: 0.8915 - val_f1_score: 0.8879\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0694 - accuracy: 0.9747 - f1_score: 0.9746 - val_loss: 0.4420 - val_accuracy: 0.8752 - val_f1_score: 0.8732\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2924 - accuracy: 0.8764 - f1_score: 0.8975\n","47/47 [==============================] - 2s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 23ms/step - loss: 0.4723 - accuracy: 0.7735 - f1_score: 0.7670 - val_loss: 0.3326 - val_accuracy: 0.8481 - val_f1_score: 0.8481\n","Epoch 2/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.3130 - accuracy: 0.8718 - f1_score: 0.8712 - val_loss: 0.3100 - val_accuracy: 0.8689 - val_f1_score: 0.8664\n","Epoch 3/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.2575 - accuracy: 0.8935 - f1_score: 0.8939 - val_loss: 0.2973 - val_accuracy: 0.8725 - val_f1_score: 0.8710\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2113 - accuracy: 0.9168 - f1_score: 0.9167 - val_loss: 0.3139 - val_accuracy: 0.8725 - val_f1_score: 0.8740\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9388 - f1_score: 0.9389 - val_loss: 0.3548 - val_accuracy: 0.8698 - val_f1_score: 0.8723\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1212 - accuracy: 0.9536 - f1_score: 0.9534 - val_loss: 0.3532 - val_accuracy: 0.8644 - val_f1_score: 0.8626\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0952 - accuracy: 0.9611 - f1_score: 0.9611 - val_loss: 0.4241 - val_accuracy: 0.8617 - val_f1_score: 0.8613\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0662 - accuracy: 0.9759 - f1_score: 0.9758 - val_loss: 0.6192 - val_accuracy: 0.8580 - val_f1_score: 0.8526\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3102 - accuracy: 0.8710 - f1_score: 0.8920\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 29ms/step - loss: 0.4645 - accuracy: 0.7732 - f1_score: 0.7770 - val_loss: 0.3304 - val_accuracy: 0.8644 - val_f1_score: 0.8619\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3015 - accuracy: 0.8730 - f1_score: 0.8735 - val_loss: 0.3190 - val_accuracy: 0.8553 - val_f1_score: 0.8447\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2549 - accuracy: 0.8929 - f1_score: 0.8919 - val_loss: 0.2995 - val_accuracy: 0.8716 - val_f1_score: 0.8700\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2137 - accuracy: 0.9113 - f1_score: 0.9110 - val_loss: 0.3066 - val_accuracy: 0.8743 - val_f1_score: 0.8690\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1649 - accuracy: 0.9391 - f1_score: 0.9389 - val_loss: 0.3257 - val_accuracy: 0.8770 - val_f1_score: 0.8796\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1299 - accuracy: 0.9524 - f1_score: 0.9524 - val_loss: 0.3818 - val_accuracy: 0.8825 - val_f1_score: 0.8822\n","Epoch 7/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0894 - accuracy: 0.9683 - f1_score: 0.9682 - val_loss: 0.4626 - val_accuracy: 0.8743 - val_f1_score: 0.8649\n","Epoch 8/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0648 - accuracy: 0.9756 - f1_score: 0.9755 - val_loss: 0.5547 - val_accuracy: 0.8671 - val_f1_score: 0.8588\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3047 - accuracy: 0.8656 - f1_score: 0.8867\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 23ms/step - loss: 0.4798 - accuracy: 0.7720 - f1_score: 0.7766 - val_loss: 0.3343 - val_accuracy: 0.8472 - val_f1_score: 0.8484\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3040 - accuracy: 0.8733 - f1_score: 0.8733 - val_loss: 0.3218 - val_accuracy: 0.8526 - val_f1_score: 0.8622\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2484 - accuracy: 0.8975 - f1_score: 0.8983 - val_loss: 0.2970 - val_accuracy: 0.8626 - val_f1_score: 0.8618\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2122 - accuracy: 0.9134 - f1_score: 0.9133 - val_loss: 0.3282 - val_accuracy: 0.8635 - val_f1_score: 0.8555\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1651 - accuracy: 0.9424 - f1_score: 0.9424 - val_loss: 0.3570 - val_accuracy: 0.8698 - val_f1_score: 0.8691\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1263 - accuracy: 0.9542 - f1_score: 0.9541 - val_loss: 0.3684 - val_accuracy: 0.8734 - val_f1_score: 0.8730\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0872 - accuracy: 0.9683 - f1_score: 0.9683 - val_loss: 0.4427 - val_accuracy: 0.8617 - val_f1_score: 0.8547\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0757 - accuracy: 0.9747 - f1_score: 0.9746 - val_loss: 0.5250 - val_accuracy: 0.8680 - val_f1_score: 0.8599\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.8758 - f1_score: 0.8957\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 21ms/step - loss: 0.4915 - accuracy: 0.7530 - f1_score: 0.7350 - val_loss: 0.3611 - val_accuracy: 0.8391 - val_f1_score: 0.8411\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3148 - accuracy: 0.8697 - f1_score: 0.8689 - val_loss: 0.3417 - val_accuracy: 0.8508 - val_f1_score: 0.8541\n","Epoch 3/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.2580 - accuracy: 0.8923 - f1_score: 0.8915 - val_loss: 0.3103 - val_accuracy: 0.8617 - val_f1_score: 0.8582\n","Epoch 4/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.2063 - accuracy: 0.9231 - f1_score: 0.9225 - val_loss: 0.3187 - val_accuracy: 0.8680 - val_f1_score: 0.8643\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1701 - accuracy: 0.9343 - f1_score: 0.9336 - val_loss: 0.3846 - val_accuracy: 0.8644 - val_f1_score: 0.8580\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1319 - accuracy: 0.9493 - f1_score: 0.9489 - val_loss: 0.4024 - val_accuracy: 0.8608 - val_f1_score: 0.8603\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1075 - accuracy: 0.9569 - f1_score: 0.9565 - val_loss: 0.5539 - val_accuracy: 0.8499 - val_f1_score: 0.8607\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0827 - accuracy: 0.9689 - f1_score: 0.9688 - val_loss: 0.5273 - val_accuracy: 0.8644 - val_f1_score: 0.8698\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8447 - f1_score: 0.8675\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 23ms/step - loss: 0.4832 - accuracy: 0.7660 - f1_score: 0.7603 - val_loss: 0.3802 - val_accuracy: 0.8309 - val_f1_score: 0.8238\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3087 - accuracy: 0.8691 - f1_score: 0.8676 - val_loss: 0.3457 - val_accuracy: 0.8508 - val_f1_score: 0.8541\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2395 - accuracy: 0.9026 - f1_score: 0.9019 - val_loss: 0.3406 - val_accuracy: 0.8580 - val_f1_score: 0.8523\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1942 - accuracy: 0.9270 - f1_score: 0.9261 - val_loss: 0.3470 - val_accuracy: 0.8689 - val_f1_score: 0.8757\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1563 - accuracy: 0.9406 - f1_score: 0.9400 - val_loss: 0.3689 - val_accuracy: 0.8725 - val_f1_score: 0.8753\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1126 - accuracy: 0.9590 - f1_score: 0.9587 - val_loss: 0.4225 - val_accuracy: 0.8743 - val_f1_score: 0.8714\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0898 - accuracy: 0.9698 - f1_score: 0.9697 - val_loss: 0.4512 - val_accuracy: 0.8599 - val_f1_score: 0.8607\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0684 - accuracy: 0.9780 - f1_score: 0.9779 - val_loss: 0.4730 - val_accuracy: 0.8644 - val_f1_score: 0.8663\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8542 - f1_score: 0.8763\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 12s 22ms/step - loss: 0.4817 - accuracy: 0.7678 - f1_score: 0.7597 - val_loss: 0.3587 - val_accuracy: 0.8363 - val_f1_score: 0.8457\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3093 - accuracy: 0.8724 - f1_score: 0.8712 - val_loss: 0.3433 - val_accuracy: 0.8508 - val_f1_score: 0.8400\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2422 - accuracy: 0.9047 - f1_score: 0.9034 - val_loss: 0.3460 - val_accuracy: 0.8644 - val_f1_score: 0.8585\n","Epoch 4/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2074 - accuracy: 0.9156 - f1_score: 0.9143 - val_loss: 0.3486 - val_accuracy: 0.8626 - val_f1_score: 0.8631\n","Epoch 5/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1637 - accuracy: 0.9385 - f1_score: 0.9377 - val_loss: 0.3942 - val_accuracy: 0.8590 - val_f1_score: 0.8592\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1218 - accuracy: 0.9572 - f1_score: 0.9568 - val_loss: 0.4208 - val_accuracy: 0.8562 - val_f1_score: 0.8611\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1121 - accuracy: 0.9599 - f1_score: 0.9596 - val_loss: 0.4165 - val_accuracy: 0.8671 - val_f1_score: 0.8684\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8379 - f1_score: 0.8608\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 24ms/step - loss: 0.4904 - accuracy: 0.7645 - f1_score: 0.7596 - val_loss: 0.3664 - val_accuracy: 0.8327 - val_f1_score: 0.8184\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3164 - accuracy: 0.8652 - f1_score: 0.8646 - val_loss: 0.3474 - val_accuracy: 0.8517 - val_f1_score: 0.8383\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2599 - accuracy: 0.8899 - f1_score: 0.8888 - val_loss: 0.3271 - val_accuracy: 0.8725 - val_f1_score: 0.8681\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2097 - accuracy: 0.9128 - f1_score: 0.9122 - val_loss: 0.3298 - val_accuracy: 0.8779 - val_f1_score: 0.8732\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1762 - accuracy: 0.9261 - f1_score: 0.9253 - val_loss: 0.3045 - val_accuracy: 0.8761 - val_f1_score: 0.8753\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1352 - accuracy: 0.9454 - f1_score: 0.9454 - val_loss: 0.3984 - val_accuracy: 0.8779 - val_f1_score: 0.8713\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1259 - accuracy: 0.9493 - f1_score: 0.9490 - val_loss: 0.3802 - val_accuracy: 0.8807 - val_f1_score: 0.8748\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0729 - accuracy: 0.9732 - f1_score: 0.9732 - val_loss: 0.5315 - val_accuracy: 0.8825 - val_f1_score: 0.8790\n","Epoch 9/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.0762 - accuracy: 0.9717 - f1_score: 0.9716 - val_loss: 0.4515 - val_accuracy: 0.8924 - val_f1_score: 0.8907\n","Epoch 10/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0441 - accuracy: 0.9849 - f1_score: 0.9849 - val_loss: 0.5973 - val_accuracy: 0.8807 - val_f1_score: 0.8785\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8663 - f1_score: 0.8929\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 39ms/step - loss: 0.5069 - accuracy: 0.7621 - f1_score: 0.7579 - val_loss: 0.3552 - val_accuracy: 0.8490 - val_f1_score: 0.8441\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3149 - accuracy: 0.8631 - f1_score: 0.8630 - val_loss: 0.3200 - val_accuracy: 0.8752 - val_f1_score: 0.8750\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2519 - accuracy: 0.8935 - f1_score: 0.8925 - val_loss: 0.3037 - val_accuracy: 0.8788 - val_f1_score: 0.8729\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2087 - accuracy: 0.9162 - f1_score: 0.9155 - val_loss: 0.2925 - val_accuracy: 0.8797 - val_f1_score: 0.8742\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1701 - accuracy: 0.9352 - f1_score: 0.9346 - val_loss: 0.3403 - val_accuracy: 0.8843 - val_f1_score: 0.8830\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1233 - accuracy: 0.9527 - f1_score: 0.9523 - val_loss: 0.3892 - val_accuracy: 0.8897 - val_f1_score: 0.8849\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0989 - accuracy: 0.9611 - f1_score: 0.9610 - val_loss: 0.4276 - val_accuracy: 0.8834 - val_f1_score: 0.8782\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0742 - accuracy: 0.9720 - f1_score: 0.9718 - val_loss: 0.5088 - val_accuracy: 0.8825 - val_f1_score: 0.8762\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0596 - accuracy: 0.9783 - f1_score: 0.9783 - val_loss: 0.5392 - val_accuracy: 0.8770 - val_f1_score: 0.8731\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8650 - f1_score: 0.8878\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 22ms/step - loss: 0.4936 - accuracy: 0.7575 - f1_score: 0.7469 - val_loss: 0.3474 - val_accuracy: 0.8463 - val_f1_score: 0.8490\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3383 - accuracy: 0.8519 - f1_score: 0.8520 - val_loss: 0.3122 - val_accuracy: 0.8644 - val_f1_score: 0.8707\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2755 - accuracy: 0.8857 - f1_score: 0.8853 - val_loss: 0.2928 - val_accuracy: 0.8834 - val_f1_score: 0.8773\n","Epoch 4/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.2367 - accuracy: 0.9038 - f1_score: 0.9032 - val_loss: 0.2757 - val_accuracy: 0.8924 - val_f1_score: 0.8909\n","Epoch 5/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1843 - accuracy: 0.9276 - f1_score: 0.9273 - val_loss: 0.3422 - val_accuracy: 0.8626 - val_f1_score: 0.8489\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1522 - accuracy: 0.9400 - f1_score: 0.9394 - val_loss: 0.3255 - val_accuracy: 0.8879 - val_f1_score: 0.8830\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1135 - accuracy: 0.9569 - f1_score: 0.9567 - val_loss: 0.3830 - val_accuracy: 0.8843 - val_f1_score: 0.8767\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0921 - accuracy: 0.9632 - f1_score: 0.9631 - val_loss: 0.3654 - val_accuracy: 0.8861 - val_f1_score: 0.8857\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0727 - accuracy: 0.9723 - f1_score: 0.9722 - val_loss: 0.6744 - val_accuracy: 0.8445 - val_f1_score: 0.8201\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3069 - accuracy: 0.8758 - f1_score: 0.8978\n","47/47 [==============================] - 2s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 26ms/step - loss: 0.4695 - accuracy: 0.7684 - f1_score: 0.7545 - val_loss: 0.3762 - val_accuracy: 0.8219 - val_f1_score: 0.8118\n","Epoch 2/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.3179 - accuracy: 0.8703 - f1_score: 0.8706 - val_loss: 0.3354 - val_accuracy: 0.8499 - val_f1_score: 0.8466\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2606 - accuracy: 0.8881 - f1_score: 0.8871 - val_loss: 0.3322 - val_accuracy: 0.8590 - val_f1_score: 0.8553\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2163 - accuracy: 0.9162 - f1_score: 0.9158 - val_loss: 0.3273 - val_accuracy: 0.8653 - val_f1_score: 0.8588\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1722 - accuracy: 0.9321 - f1_score: 0.9317 - val_loss: 0.3306 - val_accuracy: 0.8653 - val_f1_score: 0.8659\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1344 - accuracy: 0.9502 - f1_score: 0.9498 - val_loss: 0.4040 - val_accuracy: 0.8852 - val_f1_score: 0.8782\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0992 - accuracy: 0.9656 - f1_score: 0.9654 - val_loss: 0.4299 - val_accuracy: 0.8734 - val_f1_score: 0.8659\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0782 - accuracy: 0.9723 - f1_score: 0.9721 - val_loss: 0.5380 - val_accuracy: 0.8544 - val_f1_score: 0.8453\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0702 - accuracy: 0.9747 - f1_score: 0.9745 - val_loss: 0.4735 - val_accuracy: 0.8761 - val_f1_score: 0.8753\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8690 - f1_score: 0.8911\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 26ms/step - loss: 0.4751 - accuracy: 0.7590 - f1_score: 0.7554 - val_loss: 0.3675 - val_accuracy: 0.8373 - val_f1_score: 0.8315\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3057 - accuracy: 0.8727 - f1_score: 0.8728 - val_loss: 0.3361 - val_accuracy: 0.8571 - val_f1_score: 0.8540\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2540 - accuracy: 0.8945 - f1_score: 0.8936 - val_loss: 0.3328 - val_accuracy: 0.8680 - val_f1_score: 0.8651\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2079 - accuracy: 0.9168 - f1_score: 0.9161 - val_loss: 0.3660 - val_accuracy: 0.8571 - val_f1_score: 0.8475\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1610 - accuracy: 0.9400 - f1_score: 0.9396 - val_loss: 0.3758 - val_accuracy: 0.8608 - val_f1_score: 0.8579\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9436 - f1_score: 0.9432 - val_loss: 0.3870 - val_accuracy: 0.8635 - val_f1_score: 0.8611\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0906 - accuracy: 0.9665 - f1_score: 0.9664 - val_loss: 0.4656 - val_accuracy: 0.8734 - val_f1_score: 0.8720\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0761 - accuracy: 0.9744 - f1_score: 0.9743 - val_loss: 0.6259 - val_accuracy: 0.8499 - val_f1_score: 0.8395\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8778 - f1_score: 0.8987\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 22ms/step - loss: 0.4946 - accuracy: 0.7630 - f1_score: 0.7688 - val_loss: 0.3757 - val_accuracy: 0.8056 - val_f1_score: 0.7826\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3257 - accuracy: 0.8634 - f1_score: 0.8608 - val_loss: 0.3233 - val_accuracy: 0.8463 - val_f1_score: 0.8378\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2702 - accuracy: 0.8963 - f1_score: 0.8952 - val_loss: 0.3233 - val_accuracy: 0.8689 - val_f1_score: 0.8729\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2232 - accuracy: 0.9107 - f1_score: 0.9088 - val_loss: 0.3123 - val_accuracy: 0.8716 - val_f1_score: 0.8692\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1797 - accuracy: 0.9306 - f1_score: 0.9294 - val_loss: 0.3211 - val_accuracy: 0.8716 - val_f1_score: 0.8655\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1476 - accuracy: 0.9448 - f1_score: 0.9438 - val_loss: 0.3382 - val_accuracy: 0.8707 - val_f1_score: 0.8647\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1105 - accuracy: 0.9563 - f1_score: 0.9556 - val_loss: 0.3922 - val_accuracy: 0.8725 - val_f1_score: 0.8683\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0980 - accuracy: 0.9647 - f1_score: 0.9643 - val_loss: 0.4959 - val_accuracy: 0.8463 - val_f1_score: 0.8320\n","Epoch 9/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0649 - accuracy: 0.9774 - f1_score: 0.9772 - val_loss: 0.6261 - val_accuracy: 0.8671 - val_f1_score: 0.8774\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8785 - f1_score: 0.8996\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 22ms/step - loss: 0.4768 - accuracy: 0.7675 - f1_score: 0.7698 - val_loss: 0.3332 - val_accuracy: 0.8608 - val_f1_score: 0.8566\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3254 - accuracy: 0.8592 - f1_score: 0.8581 - val_loss: 0.3032 - val_accuracy: 0.8698 - val_f1_score: 0.8652\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2780 - accuracy: 0.8875 - f1_score: 0.8852 - val_loss: 0.3098 - val_accuracy: 0.8644 - val_f1_score: 0.8524\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2229 - accuracy: 0.9098 - f1_score: 0.9091 - val_loss: 0.2891 - val_accuracy: 0.8834 - val_f1_score: 0.8786\n","Epoch 5/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1797 - accuracy: 0.9309 - f1_score: 0.9302 - val_loss: 0.3178 - val_accuracy: 0.8743 - val_f1_score: 0.8775\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1450 - accuracy: 0.9454 - f1_score: 0.9451 - val_loss: 0.3369 - val_accuracy: 0.8816 - val_f1_score: 0.8754\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1081 - accuracy: 0.9599 - f1_score: 0.9597 - val_loss: 0.3801 - val_accuracy: 0.8797 - val_f1_score: 0.8754\n","Epoch 8/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0832 - accuracy: 0.9689 - f1_score: 0.9688 - val_loss: 0.4114 - val_accuracy: 0.8779 - val_f1_score: 0.8776\n","Epoch 9/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0582 - accuracy: 0.9795 - f1_score: 0.9795 - val_loss: 0.5434 - val_accuracy: 0.8617 - val_f1_score: 0.8561\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3088 - accuracy: 0.8737 - f1_score: 0.8941\n","47/47 [==============================] - 2s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 30ms/step - loss: 0.4891 - accuracy: 0.7545 - f1_score: 0.7538 - val_loss: 0.3543 - val_accuracy: 0.8427 - val_f1_score: 0.8484\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3131 - accuracy: 0.8646 - f1_score: 0.8630 - val_loss: 0.3190 - val_accuracy: 0.8562 - val_f1_score: 0.8504\n","Epoch 3/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.2616 - accuracy: 0.8972 - f1_score: 0.8960 - val_loss: 0.3008 - val_accuracy: 0.8707 - val_f1_score: 0.8660\n","Epoch 4/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.2132 - accuracy: 0.9162 - f1_score: 0.9153 - val_loss: 0.3068 - val_accuracy: 0.8689 - val_f1_score: 0.8646\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1767 - accuracy: 0.9334 - f1_score: 0.9329 - val_loss: 0.3169 - val_accuracy: 0.8807 - val_f1_score: 0.8802\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1331 - accuracy: 0.9502 - f1_score: 0.9502 - val_loss: 0.3610 - val_accuracy: 0.8752 - val_f1_score: 0.8681\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0994 - accuracy: 0.9677 - f1_score: 0.9675 - val_loss: 0.4531 - val_accuracy: 0.8590 - val_f1_score: 0.8651\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0778 - accuracy: 0.9747 - f1_score: 0.9745 - val_loss: 0.4269 - val_accuracy: 0.8861 - val_f1_score: 0.8859\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8494 - f1_score: 0.8722\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 22ms/step - loss: 0.4835 - accuracy: 0.7630 - f1_score: 0.7593 - val_loss: 0.3312 - val_accuracy: 0.8698 - val_f1_score: 0.8712\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3069 - accuracy: 0.8682 - f1_score: 0.8675 - val_loss: 0.3199 - val_accuracy: 0.8752 - val_f1_score: 0.8705\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2626 - accuracy: 0.8938 - f1_score: 0.8927 - val_loss: 0.2984 - val_accuracy: 0.8770 - val_f1_score: 0.8719\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2091 - accuracy: 0.9147 - f1_score: 0.9132 - val_loss: 0.3439 - val_accuracy: 0.8807 - val_f1_score: 0.8836\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9412 - f1_score: 0.9406 - val_loss: 0.3080 - val_accuracy: 0.8807 - val_f1_score: 0.8762\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1244 - accuracy: 0.9551 - f1_score: 0.9548 - val_loss: 0.3984 - val_accuracy: 0.8852 - val_f1_score: 0.8865\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1118 - accuracy: 0.9605 - f1_score: 0.9603 - val_loss: 0.3548 - val_accuracy: 0.8825 - val_f1_score: 0.8833\n","Epoch 8/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0642 - accuracy: 0.9792 - f1_score: 0.9791 - val_loss: 0.4852 - val_accuracy: 0.8797 - val_f1_score: 0.8788\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.8413 - f1_score: 0.8641\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 28ms/step - loss: 0.4864 - accuracy: 0.7473 - f1_score: 0.7398 - val_loss: 0.3669 - val_accuracy: 0.8363 - val_f1_score: 0.8380\n","Epoch 2/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.3089 - accuracy: 0.8733 - f1_score: 0.8716 - val_loss: 0.3277 - val_accuracy: 0.8635 - val_f1_score: 0.8590\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2557 - accuracy: 0.8963 - f1_score: 0.8949 - val_loss: 0.3329 - val_accuracy: 0.8626 - val_f1_score: 0.8636\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2200 - accuracy: 0.9150 - f1_score: 0.9141 - val_loss: 0.3219 - val_accuracy: 0.8734 - val_f1_score: 0.8669\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1734 - accuracy: 0.9385 - f1_score: 0.9380 - val_loss: 0.3365 - val_accuracy: 0.8725 - val_f1_score: 0.8749\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1381 - accuracy: 0.9436 - f1_score: 0.9432 - val_loss: 0.3361 - val_accuracy: 0.8743 - val_f1_score: 0.8709\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1020 - accuracy: 0.9638 - f1_score: 0.9635 - val_loss: 0.3965 - val_accuracy: 0.8725 - val_f1_score: 0.8735\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0842 - accuracy: 0.9704 - f1_score: 0.9703 - val_loss: 0.3895 - val_accuracy: 0.8779 - val_f1_score: 0.8711\n","Epoch 9/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0606 - accuracy: 0.9777 - f1_score: 0.9776 - val_loss: 0.5307 - val_accuracy: 0.8716 - val_f1_score: 0.8767\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8589 - f1_score: 0.8808\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 23ms/step - loss: 0.4610 - accuracy: 0.7750 - f1_score: 0.7695 - val_loss: 0.3639 - val_accuracy: 0.8345 - val_f1_score: 0.8269\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3040 - accuracy: 0.8785 - f1_score: 0.8775 - val_loss: 0.3450 - val_accuracy: 0.8517 - val_f1_score: 0.8417\n","Epoch 3/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.2460 - accuracy: 0.8978 - f1_score: 0.8957 - val_loss: 0.4129 - val_accuracy: 0.8309 - val_f1_score: 0.8443\n","Epoch 4/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.2019 - accuracy: 0.9183 - f1_score: 0.9176 - val_loss: 0.3465 - val_accuracy: 0.8617 - val_f1_score: 0.8563\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1527 - accuracy: 0.9394 - f1_score: 0.9387 - val_loss: 0.3941 - val_accuracy: 0.8508 - val_f1_score: 0.8352\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1174 - accuracy: 0.9560 - f1_score: 0.9555 - val_loss: 0.4406 - val_accuracy: 0.8571 - val_f1_score: 0.8566\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0911 - accuracy: 0.9683 - f1_score: 0.9681 - val_loss: 0.4420 - val_accuracy: 0.8689 - val_f1_score: 0.8681\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8339 - f1_score: 0.8553\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 23ms/step - loss: 0.4960 - accuracy: 0.7530 - f1_score: 0.7383 - val_loss: 0.3560 - val_accuracy: 0.8400 - val_f1_score: 0.8303\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3194 - accuracy: 0.8718 - f1_score: 0.8711 - val_loss: 0.3339 - val_accuracy: 0.8562 - val_f1_score: 0.8455\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2506 - accuracy: 0.8993 - f1_score: 0.8980 - val_loss: 0.3191 - val_accuracy: 0.8626 - val_f1_score: 0.8643\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2079 - accuracy: 0.9195 - f1_score: 0.9189 - val_loss: 0.3054 - val_accuracy: 0.8834 - val_f1_score: 0.8849\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1701 - accuracy: 0.9334 - f1_score: 0.9328 - val_loss: 0.3230 - val_accuracy: 0.8662 - val_f1_score: 0.8580\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1279 - accuracy: 0.9575 - f1_score: 0.9571 - val_loss: 0.3987 - val_accuracy: 0.8761 - val_f1_score: 0.8826\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1201 - accuracy: 0.9554 - f1_score: 0.9551 - val_loss: 0.3675 - val_accuracy: 0.8825 - val_f1_score: 0.8816\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0798 - accuracy: 0.9720 - f1_score: 0.9718 - val_loss: 0.4051 - val_accuracy: 0.8852 - val_f1_score: 0.8867\n","Epoch 9/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0547 - accuracy: 0.9825 - f1_score: 0.9824 - val_loss: 0.4920 - val_accuracy: 0.8797 - val_f1_score: 0.8779\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3130 - accuracy: 0.8744 - f1_score: 0.8978\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 22ms/step - loss: 0.4762 - accuracy: 0.7642 - f1_score: 0.7635 - val_loss: 0.3529 - val_accuracy: 0.8490 - val_f1_score: 0.8510\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3096 - accuracy: 0.8688 - f1_score: 0.8689 - val_loss: 0.3479 - val_accuracy: 0.8590 - val_f1_score: 0.8664\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2597 - accuracy: 0.8926 - f1_score: 0.8924 - val_loss: 0.3147 - val_accuracy: 0.8544 - val_f1_score: 0.8474\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2125 - accuracy: 0.9113 - f1_score: 0.9100 - val_loss: 0.3431 - val_accuracy: 0.8716 - val_f1_score: 0.8685\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1696 - accuracy: 0.9337 - f1_score: 0.9330 - val_loss: 0.3637 - val_accuracy: 0.8626 - val_f1_score: 0.8521\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1230 - accuracy: 0.9533 - f1_score: 0.9530 - val_loss: 0.3891 - val_accuracy: 0.8716 - val_f1_score: 0.8648\n","Epoch 7/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0982 - accuracy: 0.9629 - f1_score: 0.9626 - val_loss: 0.4161 - val_accuracy: 0.8788 - val_f1_score: 0.8780\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0700 - accuracy: 0.9738 - f1_score: 0.9737 - val_loss: 0.5024 - val_accuracy: 0.8807 - val_f1_score: 0.8836\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3246 - accuracy: 0.8474 - f1_score: 0.8720\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 22ms/step - loss: 0.4948 - accuracy: 0.7636 - f1_score: 0.7545 - val_loss: 0.3669 - val_accuracy: 0.8336 - val_f1_score: 0.8321\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3106 - accuracy: 0.8724 - f1_score: 0.8706 - val_loss: 0.3392 - val_accuracy: 0.8544 - val_f1_score: 0.8571\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2501 - accuracy: 0.8996 - f1_score: 0.8995 - val_loss: 0.3224 - val_accuracy: 0.8644 - val_f1_score: 0.8711\n","Epoch 4/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2121 - accuracy: 0.9156 - f1_score: 0.9149 - val_loss: 0.3170 - val_accuracy: 0.8797 - val_f1_score: 0.8781\n","Epoch 5/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1739 - accuracy: 0.9331 - f1_score: 0.9325 - val_loss: 0.3314 - val_accuracy: 0.8644 - val_f1_score: 0.8711\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1265 - accuracy: 0.9533 - f1_score: 0.9528 - val_loss: 0.4485 - val_accuracy: 0.8635 - val_f1_score: 0.8721\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1088 - accuracy: 0.9596 - f1_score: 0.9592 - val_loss: 0.3972 - val_accuracy: 0.8788 - val_f1_score: 0.8816\n","Epoch 8/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0661 - accuracy: 0.9780 - f1_score: 0.9779 - val_loss: 0.4928 - val_accuracy: 0.8743 - val_f1_score: 0.8767\n","Epoch 9/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0583 - accuracy: 0.9810 - f1_score: 0.9809 - val_loss: 0.6812 - val_accuracy: 0.8626 - val_f1_score: 0.8710\n","47/47 [==============================] - 0s 8ms/step - loss: 0.3431 - accuracy: 0.8602 - f1_score: 0.8808\n","47/47 [==============================] - 2s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 30ms/step - loss: 0.4808 - accuracy: 0.7702 - f1_score: 0.7595 - val_loss: 0.3358 - val_accuracy: 0.8608 - val_f1_score: 0.8668\n","Epoch 2/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.3225 - accuracy: 0.8676 - f1_score: 0.8678 - val_loss: 0.2879 - val_accuracy: 0.8725 - val_f1_score: 0.8733\n","Epoch 3/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.2655 - accuracy: 0.8914 - f1_score: 0.8900 - val_loss: 0.2744 - val_accuracy: 0.8843 - val_f1_score: 0.8855\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2177 - accuracy: 0.9098 - f1_score: 0.9098 - val_loss: 0.2846 - val_accuracy: 0.8807 - val_f1_score: 0.8780\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1733 - accuracy: 0.9331 - f1_score: 0.9325 - val_loss: 0.2896 - val_accuracy: 0.8897 - val_f1_score: 0.8932\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1275 - accuracy: 0.9527 - f1_score: 0.9525 - val_loss: 0.3192 - val_accuracy: 0.8915 - val_f1_score: 0.8951\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0933 - accuracy: 0.9674 - f1_score: 0.9674 - val_loss: 0.3555 - val_accuracy: 0.8897 - val_f1_score: 0.8899\n","Epoch 8/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0708 - accuracy: 0.9768 - f1_score: 0.9767 - val_loss: 0.4035 - val_accuracy: 0.8897 - val_f1_score: 0.8893\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8798 - f1_score: 0.9012\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 23ms/step - loss: 0.4731 - accuracy: 0.7669 - f1_score: 0.7553 - val_loss: 0.3374 - val_accuracy: 0.8490 - val_f1_score: 0.8531\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3007 - accuracy: 0.8706 - f1_score: 0.8701 - val_loss: 0.3100 - val_accuracy: 0.8608 - val_f1_score: 0.8695\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2442 - accuracy: 0.8951 - f1_score: 0.8952 - val_loss: 0.2842 - val_accuracy: 0.8807 - val_f1_score: 0.8759\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9159 - f1_score: 0.9154 - val_loss: 0.2751 - val_accuracy: 0.8807 - val_f1_score: 0.8771\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9400 - f1_score: 0.9397 - val_loss: 0.2825 - val_accuracy: 0.8906 - val_f1_score: 0.8911\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1409 - accuracy: 0.9484 - f1_score: 0.9480 - val_loss: 0.3118 - val_accuracy: 0.8897 - val_f1_score: 0.8924\n","Epoch 7/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0904 - accuracy: 0.9677 - f1_score: 0.9677 - val_loss: 0.3340 - val_accuracy: 0.8960 - val_f1_score: 0.8940\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0754 - accuracy: 0.9750 - f1_score: 0.9749 - val_loss: 0.3905 - val_accuracy: 0.8843 - val_f1_score: 0.8881\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0586 - accuracy: 0.9822 - f1_score: 0.9822 - val_loss: 0.3986 - val_accuracy: 0.8825 - val_f1_score: 0.8856\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8447 - f1_score: 0.8669\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 23ms/step - loss: 0.4891 - accuracy: 0.7618 - f1_score: 0.7646 - val_loss: 0.3511 - val_accuracy: 0.8454 - val_f1_score: 0.8315\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3175 - accuracy: 0.8619 - f1_score: 0.8593 - val_loss: 0.2990 - val_accuracy: 0.8680 - val_f1_score: 0.8646\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2563 - accuracy: 0.8923 - f1_score: 0.8903 - val_loss: 0.3226 - val_accuracy: 0.8761 - val_f1_score: 0.8816\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2113 - accuracy: 0.9144 - f1_score: 0.9131 - val_loss: 0.3454 - val_accuracy: 0.8807 - val_f1_score: 0.8860\n","Epoch 5/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1620 - accuracy: 0.9391 - f1_score: 0.9385 - val_loss: 0.3161 - val_accuracy: 0.8807 - val_f1_score: 0.8773\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1265 - accuracy: 0.9505 - f1_score: 0.9500 - val_loss: 0.3767 - val_accuracy: 0.8788 - val_f1_score: 0.8814\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0965 - accuracy: 0.9686 - f1_score: 0.9684 - val_loss: 0.4522 - val_accuracy: 0.8788 - val_f1_score: 0.8801\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8501 - f1_score: 0.8714\n","47/47 [==============================] - 2s 5ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5lr6hoixKue","executionInfo":{"status":"ok","timestamp":1697624867160,"user_tz":-330,"elapsed":66,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"2e66baa1-de84-40be-a1f2-746c38c27509"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8784605264663696, 0.876434862613678, 0.8710330724716187, 0.8656313419342041, 0.8757596015930176, 0.844699501991272, 0.8541526198387146, 0.8379473090171814, 0.8663065433502197, 0.8649561405181885, 0.8757596015930176, 0.869007408618927, 0.8777852654457092, 0.8784605264663696, 0.8737339377403259, 0.8494260907173157, 0.8413234353065491, 0.8588791489601135, 0.8338960409164429, 0.8744091987609863, 0.847400426864624, 0.8602295517921448, 0.8798109292984009, 0.844699501991272, 0.8501012921333313]\n","0.8620121550559997\n","0.014338684346485631\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXLhS31xxK4W","executionInfo":{"status":"ok","timestamp":1697624867160,"user_tz":-330,"elapsed":61,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6578cf9b-7c66-466a-bffe-f367396bd67e"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.2856077253818512, 0.2924412488937378, 0.31024280190467834, 0.3047018051147461, 0.3131870627403259, 0.34166643023490906, 0.36153513193130493, 0.3807147145271301, 0.3332062363624573, 0.3301382064819336, 0.3068511486053467, 0.32701271772384644, 0.31096091866493225, 0.3091809153556824, 0.3087543249130249, 0.3467211127281189, 0.35676273703575134, 0.34690147638320923, 0.36975163221359253, 0.31299710273742676, 0.3245975375175476, 0.3431488275527954, 0.2921034097671509, 0.348874568939209, 0.3345244526863098]\n","0.3277033698558807\n","0.024684550603873864\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37uYqTYgxLCf","executionInfo":{"status":"ok","timestamp":1697624867161,"user_tz":-330,"elapsed":56,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"92c0596d-058e-41d4-cdcb-94b595df0638"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.9004424214363098, 0.8974789381027222, 0.892029345035553, 0.8867387175559998, 0.8956915140151978, 0.8675114512443542, 0.8762885928153992, 0.8607887625694275, 0.8928571343421936, 0.8877664804458618, 0.8977777361869812, 0.8911335468292236, 0.8987128734588623, 0.8995535373687744, 0.8940508961677551, 0.8722062706947327, 0.8640832304954529, 0.8807756900787354, 0.8552939891815186, 0.8978021740913391, 0.8720271587371826, 0.8808289170265198, 0.9012207984924316, 0.8668981194496155, 0.8713788390159607]\n","0.8840534853935241\n","0.013979850540140174\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7so9hERxLLw","executionInfo":{"status":"ok","timestamp":1697624867161,"user_tz":-330,"elapsed":51,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"0fe5c9ba-e74a-43c6-ea0c-0a6106a98865"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.7464764600453927, 0.7463470775418937, 0.7383724088843583, 0.7298457349793346, 0.749337106311035, 0.6916429114663031, 0.7086637099458319, 0.6809609606759072, 0.7151754920709111, 0.7229245381032716, 0.7421506051887887, 0.7314002669361872, 0.7487874307423505, 0.7492601024447404, 0.7448902431820513, 0.6990944062192139, 0.6865532568462615, 0.7167510377559299, 0.679768418111, 0.7360633445044071, 0.6897483819187364, 0.7236190695217359, 0.7503176295047613, 0.6938345350806772, 0.7055958920053104]\n","0.7211032407994555\n","0.023879560624336573\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"52m502p8xLot","executionInfo":{"status":"ok","timestamp":1697622878385,"user_tz":-330,"elapsed":53,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["Emb A\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.872/0.007\n","2. Loss - 0.300/0.019\n","3. F1 score - 0.894/0.007\n","4. MCC - 0.738/0.012\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.870/0.011\n","2. Loss - 0.302/0.018\n","3. F1 score - 0.892/0.011\n","4. MCC - 0.734/0.019"],"metadata":{"id":"b5KbSTnmxL2C"}},{"cell_type":"markdown","source":["Emb E\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.854/0.007\n","2. Loss - 0.340/0.009\n","3. F1 score - 0.878/0.007\n","4. MCC - 0.700/0.013\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.855/0.007\n","2. Loss - 0.337/0.010\n","3. F1 score - 0.879/0.006\n","4. MCC - 0.702/0.014"],"metadata":{"id":"-U0X2er9xMAG"}},{"cell_type":"markdown","source":["Emb H\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.856/0.013\n","2. Loss - 0.328/0.020\n","3. F1 score - 0.879/0.015\n","4. MCC - 0.710/0.018\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.858/0.009\n","2. Loss - 0.325/0.020\n","3. F1 score - 0.881/0.011\n","4. MCC - 0.711/0.012"],"metadata":{"id":"OPY0YI6gxMLb"}},{"cell_type":"markdown","source":["Emb I\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.864/0.008\n","2. Loss - 0.318/0.016\n","3. F1 score - 0.887/0.008\n","4. MCC - 0.722/0.016\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.862/0.014\n","2. Loss - 0.327/0.024\n","3. F1 score - 0.884/0.013\n","4. MCC - 0.721/0.023"],"metadata":{"id":"WM_-iSKwxMVj"}},{"cell_type":"code","source":[],"metadata":{"id":"5vq9bIJhXo72"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNN layer to emotions with maxpooling (pool size 3 and stride 1) (without additional LSTM layer in emotions)"],"metadata":{"id":"QQQp6VDqYZDq"}},{"cell_type":"code","source":["# LSTM CNN nothing nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=3, strides=1)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        #cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))  # cnn_emotions returns length 3072, ie cnn_emotions.shape[1] = 3072\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_emotions, input_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rcb6XG3gYb6G","executionInfo":{"status":"ok","timestamp":1697705757748,"user_tz":-330,"elapsed":420810,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"b13a8922-c67d-4884-85ba-9d700ae7f4fe"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 5s 14ms/step - loss: 0.4850 - accuracy: 0.7584 - f1_score: 0.7566 - val_loss: 0.3727 - val_accuracy: 0.8291 - val_f1_score: 0.8174\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3059 - accuracy: 0.8721 - f1_score: 0.8717 - val_loss: 0.3316 - val_accuracy: 0.8499 - val_f1_score: 0.8407\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2539 - accuracy: 0.8963 - f1_score: 0.8955 - val_loss: 0.3399 - val_accuracy: 0.8499 - val_f1_score: 0.8353\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2125 - accuracy: 0.9213 - f1_score: 0.9207 - val_loss: 0.3382 - val_accuracy: 0.8590 - val_f1_score: 0.8537\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1743 - accuracy: 0.9388 - f1_score: 0.9387 - val_loss: 0.3592 - val_accuracy: 0.8599 - val_f1_score: 0.8497\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1400 - accuracy: 0.9499 - f1_score: 0.9497 - val_loss: 0.3985 - val_accuracy: 0.8508 - val_f1_score: 0.8400\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1133 - accuracy: 0.9575 - f1_score: 0.9571 - val_loss: 0.4290 - val_accuracy: 0.8580 - val_f1_score: 0.8495\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8562 - f1_score: 0.8762\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4970 - accuracy: 0.7494 - f1_score: 0.7459 - val_loss: 0.3493 - val_accuracy: 0.8526 - val_f1_score: 0.8514\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3218 - accuracy: 0.8637 - f1_score: 0.8636 - val_loss: 0.3226 - val_accuracy: 0.8662 - val_f1_score: 0.8676\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2576 - accuracy: 0.8954 - f1_score: 0.8957 - val_loss: 0.3064 - val_accuracy: 0.8707 - val_f1_score: 0.8684\n","Epoch 4/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2196 - accuracy: 0.9141 - f1_score: 0.9139 - val_loss: 0.3319 - val_accuracy: 0.8580 - val_f1_score: 0.8483\n","Epoch 5/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1730 - accuracy: 0.9367 - f1_score: 0.9367 - val_loss: 0.3202 - val_accuracy: 0.8553 - val_f1_score: 0.8592\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1444 - accuracy: 0.9475 - f1_score: 0.9474 - val_loss: 0.3204 - val_accuracy: 0.8816 - val_f1_score: 0.8777\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1120 - accuracy: 0.9608 - f1_score: 0.9607 - val_loss: 0.3796 - val_accuracy: 0.8761 - val_f1_score: 0.8730\n","Epoch 8/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.0882 - accuracy: 0.9704 - f1_score: 0.9704 - val_loss: 0.3999 - val_accuracy: 0.8698 - val_f1_score: 0.8610\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3136 - accuracy: 0.8683 - f1_score: 0.8890\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 23ms/step - loss: 0.4902 - accuracy: 0.7642 - f1_score: 0.7588 - val_loss: 0.3508 - val_accuracy: 0.8427 - val_f1_score: 0.8362\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3259 - accuracy: 0.8625 - f1_score: 0.8623 - val_loss: 0.3230 - val_accuracy: 0.8472 - val_f1_score: 0.8482\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2667 - accuracy: 0.8863 - f1_score: 0.8859 - val_loss: 0.3088 - val_accuracy: 0.8725 - val_f1_score: 0.8674\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2161 - accuracy: 0.9128 - f1_score: 0.9126 - val_loss: 0.3080 - val_accuracy: 0.8689 - val_f1_score: 0.8661\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1794 - accuracy: 0.9309 - f1_score: 0.9305 - val_loss: 0.3226 - val_accuracy: 0.8743 - val_f1_score: 0.8738\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1385 - accuracy: 0.9472 - f1_score: 0.9469 - val_loss: 0.3934 - val_accuracy: 0.8517 - val_f1_score: 0.8357\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1183 - accuracy: 0.9514 - f1_score: 0.9506 - val_loss: 0.4043 - val_accuracy: 0.8716 - val_f1_score: 0.8707\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0787 - accuracy: 0.9686 - f1_score: 0.9685 - val_loss: 0.5370 - val_accuracy: 0.8707 - val_f1_score: 0.8652\n","Epoch 9/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0671 - accuracy: 0.9762 - f1_score: 0.9761 - val_loss: 0.5239 - val_accuracy: 0.8626 - val_f1_score: 0.8574\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.8758 - f1_score: 0.8957\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 20ms/step - loss: 0.4708 - accuracy: 0.7663 - f1_score: 0.7588 - val_loss: 0.3488 - val_accuracy: 0.8590 - val_f1_score: 0.8579\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3152 - accuracy: 0.8613 - f1_score: 0.8605 - val_loss: 0.3214 - val_accuracy: 0.8580 - val_f1_score: 0.8500\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2530 - accuracy: 0.8957 - f1_score: 0.8952 - val_loss: 0.2956 - val_accuracy: 0.8761 - val_f1_score: 0.8756\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2175 - accuracy: 0.9080 - f1_score: 0.9077 - val_loss: 0.3219 - val_accuracy: 0.8752 - val_f1_score: 0.8686\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1728 - accuracy: 0.9364 - f1_score: 0.9362 - val_loss: 0.3378 - val_accuracy: 0.8725 - val_f1_score: 0.8715\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1271 - accuracy: 0.9530 - f1_score: 0.9526 - val_loss: 0.3731 - val_accuracy: 0.8788 - val_f1_score: 0.8793\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1145 - accuracy: 0.9569 - f1_score: 0.9569 - val_loss: 0.4045 - val_accuracy: 0.8761 - val_f1_score: 0.8787\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0906 - accuracy: 0.9677 - f1_score: 0.9677 - val_loss: 0.4139 - val_accuracy: 0.8852 - val_f1_score: 0.8842\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.8710 - f1_score: 0.8915\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4822 - accuracy: 0.7603 - f1_score: 0.7597 - val_loss: 0.3493 - val_accuracy: 0.8391 - val_f1_score: 0.8358\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3304 - accuracy: 0.8628 - f1_score: 0.8631 - val_loss: 0.3107 - val_accuracy: 0.8544 - val_f1_score: 0.8538\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2617 - accuracy: 0.8945 - f1_score: 0.8937 - val_loss: 0.3057 - val_accuracy: 0.8635 - val_f1_score: 0.8643\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2314 - accuracy: 0.9083 - f1_score: 0.9077 - val_loss: 0.3390 - val_accuracy: 0.8535 - val_f1_score: 0.8367\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1861 - accuracy: 0.9340 - f1_score: 0.9334 - val_loss: 0.3051 - val_accuracy: 0.8779 - val_f1_score: 0.8783\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1417 - accuracy: 0.9481 - f1_score: 0.9480 - val_loss: 0.3772 - val_accuracy: 0.8689 - val_f1_score: 0.8651\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1146 - accuracy: 0.9587 - f1_score: 0.9585 - val_loss: 0.4198 - val_accuracy: 0.8662 - val_f1_score: 0.8722\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0785 - accuracy: 0.9741 - f1_score: 0.9740 - val_loss: 0.4678 - val_accuracy: 0.8689 - val_f1_score: 0.8656\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0650 - accuracy: 0.9774 - f1_score: 0.9773 - val_loss: 0.4786 - val_accuracy: 0.8743 - val_f1_score: 0.8714\n","Epoch 10/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0484 - accuracy: 0.9834 - f1_score: 0.9833 - val_loss: 0.5435 - val_accuracy: 0.8752 - val_f1_score: 0.8743\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8724 - f1_score: 0.8918\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4992 - accuracy: 0.7470 - f1_score: 0.7361 - val_loss: 0.3728 - val_accuracy: 0.8373 - val_f1_score: 0.8396\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3112 - accuracy: 0.8742 - f1_score: 0.8734 - val_loss: 0.3275 - val_accuracy: 0.8499 - val_f1_score: 0.8541\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2522 - accuracy: 0.9008 - f1_score: 0.8996 - val_loss: 0.3156 - val_accuracy: 0.8608 - val_f1_score: 0.8582\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1987 - accuracy: 0.9240 - f1_score: 0.9231 - val_loss: 0.3215 - val_accuracy: 0.8635 - val_f1_score: 0.8643\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9412 - f1_score: 0.9404 - val_loss: 0.3131 - val_accuracy: 0.8698 - val_f1_score: 0.8659\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1338 - accuracy: 0.9502 - f1_score: 0.9498 - val_loss: 0.4955 - val_accuracy: 0.8481 - val_f1_score: 0.8588\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0977 - accuracy: 0.9659 - f1_score: 0.9657 - val_loss: 0.4190 - val_accuracy: 0.8698 - val_f1_score: 0.8684\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0808 - accuracy: 0.9717 - f1_score: 0.9715 - val_loss: 0.4666 - val_accuracy: 0.8752 - val_f1_score: 0.8729\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0626 - accuracy: 0.9777 - f1_score: 0.9776 - val_loss: 0.5212 - val_accuracy: 0.8617 - val_f1_score: 0.8635\n","Epoch 10/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.0554 - accuracy: 0.9804 - f1_score: 0.9804 - val_loss: 0.5047 - val_accuracy: 0.8761 - val_f1_score: 0.8758\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8515 - f1_score: 0.8739\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4900 - accuracy: 0.7527 - f1_score: 0.7326 - val_loss: 0.3820 - val_accuracy: 0.8273 - val_f1_score: 0.8314\n","Epoch 2/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.3066 - accuracy: 0.8691 - f1_score: 0.8685 - val_loss: 0.3443 - val_accuracy: 0.8436 - val_f1_score: 0.8454\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2535 - accuracy: 0.8975 - f1_score: 0.8968 - val_loss: 0.3276 - val_accuracy: 0.8526 - val_f1_score: 0.8484\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2075 - accuracy: 0.9213 - f1_score: 0.9209 - val_loss: 0.3264 - val_accuracy: 0.8599 - val_f1_score: 0.8536\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1630 - accuracy: 0.9406 - f1_score: 0.9403 - val_loss: 0.3420 - val_accuracy: 0.8635 - val_f1_score: 0.8582\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1347 - accuracy: 0.9508 - f1_score: 0.9506 - val_loss: 0.3647 - val_accuracy: 0.8626 - val_f1_score: 0.8558\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0959 - accuracy: 0.9665 - f1_score: 0.9664 - val_loss: 0.4531 - val_accuracy: 0.8562 - val_f1_score: 0.8521\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0921 - accuracy: 0.9668 - f1_score: 0.9667 - val_loss: 0.4520 - val_accuracy: 0.8689 - val_f1_score: 0.8610\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0604 - accuracy: 0.9789 - f1_score: 0.9788 - val_loss: 0.5130 - val_accuracy: 0.8580 - val_f1_score: 0.8604\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8528 - f1_score: 0.8749\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.5174 - accuracy: 0.7349 - f1_score: 0.7156 - val_loss: 0.3609 - val_accuracy: 0.8454 - val_f1_score: 0.8388\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3205 - accuracy: 0.8634 - f1_score: 0.8601 - val_loss: 0.3506 - val_accuracy: 0.8454 - val_f1_score: 0.8488\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2641 - accuracy: 0.8869 - f1_score: 0.8853 - val_loss: 0.3540 - val_accuracy: 0.8454 - val_f1_score: 0.8315\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2134 - accuracy: 0.9150 - f1_score: 0.9140 - val_loss: 0.3413 - val_accuracy: 0.8626 - val_f1_score: 0.8667\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1880 - accuracy: 0.9285 - f1_score: 0.9274 - val_loss: 0.3389 - val_accuracy: 0.8698 - val_f1_score: 0.8649\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1335 - accuracy: 0.9487 - f1_score: 0.9482 - val_loss: 0.3925 - val_accuracy: 0.8680 - val_f1_score: 0.8620\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1086 - accuracy: 0.9644 - f1_score: 0.9642 - val_loss: 0.3992 - val_accuracy: 0.8725 - val_f1_score: 0.8698\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0834 - accuracy: 0.9698 - f1_score: 0.9697 - val_loss: 0.4802 - val_accuracy: 0.8725 - val_f1_score: 0.8742\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0611 - accuracy: 0.9777 - f1_score: 0.9776 - val_loss: 0.5460 - val_accuracy: 0.8743 - val_f1_score: 0.8709\n","Epoch 10/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0580 - accuracy: 0.9816 - f1_score: 0.9816 - val_loss: 0.5819 - val_accuracy: 0.8716 - val_f1_score: 0.8709\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8582 - f1_score: 0.8793\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.5025 - accuracy: 0.7407 - f1_score: 0.7342 - val_loss: 0.3500 - val_accuracy: 0.8562 - val_f1_score: 0.8609\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3226 - accuracy: 0.8619 - f1_score: 0.8610 - val_loss: 0.3101 - val_accuracy: 0.8644 - val_f1_score: 0.8649\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2592 - accuracy: 0.8941 - f1_score: 0.8942 - val_loss: 0.2965 - val_accuracy: 0.8743 - val_f1_score: 0.8751\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2165 - accuracy: 0.9138 - f1_score: 0.9136 - val_loss: 0.3236 - val_accuracy: 0.8834 - val_f1_score: 0.8837\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1753 - accuracy: 0.9300 - f1_score: 0.9298 - val_loss: 0.3851 - val_accuracy: 0.8644 - val_f1_score: 0.8538\n","Epoch 6/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1342 - accuracy: 0.9463 - f1_score: 0.9462 - val_loss: 0.3383 - val_accuracy: 0.8797 - val_f1_score: 0.8765\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0986 - accuracy: 0.9647 - f1_score: 0.9646 - val_loss: 0.4192 - val_accuracy: 0.8816 - val_f1_score: 0.8814\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0927 - accuracy: 0.9650 - f1_score: 0.9651 - val_loss: 0.4962 - val_accuracy: 0.8761 - val_f1_score: 0.8679\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3215 - accuracy: 0.8596 - f1_score: 0.8865\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4789 - accuracy: 0.7714 - f1_score: 0.7729 - val_loss: 0.3952 - val_accuracy: 0.8282 - val_f1_score: 0.8403\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3123 - accuracy: 0.8691 - f1_score: 0.8680 - val_loss: 0.3098 - val_accuracy: 0.8680 - val_f1_score: 0.8701\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2565 - accuracy: 0.8984 - f1_score: 0.8973 - val_loss: 0.3108 - val_accuracy: 0.8779 - val_f1_score: 0.8756\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2124 - accuracy: 0.9086 - f1_score: 0.9078 - val_loss: 0.3052 - val_accuracy: 0.8834 - val_f1_score: 0.8839\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1686 - accuracy: 0.9352 - f1_score: 0.9344 - val_loss: 0.3078 - val_accuracy: 0.8861 - val_f1_score: 0.8857\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1297 - accuracy: 0.9533 - f1_score: 0.9530 - val_loss: 0.3916 - val_accuracy: 0.8644 - val_f1_score: 0.8509\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1031 - accuracy: 0.9629 - f1_score: 0.9626 - val_loss: 0.4219 - val_accuracy: 0.8671 - val_f1_score: 0.8615\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0811 - accuracy: 0.9723 - f1_score: 0.9722 - val_loss: 0.4707 - val_accuracy: 0.8788 - val_f1_score: 0.8780\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0537 - accuracy: 0.9837 - f1_score: 0.9836 - val_loss: 0.4592 - val_accuracy: 0.8825 - val_f1_score: 0.8814\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8717 - f1_score: 0.8966\n","47/47 [==============================] - 0s 2ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.5006 - accuracy: 0.7473 - f1_score: 0.7402 - val_loss: 0.3435 - val_accuracy: 0.8508 - val_f1_score: 0.8554\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3255 - accuracy: 0.8652 - f1_score: 0.8642 - val_loss: 0.2968 - val_accuracy: 0.8752 - val_f1_score: 0.8768\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2693 - accuracy: 0.8869 - f1_score: 0.8859 - val_loss: 0.2856 - val_accuracy: 0.8834 - val_f1_score: 0.8802\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2290 - accuracy: 0.9080 - f1_score: 0.9074 - val_loss: 0.2882 - val_accuracy: 0.8807 - val_f1_score: 0.8757\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1917 - accuracy: 0.9282 - f1_score: 0.9274 - val_loss: 0.3034 - val_accuracy: 0.8897 - val_f1_score: 0.8851\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1511 - accuracy: 0.9430 - f1_score: 0.9424 - val_loss: 0.2960 - val_accuracy: 0.8870 - val_f1_score: 0.8833\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1270 - accuracy: 0.9554 - f1_score: 0.9550 - val_loss: 0.3304 - val_accuracy: 0.8879 - val_f1_score: 0.8835\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0937 - accuracy: 0.9641 - f1_score: 0.9638 - val_loss: 0.4391 - val_accuracy: 0.8870 - val_f1_score: 0.8865\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8710 - f1_score: 0.8914\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4918 - accuracy: 0.7581 - f1_score: 0.7636 - val_loss: 0.3754 - val_accuracy: 0.8291 - val_f1_score: 0.8296\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3187 - accuracy: 0.8616 - f1_score: 0.8615 - val_loss: 0.3932 - val_accuracy: 0.8291 - val_f1_score: 0.8108\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2684 - accuracy: 0.8908 - f1_score: 0.8905 - val_loss: 0.3629 - val_accuracy: 0.8562 - val_f1_score: 0.8642\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2312 - accuracy: 0.9032 - f1_score: 0.9027 - val_loss: 0.3236 - val_accuracy: 0.8635 - val_f1_score: 0.8598\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1913 - accuracy: 0.9246 - f1_score: 0.9236 - val_loss: 0.3468 - val_accuracy: 0.8689 - val_f1_score: 0.8638\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1614 - accuracy: 0.9379 - f1_score: 0.9373 - val_loss: 0.3466 - val_accuracy: 0.8671 - val_f1_score: 0.8620\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1328 - accuracy: 0.9469 - f1_score: 0.9466 - val_loss: 0.3967 - val_accuracy: 0.8508 - val_f1_score: 0.8368\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1010 - accuracy: 0.9617 - f1_score: 0.9616 - val_loss: 0.4181 - val_accuracy: 0.8653 - val_f1_score: 0.8652\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0732 - accuracy: 0.9753 - f1_score: 0.9751 - val_loss: 0.4569 - val_accuracy: 0.8671 - val_f1_score: 0.8596\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8751 - f1_score: 0.8966\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4906 - accuracy: 0.7572 - f1_score: 0.7679 - val_loss: 0.3702 - val_accuracy: 0.8327 - val_f1_score: 0.8317\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3150 - accuracy: 0.8652 - f1_score: 0.8632 - val_loss: 0.3374 - val_accuracy: 0.8517 - val_f1_score: 0.8476\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2810 - accuracy: 0.8815 - f1_score: 0.8801 - val_loss: 0.3293 - val_accuracy: 0.8599 - val_f1_score: 0.8550\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2249 - accuracy: 0.9125 - f1_score: 0.9111 - val_loss: 0.3306 - val_accuracy: 0.8635 - val_f1_score: 0.8663\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1913 - accuracy: 0.9294 - f1_score: 0.9290 - val_loss: 0.3646 - val_accuracy: 0.8689 - val_f1_score: 0.8633\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1513 - accuracy: 0.9400 - f1_score: 0.9392 - val_loss: 0.3728 - val_accuracy: 0.8599 - val_f1_score: 0.8637\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1066 - accuracy: 0.9593 - f1_score: 0.9591 - val_loss: 0.4206 - val_accuracy: 0.8743 - val_f1_score: 0.8712\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0913 - accuracy: 0.9674 - f1_score: 0.9673 - val_loss: 0.5022 - val_accuracy: 0.8599 - val_f1_score: 0.8615\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8737 - f1_score: 0.8942\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4943 - accuracy: 0.7581 - f1_score: 0.7460 - val_loss: 0.3660 - val_accuracy: 0.8400 - val_f1_score: 0.8443\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3357 - accuracy: 0.8619 - f1_score: 0.8603 - val_loss: 0.3407 - val_accuracy: 0.8571 - val_f1_score: 0.8628\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2758 - accuracy: 0.8881 - f1_score: 0.8874 - val_loss: 0.3043 - val_accuracy: 0.8562 - val_f1_score: 0.8535\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2289 - accuracy: 0.9107 - f1_score: 0.9095 - val_loss: 0.3018 - val_accuracy: 0.8689 - val_f1_score: 0.8664\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1900 - accuracy: 0.9228 - f1_score: 0.9220 - val_loss: 0.3262 - val_accuracy: 0.8617 - val_f1_score: 0.8525\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1535 - accuracy: 0.9439 - f1_score: 0.9431 - val_loss: 0.3347 - val_accuracy: 0.8752 - val_f1_score: 0.8683\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1260 - accuracy: 0.9533 - f1_score: 0.9526 - val_loss: 0.3504 - val_accuracy: 0.8752 - val_f1_score: 0.8794\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0974 - accuracy: 0.9629 - f1_score: 0.9626 - val_loss: 0.4105 - val_accuracy: 0.8734 - val_f1_score: 0.8692\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0688 - accuracy: 0.9789 - f1_score: 0.9787 - val_loss: 0.4892 - val_accuracy: 0.8635 - val_f1_score: 0.8641\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8778 - f1_score: 0.8981\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4983 - accuracy: 0.7521 - f1_score: 0.7613 - val_loss: 0.3398 - val_accuracy: 0.8608 - val_f1_score: 0.8597\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3246 - accuracy: 0.8625 - f1_score: 0.8627 - val_loss: 0.3021 - val_accuracy: 0.8689 - val_f1_score: 0.8736\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2718 - accuracy: 0.8902 - f1_score: 0.8894 - val_loss: 0.3067 - val_accuracy: 0.8635 - val_f1_score: 0.8566\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2256 - accuracy: 0.9156 - f1_score: 0.9145 - val_loss: 0.2983 - val_accuracy: 0.8743 - val_f1_score: 0.8780\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1977 - accuracy: 0.9237 - f1_score: 0.9231 - val_loss: 0.4577 - val_accuracy: 0.8255 - val_f1_score: 0.7975\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1663 - accuracy: 0.9361 - f1_score: 0.9353 - val_loss: 0.3690 - val_accuracy: 0.8590 - val_f1_score: 0.8471\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1288 - accuracy: 0.9490 - f1_score: 0.9486 - val_loss: 0.3744 - val_accuracy: 0.8743 - val_f1_score: 0.8733\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0962 - accuracy: 0.9602 - f1_score: 0.9599 - val_loss: 0.3653 - val_accuracy: 0.8788 - val_f1_score: 0.8771\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0828 - accuracy: 0.9671 - f1_score: 0.9670 - val_loss: 0.4574 - val_accuracy: 0.8716 - val_f1_score: 0.8697\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.8852 - f1_score: 0.9081\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4857 - accuracy: 0.7639 - f1_score: 0.7534 - val_loss: 0.3403 - val_accuracy: 0.8562 - val_f1_score: 0.8526\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3116 - accuracy: 0.8767 - f1_score: 0.8762 - val_loss: 0.3220 - val_accuracy: 0.8580 - val_f1_score: 0.8492\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2693 - accuracy: 0.8878 - f1_score: 0.8863 - val_loss: 0.3151 - val_accuracy: 0.8599 - val_f1_score: 0.8617\n","Epoch 4/20\n","104/104 [==============================] - 2s 19ms/step - loss: 0.2314 - accuracy: 0.9110 - f1_score: 0.9099 - val_loss: 0.3079 - val_accuracy: 0.8671 - val_f1_score: 0.8691\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1833 - accuracy: 0.9303 - f1_score: 0.9297 - val_loss: 0.3266 - val_accuracy: 0.8761 - val_f1_score: 0.8723\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1451 - accuracy: 0.9481 - f1_score: 0.9478 - val_loss: 0.3442 - val_accuracy: 0.8807 - val_f1_score: 0.8789\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1089 - accuracy: 0.9608 - f1_score: 0.9606 - val_loss: 0.4648 - val_accuracy: 0.8671 - val_f1_score: 0.8736\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0953 - accuracy: 0.9659 - f1_score: 0.9658 - val_loss: 0.4192 - val_accuracy: 0.8608 - val_f1_score: 0.8618\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0796 - accuracy: 0.9729 - f1_score: 0.9728 - val_loss: 0.3901 - val_accuracy: 0.8807 - val_f1_score: 0.8817\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8690 - f1_score: 0.8951\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 19ms/step - loss: 0.4865 - accuracy: 0.7627 - f1_score: 0.7551 - val_loss: 0.3574 - val_accuracy: 0.8517 - val_f1_score: 0.8569\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3267 - accuracy: 0.8595 - f1_score: 0.8574 - val_loss: 0.3070 - val_accuracy: 0.8770 - val_f1_score: 0.8761\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2677 - accuracy: 0.8857 - f1_score: 0.8842 - val_loss: 0.3181 - val_accuracy: 0.8807 - val_f1_score: 0.8844\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2250 - accuracy: 0.9044 - f1_score: 0.9033 - val_loss: 0.3027 - val_accuracy: 0.8843 - val_f1_score: 0.8845\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1807 - accuracy: 0.9303 - f1_score: 0.9291 - val_loss: 0.2970 - val_accuracy: 0.8816 - val_f1_score: 0.8784\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1417 - accuracy: 0.9478 - f1_score: 0.9472 - val_loss: 0.3682 - val_accuracy: 0.8825 - val_f1_score: 0.8852\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1159 - accuracy: 0.9563 - f1_score: 0.9558 - val_loss: 0.4379 - val_accuracy: 0.8870 - val_f1_score: 0.8897\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9644 - f1_score: 0.9641 - val_loss: 0.3731 - val_accuracy: 0.8933 - val_f1_score: 0.8917\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0720 - accuracy: 0.9738 - f1_score: 0.9737 - val_loss: 0.4097 - val_accuracy: 0.8779 - val_f1_score: 0.8796\n","Epoch 10/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0646 - accuracy: 0.9792 - f1_score: 0.9790 - val_loss: 0.4093 - val_accuracy: 0.8951 - val_f1_score: 0.8930\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8542 - f1_score: 0.8766\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 19ms/step - loss: 0.4876 - accuracy: 0.7572 - f1_score: 0.7479 - val_loss: 0.3736 - val_accuracy: 0.8391 - val_f1_score: 0.8292\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3112 - accuracy: 0.8721 - f1_score: 0.8715 - val_loss: 0.3308 - val_accuracy: 0.8535 - val_f1_score: 0.8530\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2646 - accuracy: 0.8996 - f1_score: 0.8980 - val_loss: 0.3363 - val_accuracy: 0.8599 - val_f1_score: 0.8563\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2153 - accuracy: 0.9131 - f1_score: 0.9120 - val_loss: 0.3263 - val_accuracy: 0.8635 - val_f1_score: 0.8577\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1678 - accuracy: 0.9373 - f1_score: 0.9368 - val_loss: 0.3423 - val_accuracy: 0.8752 - val_f1_score: 0.8743\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1393 - accuracy: 0.9496 - f1_score: 0.9494 - val_loss: 0.3177 - val_accuracy: 0.8770 - val_f1_score: 0.8781\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1118 - accuracy: 0.9605 - f1_score: 0.9602 - val_loss: 0.4460 - val_accuracy: 0.8653 - val_f1_score: 0.8671\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1019 - accuracy: 0.9617 - f1_score: 0.9616 - val_loss: 0.3720 - val_accuracy: 0.8797 - val_f1_score: 0.8783\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0695 - accuracy: 0.9729 - f1_score: 0.9728 - val_loss: 0.4929 - val_accuracy: 0.8761 - val_f1_score: 0.8760\n","Epoch 10/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0490 - accuracy: 0.9804 - f1_score: 0.9804 - val_loss: 0.5133 - val_accuracy: 0.8653 - val_f1_score: 0.8678\n","Epoch 11/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0286 - accuracy: 0.9913 - f1_score: 0.9912 - val_loss: 0.6371 - val_accuracy: 0.8725 - val_f1_score: 0.8726\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8690 - f1_score: 0.8929\n","47/47 [==============================] - 0s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 6s 14ms/step - loss: 0.4725 - accuracy: 0.7657 - f1_score: 0.7699 - val_loss: 0.3704 - val_accuracy: 0.8336 - val_f1_score: 0.8277\n","Epoch 2/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.3072 - accuracy: 0.8715 - f1_score: 0.8696 - val_loss: 0.3373 - val_accuracy: 0.8526 - val_f1_score: 0.8511\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2536 - accuracy: 0.9002 - f1_score: 0.8984 - val_loss: 0.3597 - val_accuracy: 0.8354 - val_f1_score: 0.8147\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2041 - accuracy: 0.9201 - f1_score: 0.9193 - val_loss: 0.3558 - val_accuracy: 0.8644 - val_f1_score: 0.8614\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1702 - accuracy: 0.9343 - f1_score: 0.9335 - val_loss: 0.3452 - val_accuracy: 0.8635 - val_f1_score: 0.8571\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1298 - accuracy: 0.9536 - f1_score: 0.9530 - val_loss: 0.4133 - val_accuracy: 0.8571 - val_f1_score: 0.8523\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0940 - accuracy: 0.9701 - f1_score: 0.9699 - val_loss: 0.4540 - val_accuracy: 0.8617 - val_f1_score: 0.8569\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8562 - f1_score: 0.8819\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4963 - accuracy: 0.7539 - f1_score: 0.7552 - val_loss: 0.3666 - val_accuracy: 0.8391 - val_f1_score: 0.8367\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3183 - accuracy: 0.8700 - f1_score: 0.8693 - val_loss: 0.3316 - val_accuracy: 0.8562 - val_f1_score: 0.8599\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2637 - accuracy: 0.9005 - f1_score: 0.8996 - val_loss: 0.3134 - val_accuracy: 0.8635 - val_f1_score: 0.8598\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2084 - accuracy: 0.9125 - f1_score: 0.9117 - val_loss: 0.3031 - val_accuracy: 0.8752 - val_f1_score: 0.8736\n","Epoch 5/20\n","104/104 [==============================] - 1s 7ms/step - loss: 0.1720 - accuracy: 0.9340 - f1_score: 0.9333 - val_loss: 0.3290 - val_accuracy: 0.8752 - val_f1_score: 0.8717\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1421 - accuracy: 0.9460 - f1_score: 0.9455 - val_loss: 0.3684 - val_accuracy: 0.8752 - val_f1_score: 0.8688\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1061 - accuracy: 0.9620 - f1_score: 0.9617 - val_loss: 0.3890 - val_accuracy: 0.8779 - val_f1_score: 0.8780\n","Epoch 8/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0750 - accuracy: 0.9732 - f1_score: 0.9732 - val_loss: 0.4469 - val_accuracy: 0.8788 - val_f1_score: 0.8780\n","Epoch 9/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0511 - accuracy: 0.9855 - f1_score: 0.9855 - val_loss: 0.6215 - val_accuracy: 0.8734 - val_f1_score: 0.8757\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3172 - accuracy: 0.8636 - f1_score: 0.8861\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4893 - accuracy: 0.7572 - f1_score: 0.7528 - val_loss: 0.3664 - val_accuracy: 0.8472 - val_f1_score: 0.8511\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3178 - accuracy: 0.8676 - f1_score: 0.8672 - val_loss: 0.3414 - val_accuracy: 0.8644 - val_f1_score: 0.8611\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2614 - accuracy: 0.8896 - f1_score: 0.8888 - val_loss: 0.3684 - val_accuracy: 0.8526 - val_f1_score: 0.8598\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2232 - accuracy: 0.9098 - f1_score: 0.9088 - val_loss: 0.3066 - val_accuracy: 0.8698 - val_f1_score: 0.8644\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1762 - accuracy: 0.9234 - f1_score: 0.9225 - val_loss: 0.3476 - val_accuracy: 0.8617 - val_f1_score: 0.8510\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1431 - accuracy: 0.9478 - f1_score: 0.9475 - val_loss: 0.3410 - val_accuracy: 0.8752 - val_f1_score: 0.8739\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1187 - accuracy: 0.9511 - f1_score: 0.9509 - val_loss: 0.4596 - val_accuracy: 0.8617 - val_f1_score: 0.8519\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0933 - accuracy: 0.9614 - f1_score: 0.9611 - val_loss: 0.4232 - val_accuracy: 0.8689 - val_f1_score: 0.8727\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0538 - accuracy: 0.9804 - f1_score: 0.9803 - val_loss: 0.6005 - val_accuracy: 0.8788 - val_f1_score: 0.8835\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8629 - f1_score: 0.8847\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4720 - accuracy: 0.7729 - f1_score: 0.7706 - val_loss: 0.3568 - val_accuracy: 0.8354 - val_f1_score: 0.8296\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3126 - accuracy: 0.8691 - f1_score: 0.8677 - val_loss: 0.3194 - val_accuracy: 0.8608 - val_f1_score: 0.8569\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2566 - accuracy: 0.8914 - f1_score: 0.8911 - val_loss: 0.3204 - val_accuracy: 0.8698 - val_f1_score: 0.8657\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2163 - accuracy: 0.9125 - f1_score: 0.9116 - val_loss: 0.3206 - val_accuracy: 0.8662 - val_f1_score: 0.8593\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1732 - accuracy: 0.9306 - f1_score: 0.9303 - val_loss: 0.3668 - val_accuracy: 0.8553 - val_f1_score: 0.8400\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1477 - accuracy: 0.9412 - f1_score: 0.9405 - val_loss: 0.3261 - val_accuracy: 0.8797 - val_f1_score: 0.8799\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1122 - accuracy: 0.9563 - f1_score: 0.9561 - val_loss: 0.4223 - val_accuracy: 0.8626 - val_f1_score: 0.8550\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3414 - accuracy: 0.8535 - f1_score: 0.8748\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4939 - accuracy: 0.7397 - f1_score: 0.7316 - val_loss: 0.3234 - val_accuracy: 0.8734 - val_f1_score: 0.8741\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3227 - accuracy: 0.8622 - f1_score: 0.8604 - val_loss: 0.2944 - val_accuracy: 0.8770 - val_f1_score: 0.8745\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2621 - accuracy: 0.8926 - f1_score: 0.8912 - val_loss: 0.2771 - val_accuracy: 0.8797 - val_f1_score: 0.8774\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2220 - accuracy: 0.9059 - f1_score: 0.9041 - val_loss: 0.3366 - val_accuracy: 0.8779 - val_f1_score: 0.8863\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1741 - accuracy: 0.9303 - f1_score: 0.9296 - val_loss: 0.3389 - val_accuracy: 0.8788 - val_f1_score: 0.8702\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1600 - accuracy: 0.9391 - f1_score: 0.9383 - val_loss: 0.3194 - val_accuracy: 0.8807 - val_f1_score: 0.8766\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1104 - accuracy: 0.9584 - f1_score: 0.9581 - val_loss: 0.4039 - val_accuracy: 0.8689 - val_f1_score: 0.8571\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0932 - accuracy: 0.9626 - f1_score: 0.9624 - val_loss: 0.4400 - val_accuracy: 0.8843 - val_f1_score: 0.8865\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8643 - f1_score: 0.8853\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4789 - accuracy: 0.7636 - f1_score: 0.7717 - val_loss: 0.3475 - val_accuracy: 0.8544 - val_f1_score: 0.8556\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3130 - accuracy: 0.8661 - f1_score: 0.8652 - val_loss: 0.3340 - val_accuracy: 0.8490 - val_f1_score: 0.8616\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2631 - accuracy: 0.8926 - f1_score: 0.8925 - val_loss: 0.2727 - val_accuracy: 0.8870 - val_f1_score: 0.8873\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2214 - accuracy: 0.9089 - f1_score: 0.9088 - val_loss: 0.2716 - val_accuracy: 0.8933 - val_f1_score: 0.8907\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1744 - accuracy: 0.9294 - f1_score: 0.9290 - val_loss: 0.3018 - val_accuracy: 0.8879 - val_f1_score: 0.8893\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1359 - accuracy: 0.9490 - f1_score: 0.9486 - val_loss: 0.2807 - val_accuracy: 0.8816 - val_f1_score: 0.8846\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1120 - accuracy: 0.9599 - f1_score: 0.9598 - val_loss: 0.3422 - val_accuracy: 0.8834 - val_f1_score: 0.8839\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0825 - accuracy: 0.9677 - f1_score: 0.9677 - val_loss: 0.3460 - val_accuracy: 0.8770 - val_f1_score: 0.8819\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0615 - accuracy: 0.9795 - f1_score: 0.9794 - val_loss: 0.3448 - val_accuracy: 0.8807 - val_f1_score: 0.8800\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8643 - f1_score: 0.8847\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 5s 13ms/step - loss: 0.4816 - accuracy: 0.7560 - f1_score: 0.7419 - val_loss: 0.3381 - val_accuracy: 0.8454 - val_f1_score: 0.8409\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3092 - accuracy: 0.8658 - f1_score: 0.8641 - val_loss: 0.2912 - val_accuracy: 0.8698 - val_f1_score: 0.8700\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2555 - accuracy: 0.8923 - f1_score: 0.8905 - val_loss: 0.3661 - val_accuracy: 0.8553 - val_f1_score: 0.8664\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2121 - accuracy: 0.9107 - f1_score: 0.9096 - val_loss: 0.2989 - val_accuracy: 0.8725 - val_f1_score: 0.8664\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1707 - accuracy: 0.9318 - f1_score: 0.9308 - val_loss: 0.3262 - val_accuracy: 0.8843 - val_f1_score: 0.8832\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1439 - accuracy: 0.9418 - f1_score: 0.9411 - val_loss: 0.3232 - val_accuracy: 0.8843 - val_f1_score: 0.8808\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1065 - accuracy: 0.9605 - f1_score: 0.9600 - val_loss: 0.3606 - val_accuracy: 0.8807 - val_f1_score: 0.8757\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8548 - f1_score: 0.8779\n","47/47 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyB4qGHT01pG","executionInfo":{"status":"ok","timestamp":1697705757748,"user_tz":-330,"elapsed":16,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"d5c1564f-5383-4ce1-de52-32cd66e3cbdd"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8561782836914062, 0.8683322072029114, 0.8757596015930176, 0.8710330724716187, 0.8723835349082947, 0.8514516949653625, 0.8528021574020386, 0.8582038879394531, 0.8595543503761292, 0.871708333492279, 0.8710330724716187, 0.875084400177002, 0.8737339377403259, 0.8777852654457092, 0.8852127194404602, 0.869007408618927, 0.8541526198387146, 0.869007408618927, 0.8561782836914062, 0.8636056780815125, 0.8629304766654968, 0.8534773588180542, 0.8642808794975281, 0.8642808794975281, 0.8548278212547302]\n","0.865280213356018\n","0.008953969787785574\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjNU6rdh011L","executionInfo":{"status":"ok","timestamp":1697705757749,"user_tz":-330,"elapsed":15,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"bbcc4b13-cb89-4e05-a7d0-76d9f0d33386"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.32861340045928955, 0.31363728642463684, 0.3085896372795105, 0.30269160866737366, 0.31762537360191345, 0.37142929434776306, 0.36179229617118835, 0.37538808584213257, 0.32154911756515503, 0.321010559797287, 0.3115045726299286, 0.30121979117393494, 0.3076421618461609, 0.3044484853744507, 0.2782241702079773, 0.3172413110733032, 0.35292762517929077, 0.31775331497192383, 0.3320285975933075, 0.31715553998947144, 0.32018688321113586, 0.3413502871990204, 0.3054296374320984, 0.3334346413612366, 0.3279179334640503]\n","0.3236316645145416\n","0.02227901467913345\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1KoQX1Bq02Ad","executionInfo":{"status":"ok","timestamp":1697705757749,"user_tz":-330,"elapsed":13,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"191038fe-ab83-46ad-88bb-d9e19651a3b4"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8762346506118774, 0.889015257358551, 0.8956915140151978, 0.8915388584136963, 0.8918144702911377, 0.8738531470298767, 0.8748564124107361, 0.8793103098869324, 0.8864628076553345, 0.8966267108917236, 0.8914154767990112, 0.8965902328491211, 0.894170880317688, 0.8981428742408752, 0.9081080555915833, 0.8951350450515747, 0.8765713572502136, 0.8929359316825867, 0.8818634748458862, 0.8861330151557922, 0.884724497795105, 0.8747835755348206, 0.8853393197059631, 0.8846815228462219, 0.8779101967811584]\n","0.8873563838005066\n","0.008771747166707667\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2_did-d202LO","executionInfo":{"status":"ok","timestamp":1697705757749,"user_tz":-330,"elapsed":12,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"656d385c-12ee-438c-e562-ad8e0de3a3e4"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.719606963783307, 0.7354697625010999, 0.749337106311035, 0.7401656301193176, 0.7463138671638887, 0.7035615244247785, 0.7068845586917814, 0.7186259469903079, 0.70288918130601, 0.7278726940239657, 0.7406270816829716, 0.7427469830027411, 0.7444466054026541, 0.7507750040517156, 0.7552628761121492, 0.7207064845548171, 0.7076571242001433, 0.7259148179090831, 0.7004638194336804, 0.7217809268718284, 0.7232822362753747, 0.7106719522391106, 0.7279918993923974, 0.7304774808907087, 0.7063988424314317]\n","0.7263972547906521\n","0.016413615772514923\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ODGo-mR102Wm","executionInfo":{"status":"ok","timestamp":1697705757749,"user_tz":-330,"elapsed":11,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["# LSTM CNN LSTM nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=3, strides=1)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        #cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))  # cnn_emotions returns length 3072, ie cnn_emotions.shape[1] = 3072\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","        lstm_intensity = LSTM(32)(Reshape((1, 8))(input_intensity))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_emotions, lstm_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sV7xrUZ302kT","executionInfo":{"status":"ok","timestamp":1697706327099,"user_tz":-330,"elapsed":569361,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6089b446-a4a1-4f4c-ec34-ce7d7a56fcfa"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 7s 21ms/step - loss: 0.4838 - accuracy: 0.7497 - f1_score: 0.7395 - val_loss: 0.3518 - val_accuracy: 0.8508 - val_f1_score: 0.8539\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3093 - accuracy: 0.8721 - f1_score: 0.8717 - val_loss: 0.3452 - val_accuracy: 0.8526 - val_f1_score: 0.8440\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2447 - accuracy: 0.9029 - f1_score: 0.9030 - val_loss: 0.3316 - val_accuracy: 0.8617 - val_f1_score: 0.8585\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2146 - accuracy: 0.9195 - f1_score: 0.9193 - val_loss: 0.3264 - val_accuracy: 0.8617 - val_f1_score: 0.8647\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1738 - accuracy: 0.9376 - f1_score: 0.9376 - val_loss: 0.3716 - val_accuracy: 0.8752 - val_f1_score: 0.8729\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1265 - accuracy: 0.9548 - f1_score: 0.9545 - val_loss: 0.4016 - val_accuracy: 0.8716 - val_f1_score: 0.8665\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0902 - accuracy: 0.9698 - f1_score: 0.9697 - val_loss: 0.5483 - val_accuracy: 0.8725 - val_f1_score: 0.8671\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0886 - accuracy: 0.9671 - f1_score: 0.9671 - val_loss: 0.5320 - val_accuracy: 0.8680 - val_f1_score: 0.8602\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0663 - accuracy: 0.9771 - f1_score: 0.9770 - val_loss: 0.5169 - val_accuracy: 0.8689 - val_f1_score: 0.8626\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.8812 - f1_score: 0.9035\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 26ms/step - loss: 0.4899 - accuracy: 0.7563 - f1_score: 0.7511 - val_loss: 0.3466 - val_accuracy: 0.8580 - val_f1_score: 0.8553\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3137 - accuracy: 0.8670 - f1_score: 0.8668 - val_loss: 0.3194 - val_accuracy: 0.8716 - val_f1_score: 0.8702\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2584 - accuracy: 0.8948 - f1_score: 0.8958 - val_loss: 0.3000 - val_accuracy: 0.8743 - val_f1_score: 0.8707\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2087 - accuracy: 0.9177 - f1_score: 0.9173 - val_loss: 0.3128 - val_accuracy: 0.8816 - val_f1_score: 0.8833\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1636 - accuracy: 0.9388 - f1_score: 0.9389 - val_loss: 0.3368 - val_accuracy: 0.8698 - val_f1_score: 0.8707\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1261 - accuracy: 0.9517 - f1_score: 0.9517 - val_loss: 0.3587 - val_accuracy: 0.8725 - val_f1_score: 0.8708\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0953 - accuracy: 0.9656 - f1_score: 0.9656 - val_loss: 0.4010 - val_accuracy: 0.8716 - val_f1_score: 0.8690\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0713 - accuracy: 0.9768 - f1_score: 0.9767 - val_loss: 0.4336 - val_accuracy: 0.8743 - val_f1_score: 0.8724\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8690 - f1_score: 0.8896\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.4666 - accuracy: 0.7847 - f1_score: 0.7875 - val_loss: 0.3456 - val_accuracy: 0.8463 - val_f1_score: 0.8449\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3182 - accuracy: 0.8679 - f1_score: 0.8665 - val_loss: 0.3237 - val_accuracy: 0.8580 - val_f1_score: 0.8548\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2625 - accuracy: 0.8896 - f1_score: 0.8892 - val_loss: 0.2978 - val_accuracy: 0.8626 - val_f1_score: 0.8593\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2297 - accuracy: 0.9080 - f1_score: 0.9078 - val_loss: 0.3037 - val_accuracy: 0.8689 - val_f1_score: 0.8644\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1838 - accuracy: 0.9300 - f1_score: 0.9298 - val_loss: 0.3120 - val_accuracy: 0.8734 - val_f1_score: 0.8734\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1452 - accuracy: 0.9460 - f1_score: 0.9455 - val_loss: 0.3273 - val_accuracy: 0.8897 - val_f1_score: 0.8918\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1209 - accuracy: 0.9560 - f1_score: 0.9558 - val_loss: 0.3792 - val_accuracy: 0.8725 - val_f1_score: 0.8679\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0944 - accuracy: 0.9662 - f1_score: 0.9661 - val_loss: 0.4166 - val_accuracy: 0.8716 - val_f1_score: 0.8692\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8731 - f1_score: 0.8934\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4779 - accuracy: 0.7630 - f1_score: 0.7463 - val_loss: 0.3488 - val_accuracy: 0.8580 - val_f1_score: 0.8587\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3111 - accuracy: 0.8586 - f1_score: 0.8595 - val_loss: 0.3214 - val_accuracy: 0.8635 - val_f1_score: 0.8569\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2599 - accuracy: 0.8914 - f1_score: 0.8913 - val_loss: 0.3192 - val_accuracy: 0.8644 - val_f1_score: 0.8560\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2150 - accuracy: 0.9101 - f1_score: 0.9099 - val_loss: 0.3377 - val_accuracy: 0.8807 - val_f1_score: 0.8856\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1793 - accuracy: 0.9297 - f1_score: 0.9300 - val_loss: 0.3338 - val_accuracy: 0.8816 - val_f1_score: 0.8810\n","Epoch 6/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1340 - accuracy: 0.9484 - f1_score: 0.9483 - val_loss: 0.4082 - val_accuracy: 0.8752 - val_f1_score: 0.8785\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0959 - accuracy: 0.9623 - f1_score: 0.9623 - val_loss: 0.3947 - val_accuracy: 0.8843 - val_f1_score: 0.8838\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0665 - accuracy: 0.9798 - f1_score: 0.9798 - val_loss: 0.5245 - val_accuracy: 0.8807 - val_f1_score: 0.8773\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3483 - accuracy: 0.8562 - f1_score: 0.8754\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.5023 - accuracy: 0.7536 - f1_score: 0.7517 - val_loss: 0.3514 - val_accuracy: 0.8354 - val_f1_score: 0.8339\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3272 - accuracy: 0.8631 - f1_score: 0.8637 - val_loss: 0.3129 - val_accuracy: 0.8580 - val_f1_score: 0.8597\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2698 - accuracy: 0.8836 - f1_score: 0.8842 - val_loss: 0.3129 - val_accuracy: 0.8590 - val_f1_score: 0.8648\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2297 - accuracy: 0.9020 - f1_score: 0.9027 - val_loss: 0.2977 - val_accuracy: 0.8689 - val_f1_score: 0.8685\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1807 - accuracy: 0.9276 - f1_score: 0.9279 - val_loss: 0.3457 - val_accuracy: 0.8734 - val_f1_score: 0.8687\n","Epoch 6/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1492 - accuracy: 0.9400 - f1_score: 0.9399 - val_loss: 0.3195 - val_accuracy: 0.8653 - val_f1_score: 0.8574\n","Epoch 7/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1225 - accuracy: 0.9554 - f1_score: 0.9551 - val_loss: 0.3572 - val_accuracy: 0.8734 - val_f1_score: 0.8696\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0826 - accuracy: 0.9723 - f1_score: 0.9722 - val_loss: 0.4879 - val_accuracy: 0.8608 - val_f1_score: 0.8579\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0701 - accuracy: 0.9747 - f1_score: 0.9746 - val_loss: 0.4478 - val_accuracy: 0.8788 - val_f1_score: 0.8764\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8771 - f1_score: 0.8966\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 23ms/step - loss: 0.4865 - accuracy: 0.7648 - f1_score: 0.7562 - val_loss: 0.3516 - val_accuracy: 0.8463 - val_f1_score: 0.8460\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3062 - accuracy: 0.8764 - f1_score: 0.8753 - val_loss: 0.3251 - val_accuracy: 0.8490 - val_f1_score: 0.8500\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2493 - accuracy: 0.8996 - f1_score: 0.8988 - val_loss: 0.3106 - val_accuracy: 0.8671 - val_f1_score: 0.8693\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2005 - accuracy: 0.9219 - f1_score: 0.9211 - val_loss: 0.3362 - val_accuracy: 0.8680 - val_f1_score: 0.8646\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1617 - accuracy: 0.9358 - f1_score: 0.9351 - val_loss: 0.3978 - val_accuracy: 0.8644 - val_f1_score: 0.8673\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1303 - accuracy: 0.9527 - f1_score: 0.9524 - val_loss: 0.4017 - val_accuracy: 0.8671 - val_f1_score: 0.8653\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1130 - accuracy: 0.9572 - f1_score: 0.9567 - val_loss: 0.4662 - val_accuracy: 0.8680 - val_f1_score: 0.8694\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0829 - accuracy: 0.9689 - f1_score: 0.9686 - val_loss: 0.4860 - val_accuracy: 0.8644 - val_f1_score: 0.8661\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8670 - f1_score: 0.8915\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.4740 - accuracy: 0.7681 - f1_score: 0.7649 - val_loss: 0.3756 - val_accuracy: 0.8363 - val_f1_score: 0.8377\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3012 - accuracy: 0.8755 - f1_score: 0.8747 - val_loss: 0.3289 - val_accuracy: 0.8481 - val_f1_score: 0.8505\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2473 - accuracy: 0.8969 - f1_score: 0.8962 - val_loss: 0.3155 - val_accuracy: 0.8517 - val_f1_score: 0.8473\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2062 - accuracy: 0.9228 - f1_score: 0.9220 - val_loss: 0.3338 - val_accuracy: 0.8635 - val_f1_score: 0.8577\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1579 - accuracy: 0.9403 - f1_score: 0.9399 - val_loss: 0.3425 - val_accuracy: 0.8590 - val_f1_score: 0.8577\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1180 - accuracy: 0.9608 - f1_score: 0.9606 - val_loss: 0.3767 - val_accuracy: 0.8653 - val_f1_score: 0.8652\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1016 - accuracy: 0.9632 - f1_score: 0.9631 - val_loss: 0.3896 - val_accuracy: 0.8707 - val_f1_score: 0.8675\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0647 - accuracy: 0.9777 - f1_score: 0.9777 - val_loss: 0.5635 - val_accuracy: 0.8653 - val_f1_score: 0.8659\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8555 - f1_score: 0.8790\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4834 - accuracy: 0.7651 - f1_score: 0.7707 - val_loss: 0.3515 - val_accuracy: 0.8499 - val_f1_score: 0.8515\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3037 - accuracy: 0.8745 - f1_score: 0.8720 - val_loss: 0.3259 - val_accuracy: 0.8571 - val_f1_score: 0.8604\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2475 - accuracy: 0.9041 - f1_score: 0.9031 - val_loss: 0.3241 - val_accuracy: 0.8680 - val_f1_score: 0.8713\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2054 - accuracy: 0.9195 - f1_score: 0.9185 - val_loss: 0.3775 - val_accuracy: 0.8635 - val_f1_score: 0.8547\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1647 - accuracy: 0.9421 - f1_score: 0.9414 - val_loss: 0.3541 - val_accuracy: 0.8644 - val_f1_score: 0.8677\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1304 - accuracy: 0.9517 - f1_score: 0.9515 - val_loss: 0.3817 - val_accuracy: 0.8680 - val_f1_score: 0.8680\n","Epoch 7/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.0998 - accuracy: 0.9632 - f1_score: 0.9630 - val_loss: 0.4006 - val_accuracy: 0.8707 - val_f1_score: 0.8711\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0734 - accuracy: 0.9750 - f1_score: 0.9749 - val_loss: 0.5761 - val_accuracy: 0.8562 - val_f1_score: 0.8645\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8623 - f1_score: 0.8888\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4900 - accuracy: 0.7609 - f1_score: 0.7496 - val_loss: 0.3418 - val_accuracy: 0.8454 - val_f1_score: 0.8501\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3038 - accuracy: 0.8724 - f1_score: 0.8715 - val_loss: 0.3214 - val_accuracy: 0.8662 - val_f1_score: 0.8619\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2509 - accuracy: 0.8987 - f1_score: 0.8983 - val_loss: 0.3498 - val_accuracy: 0.8680 - val_f1_score: 0.8585\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2115 - accuracy: 0.9171 - f1_score: 0.9165 - val_loss: 0.2950 - val_accuracy: 0.8861 - val_f1_score: 0.8835\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1603 - accuracy: 0.9361 - f1_score: 0.9356 - val_loss: 0.3338 - val_accuracy: 0.8897 - val_f1_score: 0.8885\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1265 - accuracy: 0.9493 - f1_score: 0.9496 - val_loss: 0.5219 - val_accuracy: 0.8653 - val_f1_score: 0.8514\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0982 - accuracy: 0.9572 - f1_score: 0.9572 - val_loss: 0.4821 - val_accuracy: 0.8734 - val_f1_score: 0.8633\n","Epoch 8/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0753 - accuracy: 0.9750 - f1_score: 0.9750 - val_loss: 0.4548 - val_accuracy: 0.8761 - val_f1_score: 0.8709\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0568 - accuracy: 0.9777 - f1_score: 0.9777 - val_loss: 0.6086 - val_accuracy: 0.8734 - val_f1_score: 0.8656\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8717 - f1_score: 0.8949\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 24ms/step - loss: 0.4862 - accuracy: 0.7455 - f1_score: 0.7286 - val_loss: 0.3715 - val_accuracy: 0.8427 - val_f1_score: 0.8525\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3167 - accuracy: 0.8610 - f1_score: 0.8592 - val_loss: 0.3127 - val_accuracy: 0.8734 - val_f1_score: 0.8732\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2560 - accuracy: 0.8908 - f1_score: 0.8891 - val_loss: 0.2992 - val_accuracy: 0.8788 - val_f1_score: 0.8764\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2133 - accuracy: 0.9122 - f1_score: 0.9113 - val_loss: 0.4220 - val_accuracy: 0.8291 - val_f1_score: 0.8008\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1719 - accuracy: 0.9315 - f1_score: 0.9309 - val_loss: 0.3174 - val_accuracy: 0.8797 - val_f1_score: 0.8735\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1373 - accuracy: 0.9508 - f1_score: 0.9503 - val_loss: 0.3614 - val_accuracy: 0.8644 - val_f1_score: 0.8521\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1034 - accuracy: 0.9626 - f1_score: 0.9623 - val_loss: 0.4285 - val_accuracy: 0.8870 - val_f1_score: 0.8813\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0717 - accuracy: 0.9753 - f1_score: 0.9751 - val_loss: 0.4670 - val_accuracy: 0.8870 - val_f1_score: 0.8824\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8704 - f1_score: 0.8932\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 24ms/step - loss: 0.5206 - accuracy: 0.7334 - f1_score: 0.7290 - val_loss: 0.3617 - val_accuracy: 0.8454 - val_f1_score: 0.8496\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3348 - accuracy: 0.8634 - f1_score: 0.8627 - val_loss: 0.3221 - val_accuracy: 0.8535 - val_f1_score: 0.8615\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2885 - accuracy: 0.8821 - f1_score: 0.8814 - val_loss: 0.3195 - val_accuracy: 0.8635 - val_f1_score: 0.8488\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2412 - accuracy: 0.9017 - f1_score: 0.9010 - val_loss: 0.2797 - val_accuracy: 0.8870 - val_f1_score: 0.8848\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.9192 - f1_score: 0.9181 - val_loss: 0.2835 - val_accuracy: 0.8807 - val_f1_score: 0.8748\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1587 - accuracy: 0.9439 - f1_score: 0.9433 - val_loss: 0.3039 - val_accuracy: 0.8825 - val_f1_score: 0.8839\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1321 - accuracy: 0.9496 - f1_score: 0.9495 - val_loss: 0.3731 - val_accuracy: 0.8779 - val_f1_score: 0.8685\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0990 - accuracy: 0.9653 - f1_score: 0.9651 - val_loss: 0.4075 - val_accuracy: 0.8897 - val_f1_score: 0.8905\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0833 - accuracy: 0.9683 - f1_score: 0.9681 - val_loss: 0.4527 - val_accuracy: 0.8843 - val_f1_score: 0.8817\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8812 - f1_score: 0.9028\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 25ms/step - loss: 0.5077 - accuracy: 0.7425 - f1_score: 0.7213 - val_loss: 0.3658 - val_accuracy: 0.8309 - val_f1_score: 0.8295\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3120 - accuracy: 0.8634 - f1_score: 0.8630 - val_loss: 0.3628 - val_accuracy: 0.8445 - val_f1_score: 0.8330\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2629 - accuracy: 0.8896 - f1_score: 0.8896 - val_loss: 0.3203 - val_accuracy: 0.8617 - val_f1_score: 0.8628\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2199 - accuracy: 0.9107 - f1_score: 0.9111 - val_loss: 0.3161 - val_accuracy: 0.8680 - val_f1_score: 0.8696\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1811 - accuracy: 0.9321 - f1_score: 0.9317 - val_loss: 0.3273 - val_accuracy: 0.8716 - val_f1_score: 0.8704\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1443 - accuracy: 0.9442 - f1_score: 0.9441 - val_loss: 0.3615 - val_accuracy: 0.8689 - val_f1_score: 0.8695\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1098 - accuracy: 0.9578 - f1_score: 0.9574 - val_loss: 0.4170 - val_accuracy: 0.8716 - val_f1_score: 0.8692\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0919 - accuracy: 0.9668 - f1_score: 0.9667 - val_loss: 0.4497 - val_accuracy: 0.8725 - val_f1_score: 0.8693\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0659 - accuracy: 0.9789 - f1_score: 0.9789 - val_loss: 0.5123 - val_accuracy: 0.8734 - val_f1_score: 0.8706\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3007 - accuracy: 0.8758 - f1_score: 0.9003\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 27ms/step - loss: 0.4743 - accuracy: 0.7690 - f1_score: 0.7665 - val_loss: 0.3668 - val_accuracy: 0.8382 - val_f1_score: 0.8431\n","Epoch 2/20\n","104/104 [==============================] - 2s 20ms/step - loss: 0.3102 - accuracy: 0.8700 - f1_score: 0.8702 - val_loss: 0.3626 - val_accuracy: 0.8373 - val_f1_score: 0.8263\n","Epoch 3/20\n","104/104 [==============================] - 2s 18ms/step - loss: 0.2510 - accuracy: 0.8978 - f1_score: 0.8967 - val_loss: 0.3778 - val_accuracy: 0.8517 - val_f1_score: 0.8581\n","Epoch 4/20\n","104/104 [==============================] - 2s 20ms/step - loss: 0.2244 - accuracy: 0.9162 - f1_score: 0.9157 - val_loss: 0.3480 - val_accuracy: 0.8580 - val_f1_score: 0.8617\n","Epoch 5/20\n","104/104 [==============================] - 2s 20ms/step - loss: 0.1729 - accuracy: 0.9331 - f1_score: 0.9324 - val_loss: 0.3349 - val_accuracy: 0.8734 - val_f1_score: 0.8699\n","Epoch 6/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1362 - accuracy: 0.9445 - f1_score: 0.9442 - val_loss: 0.3835 - val_accuracy: 0.8734 - val_f1_score: 0.8716\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1146 - accuracy: 0.9584 - f1_score: 0.9583 - val_loss: 0.4826 - val_accuracy: 0.8490 - val_f1_score: 0.8420\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0951 - accuracy: 0.9653 - f1_score: 0.9652 - val_loss: 0.4560 - val_accuracy: 0.8671 - val_f1_score: 0.8665\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0703 - accuracy: 0.9750 - f1_score: 0.9750 - val_loss: 0.4968 - val_accuracy: 0.8608 - val_f1_score: 0.8654\n","Epoch 10/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0484 - accuracy: 0.9828 - f1_score: 0.9828 - val_loss: 0.6153 - val_accuracy: 0.8617 - val_f1_score: 0.8592\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 0.8744 - f1_score: 0.8957\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 26ms/step - loss: 0.4898 - accuracy: 0.7581 - f1_score: 0.7462 - val_loss: 0.3630 - val_accuracy: 0.8373 - val_f1_score: 0.8440\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3247 - accuracy: 0.8622 - f1_score: 0.8611 - val_loss: 0.3229 - val_accuracy: 0.8635 - val_f1_score: 0.8665\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2675 - accuracy: 0.8951 - f1_score: 0.8934 - val_loss: 0.3325 - val_accuracy: 0.8716 - val_f1_score: 0.8803\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2253 - accuracy: 0.9071 - f1_score: 0.9063 - val_loss: 0.3177 - val_accuracy: 0.8590 - val_f1_score: 0.8497\n","Epoch 5/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1911 - accuracy: 0.9267 - f1_score: 0.9258 - val_loss: 0.2946 - val_accuracy: 0.8734 - val_f1_score: 0.8716\n","Epoch 6/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1431 - accuracy: 0.9466 - f1_score: 0.9462 - val_loss: 0.3154 - val_accuracy: 0.8807 - val_f1_score: 0.8793\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1089 - accuracy: 0.9587 - f1_score: 0.9583 - val_loss: 0.3475 - val_accuracy: 0.8734 - val_f1_score: 0.8763\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0820 - accuracy: 0.9692 - f1_score: 0.9691 - val_loss: 0.4416 - val_accuracy: 0.8680 - val_f1_score: 0.8708\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0602 - accuracy: 0.9786 - f1_score: 0.9785 - val_loss: 0.5454 - val_accuracy: 0.8635 - val_f1_score: 0.8613\n","Epoch 10/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0559 - accuracy: 0.9792 - f1_score: 0.9791 - val_loss: 0.6190 - val_accuracy: 0.8544 - val_f1_score: 0.8596\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3077 - accuracy: 0.8744 - f1_score: 0.8962\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.5004 - accuracy: 0.7446 - f1_score: 0.7279 - val_loss: 0.3423 - val_accuracy: 0.8571 - val_f1_score: 0.8534\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3344 - accuracy: 0.8580 - f1_score: 0.8561 - val_loss: 0.2995 - val_accuracy: 0.8680 - val_f1_score: 0.8615\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2769 - accuracy: 0.8857 - f1_score: 0.8832 - val_loss: 0.3029 - val_accuracy: 0.8797 - val_f1_score: 0.8758\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2298 - accuracy: 0.9047 - f1_score: 0.9032 - val_loss: 0.2975 - val_accuracy: 0.8834 - val_f1_score: 0.8824\n","Epoch 5/20\n","104/104 [==============================] - 2s 17ms/step - loss: 0.1893 - accuracy: 0.9276 - f1_score: 0.9264 - val_loss: 0.3188 - val_accuracy: 0.8752 - val_f1_score: 0.8717\n","Epoch 6/20\n","104/104 [==============================] - 2s 19ms/step - loss: 0.1532 - accuracy: 0.9418 - f1_score: 0.9411 - val_loss: 0.4030 - val_accuracy: 0.8635 - val_f1_score: 0.8577\n","Epoch 7/20\n","104/104 [==============================] - 2s 17ms/step - loss: 0.1148 - accuracy: 0.9581 - f1_score: 0.9576 - val_loss: 0.4109 - val_accuracy: 0.8770 - val_f1_score: 0.8759\n","Epoch 8/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1121 - accuracy: 0.9581 - f1_score: 0.9576 - val_loss: 0.3985 - val_accuracy: 0.8689 - val_f1_score: 0.8633\n","Epoch 9/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0853 - accuracy: 0.9701 - f1_score: 0.9699 - val_loss: 0.4708 - val_accuracy: 0.8779 - val_f1_score: 0.8751\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8737 - f1_score: 0.8957\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 17ms/step - loss: 0.4858 - accuracy: 0.7621 - f1_score: 0.7589 - val_loss: 0.3597 - val_accuracy: 0.8490 - val_f1_score: 0.8472\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3216 - accuracy: 0.8580 - f1_score: 0.8554 - val_loss: 0.3325 - val_accuracy: 0.8517 - val_f1_score: 0.8398\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2633 - accuracy: 0.8954 - f1_score: 0.8932 - val_loss: 0.2912 - val_accuracy: 0.8707 - val_f1_score: 0.8665\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2125 - accuracy: 0.9183 - f1_score: 0.9173 - val_loss: 0.3284 - val_accuracy: 0.8671 - val_f1_score: 0.8574\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1754 - accuracy: 0.9355 - f1_score: 0.9347 - val_loss: 0.3288 - val_accuracy: 0.8743 - val_f1_score: 0.8675\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1355 - accuracy: 0.9490 - f1_score: 0.9485 - val_loss: 0.3871 - val_accuracy: 0.8807 - val_f1_score: 0.8804\n","Epoch 7/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1071 - accuracy: 0.9644 - f1_score: 0.9641 - val_loss: 0.3594 - val_accuracy: 0.8788 - val_f1_score: 0.8771\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0910 - accuracy: 0.9659 - f1_score: 0.9656 - val_loss: 0.3957 - val_accuracy: 0.8743 - val_f1_score: 0.8670\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3146 - accuracy: 0.8596 - f1_score: 0.8829\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 19ms/step - loss: 0.4893 - accuracy: 0.7590 - f1_score: 0.7498 - val_loss: 0.3421 - val_accuracy: 0.8580 - val_f1_score: 0.8622\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3191 - accuracy: 0.8634 - f1_score: 0.8637 - val_loss: 0.3146 - val_accuracy: 0.8752 - val_f1_score: 0.8703\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2719 - accuracy: 0.8845 - f1_score: 0.8833 - val_loss: 0.2953 - val_accuracy: 0.8797 - val_f1_score: 0.8760\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2225 - accuracy: 0.9092 - f1_score: 0.9082 - val_loss: 0.2928 - val_accuracy: 0.8870 - val_f1_score: 0.8863\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1755 - accuracy: 0.9267 - f1_score: 0.9259 - val_loss: 0.3149 - val_accuracy: 0.8942 - val_f1_score: 0.8935\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1448 - accuracy: 0.9475 - f1_score: 0.9472 - val_loss: 0.3174 - val_accuracy: 0.8807 - val_f1_score: 0.8755\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1103 - accuracy: 0.9605 - f1_score: 0.9603 - val_loss: 0.3047 - val_accuracy: 0.8870 - val_f1_score: 0.8856\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0817 - accuracy: 0.9707 - f1_score: 0.9706 - val_loss: 0.4180 - val_accuracy: 0.8852 - val_f1_score: 0.8871\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0718 - accuracy: 0.9723 - f1_score: 0.9722 - val_loss: 0.3957 - val_accuracy: 0.8825 - val_f1_score: 0.8807\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8596 - f1_score: 0.8847\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 24ms/step - loss: 0.4972 - accuracy: 0.7600 - f1_score: 0.7412 - val_loss: 0.3861 - val_accuracy: 0.8318 - val_f1_score: 0.8318\n","Epoch 2/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.3181 - accuracy: 0.8721 - f1_score: 0.8717 - val_loss: 0.3654 - val_accuracy: 0.8354 - val_f1_score: 0.8442\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2652 - accuracy: 0.8957 - f1_score: 0.8947 - val_loss: 0.3391 - val_accuracy: 0.8535 - val_f1_score: 0.8466\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2156 - accuracy: 0.9204 - f1_score: 0.9199 - val_loss: 0.3074 - val_accuracy: 0.8743 - val_f1_score: 0.8769\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1780 - accuracy: 0.9361 - f1_score: 0.9356 - val_loss: 0.3367 - val_accuracy: 0.8770 - val_f1_score: 0.8727\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1366 - accuracy: 0.9548 - f1_score: 0.9545 - val_loss: 0.3637 - val_accuracy: 0.8608 - val_f1_score: 0.8637\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1066 - accuracy: 0.9647 - f1_score: 0.9646 - val_loss: 0.3620 - val_accuracy: 0.8834 - val_f1_score: 0.8824\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0800 - accuracy: 0.9686 - f1_score: 0.9686 - val_loss: 0.4892 - val_accuracy: 0.8653 - val_f1_score: 0.8526\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0621 - accuracy: 0.9777 - f1_score: 0.9775 - val_loss: 0.4915 - val_accuracy: 0.8752 - val_f1_score: 0.8768\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8683 - f1_score: 0.8950\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 19ms/step - loss: 0.4788 - accuracy: 0.7675 - f1_score: 0.7561 - val_loss: 0.3734 - val_accuracy: 0.8363 - val_f1_score: 0.8307\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3146 - accuracy: 0.8791 - f1_score: 0.8775 - val_loss: 0.3539 - val_accuracy: 0.8535 - val_f1_score: 0.8460\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2528 - accuracy: 0.9011 - f1_score: 0.9004 - val_loss: 0.3499 - val_accuracy: 0.8508 - val_f1_score: 0.8525\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2126 - accuracy: 0.9159 - f1_score: 0.9154 - val_loss: 0.3233 - val_accuracy: 0.8635 - val_f1_score: 0.8626\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1651 - accuracy: 0.9376 - f1_score: 0.9374 - val_loss: 0.4161 - val_accuracy: 0.8626 - val_f1_score: 0.8587\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1360 - accuracy: 0.9496 - f1_score: 0.9493 - val_loss: 0.3919 - val_accuracy: 0.8689 - val_f1_score: 0.8618\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1009 - accuracy: 0.9674 - f1_score: 0.9673 - val_loss: 0.5051 - val_accuracy: 0.8553 - val_f1_score: 0.8476\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0707 - accuracy: 0.9768 - f1_score: 0.9766 - val_loss: 0.5278 - val_accuracy: 0.8580 - val_f1_score: 0.8477\n","Epoch 9/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0548 - accuracy: 0.9810 - f1_score: 0.9810 - val_loss: 0.6843 - val_accuracy: 0.8608 - val_f1_score: 0.8505\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8643 - f1_score: 0.8901\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4670 - accuracy: 0.7805 - f1_score: 0.7764 - val_loss: 0.3528 - val_accuracy: 0.8436 - val_f1_score: 0.8434\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3033 - accuracy: 0.8794 - f1_score: 0.8783 - val_loss: 0.3330 - val_accuracy: 0.8599 - val_f1_score: 0.8625\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2570 - accuracy: 0.8911 - f1_score: 0.8897 - val_loss: 0.3229 - val_accuracy: 0.8590 - val_f1_score: 0.8612\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2077 - accuracy: 0.9207 - f1_score: 0.9200 - val_loss: 0.3172 - val_accuracy: 0.8716 - val_f1_score: 0.8700\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1772 - accuracy: 0.9328 - f1_score: 0.9325 - val_loss: 0.3429 - val_accuracy: 0.8734 - val_f1_score: 0.8711\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1359 - accuracy: 0.9463 - f1_score: 0.9458 - val_loss: 0.3792 - val_accuracy: 0.8590 - val_f1_score: 0.8678\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1112 - accuracy: 0.9599 - f1_score: 0.9599 - val_loss: 0.3736 - val_accuracy: 0.8716 - val_f1_score: 0.8714\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0709 - accuracy: 0.9732 - f1_score: 0.9730 - val_loss: 0.5075 - val_accuracy: 0.8617 - val_f1_score: 0.8680\n","Epoch 9/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0483 - accuracy: 0.9843 - f1_score: 0.9843 - val_loss: 0.5522 - val_accuracy: 0.8743 - val_f1_score: 0.8728\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8548 - f1_score: 0.8782\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 17ms/step - loss: 0.4704 - accuracy: 0.7681 - f1_score: 0.7734 - val_loss: 0.3529 - val_accuracy: 0.8481 - val_f1_score: 0.8415\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3019 - accuracy: 0.8752 - f1_score: 0.8735 - val_loss: 0.3389 - val_accuracy: 0.8481 - val_f1_score: 0.8359\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2531 - accuracy: 0.8969 - f1_score: 0.8953 - val_loss: 0.3464 - val_accuracy: 0.8698 - val_f1_score: 0.8657\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2028 - accuracy: 0.9192 - f1_score: 0.9183 - val_loss: 0.3168 - val_accuracy: 0.8743 - val_f1_score: 0.8709\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1647 - accuracy: 0.9373 - f1_score: 0.9367 - val_loss: 0.3067 - val_accuracy: 0.8761 - val_f1_score: 0.8737\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1225 - accuracy: 0.9533 - f1_score: 0.9528 - val_loss: 0.3539 - val_accuracy: 0.8743 - val_f1_score: 0.8731\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0967 - accuracy: 0.9629 - f1_score: 0.9627 - val_loss: 0.3881 - val_accuracy: 0.8725 - val_f1_score: 0.8638\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0605 - accuracy: 0.9801 - f1_score: 0.9800 - val_loss: 0.4482 - val_accuracy: 0.8861 - val_f1_score: 0.8850\n","Epoch 9/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0636 - accuracy: 0.9756 - f1_score: 0.9755 - val_loss: 0.5585 - val_accuracy: 0.8553 - val_f1_score: 0.8428\n","Epoch 10/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0385 - accuracy: 0.9870 - f1_score: 0.9870 - val_loss: 0.5347 - val_accuracy: 0.8852 - val_f1_score: 0.8844\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2937 - accuracy: 0.8832 - f1_score: 0.9030\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 29ms/step - loss: 0.4954 - accuracy: 0.7587 - f1_score: 0.7598 - val_loss: 0.3824 - val_accuracy: 0.8300 - val_f1_score: 0.8433\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3164 - accuracy: 0.8667 - f1_score: 0.8673 - val_loss: 0.3288 - val_accuracy: 0.8553 - val_f1_score: 0.8553\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2623 - accuracy: 0.8926 - f1_score: 0.8924 - val_loss: 0.3301 - val_accuracy: 0.8599 - val_f1_score: 0.8649\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2237 - accuracy: 0.9089 - f1_score: 0.9084 - val_loss: 0.3104 - val_accuracy: 0.8680 - val_f1_score: 0.8726\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1859 - accuracy: 0.9234 - f1_score: 0.9228 - val_loss: 0.3306 - val_accuracy: 0.8671 - val_f1_score: 0.8670\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1459 - accuracy: 0.9445 - f1_score: 0.9445 - val_loss: 0.3206 - val_accuracy: 0.8861 - val_f1_score: 0.8871\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1115 - accuracy: 0.9575 - f1_score: 0.9573 - val_loss: 0.3964 - val_accuracy: 0.8852 - val_f1_score: 0.8881\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0746 - accuracy: 0.9720 - f1_score: 0.9719 - val_loss: 0.4481 - val_accuracy: 0.8816 - val_f1_score: 0.8814\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0736 - accuracy: 0.9738 - f1_score: 0.9737 - val_loss: 0.5002 - val_accuracy: 0.8707 - val_f1_score: 0.8677\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8791 - f1_score: 0.9030\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4908 - accuracy: 0.7636 - f1_score: 0.7676 - val_loss: 0.3397 - val_accuracy: 0.8481 - val_f1_score: 0.8403\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8613 - f1_score: 0.8588 - val_loss: 0.2904 - val_accuracy: 0.8734 - val_f1_score: 0.8687\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2630 - accuracy: 0.8899 - f1_score: 0.8868 - val_loss: 0.2878 - val_accuracy: 0.8852 - val_f1_score: 0.8899\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2137 - accuracy: 0.9141 - f1_score: 0.9123 - val_loss: 0.2832 - val_accuracy: 0.8969 - val_f1_score: 0.8942\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1803 - accuracy: 0.9288 - f1_score: 0.9279 - val_loss: 0.3048 - val_accuracy: 0.8770 - val_f1_score: 0.8690\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1397 - accuracy: 0.9445 - f1_score: 0.9437 - val_loss: 0.3035 - val_accuracy: 0.8978 - val_f1_score: 0.8960\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1146 - accuracy: 0.9554 - f1_score: 0.9550 - val_loss: 0.4771 - val_accuracy: 0.8761 - val_f1_score: 0.8844\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0864 - accuracy: 0.9701 - f1_score: 0.9699 - val_loss: 0.3818 - val_accuracy: 0.8897 - val_f1_score: 0.8881\n","Epoch 9/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0662 - accuracy: 0.9762 - f1_score: 0.9761 - val_loss: 0.4103 - val_accuracy: 0.8942 - val_f1_score: 0.8918\n","47/47 [==============================] - 0s 9ms/step - loss: 0.3271 - accuracy: 0.8758 - f1_score: 0.8951\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4764 - accuracy: 0.7690 - f1_score: 0.7730 - val_loss: 0.3382 - val_accuracy: 0.8617 - val_f1_score: 0.8640\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3097 - accuracy: 0.8688 - f1_score: 0.8680 - val_loss: 0.3072 - val_accuracy: 0.8580 - val_f1_score: 0.8540\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2601 - accuracy: 0.8923 - f1_score: 0.8922 - val_loss: 0.2928 - val_accuracy: 0.8734 - val_f1_score: 0.8696\n","Epoch 4/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2219 - accuracy: 0.9050 - f1_score: 0.9041 - val_loss: 0.2832 - val_accuracy: 0.8933 - val_f1_score: 0.8925\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1779 - accuracy: 0.9258 - f1_score: 0.9252 - val_loss: 0.3511 - val_accuracy: 0.8761 - val_f1_score: 0.8812\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1404 - accuracy: 0.9391 - f1_score: 0.9389 - val_loss: 0.3137 - val_accuracy: 0.8825 - val_f1_score: 0.8835\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1184 - accuracy: 0.9524 - f1_score: 0.9522 - val_loss: 0.3106 - val_accuracy: 0.8924 - val_f1_score: 0.8901\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0959 - accuracy: 0.9611 - f1_score: 0.9609 - val_loss: 0.3319 - val_accuracy: 0.8834 - val_f1_score: 0.8833\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0707 - accuracy: 0.9704 - f1_score: 0.9705 - val_loss: 0.4188 - val_accuracy: 0.8897 - val_f1_score: 0.8862\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8710 - f1_score: 0.8914\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 30ms/step - loss: 0.5022 - accuracy: 0.7503 - f1_score: 0.7603 - val_loss: 0.3512 - val_accuracy: 0.8508 - val_f1_score: 0.8493\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3265 - accuracy: 0.8646 - f1_score: 0.8618 - val_loss: 0.3104 - val_accuracy: 0.8580 - val_f1_score: 0.8540\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2684 - accuracy: 0.8932 - f1_score: 0.8911 - val_loss: 0.2930 - val_accuracy: 0.8825 - val_f1_score: 0.8843\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2212 - accuracy: 0.9098 - f1_score: 0.9084 - val_loss: 0.2911 - val_accuracy: 0.8779 - val_f1_score: 0.8791\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1865 - accuracy: 0.9273 - f1_score: 0.9264 - val_loss: 0.3380 - val_accuracy: 0.8807 - val_f1_score: 0.8836\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1464 - accuracy: 0.9454 - f1_score: 0.9449 - val_loss: 0.3495 - val_accuracy: 0.8770 - val_f1_score: 0.8794\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1193 - accuracy: 0.9581 - f1_score: 0.9576 - val_loss: 0.3681 - val_accuracy: 0.8797 - val_f1_score: 0.8763\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0954 - accuracy: 0.9650 - f1_score: 0.9647 - val_loss: 0.3836 - val_accuracy: 0.8834 - val_f1_score: 0.8798\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0723 - accuracy: 0.9717 - f1_score: 0.9715 - val_loss: 0.5631 - val_accuracy: 0.8599 - val_f1_score: 0.8688\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8683 - f1_score: 0.8903\n","47/47 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVO0gVHu03X6","executionInfo":{"status":"ok","timestamp":1697706327099,"user_tz":-330,"elapsed":28,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"8d1173d4-9fd0-4301-8d70-2dc8b106ddb9"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8811613917350769, 0.869007408618927, 0.8730587363243103, 0.8561782836914062, 0.8771100640296936, 0.8669817447662354, 0.8555030226707458, 0.8622552156448364, 0.871708333492279, 0.870357871055603, 0.8811613917350769, 0.8757596015930176, 0.8744091987609863, 0.8744091987609863, 0.8737339377403259, 0.8595543503761292, 0.8595543503761292, 0.8683322072029114, 0.8642808794975281, 0.8548278212547302, 0.8831870555877686, 0.8791357278823853, 0.8757596015930176, 0.8710330724716187, 0.8683322072029114]\n","0.8698717069625854\n","0.008117298489963003\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjU540tn1HHh","executionInfo":{"status":"ok","timestamp":1697706327099,"user_tz":-330,"elapsed":20,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"c03611fd-a104-476c-bb32-fe745dc72d19"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.2858201861381531, 0.2995949685573578, 0.3023446798324585, 0.34826964139938354, 0.30270636081695557, 0.32559341192245483, 0.32733428478240967, 0.3421434760093689, 0.32233095169067383, 0.31990137696266174, 0.2834921181201935, 0.3006541430950165, 0.3172311782836914, 0.3076723515987396, 0.3094419240951538, 0.314596027135849, 0.3065513074398041, 0.30101633071899414, 0.31861165165901184, 0.34353578090667725, 0.2937028706073761, 0.30108651518821716, 0.32712507247924805, 0.3242979347705841, 0.29887691140174866]\n","0.3129572582244873\n","0.016738719427145828\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfrfNyyr1HKh","executionInfo":{"status":"ok","timestamp":1697706327099,"user_tz":-330,"elapsed":19,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"06b14a31-7980-48dd-8199-ad870183ff03"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.903508722782135, 0.8896472454071045, 0.8934239745140076, 0.8753656148910522, 0.8965908885002136, 0.8914599418640137, 0.8789591789245605, 0.888767659664154, 0.8949114084243774, 0.8932146430015564, 0.9027623534202576, 0.9003250002861023, 0.8957398533821106, 0.8962053060531616, 0.89570552110672, 0.882882833480835, 0.8847006559371948, 0.8949918150901794, 0.890103816986084, 0.8781868815422058, 0.9029724597930908, 0.9029810428619385, 0.8950968384742737, 0.8914154767990112, 0.8902644515037537]\n","0.8924073433876037\n","0.007612119635308281\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0F86nof1HMo","executionInfo":{"status":"ok","timestamp":1697706327099,"user_tz":-330,"elapsed":18,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"ccabeac0-65de-4688-da96-2a50242ffd24"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.7497566264801124, 0.736641063427236, 0.7437063659198114, 0.7231199797647303, 0.7530560865241052, 0.7211599080012024, 0.7061917588451248, 0.7083363039981053, 0.7322626686610152, 0.7311618793186249, 0.7518417377731413, 0.7355393370174935, 0.742303396343123, 0.7407655538291402, 0.7391632700021411, 0.7128875365752134, 0.7073822101093443, 0.7185222199629115, 0.7133308374389675, 0.7054680412892801, 0.7608696395965889, 0.742838294419339, 0.7516410076500704, 0.7406270816829716, 0.7310187700949677]\n","0.7319836629889904\n","0.01624618711544457\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"dBbyX_cs1Hdt","executionInfo":{"status":"ok","timestamp":1697701907358,"user_tz":-330,"elapsed":59,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["Emb A\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.870/0.008\n","2. Loss - 0.303/0.013\n","3. F1 score - 0.891/0.008\n","4. MCC - 0.735/0.014\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.872/0.007\n","2. Loss - 0.301/0.019\n","3. F1 score - 0.894/0.007\n","4. MCC - 0.738/0.015"],"metadata":{"id":"dlwiKOXr1Htc"}},{"cell_type":"markdown","source":["Emb E\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.850/0.006\n","2. Loss - 0.343/0.014\n","3. F1 score - 0.875/0.006\n","4. MCC - 0.696/0.013\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.852/0.006\n","2. Loss - 0.344/0.010\n","3. F1 score - 0.876/0.006\n","4. MCC - 0.698/0.011"],"metadata":{"id":"38DQW6Ga2xDq"}},{"cell_type":"markdown","source":["Emb H\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.859/0.016\n","2. Loss - 0.322/0.024\n","3. F1 score - 0.883/0.016\n","4. MCC - 0.715/0.024\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.858/0.012\n","2. Loss - 0.324/0.020\n","3. F1 score - 0.881/0.013\n","4. MCC - 0.712/0.018"],"metadata":{"id":"MrmxkXsG2xIO"}},{"cell_type":"markdown","source":["Emb I\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.865/0.008\n","2. Loss - 0.323/0.022\n","3. F1 score - 0.887/0.008\n","4. MCC - 0.726/0.016\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.869/0.008\n","2. Loss - 0.312/0.016\n","3. F1 score - 0.892/0.007\n","4. MCC - 0.731/0.016"],"metadata":{"id":"Rd7Pvp9o2xKZ"}},{"cell_type":"code","source":[],"metadata":{"id":"TplRDBwhDGp8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nSjnzeCRmle5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNN layer to emotions with maxpooling (pool size 3 and stride 1) (with additional LSTM layer in emotions)"],"metadata":{"id":"n8M0dxkomlt2"}},{"cell_type":"code","source":["# LSTM CNN nothing nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=3, strides=1)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_lstm_emotions, input_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9w5I1gk4mqQf","executionInfo":{"status":"ok","timestamp":1697719291355,"user_tz":-330,"elapsed":605632,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"9ec1a77c-3b95-4d35-f91c-f22e37cfa459"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 9s 23ms/step - loss: 0.4652 - accuracy: 0.7790 - f1_score: 0.7754 - val_loss: 0.3611 - val_accuracy: 0.8373 - val_f1_score: 0.8469\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3019 - accuracy: 0.8752 - f1_score: 0.8766 - val_loss: 0.4599 - val_accuracy: 0.8110 - val_f1_score: 0.7769\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2480 - accuracy: 0.8987 - f1_score: 0.8980 - val_loss: 0.3187 - val_accuracy: 0.8689 - val_f1_score: 0.8654\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2093 - accuracy: 0.9243 - f1_score: 0.9241 - val_loss: 0.3164 - val_accuracy: 0.8707 - val_f1_score: 0.8647\n","Epoch 5/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1552 - accuracy: 0.9412 - f1_score: 0.9408 - val_loss: 0.3500 - val_accuracy: 0.8689 - val_f1_score: 0.8671\n","Epoch 6/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1229 - accuracy: 0.9545 - f1_score: 0.9543 - val_loss: 0.4045 - val_accuracy: 0.8544 - val_f1_score: 0.8581\n","Epoch 7/20\n","104/104 [==============================] - 2s 17ms/step - loss: 0.0992 - accuracy: 0.9626 - f1_score: 0.9626 - val_loss: 0.4853 - val_accuracy: 0.8644 - val_f1_score: 0.8609\n","Epoch 8/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0732 - accuracy: 0.9741 - f1_score: 0.9740 - val_loss: 0.5249 - val_accuracy: 0.8608 - val_f1_score: 0.8542\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0484 - accuracy: 0.9825 - f1_score: 0.9824 - val_loss: 0.6001 - val_accuracy: 0.8617 - val_f1_score: 0.8541\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3014 - accuracy: 0.8758 - f1_score: 0.8947\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 27ms/step - loss: 0.4865 - accuracy: 0.7606 - f1_score: 0.7561 - val_loss: 0.3739 - val_accuracy: 0.8490 - val_f1_score: 0.8393\n","Epoch 2/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.3161 - accuracy: 0.8679 - f1_score: 0.8677 - val_loss: 0.3471 - val_accuracy: 0.8671 - val_f1_score: 0.8617\n","Epoch 3/20\n","104/104 [==============================] - 2s 19ms/step - loss: 0.2636 - accuracy: 0.8890 - f1_score: 0.8894 - val_loss: 0.3904 - val_accuracy: 0.8300 - val_f1_score: 0.8029\n","Epoch 4/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.2183 - accuracy: 0.9144 - f1_score: 0.9137 - val_loss: 0.3135 - val_accuracy: 0.8816 - val_f1_score: 0.8799\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1728 - accuracy: 0.9337 - f1_score: 0.9331 - val_loss: 0.3223 - val_accuracy: 0.8761 - val_f1_score: 0.8686\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1392 - accuracy: 0.9493 - f1_score: 0.9491 - val_loss: 0.3544 - val_accuracy: 0.8779 - val_f1_score: 0.8760\n","Epoch 7/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0985 - accuracy: 0.9626 - f1_score: 0.9624 - val_loss: 0.4611 - val_accuracy: 0.8734 - val_f1_score: 0.8746\n","Epoch 8/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0801 - accuracy: 0.9683 - f1_score: 0.9683 - val_loss: 0.4538 - val_accuracy: 0.8716 - val_f1_score: 0.8704\n","Epoch 9/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0515 - accuracy: 0.9822 - f1_score: 0.9821 - val_loss: 0.5409 - val_accuracy: 0.8807 - val_f1_score: 0.8817\n","47/47 [==============================] - 0s 7ms/step - loss: 0.2983 - accuracy: 0.8751 - f1_score: 0.8957\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 31ms/step - loss: 0.4761 - accuracy: 0.7714 - f1_score: 0.7649 - val_loss: 0.3485 - val_accuracy: 0.8427 - val_f1_score: 0.8324\n","Epoch 2/20\n","104/104 [==============================] - 2s 17ms/step - loss: 0.3209 - accuracy: 0.8658 - f1_score: 0.8656 - val_loss: 0.3243 - val_accuracy: 0.8535 - val_f1_score: 0.8439\n","Epoch 3/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.2495 - accuracy: 0.8993 - f1_score: 0.8990 - val_loss: 0.2881 - val_accuracy: 0.8797 - val_f1_score: 0.8785\n","Epoch 4/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.2051 - accuracy: 0.9177 - f1_score: 0.9178 - val_loss: 0.3032 - val_accuracy: 0.8689 - val_f1_score: 0.8626\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1590 - accuracy: 0.9367 - f1_score: 0.9364 - val_loss: 0.3802 - val_accuracy: 0.8689 - val_f1_score: 0.8649\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1240 - accuracy: 0.9508 - f1_score: 0.9507 - val_loss: 0.3838 - val_accuracy: 0.8861 - val_f1_score: 0.8852\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1014 - accuracy: 0.9635 - f1_score: 0.9634 - val_loss: 0.4465 - val_accuracy: 0.8635 - val_f1_score: 0.8549\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0733 - accuracy: 0.9720 - f1_score: 0.9719 - val_loss: 0.4043 - val_accuracy: 0.8770 - val_f1_score: 0.8752\n","47/47 [==============================] - 0s 8ms/step - loss: 0.2860 - accuracy: 0.8771 - f1_score: 0.8982\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 13s 31ms/step - loss: 0.4778 - accuracy: 0.7738 - f1_score: 0.7715 - val_loss: 0.3393 - val_accuracy: 0.8535 - val_f1_score: 0.8497\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3043 - accuracy: 0.8764 - f1_score: 0.8756 - val_loss: 0.3022 - val_accuracy: 0.8680 - val_f1_score: 0.8678\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2392 - accuracy: 0.9038 - f1_score: 0.9034 - val_loss: 0.3175 - val_accuracy: 0.8707 - val_f1_score: 0.8677\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2061 - accuracy: 0.9171 - f1_score: 0.9168 - val_loss: 0.3179 - val_accuracy: 0.8761 - val_f1_score: 0.8676\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1583 - accuracy: 0.9382 - f1_score: 0.9379 - val_loss: 0.3191 - val_accuracy: 0.8861 - val_f1_score: 0.8842\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1215 - accuracy: 0.9575 - f1_score: 0.9573 - val_loss: 0.3884 - val_accuracy: 0.8698 - val_f1_score: 0.8691\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0864 - accuracy: 0.9714 - f1_score: 0.9713 - val_loss: 0.4136 - val_accuracy: 0.8770 - val_f1_score: 0.8775\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8650 - f1_score: 0.8880\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 25ms/step - loss: 0.4825 - accuracy: 0.7627 - f1_score: 0.7616 - val_loss: 0.3602 - val_accuracy: 0.8309 - val_f1_score: 0.8398\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3153 - accuracy: 0.8673 - f1_score: 0.8676 - val_loss: 0.3102 - val_accuracy: 0.8562 - val_f1_score: 0.8579\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2637 - accuracy: 0.8902 - f1_score: 0.8901 - val_loss: 0.2967 - val_accuracy: 0.8599 - val_f1_score: 0.8555\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2139 - accuracy: 0.9113 - f1_score: 0.9113 - val_loss: 0.3224 - val_accuracy: 0.8671 - val_f1_score: 0.8627\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1649 - accuracy: 0.9337 - f1_score: 0.9333 - val_loss: 0.3319 - val_accuracy: 0.8816 - val_f1_score: 0.8781\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1316 - accuracy: 0.9530 - f1_score: 0.9527 - val_loss: 0.3618 - val_accuracy: 0.8797 - val_f1_score: 0.8828\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0916 - accuracy: 0.9659 - f1_score: 0.9657 - val_loss: 0.4016 - val_accuracy: 0.8716 - val_f1_score: 0.8721\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0728 - accuracy: 0.9741 - f1_score: 0.9740 - val_loss: 0.4713 - val_accuracy: 0.8761 - val_f1_score: 0.8696\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8575 - f1_score: 0.8770\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 22ms/step - loss: 0.4897 - accuracy: 0.7603 - f1_score: 0.7515 - val_loss: 0.3594 - val_accuracy: 0.8409 - val_f1_score: 0.8448\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3197 - accuracy: 0.8679 - f1_score: 0.8663 - val_loss: 0.3823 - val_accuracy: 0.8345 - val_f1_score: 0.8496\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2590 - accuracy: 0.8993 - f1_score: 0.8980 - val_loss: 0.3587 - val_accuracy: 0.8535 - val_f1_score: 0.8418\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2168 - accuracy: 0.9150 - f1_score: 0.9137 - val_loss: 0.3224 - val_accuracy: 0.8535 - val_f1_score: 0.8483\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1757 - accuracy: 0.9297 - f1_score: 0.9284 - val_loss: 0.3513 - val_accuracy: 0.8689 - val_f1_score: 0.8725\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1306 - accuracy: 0.9514 - f1_score: 0.9511 - val_loss: 0.4106 - val_accuracy: 0.8617 - val_f1_score: 0.8691\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1033 - accuracy: 0.9623 - f1_score: 0.9621 - val_loss: 0.3804 - val_accuracy: 0.8689 - val_f1_score: 0.8690\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9753 - f1_score: 0.9752 - val_loss: 0.5155 - val_accuracy: 0.8662 - val_f1_score: 0.8720\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0548 - accuracy: 0.9783 - f1_score: 0.9782 - val_loss: 0.6009 - val_accuracy: 0.8553 - val_f1_score: 0.8639\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8508 - f1_score: 0.8722\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 19ms/step - loss: 0.4862 - accuracy: 0.7690 - f1_score: 0.7777 - val_loss: 0.3715 - val_accuracy: 0.8373 - val_f1_score: 0.8399\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3130 - accuracy: 0.8715 - f1_score: 0.8711 - val_loss: 0.3727 - val_accuracy: 0.8436 - val_f1_score: 0.8520\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2412 - accuracy: 0.9059 - f1_score: 0.9054 - val_loss: 0.3280 - val_accuracy: 0.8680 - val_f1_score: 0.8675\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1987 - accuracy: 0.9267 - f1_score: 0.9258 - val_loss: 0.3415 - val_accuracy: 0.8599 - val_f1_score: 0.8620\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1668 - accuracy: 0.9373 - f1_score: 0.9367 - val_loss: 0.3970 - val_accuracy: 0.8571 - val_f1_score: 0.8454\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1269 - accuracy: 0.9536 - f1_score: 0.9532 - val_loss: 0.3841 - val_accuracy: 0.8698 - val_f1_score: 0.8659\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1013 - accuracy: 0.9638 - f1_score: 0.9636 - val_loss: 0.4453 - val_accuracy: 0.8526 - val_f1_score: 0.8624\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0696 - accuracy: 0.9738 - f1_score: 0.9738 - val_loss: 0.4474 - val_accuracy: 0.8671 - val_f1_score: 0.8627\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8575 - f1_score: 0.8827\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.4881 - accuracy: 0.7678 - f1_score: 0.7585 - val_loss: 0.3510 - val_accuracy: 0.8517 - val_f1_score: 0.8514\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2967 - accuracy: 0.8718 - f1_score: 0.8719 - val_loss: 0.3499 - val_accuracy: 0.8427 - val_f1_score: 0.8330\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2428 - accuracy: 0.8990 - f1_score: 0.8980 - val_loss: 0.3164 - val_accuracy: 0.8626 - val_f1_score: 0.8631\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2036 - accuracy: 0.9204 - f1_score: 0.9196 - val_loss: 0.3352 - val_accuracy: 0.8626 - val_f1_score: 0.8650\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1648 - accuracy: 0.9340 - f1_score: 0.9337 - val_loss: 0.3723 - val_accuracy: 0.8617 - val_f1_score: 0.8530\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1335 - accuracy: 0.9490 - f1_score: 0.9486 - val_loss: 0.3904 - val_accuracy: 0.8761 - val_f1_score: 0.8776\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0943 - accuracy: 0.9674 - f1_score: 0.9673 - val_loss: 0.4548 - val_accuracy: 0.8698 - val_f1_score: 0.8674\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0802 - accuracy: 0.9720 - f1_score: 0.9719 - val_loss: 0.4694 - val_accuracy: 0.8680 - val_f1_score: 0.8733\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8582 - f1_score: 0.8836\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 17ms/step - loss: 0.4851 - accuracy: 0.7684 - f1_score: 0.7714 - val_loss: 0.3409 - val_accuracy: 0.8526 - val_f1_score: 0.8492\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3129 - accuracy: 0.8652 - f1_score: 0.8645 - val_loss: 0.3115 - val_accuracy: 0.8580 - val_f1_score: 0.8594\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2508 - accuracy: 0.8932 - f1_score: 0.8921 - val_loss: 0.3571 - val_accuracy: 0.8535 - val_f1_score: 0.8399\n","Epoch 4/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2038 - accuracy: 0.9153 - f1_score: 0.9144 - val_loss: 0.3698 - val_accuracy: 0.8562 - val_f1_score: 0.8396\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1735 - accuracy: 0.9276 - f1_score: 0.9267 - val_loss: 0.3354 - val_accuracy: 0.8752 - val_f1_score: 0.8676\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1256 - accuracy: 0.9521 - f1_score: 0.9517 - val_loss: 0.3750 - val_accuracy: 0.8788 - val_f1_score: 0.8707\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1010 - accuracy: 0.9614 - f1_score: 0.9613 - val_loss: 0.3433 - val_accuracy: 0.8942 - val_f1_score: 0.8885\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8596 - f1_score: 0.8871\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 18ms/step - loss: 0.4805 - accuracy: 0.7627 - f1_score: 0.7705 - val_loss: 0.3521 - val_accuracy: 0.8481 - val_f1_score: 0.8430\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3069 - accuracy: 0.8718 - f1_score: 0.8713 - val_loss: 0.3427 - val_accuracy: 0.8508 - val_f1_score: 0.8371\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2485 - accuracy: 0.8948 - f1_score: 0.8944 - val_loss: 0.3127 - val_accuracy: 0.8698 - val_f1_score: 0.8605\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1968 - accuracy: 0.9195 - f1_score: 0.9191 - val_loss: 0.3192 - val_accuracy: 0.8816 - val_f1_score: 0.8831\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1469 - accuracy: 0.9454 - f1_score: 0.9451 - val_loss: 0.3682 - val_accuracy: 0.8635 - val_f1_score: 0.8527\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1142 - accuracy: 0.9587 - f1_score: 0.9584 - val_loss: 0.3971 - val_accuracy: 0.8626 - val_f1_score: 0.8527\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0858 - accuracy: 0.9695 - f1_score: 0.9695 - val_loss: 0.4433 - val_accuracy: 0.8743 - val_f1_score: 0.8654\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0535 - accuracy: 0.9840 - f1_score: 0.9839 - val_loss: 0.5738 - val_accuracy: 0.8779 - val_f1_score: 0.8723\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8555 - f1_score: 0.8780\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4951 - accuracy: 0.7572 - f1_score: 0.7445 - val_loss: 0.3591 - val_accuracy: 0.8463 - val_f1_score: 0.8547\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3253 - accuracy: 0.8622 - f1_score: 0.8640 - val_loss: 0.3084 - val_accuracy: 0.8734 - val_f1_score: 0.8687\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2723 - accuracy: 0.8893 - f1_score: 0.8894 - val_loss: 0.2947 - val_accuracy: 0.8834 - val_f1_score: 0.8782\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2307 - accuracy: 0.9116 - f1_score: 0.9121 - val_loss: 0.2911 - val_accuracy: 0.8852 - val_f1_score: 0.8821\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1902 - accuracy: 0.9273 - f1_score: 0.9269 - val_loss: 0.3000 - val_accuracy: 0.8807 - val_f1_score: 0.8846\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1465 - accuracy: 0.9469 - f1_score: 0.9468 - val_loss: 0.3405 - val_accuracy: 0.8843 - val_f1_score: 0.8851\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1206 - accuracy: 0.9590 - f1_score: 0.9591 - val_loss: 0.3643 - val_accuracy: 0.8825 - val_f1_score: 0.8762\n","Epoch 8/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0918 - accuracy: 0.9671 - f1_score: 0.9671 - val_loss: 0.4226 - val_accuracy: 0.8834 - val_f1_score: 0.8775\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0769 - accuracy: 0.9735 - f1_score: 0.9735 - val_loss: 0.4259 - val_accuracy: 0.8788 - val_f1_score: 0.8699\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8751 - f1_score: 0.8972\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 17ms/step - loss: 0.4771 - accuracy: 0.7636 - f1_score: 0.7594 - val_loss: 0.3737 - val_accuracy: 0.8282 - val_f1_score: 0.8180\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3156 - accuracy: 0.8691 - f1_score: 0.8683 - val_loss: 0.3694 - val_accuracy: 0.8354 - val_f1_score: 0.8216\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2591 - accuracy: 0.8923 - f1_score: 0.8917 - val_loss: 0.3396 - val_accuracy: 0.8617 - val_f1_score: 0.8582\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2107 - accuracy: 0.9168 - f1_score: 0.9161 - val_loss: 0.3319 - val_accuracy: 0.8698 - val_f1_score: 0.8644\n","Epoch 5/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1758 - accuracy: 0.9288 - f1_score: 0.9282 - val_loss: 0.3792 - val_accuracy: 0.8580 - val_f1_score: 0.8447\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1397 - accuracy: 0.9439 - f1_score: 0.9433 - val_loss: 0.4238 - val_accuracy: 0.8626 - val_f1_score: 0.8492\n","Epoch 7/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1099 - accuracy: 0.9557 - f1_score: 0.9555 - val_loss: 0.4056 - val_accuracy: 0.8707 - val_f1_score: 0.8731\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0756 - accuracy: 0.9759 - f1_score: 0.9758 - val_loss: 0.4678 - val_accuracy: 0.8635 - val_f1_score: 0.8544\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0597 - accuracy: 0.9807 - f1_score: 0.9806 - val_loss: 0.6607 - val_accuracy: 0.8562 - val_f1_score: 0.8418\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8778 - f1_score: 0.8977\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 19ms/step - loss: 0.4717 - accuracy: 0.7672 - f1_score: 0.7729 - val_loss: 0.3728 - val_accuracy: 0.8336 - val_f1_score: 0.8394\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3064 - accuracy: 0.8742 - f1_score: 0.8732 - val_loss: 0.3513 - val_accuracy: 0.8580 - val_f1_score: 0.8579\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2580 - accuracy: 0.8969 - f1_score: 0.8955 - val_loss: 0.3351 - val_accuracy: 0.8635 - val_f1_score: 0.8585\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2137 - accuracy: 0.9180 - f1_score: 0.9168 - val_loss: 0.3790 - val_accuracy: 0.8553 - val_f1_score: 0.8431\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1691 - accuracy: 0.9373 - f1_score: 0.9366 - val_loss: 0.3625 - val_accuracy: 0.8608 - val_f1_score: 0.8522\n","Epoch 6/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.1497 - accuracy: 0.9448 - f1_score: 0.9440 - val_loss: 0.3831 - val_accuracy: 0.8535 - val_f1_score: 0.8503\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1112 - accuracy: 0.9599 - f1_score: 0.9595 - val_loss: 0.4256 - val_accuracy: 0.8671 - val_f1_score: 0.8645\n","Epoch 8/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0837 - accuracy: 0.9720 - f1_score: 0.9717 - val_loss: 0.5771 - val_accuracy: 0.8571 - val_f1_score: 0.8624\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2992 - accuracy: 0.8859 - f1_score: 0.9053\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.5058 - accuracy: 0.7467 - f1_score: 0.7407 - val_loss: 0.3772 - val_accuracy: 0.8300 - val_f1_score: 0.8360\n","Epoch 2/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.3337 - accuracy: 0.8528 - f1_score: 0.8532 - val_loss: 0.3342 - val_accuracy: 0.8508 - val_f1_score: 0.8474\n","Epoch 3/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.2774 - accuracy: 0.8941 - f1_score: 0.8926 - val_loss: 0.3041 - val_accuracy: 0.8698 - val_f1_score: 0.8696\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2344 - accuracy: 0.9077 - f1_score: 0.9070 - val_loss: 0.3019 - val_accuracy: 0.8788 - val_f1_score: 0.8791\n","Epoch 5/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1914 - accuracy: 0.9282 - f1_score: 0.9274 - val_loss: 0.3363 - val_accuracy: 0.8608 - val_f1_score: 0.8531\n","Epoch 6/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1520 - accuracy: 0.9475 - f1_score: 0.9470 - val_loss: 0.3266 - val_accuracy: 0.8662 - val_f1_score: 0.8627\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1136 - accuracy: 0.9584 - f1_score: 0.9582 - val_loss: 0.3491 - val_accuracy: 0.8671 - val_f1_score: 0.8643\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0814 - accuracy: 0.9720 - f1_score: 0.9718 - val_loss: 0.4545 - val_accuracy: 0.8617 - val_f1_score: 0.8590\n","Epoch 9/20\n","104/104 [==============================] - 1s 8ms/step - loss: 0.0580 - accuracy: 0.9798 - f1_score: 0.9798 - val_loss: 0.5072 - val_accuracy: 0.8617 - val_f1_score: 0.8698\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.8764 - f1_score: 0.8988\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 25ms/step - loss: 0.4883 - accuracy: 0.7687 - f1_score: 0.7688 - val_loss: 0.3309 - val_accuracy: 0.8626 - val_f1_score: 0.8655\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3242 - accuracy: 0.8628 - f1_score: 0.8624 - val_loss: 0.3035 - val_accuracy: 0.8734 - val_f1_score: 0.8774\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2741 - accuracy: 0.8911 - f1_score: 0.8896 - val_loss: 0.2848 - val_accuracy: 0.8816 - val_f1_score: 0.8829\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2271 - accuracy: 0.9119 - f1_score: 0.9110 - val_loss: 0.3071 - val_accuracy: 0.8761 - val_f1_score: 0.8756\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1908 - accuracy: 0.9282 - f1_score: 0.9274 - val_loss: 0.2945 - val_accuracy: 0.8779 - val_f1_score: 0.8804\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1506 - accuracy: 0.9430 - f1_score: 0.9420 - val_loss: 0.3151 - val_accuracy: 0.8770 - val_f1_score: 0.8775\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1244 - accuracy: 0.9536 - f1_score: 0.9533 - val_loss: 0.4102 - val_accuracy: 0.8716 - val_f1_score: 0.8655\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0843 - accuracy: 0.9704 - f1_score: 0.9703 - val_loss: 0.4168 - val_accuracy: 0.8852 - val_f1_score: 0.8844\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8744 - f1_score: 0.8986\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 22ms/step - loss: 0.4747 - accuracy: 0.7696 - f1_score: 0.7758 - val_loss: 0.3444 - val_accuracy: 0.8481 - val_f1_score: 0.8453\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3058 - accuracy: 0.8758 - f1_score: 0.8753 - val_loss: 0.3183 - val_accuracy: 0.8680 - val_f1_score: 0.8610\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2589 - accuracy: 0.8969 - f1_score: 0.8961 - val_loss: 0.3210 - val_accuracy: 0.8580 - val_f1_score: 0.8462\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2081 - accuracy: 0.9255 - f1_score: 0.9251 - val_loss: 0.2915 - val_accuracy: 0.8770 - val_f1_score: 0.8792\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1635 - accuracy: 0.9373 - f1_score: 0.9367 - val_loss: 0.3006 - val_accuracy: 0.8770 - val_f1_score: 0.8794\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1344 - accuracy: 0.9508 - f1_score: 0.9505 - val_loss: 0.3455 - val_accuracy: 0.8725 - val_f1_score: 0.8648\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1121 - accuracy: 0.9614 - f1_score: 0.9610 - val_loss: 0.3518 - val_accuracy: 0.8716 - val_f1_score: 0.8728\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0865 - accuracy: 0.9701 - f1_score: 0.9699 - val_loss: 0.4250 - val_accuracy: 0.8590 - val_f1_score: 0.8651\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0517 - accuracy: 0.9810 - f1_score: 0.9809 - val_loss: 0.5587 - val_accuracy: 0.8617 - val_f1_score: 0.8481\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8758 - f1_score: 0.9005\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 20ms/step - loss: 0.4728 - accuracy: 0.7747 - f1_score: 0.7745 - val_loss: 0.3602 - val_accuracy: 0.8472 - val_f1_score: 0.8590\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3092 - accuracy: 0.8664 - f1_score: 0.8652 - val_loss: 0.3032 - val_accuracy: 0.8788 - val_f1_score: 0.8775\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2552 - accuracy: 0.8875 - f1_score: 0.8857 - val_loss: 0.2928 - val_accuracy: 0.8788 - val_f1_score: 0.8775\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2141 - accuracy: 0.9095 - f1_score: 0.9087 - val_loss: 0.2807 - val_accuracy: 0.8879 - val_f1_score: 0.8839\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1740 - accuracy: 0.9285 - f1_score: 0.9278 - val_loss: 0.2930 - val_accuracy: 0.8861 - val_f1_score: 0.8883\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1312 - accuracy: 0.9460 - f1_score: 0.9456 - val_loss: 0.3101 - val_accuracy: 0.8861 - val_f1_score: 0.8852\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1045 - accuracy: 0.9614 - f1_score: 0.9612 - val_loss: 0.3457 - val_accuracy: 0.8816 - val_f1_score: 0.8829\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0843 - accuracy: 0.9674 - f1_score: 0.9674 - val_loss: 0.4574 - val_accuracy: 0.8689 - val_f1_score: 0.8725\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0612 - accuracy: 0.9774 - f1_score: 0.9773 - val_loss: 0.4461 - val_accuracy: 0.8743 - val_f1_score: 0.8775\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8521 - f1_score: 0.8754\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 18ms/step - loss: 0.4714 - accuracy: 0.7747 - f1_score: 0.7743 - val_loss: 0.3673 - val_accuracy: 0.8418 - val_f1_score: 0.8369\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3060 - accuracy: 0.8733 - f1_score: 0.8721 - val_loss: 0.3279 - val_accuracy: 0.8571 - val_f1_score: 0.8558\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2544 - accuracy: 0.9017 - f1_score: 0.9013 - val_loss: 0.3172 - val_accuracy: 0.8653 - val_f1_score: 0.8606\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2027 - accuracy: 0.9228 - f1_score: 0.9221 - val_loss: 0.3206 - val_accuracy: 0.8788 - val_f1_score: 0.8812\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1642 - accuracy: 0.9352 - f1_score: 0.9348 - val_loss: 0.3578 - val_accuracy: 0.8761 - val_f1_score: 0.8787\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1261 - accuracy: 0.9496 - f1_score: 0.9494 - val_loss: 0.3241 - val_accuracy: 0.8680 - val_f1_score: 0.8699\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0946 - accuracy: 0.9686 - f1_score: 0.9684 - val_loss: 0.3909 - val_accuracy: 0.8816 - val_f1_score: 0.8788\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0641 - accuracy: 0.9762 - f1_score: 0.9761 - val_loss: 0.4973 - val_accuracy: 0.8816 - val_f1_score: 0.8808\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8609 - f1_score: 0.8845\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4847 - accuracy: 0.7566 - f1_score: 0.7521 - val_loss: 0.3768 - val_accuracy: 0.8255 - val_f1_score: 0.8142\n","Epoch 2/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.3069 - accuracy: 0.8739 - f1_score: 0.8722 - val_loss: 0.3575 - val_accuracy: 0.8336 - val_f1_score: 0.8164\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2542 - accuracy: 0.8996 - f1_score: 0.8974 - val_loss: 0.3327 - val_accuracy: 0.8635 - val_f1_score: 0.8574\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2035 - accuracy: 0.9216 - f1_score: 0.9202 - val_loss: 0.3353 - val_accuracy: 0.8680 - val_f1_score: 0.8648\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1646 - accuracy: 0.9340 - f1_score: 0.9327 - val_loss: 0.3731 - val_accuracy: 0.8770 - val_f1_score: 0.8748\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1398 - accuracy: 0.9496 - f1_score: 0.9489 - val_loss: 0.3710 - val_accuracy: 0.8544 - val_f1_score: 0.8594\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1068 - accuracy: 0.9641 - f1_score: 0.9637 - val_loss: 0.4442 - val_accuracy: 0.8716 - val_f1_score: 0.8688\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0806 - accuracy: 0.9717 - f1_score: 0.9714 - val_loss: 0.4493 - val_accuracy: 0.8779 - val_f1_score: 0.8742\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8569 - f1_score: 0.8798\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 20ms/step - loss: 0.4629 - accuracy: 0.7877 - f1_score: 0.7895 - val_loss: 0.3475 - val_accuracy: 0.8418 - val_f1_score: 0.8396\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3053 - accuracy: 0.8682 - f1_score: 0.8679 - val_loss: 0.3550 - val_accuracy: 0.8508 - val_f1_score: 0.8421\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2504 - accuracy: 0.9014 - f1_score: 0.9013 - val_loss: 0.3152 - val_accuracy: 0.8580 - val_f1_score: 0.8592\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2117 - accuracy: 0.9177 - f1_score: 0.9173 - val_loss: 0.3139 - val_accuracy: 0.8698 - val_f1_score: 0.8719\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1621 - accuracy: 0.9379 - f1_score: 0.9376 - val_loss: 0.4005 - val_accuracy: 0.8635 - val_f1_score: 0.8618\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1292 - accuracy: 0.9527 - f1_score: 0.9527 - val_loss: 0.3819 - val_accuracy: 0.8698 - val_f1_score: 0.8672\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0956 - accuracy: 0.9662 - f1_score: 0.9662 - val_loss: 0.4159 - val_accuracy: 0.8761 - val_f1_score: 0.8799\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0681 - accuracy: 0.9777 - f1_score: 0.9777 - val_loss: 0.4942 - val_accuracy: 0.8797 - val_f1_score: 0.8790\n","Epoch 9/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0494 - accuracy: 0.9831 - f1_score: 0.9831 - val_loss: 0.5235 - val_accuracy: 0.8752 - val_f1_score: 0.8787\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8636 - f1_score: 0.8888\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4610 - accuracy: 0.7823 - f1_score: 0.7800 - val_loss: 0.3694 - val_accuracy: 0.8327 - val_f1_score: 0.8282\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3057 - accuracy: 0.8709 - f1_score: 0.8706 - val_loss: 0.3297 - val_accuracy: 0.8490 - val_f1_score: 0.8402\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2560 - accuracy: 0.8878 - f1_score: 0.8869 - val_loss: 0.3238 - val_accuracy: 0.8644 - val_f1_score: 0.8585\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2066 - accuracy: 0.9125 - f1_score: 0.9121 - val_loss: 0.3649 - val_accuracy: 0.8653 - val_f1_score: 0.8622\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1646 - accuracy: 0.9309 - f1_score: 0.9303 - val_loss: 0.3249 - val_accuracy: 0.8653 - val_f1_score: 0.8619\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1244 - accuracy: 0.9496 - f1_score: 0.9493 - val_loss: 0.4350 - val_accuracy: 0.8644 - val_f1_score: 0.8532\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0956 - accuracy: 0.9647 - f1_score: 0.9645 - val_loss: 0.4462 - val_accuracy: 0.8788 - val_f1_score: 0.8812\n","Epoch 8/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0721 - accuracy: 0.9729 - f1_score: 0.9728 - val_loss: 0.5000 - val_accuracy: 0.8752 - val_f1_score: 0.8705\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8643 - f1_score: 0.8855\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 19ms/step - loss: 0.4867 - accuracy: 0.7603 - f1_score: 0.7539 - val_loss: 0.3551 - val_accuracy: 0.8427 - val_f1_score: 0.8430\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3109 - accuracy: 0.8622 - f1_score: 0.8609 - val_loss: 0.3228 - val_accuracy: 0.8644 - val_f1_score: 0.8675\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2583 - accuracy: 0.8929 - f1_score: 0.8924 - val_loss: 0.3055 - val_accuracy: 0.8743 - val_f1_score: 0.8756\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2117 - accuracy: 0.9119 - f1_score: 0.9112 - val_loss: 0.2930 - val_accuracy: 0.8807 - val_f1_score: 0.8778\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1669 - accuracy: 0.9334 - f1_score: 0.9332 - val_loss: 0.3214 - val_accuracy: 0.8788 - val_f1_score: 0.8775\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1468 - accuracy: 0.9439 - f1_score: 0.9435 - val_loss: 0.3262 - val_accuracy: 0.8761 - val_f1_score: 0.8795\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1062 - accuracy: 0.9638 - f1_score: 0.9635 - val_loss: 0.4035 - val_accuracy: 0.8617 - val_f1_score: 0.8574\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0824 - accuracy: 0.9707 - f1_score: 0.9707 - val_loss: 0.3837 - val_accuracy: 0.8807 - val_f1_score: 0.8762\n","Epoch 9/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0549 - accuracy: 0.9816 - f1_score: 0.9816 - val_loss: 0.5289 - val_accuracy: 0.8825 - val_f1_score: 0.8805\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8596 - f1_score: 0.8805\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 19ms/step - loss: 0.4931 - accuracy: 0.7563 - f1_score: 0.7601 - val_loss: 0.3231 - val_accuracy: 0.8689 - val_f1_score: 0.8661\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3166 - accuracy: 0.8679 - f1_score: 0.8671 - val_loss: 0.3082 - val_accuracy: 0.8725 - val_f1_score: 0.8769\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2596 - accuracy: 0.8932 - f1_score: 0.8921 - val_loss: 0.2913 - val_accuracy: 0.8743 - val_f1_score: 0.8687\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2212 - accuracy: 0.9098 - f1_score: 0.9088 - val_loss: 0.2677 - val_accuracy: 0.8870 - val_f1_score: 0.8846\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1628 - accuracy: 0.9367 - f1_score: 0.9359 - val_loss: 0.2900 - val_accuracy: 0.8879 - val_f1_score: 0.8856\n","Epoch 6/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1379 - accuracy: 0.9418 - f1_score: 0.9415 - val_loss: 0.2957 - val_accuracy: 0.8825 - val_f1_score: 0.8740\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1039 - accuracy: 0.9629 - f1_score: 0.9626 - val_loss: 0.4567 - val_accuracy: 0.8816 - val_f1_score: 0.8874\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0733 - accuracy: 0.9738 - f1_score: 0.9737 - val_loss: 0.3663 - val_accuracy: 0.8897 - val_f1_score: 0.8924\n","Epoch 9/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0545 - accuracy: 0.9813 - f1_score: 0.9812 - val_loss: 0.4529 - val_accuracy: 0.8897 - val_f1_score: 0.8897\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8731 - f1_score: 0.8923\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 7s 17ms/step - loss: 0.4900 - accuracy: 0.7687 - f1_score: 0.7722 - val_loss: 0.3236 - val_accuracy: 0.8635 - val_f1_score: 0.8629\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3030 - accuracy: 0.8785 - f1_score: 0.8776 - val_loss: 0.3356 - val_accuracy: 0.8499 - val_f1_score: 0.8605\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2564 - accuracy: 0.8987 - f1_score: 0.8981 - val_loss: 0.2817 - val_accuracy: 0.8816 - val_f1_score: 0.8823\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2173 - accuracy: 0.9080 - f1_score: 0.9073 - val_loss: 0.2971 - val_accuracy: 0.8834 - val_f1_score: 0.8853\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1773 - accuracy: 0.9276 - f1_score: 0.9272 - val_loss: 0.2808 - val_accuracy: 0.8879 - val_f1_score: 0.8875\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1429 - accuracy: 0.9412 - f1_score: 0.9406 - val_loss: 0.3439 - val_accuracy: 0.8797 - val_f1_score: 0.8830\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1067 - accuracy: 0.9581 - f1_score: 0.9580 - val_loss: 0.3448 - val_accuracy: 0.8807 - val_f1_score: 0.8766\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0801 - accuracy: 0.9720 - f1_score: 0.9719 - val_loss: 0.4127 - val_accuracy: 0.8608 - val_f1_score: 0.8682\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0513 - accuracy: 0.9816 - f1_score: 0.9816 - val_loss: 0.5446 - val_accuracy: 0.8562 - val_f1_score: 0.8658\n","Epoch 10/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.0607 - accuracy: 0.9780 - f1_score: 0.9779 - val_loss: 0.5914 - val_accuracy: 0.8472 - val_f1_score: 0.8600\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8569 - f1_score: 0.8795\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 8s 17ms/step - loss: 0.4869 - accuracy: 0.7584 - f1_score: 0.7538 - val_loss: 0.3440 - val_accuracy: 0.8571 - val_f1_score: 0.8487\n","Epoch 2/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.3024 - accuracy: 0.8733 - f1_score: 0.8720 - val_loss: 0.2935 - val_accuracy: 0.8807 - val_f1_score: 0.8832\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2517 - accuracy: 0.8963 - f1_score: 0.8953 - val_loss: 0.2995 - val_accuracy: 0.8743 - val_f1_score: 0.8767\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2149 - accuracy: 0.9119 - f1_score: 0.9108 - val_loss: 0.3216 - val_accuracy: 0.8770 - val_f1_score: 0.8830\n","Epoch 5/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1730 - accuracy: 0.9306 - f1_score: 0.9300 - val_loss: 0.3068 - val_accuracy: 0.8825 - val_f1_score: 0.8852\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1332 - accuracy: 0.9508 - f1_score: 0.9506 - val_loss: 0.3281 - val_accuracy: 0.8834 - val_f1_score: 0.8786\n","Epoch 7/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1126 - accuracy: 0.9611 - f1_score: 0.9608 - val_loss: 0.3477 - val_accuracy: 0.8779 - val_f1_score: 0.8718\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3124 - accuracy: 0.8704 - f1_score: 0.8931\n","47/47 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5QXWMEDRmyE-","executionInfo":{"status":"ok","timestamp":1697719291356,"user_tz":-330,"elapsed":22,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"32b72bf7-4e02-43f0-e41b-3421ebbd2006"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8757596015930176, 0.875084400177002, 0.8771100640296936, 0.8649561405181885, 0.8575286865234375, 0.8507764935493469, 0.8575286865234375, 0.8582038879394531, 0.8595543503761292, 0.8555030226707458, 0.875084400177002, 0.8777852654457092, 0.8858879208564758, 0.876434862613678, 0.8744091987609863, 0.8757596015930176, 0.852126955986023, 0.8609048128128052, 0.8568534851074219, 0.8636056780815125, 0.8642808794975281, 0.8595543503761292, 0.8730587363243103, 0.8568534851074219, 0.870357871055603]\n","0.866198513507843\n","0.009561794778114724\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXrkIcfpmyN0","executionInfo":{"status":"ok","timestamp":1697719291356,"user_tz":-330,"elapsed":20,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"04f638fb-4196-4f22-a77e-d9a54e2bc930"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.30135831236839294, 0.2982695400714874, 0.2859920561313629, 0.3093246817588806, 0.3328467309474945, 0.3658449351787567, 0.3426494300365448, 0.3316986560821533, 0.3236217796802521, 0.3323739171028137, 0.31483736634254456, 0.31337013840675354, 0.2992148697376251, 0.27878835797309875, 0.2963360548019409, 0.30439114570617676, 0.3182051479816437, 0.31937938928604126, 0.3293134868144989, 0.32055866718292236, 0.3206067979335785, 0.34326380491256714, 0.30421021580696106, 0.3301314413547516, 0.3124466836452484]\n","0.31716134428977966\n","0.018992164702575715\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pK0H31k3myVX","executionInfo":{"status":"ok","timestamp":1697719291357,"user_tz":-330,"elapsed":19,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"173a492b-b8bc-4cc8-ddb6-0a151216fa0b"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8947367668151855, 0.8956570029258728, 0.8982102870941162, 0.8880178928375244, 0.8769678473472595, 0.8721804022789001, 0.8827126026153564, 0.8835919499397278, 0.8870791792869568, 0.877993106842041, 0.897165060043335, 0.8976821899414062, 0.9053220152854919, 0.8988390564918518, 0.8985822200775146, 0.9005405306816101, 0.8753556609153748, 0.8845290541648865, 0.8798185586929321, 0.8887665271759033, 0.8854700326919556, 0.880459725856781, 0.892325222492218, 0.8795453310012817, 0.8930957317352295]\n","0.8885857582092285\n","0.008951912816642269\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1QwfdWmmygW","executionInfo":{"status":"ok","timestamp":1697719291357,"user_tz":-330,"elapsed":17,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"6b7c3d98-1fac-4951-bd71-9936d4ca24b2"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.7530873431849233, 0.7459676146311552, 0.747181634957828, 0.7221171147593421, 0.724137880686593, 0.7061618226688716, 0.704037302199909, 0.7045424035083524, 0.7015350523112418, 0.7094811544346334, 0.7409085522726863, 0.7524620692413347, 0.7661365327713189, 0.7420488730751569, 0.7341151215610908, 0.7351049810370388, 0.7017255973705082, 0.7140388763911454, 0.7099219235724701, 0.7138781374434598, 0.7275102361090675, 0.7214309118914953, 0.7479655717661793, 0.7108547940283167, 0.7315262747473031]\n","0.726715111064857\n","0.018587832892154633\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xoSy6FM9mypy","executionInfo":{"status":"ok","timestamp":1697719291358,"user_tz":-330,"elapsed":17,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["# LSTM CNN LSTM nothing\n","\n","test_seed = [1,2,3,4,5]\n","train_val_undersample_seed = [6,7,8,9,10]\n","\n","accuracies = []\n","losses = []\n","f1scores = []\n","matthew_coreff = []\n","\n","for i in test_seed:\n","    # Split into remaining data and test\n","    X_sentemb_remaining, X_sentemb_test, y_remaining, y_test = train_test_split(X_sentemb, y, test_size=0.2, random_state=i, stratify=y)\n","    X_emotions_remaining, X_emotions_test, _, _ = train_test_split(X_emotions, X_emotions, test_size=0.2, random_state=i, stratify=y)\n","    X_intensity_remaining, X_intensity_test, _, _ = train_test_split(X_intensity, X_intensity, test_size=0.2, random_state=i, stratify=y)\n","    X_liwc_remaining, X_liwc_test, _, _ = train_test_split(X_liwc, X_liwc, test_size=0.2, random_state=i, stratify=y)\n","\n","    for j in train_val_undersample_seed:\n","\n","        final_rem_df = pd.concat([X_sentemb_remaining, X_emotions_remaining, X_intensity_remaining, X_liwc_remaining, y_remaining], axis=1)\n","\n","        # Undersampling\n","        Xtemp = final_rem_df.drop('label', axis=1)\n","        ytemp = final_rem_df['label']\n","        undersampler = RandomUnderSampler(sampling_strategy=1, random_state=i)  # 1 means the ratio between both classes be 1 - https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n","        X_undersampled, y_undersampled = undersampler.fit_resample(Xtemp, ytemp)\n","        final_rem_df = X_undersampled.copy()\n","        final_rem_df['label'] = y_undersampled\n","\n","        # making different features X and y after undersampling\n","        X_sentemb_remaining = final_rem_df.loc[:, sentemb_column_names[0]:sentemb_column_names[-1]]\n","        X_liwc_remaining = final_rem_df.loc[:, 'B_WC':'F_symptom_44_indicator']\n","        X_emotions_remaining = final_rem_df.loc[:, 'C_admiration':'C_neutral']\n","        X_intensity_remaining = final_rem_df.loc[:, 'D_anger_intensity':'D_trust_intensity']\n","        y_remaining = final_rem_df['label']\n","\n","        # Split remaining data into train and validation sets\n","        X_sentemb_train, X_sentemb_val, y_train, y_val = train_test_split(X_sentemb_remaining, y_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_emotions_train, X_emotions_val, _, _ = train_test_split(X_emotions_remaining, X_emotions_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_intensity_train, X_intensity_val, _, _ = train_test_split(X_intensity_remaining, X_intensity_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","        X_liwc_train, X_liwc_val, _, _ = train_test_split(X_liwc_remaining, X_liwc_remaining, test_size=0.25, random_state=j, stratify=y_remaining)\n","\n","        # # Normalize train and test sentence embeddings so that all values are between 0 and 1 (becasue emotions features are between 0 and 1 too)\n","        # train_scaled_sentemb = scaling.fit_transform(X_sentemb_train.values.reshape(-1, 1)).reshape(*X_sentemb_train.shape) # https://stackoverflow.com/questions/75461346/different-result-from-minmaxscaler-with-manual-calculations\n","        # val_scaled_sentemb = scaling.fit_transform(X_sentemb_val.values.reshape(-1, 1)).reshape(*X_sentemb_val.shape)\n","        # test_scaled_sentemb = scaling.fit_transform(X_sentemb_test.values.reshape(-1, 1)).reshape(*X_sentemb_test.shape)\n","        # X_sentemb_train = pd.DataFrame(train_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_val = pd.DataFrame(val_scaled_sentemb, columns=sentemb_column_names)\n","        # X_sentemb_test = pd.DataFrame(test_scaled_sentemb, columns=sentemb_column_names)\n","\n","        # No scaling required in sentence embeddings (above code) anymore as the new ones sent by Sandra (A,E,H,I) are all between -1 to 1\n","\n","        # Normalization of train and test LIWC features\n","        train_scaled_liwc = scaling.fit_transform(X_liwc_train)\n","        val_scaled_liwc = scaling.fit_transform(X_liwc_val)\n","        test_scaled_liwc = scaling.fit_transform(X_liwc_test)\n","        liwc_column_names = list(final_df.loc[:, 'B_WC':'F_symptom_44_indicator'].columns)\n","        X_liwc_train = pd.DataFrame(train_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_val = pd.DataFrame(val_scaled_liwc, columns=liwc_column_names)\n","        X_liwc_test = pd.DataFrame(test_scaled_liwc, columns=liwc_column_names)\n","\n","        # No scaling required in Emotions and Intensity data\n","\n","        # Multi layer DNN\n","\n","        # LSTM for sentemb, CNN for emotions, directly give input for intensity and liwc\n","\n","        # Input for sentemb features\n","        input_sentemb = Input(shape=X_sentemb.shape[1:])    # X_sentemb is originally of shape (7411,768) but X_sentemb.shape[1:] returns (768,) ----> hence this will be shape=(768,)\n","        lstm_sentemb = LSTM(32)(Reshape((1, len(X_sentemb.columns)))(input_sentemb))   # len(X_sentemb.columns) returns 768 ----> hence this will be Reshape((1,768))\n","\n","        # Input for emotions features\n","        input_emotions = Input(shape=(28,))\n","        reshaped_emotions = Reshape((28, 1))(input_emotions)\n","        cnn_emotions = Conv1D(128, 3, activation='relu')(reshaped_emotions)\n","        cnn_emotions = MaxPooling1D(pool_size=3, strides=1)(cnn_emotions)\n","        cnn_emotions = Flatten()(cnn_emotions)\n","        # + LSTM\n","        cnn_lstm_emotions = LSTM(32)(Reshape((1, cnn_emotions.shape[1]))(cnn_emotions))\n","\n","        # Input for intensity features\n","        input_intensity = Input(shape=(8,))\n","        lstm_intensity = LSTM(32)(Reshape((1, 8))(input_intensity))\n","\n","        # Input for LIWC features\n","        input_liwc = Input(shape=X_liwc.shape[1:])   # liwc has 162 features now, 118 liwc features + 44 f symptoms features -----> hence X_liwc.shape[1:] returns (162,)\n","\n","        # Concatenate the outputs of the LSTM and CNN layers\n","        concatenated = Concatenate()([lstm_sentemb, cnn_lstm_emotions, lstm_intensity, input_liwc])\n","\n","        # Additional Dense layers for further processing\n","        #merged_output = Dense(256, activation='relu')(concatenated)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(128, activation='relu')(concatenated)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(64, activation='relu')(merged_output)\n","        #merged_output = Dropout(rate=0.2)(merged_output)\n","        merged_output = Dense(32, activation='relu')(merged_output)\n","        merged_output = Dropout(rate=0.2)(merged_output)\n","\n","        # Output layer\n","        output = Dense(1, activation='sigmoid')(merged_output)\n","\n","        # Create the model\n","        model = Model(inputs=[input_sentemb, input_emotions, input_intensity, input_liwc], outputs=output)  # note that here it should all be input tensors, not lstm_sentemb or cnn_emotions\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","        # Compile the model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n","\n","        model.fit([X_sentemb_train, X_emotions_train, X_intensity_train, X_liwc_train], y_train,\n","                            epochs=20, batch_size=32, validation_data=([X_sentemb_val, X_emotions_val, X_intensity_val, X_liwc_val], y_val), callbacks=[early_stopping])\n","\n","        # Evaluate the model on the test set\n","        loss, accuracy, f1 = model.evaluate([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test], y_test)\n","\n","        # Calculate MCC\n","        y_pred = model.predict([X_sentemb_test, X_emotions_test, X_intensity_test, X_liwc_test])\n","        y_pred_binary = (y_pred > 0.5).astype(int)\n","        mcc = matthews_corrcoef(y_test, y_pred_binary)\n","\n","        accuracies.append(accuracy)\n","        losses.append(loss)\n","        f1scores.append(f1)\n","        matthew_coreff.append(mcc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w17VxM5Cmznc","executionInfo":{"status":"ok","timestamp":1697719899958,"user_tz":-330,"elapsed":608617,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"03d7d076-a036-4b8d-dc5f-7d6db83e9896"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 9s 25ms/step - loss: 0.4731 - accuracy: 0.7636 - f1_score: 0.7634 - val_loss: 0.3492 - val_accuracy: 0.8454 - val_f1_score: 0.8469\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3016 - accuracy: 0.8688 - f1_score: 0.8696 - val_loss: 0.3720 - val_accuracy: 0.8544 - val_f1_score: 0.8432\n","Epoch 3/20\n","104/104 [==============================] - 2s 17ms/step - loss: 0.2435 - accuracy: 0.9020 - f1_score: 0.9020 - val_loss: 0.3467 - val_accuracy: 0.8644 - val_f1_score: 0.8609\n","Epoch 4/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2023 - accuracy: 0.9198 - f1_score: 0.9198 - val_loss: 0.3529 - val_accuracy: 0.8635 - val_f1_score: 0.8535\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9418 - f1_score: 0.9416 - val_loss: 0.3400 - val_accuracy: 0.8626 - val_f1_score: 0.8606\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1221 - accuracy: 0.9542 - f1_score: 0.9540 - val_loss: 0.4322 - val_accuracy: 0.8707 - val_f1_score: 0.8665\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0923 - accuracy: 0.9671 - f1_score: 0.9671 - val_loss: 0.4954 - val_accuracy: 0.8626 - val_f1_score: 0.8538\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0774 - accuracy: 0.9717 - f1_score: 0.9715 - val_loss: 0.4617 - val_accuracy: 0.8689 - val_f1_score: 0.8659\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0618 - accuracy: 0.9765 - f1_score: 0.9764 - val_loss: 0.5541 - val_accuracy: 0.8617 - val_f1_score: 0.8558\n","Epoch 10/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0431 - accuracy: 0.9834 - f1_score: 0.9834 - val_loss: 0.6393 - val_accuracy: 0.8617 - val_f1_score: 0.8569\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8859 - f1_score: 0.9050\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 21ms/step - loss: 0.4825 - accuracy: 0.7593 - f1_score: 0.7478 - val_loss: 0.3451 - val_accuracy: 0.8454 - val_f1_score: 0.8427\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3100 - accuracy: 0.8682 - f1_score: 0.8680 - val_loss: 0.3154 - val_accuracy: 0.8698 - val_f1_score: 0.8707\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2617 - accuracy: 0.8963 - f1_score: 0.8961 - val_loss: 0.3255 - val_accuracy: 0.8770 - val_f1_score: 0.8752\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2129 - accuracy: 0.9195 - f1_score: 0.9193 - val_loss: 0.3480 - val_accuracy: 0.8707 - val_f1_score: 0.8629\n","Epoch 5/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1749 - accuracy: 0.9346 - f1_score: 0.9341 - val_loss: 0.3291 - val_accuracy: 0.8734 - val_f1_score: 0.8701\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1463 - accuracy: 0.9427 - f1_score: 0.9425 - val_loss: 0.3288 - val_accuracy: 0.8770 - val_f1_score: 0.8700\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1079 - accuracy: 0.9596 - f1_score: 0.9594 - val_loss: 0.4127 - val_accuracy: 0.8716 - val_f1_score: 0.8668\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8683 - f1_score: 0.8911\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 27ms/step - loss: 0.4784 - accuracy: 0.7732 - f1_score: 0.7727 - val_loss: 0.3304 - val_accuracy: 0.8508 - val_f1_score: 0.8499\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3072 - accuracy: 0.8697 - f1_score: 0.8692 - val_loss: 0.3267 - val_accuracy: 0.8571 - val_f1_score: 0.8640\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2566 - accuracy: 0.8963 - f1_score: 0.8958 - val_loss: 0.2990 - val_accuracy: 0.8689 - val_f1_score: 0.8671\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1981 - accuracy: 0.9249 - f1_score: 0.9244 - val_loss: 0.3011 - val_accuracy: 0.8752 - val_f1_score: 0.8752\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1561 - accuracy: 0.9376 - f1_score: 0.9374 - val_loss: 0.3176 - val_accuracy: 0.8716 - val_f1_score: 0.8700\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1237 - accuracy: 0.9517 - f1_score: 0.9516 - val_loss: 0.4138 - val_accuracy: 0.8617 - val_f1_score: 0.8566\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1088 - accuracy: 0.9551 - f1_score: 0.9547 - val_loss: 0.3627 - val_accuracy: 0.8779 - val_f1_score: 0.8776\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0692 - accuracy: 0.9738 - f1_score: 0.9737 - val_loss: 0.4540 - val_accuracy: 0.8725 - val_f1_score: 0.8688\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8731 - f1_score: 0.8935\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 22ms/step - loss: 0.4902 - accuracy: 0.7542 - f1_score: 0.7389 - val_loss: 0.3606 - val_accuracy: 0.8454 - val_f1_score: 0.8351\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3117 - accuracy: 0.8652 - f1_score: 0.8644 - val_loss: 0.3174 - val_accuracy: 0.8544 - val_f1_score: 0.8601\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2562 - accuracy: 0.8890 - f1_score: 0.8896 - val_loss: 0.3120 - val_accuracy: 0.8617 - val_f1_score: 0.8519\n","Epoch 4/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2191 - accuracy: 0.9104 - f1_score: 0.9098 - val_loss: 0.3204 - val_accuracy: 0.8761 - val_f1_score: 0.8773\n","Epoch 5/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1695 - accuracy: 0.9321 - f1_score: 0.9318 - val_loss: 0.3166 - val_accuracy: 0.8852 - val_f1_score: 0.8849\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1350 - accuracy: 0.9487 - f1_score: 0.9486 - val_loss: 0.3946 - val_accuracy: 0.8807 - val_f1_score: 0.8778\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 0.9641 - f1_score: 0.9641 - val_loss: 0.4120 - val_accuracy: 0.8888 - val_f1_score: 0.8862\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0723 - accuracy: 0.9717 - f1_score: 0.9715 - val_loss: 0.4530 - val_accuracy: 0.8734 - val_f1_score: 0.8689\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8515 - f1_score: 0.8700\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 21ms/step - loss: 0.4770 - accuracy: 0.7738 - f1_score: 0.7675 - val_loss: 0.3436 - val_accuracy: 0.8427 - val_f1_score: 0.8463\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.8673 - f1_score: 0.8670 - val_loss: 0.3105 - val_accuracy: 0.8544 - val_f1_score: 0.8601\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2600 - accuracy: 0.8960 - f1_score: 0.8954 - val_loss: 0.3095 - val_accuracy: 0.8608 - val_f1_score: 0.8597\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2125 - accuracy: 0.9174 - f1_score: 0.9164 - val_loss: 0.3313 - val_accuracy: 0.8635 - val_f1_score: 0.8641\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1687 - accuracy: 0.9331 - f1_score: 0.9323 - val_loss: 0.4238 - val_accuracy: 0.8436 - val_f1_score: 0.8564\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1227 - accuracy: 0.9533 - f1_score: 0.9529 - val_loss: 0.4074 - val_accuracy: 0.8698 - val_f1_score: 0.8717\n","Epoch 7/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.1069 - accuracy: 0.9608 - f1_score: 0.9606 - val_loss: 0.4069 - val_accuracy: 0.8599 - val_f1_score: 0.8630\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0745 - accuracy: 0.9756 - f1_score: 0.9754 - val_loss: 0.5223 - val_accuracy: 0.8626 - val_f1_score: 0.8571\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8805 - f1_score: 0.8995\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 22ms/step - loss: 0.4899 - accuracy: 0.7572 - f1_score: 0.7465 - val_loss: 0.3551 - val_accuracy: 0.8409 - val_f1_score: 0.8437\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3087 - accuracy: 0.8715 - f1_score: 0.8701 - val_loss: 0.3235 - val_accuracy: 0.8608 - val_f1_score: 0.8574\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2464 - accuracy: 0.9047 - f1_score: 0.9034 - val_loss: 0.3296 - val_accuracy: 0.8653 - val_f1_score: 0.8690\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2029 - accuracy: 0.9246 - f1_score: 0.9241 - val_loss: 0.3215 - val_accuracy: 0.8626 - val_f1_score: 0.8598\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1591 - accuracy: 0.9400 - f1_score: 0.9395 - val_loss: 0.3523 - val_accuracy: 0.8671 - val_f1_score: 0.8709\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1236 - accuracy: 0.9502 - f1_score: 0.9498 - val_loss: 0.3831 - val_accuracy: 0.8599 - val_f1_score: 0.8634\n","Epoch 7/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0907 - accuracy: 0.9704 - f1_score: 0.9703 - val_loss: 0.4679 - val_accuracy: 0.8662 - val_f1_score: 0.8702\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0691 - accuracy: 0.9780 - f1_score: 0.9779 - val_loss: 0.5433 - val_accuracy: 0.8617 - val_f1_score: 0.8678\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0606 - accuracy: 0.9786 - f1_score: 0.9785 - val_loss: 0.5319 - val_accuracy: 0.8626 - val_f1_score: 0.8606\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8521 - f1_score: 0.8762\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 37ms/step - loss: 0.4772 - accuracy: 0.7678 - f1_score: 0.7642 - val_loss: 0.3699 - val_accuracy: 0.8354 - val_f1_score: 0.8305\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3005 - accuracy: 0.8764 - f1_score: 0.8749 - val_loss: 0.3294 - val_accuracy: 0.8472 - val_f1_score: 0.8425\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2446 - accuracy: 0.8972 - f1_score: 0.8966 - val_loss: 0.3344 - val_accuracy: 0.8562 - val_f1_score: 0.8484\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1914 - accuracy: 0.9258 - f1_score: 0.9250 - val_loss: 0.3352 - val_accuracy: 0.8653 - val_f1_score: 0.8661\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1589 - accuracy: 0.9397 - f1_score: 0.9390 - val_loss: 0.3461 - val_accuracy: 0.8617 - val_f1_score: 0.8579\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1185 - accuracy: 0.9539 - f1_score: 0.9535 - val_loss: 0.4120 - val_accuracy: 0.8698 - val_f1_score: 0.8686\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0867 - accuracy: 0.9704 - f1_score: 0.9704 - val_loss: 0.4438 - val_accuracy: 0.8644 - val_f1_score: 0.8631\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8548 - f1_score: 0.8778\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 21ms/step - loss: 0.4864 - accuracy: 0.7587 - f1_score: 0.7465 - val_loss: 0.3508 - val_accuracy: 0.8445 - val_f1_score: 0.8515\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2972 - accuracy: 0.8745 - f1_score: 0.8734 - val_loss: 0.3196 - val_accuracy: 0.8644 - val_f1_score: 0.8621\n","Epoch 3/20\n","104/104 [==============================] - 1s 9ms/step - loss: 0.2411 - accuracy: 0.9035 - f1_score: 0.9029 - val_loss: 0.3237 - val_accuracy: 0.8635 - val_f1_score: 0.8582\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1993 - accuracy: 0.9258 - f1_score: 0.9255 - val_loss: 0.3211 - val_accuracy: 0.8716 - val_f1_score: 0.8702\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1588 - accuracy: 0.9418 - f1_score: 0.9415 - val_loss: 0.3445 - val_accuracy: 0.8725 - val_f1_score: 0.8705\n","Epoch 6/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1261 - accuracy: 0.9530 - f1_score: 0.9527 - val_loss: 0.3600 - val_accuracy: 0.8752 - val_f1_score: 0.8763\n","Epoch 7/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.1008 - accuracy: 0.9650 - f1_score: 0.9648 - val_loss: 0.4484 - val_accuracy: 0.8626 - val_f1_score: 0.8681\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8474 - f1_score: 0.8730\n","47/47 [==============================] - 1s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 22ms/step - loss: 0.4860 - accuracy: 0.7636 - f1_score: 0.7641 - val_loss: 0.3379 - val_accuracy: 0.8526 - val_f1_score: 0.8492\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3046 - accuracy: 0.8712 - f1_score: 0.8695 - val_loss: 0.3366 - val_accuracy: 0.8508 - val_f1_score: 0.8374\n","Epoch 3/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.2508 - accuracy: 0.8984 - f1_score: 0.8972 - val_loss: 0.3550 - val_accuracy: 0.8580 - val_f1_score: 0.8498\n","Epoch 4/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1981 - accuracy: 0.9195 - f1_score: 0.9184 - val_loss: 0.3432 - val_accuracy: 0.8752 - val_f1_score: 0.8686\n","Epoch 5/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1608 - accuracy: 0.9373 - f1_score: 0.9366 - val_loss: 0.3644 - val_accuracy: 0.8580 - val_f1_score: 0.8650\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1284 - accuracy: 0.9548 - f1_score: 0.9544 - val_loss: 0.4186 - val_accuracy: 0.8725 - val_f1_score: 0.8686\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0962 - accuracy: 0.9650 - f1_score: 0.9648 - val_loss: 0.5029 - val_accuracy: 0.8662 - val_f1_score: 0.8560\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8184 - f1_score: 0.8409\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 21ms/step - loss: 0.4925 - accuracy: 0.7575 - f1_score: 0.7564 - val_loss: 0.3510 - val_accuracy: 0.8562 - val_f1_score: 0.8490\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3138 - accuracy: 0.8646 - f1_score: 0.8637 - val_loss: 0.3368 - val_accuracy: 0.8544 - val_f1_score: 0.8432\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2535 - accuracy: 0.8975 - f1_score: 0.8969 - val_loss: 0.3024 - val_accuracy: 0.8807 - val_f1_score: 0.8773\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2020 - accuracy: 0.9168 - f1_score: 0.9160 - val_loss: 0.2990 - val_accuracy: 0.8834 - val_f1_score: 0.8818\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1703 - accuracy: 0.9343 - f1_score: 0.9333 - val_loss: 0.3160 - val_accuracy: 0.8752 - val_f1_score: 0.8708\n","Epoch 6/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.1329 - accuracy: 0.9514 - f1_score: 0.9509 - val_loss: 0.3696 - val_accuracy: 0.8816 - val_f1_score: 0.8761\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1022 - accuracy: 0.9638 - f1_score: 0.9636 - val_loss: 0.3711 - val_accuracy: 0.8870 - val_f1_score: 0.8848\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0726 - accuracy: 0.9774 - f1_score: 0.9772 - val_loss: 0.4253 - val_accuracy: 0.8761 - val_f1_score: 0.8696\n","Epoch 9/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.0556 - accuracy: 0.9801 - f1_score: 0.9800 - val_loss: 0.5069 - val_accuracy: 0.8770 - val_f1_score: 0.8777\n","47/47 [==============================] - 0s 8ms/step - loss: 0.3337 - accuracy: 0.8589 - f1_score: 0.8840\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 31ms/step - loss: 0.4829 - accuracy: 0.7615 - f1_score: 0.7498 - val_loss: 0.3357 - val_accuracy: 0.8626 - val_f1_score: 0.8640\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3315 - accuracy: 0.8613 - f1_score: 0.8619 - val_loss: 0.2978 - val_accuracy: 0.8725 - val_f1_score: 0.8724\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2736 - accuracy: 0.8860 - f1_score: 0.8856 - val_loss: 0.2851 - val_accuracy: 0.8770 - val_f1_score: 0.8743\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2381 - accuracy: 0.9071 - f1_score: 0.9063 - val_loss: 0.2765 - val_accuracy: 0.8834 - val_f1_score: 0.8804\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1900 - accuracy: 0.9273 - f1_score: 0.9266 - val_loss: 0.2791 - val_accuracy: 0.8933 - val_f1_score: 0.8899\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9445 - f1_score: 0.9440 - val_loss: 0.3478 - val_accuracy: 0.8698 - val_f1_score: 0.8615\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1224 - accuracy: 0.9530 - f1_score: 0.9526 - val_loss: 0.3283 - val_accuracy: 0.8843 - val_f1_score: 0.8804\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0987 - accuracy: 0.9605 - f1_score: 0.9603 - val_loss: 0.3651 - val_accuracy: 0.8906 - val_f1_score: 0.8877\n","Epoch 9/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0829 - accuracy: 0.9714 - f1_score: 0.9712 - val_loss: 0.4526 - val_accuracy: 0.8797 - val_f1_score: 0.8760\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2885 - accuracy: 0.8778 - f1_score: 0.8986\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 22ms/step - loss: 0.4858 - accuracy: 0.7551 - f1_score: 0.7419 - val_loss: 0.3860 - val_accuracy: 0.8300 - val_f1_score: 0.8327\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3143 - accuracy: 0.8694 - f1_score: 0.8687 - val_loss: 0.3401 - val_accuracy: 0.8445 - val_f1_score: 0.8416\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2635 - accuracy: 0.8854 - f1_score: 0.8840 - val_loss: 0.3370 - val_accuracy: 0.8336 - val_f1_score: 0.8227\n","Epoch 4/20\n","104/104 [==============================] - 2s 17ms/step - loss: 0.2222 - accuracy: 0.9089 - f1_score: 0.9082 - val_loss: 0.3261 - val_accuracy: 0.8662 - val_f1_score: 0.8606\n","Epoch 5/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1850 - accuracy: 0.9252 - f1_score: 0.9245 - val_loss: 0.3890 - val_accuracy: 0.8608 - val_f1_score: 0.8677\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1562 - accuracy: 0.9361 - f1_score: 0.9355 - val_loss: 0.3912 - val_accuracy: 0.8779 - val_f1_score: 0.8769\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1131 - accuracy: 0.9572 - f1_score: 0.9568 - val_loss: 0.4419 - val_accuracy: 0.8761 - val_f1_score: 0.8751\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0987 - accuracy: 0.9620 - f1_score: 0.9618 - val_loss: 0.4514 - val_accuracy: 0.8653 - val_f1_score: 0.8708\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9735 - f1_score: 0.9733 - val_loss: 0.5396 - val_accuracy: 0.8779 - val_f1_score: 0.8701\n","47/47 [==============================] - 0s 6ms/step - loss: 0.3165 - accuracy: 0.8731 - f1_score: 0.8926\n","47/47 [==============================] - 2s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 32ms/step - loss: 0.4671 - accuracy: 0.7753 - f1_score: 0.7757 - val_loss: 0.3574 - val_accuracy: 0.8427 - val_f1_score: 0.8424\n","Epoch 2/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.3056 - accuracy: 0.8730 - f1_score: 0.8723 - val_loss: 0.3440 - val_accuracy: 0.8580 - val_f1_score: 0.8520\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2579 - accuracy: 0.8941 - f1_score: 0.8927 - val_loss: 0.3260 - val_accuracy: 0.8644 - val_f1_score: 0.8644\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2041 - accuracy: 0.9237 - f1_score: 0.9229 - val_loss: 0.3755 - val_accuracy: 0.8653 - val_f1_score: 0.8666\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1825 - accuracy: 0.9273 - f1_score: 0.9267 - val_loss: 0.3246 - val_accuracy: 0.8653 - val_f1_score: 0.8639\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1365 - accuracy: 0.9484 - f1_score: 0.9480 - val_loss: 0.4173 - val_accuracy: 0.8499 - val_f1_score: 0.8395\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1079 - accuracy: 0.9614 - f1_score: 0.9610 - val_loss: 0.4565 - val_accuracy: 0.8725 - val_f1_score: 0.8753\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0777 - accuracy: 0.9717 - f1_score: 0.9714 - val_loss: 0.4709 - val_accuracy: 0.8716 - val_f1_score: 0.8697\n","Epoch 9/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0585 - accuracy: 0.9783 - f1_score: 0.9782 - val_loss: 0.5457 - val_accuracy: 0.8707 - val_f1_score: 0.8720\n","Epoch 10/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0500 - accuracy: 0.9813 - f1_score: 0.9813 - val_loss: 0.6158 - val_accuracy: 0.8698 - val_f1_score: 0.8679\n","47/47 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8839 - f1_score: 0.9056\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 30ms/step - loss: 0.4678 - accuracy: 0.7796 - f1_score: 0.7846 - val_loss: 0.3724 - val_accuracy: 0.8373 - val_f1_score: 0.8454\n","Epoch 2/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.3052 - accuracy: 0.8724 - f1_score: 0.8714 - val_loss: 0.3545 - val_accuracy: 0.8309 - val_f1_score: 0.8161\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2605 - accuracy: 0.8935 - f1_score: 0.8917 - val_loss: 0.3037 - val_accuracy: 0.8734 - val_f1_score: 0.8741\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2090 - accuracy: 0.9186 - f1_score: 0.9172 - val_loss: 0.3111 - val_accuracy: 0.8734 - val_f1_score: 0.8713\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9367 - f1_score: 0.9357 - val_loss: 0.3700 - val_accuracy: 0.8662 - val_f1_score: 0.8606\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9478 - f1_score: 0.9473 - val_loss: 0.3823 - val_accuracy: 0.8562 - val_f1_score: 0.8556\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1062 - accuracy: 0.9575 - f1_score: 0.9572 - val_loss: 0.4879 - val_accuracy: 0.8626 - val_f1_score: 0.8558\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0793 - accuracy: 0.9717 - f1_score: 0.9714 - val_loss: 0.4212 - val_accuracy: 0.8698 - val_f1_score: 0.8710\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.8798 - f1_score: 0.9004\n","47/47 [==============================] - 2s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 9s 22ms/step - loss: 0.5079 - accuracy: 0.7428 - f1_score: 0.7293 - val_loss: 0.3516 - val_accuracy: 0.8445 - val_f1_score: 0.8545\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3431 - accuracy: 0.8519 - f1_score: 0.8515 - val_loss: 0.3000 - val_accuracy: 0.8653 - val_f1_score: 0.8601\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2758 - accuracy: 0.8896 - f1_score: 0.8885 - val_loss: 0.3012 - val_accuracy: 0.8752 - val_f1_score: 0.8678\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2254 - accuracy: 0.9165 - f1_score: 0.9152 - val_loss: 0.2907 - val_accuracy: 0.8834 - val_f1_score: 0.8820\n","Epoch 5/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1905 - accuracy: 0.9303 - f1_score: 0.9290 - val_loss: 0.2997 - val_accuracy: 0.8716 - val_f1_score: 0.8653\n","Epoch 6/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1487 - accuracy: 0.9478 - f1_score: 0.9472 - val_loss: 0.3616 - val_accuracy: 0.8816 - val_f1_score: 0.8806\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1072 - accuracy: 0.9629 - f1_score: 0.9626 - val_loss: 0.4641 - val_accuracy: 0.8770 - val_f1_score: 0.8815\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0916 - accuracy: 0.9674 - f1_score: 0.9672 - val_loss: 0.4956 - val_accuracy: 0.8761 - val_f1_score: 0.8686\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0804 - accuracy: 0.9704 - f1_score: 0.9702 - val_loss: 0.4470 - val_accuracy: 0.8797 - val_f1_score: 0.8751\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.8744 - f1_score: 0.8970\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 21ms/step - loss: 0.4860 - accuracy: 0.7666 - f1_score: 0.7643 - val_loss: 0.3465 - val_accuracy: 0.8526 - val_f1_score: 0.8455\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3197 - accuracy: 0.8706 - f1_score: 0.8680 - val_loss: 0.3222 - val_accuracy: 0.8590 - val_f1_score: 0.8488\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2602 - accuracy: 0.8972 - f1_score: 0.8959 - val_loss: 0.2986 - val_accuracy: 0.8707 - val_f1_score: 0.8692\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2134 - accuracy: 0.9125 - f1_score: 0.9113 - val_loss: 0.3006 - val_accuracy: 0.8843 - val_f1_score: 0.8799\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1679 - accuracy: 0.9340 - f1_score: 0.9332 - val_loss: 0.3375 - val_accuracy: 0.8716 - val_f1_score: 0.8616\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1325 - accuracy: 0.9484 - f1_score: 0.9476 - val_loss: 0.3221 - val_accuracy: 0.8834 - val_f1_score: 0.8777\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1039 - accuracy: 0.9638 - f1_score: 0.9635 - val_loss: 0.3536 - val_accuracy: 0.8807 - val_f1_score: 0.8830\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0910 - accuracy: 0.9677 - f1_score: 0.9675 - val_loss: 0.3559 - val_accuracy: 0.8816 - val_f1_score: 0.8775\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3081 - accuracy: 0.8697 - f1_score: 0.8927\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 22ms/step - loss: 0.4787 - accuracy: 0.7786 - f1_score: 0.7782 - val_loss: 0.3390 - val_accuracy: 0.8707 - val_f1_score: 0.8733\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3103 - accuracy: 0.8715 - f1_score: 0.8688 - val_loss: 0.3006 - val_accuracy: 0.8807 - val_f1_score: 0.8778\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2613 - accuracy: 0.8951 - f1_score: 0.8931 - val_loss: 0.3323 - val_accuracy: 0.8562 - val_f1_score: 0.8421\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2154 - accuracy: 0.9138 - f1_score: 0.9119 - val_loss: 0.2873 - val_accuracy: 0.8888 - val_f1_score: 0.8871\n","Epoch 5/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.1723 - accuracy: 0.9306 - f1_score: 0.9294 - val_loss: 0.3600 - val_accuracy: 0.8752 - val_f1_score: 0.8752\n","Epoch 6/20\n","104/104 [==============================] - 2s 16ms/step - loss: 0.1323 - accuracy: 0.9493 - f1_score: 0.9487 - val_loss: 0.4113 - val_accuracy: 0.8843 - val_f1_score: 0.8889\n","Epoch 7/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.0998 - accuracy: 0.9617 - f1_score: 0.9614 - val_loss: 0.3986 - val_accuracy: 0.8797 - val_f1_score: 0.8774\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0818 - accuracy: 0.9723 - f1_score: 0.9721 - val_loss: 0.4873 - val_accuracy: 0.8825 - val_f1_score: 0.8812\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0748 - accuracy: 0.9720 - f1_score: 0.9718 - val_loss: 0.4692 - val_accuracy: 0.8852 - val_f1_score: 0.8861\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8515 - f1_score: 0.8749\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 23ms/step - loss: 0.4646 - accuracy: 0.7762 - f1_score: 0.7718 - val_loss: 0.3560 - val_accuracy: 0.8409 - val_f1_score: 0.8445\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2920 - accuracy: 0.8788 - f1_score: 0.8780 - val_loss: 0.3626 - val_accuracy: 0.8508 - val_f1_score: 0.8559\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2406 - accuracy: 0.8999 - f1_score: 0.8995 - val_loss: 0.3230 - val_accuracy: 0.8716 - val_f1_score: 0.8632\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1855 - accuracy: 0.9255 - f1_score: 0.9251 - val_loss: 0.3125 - val_accuracy: 0.8825 - val_f1_score: 0.8818\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1487 - accuracy: 0.9439 - f1_score: 0.9434 - val_loss: 0.3907 - val_accuracy: 0.8797 - val_f1_score: 0.8832\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1132 - accuracy: 0.9608 - f1_score: 0.9607 - val_loss: 0.4170 - val_accuracy: 0.8770 - val_f1_score: 0.8770\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0987 - accuracy: 0.9611 - f1_score: 0.9609 - val_loss: 0.4504 - val_accuracy: 0.8752 - val_f1_score: 0.8665\n","Epoch 8/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0672 - accuracy: 0.9747 - f1_score: 0.9746 - val_loss: 0.4379 - val_accuracy: 0.8807 - val_f1_score: 0.8782\n","Epoch 9/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.0470 - accuracy: 0.9855 - f1_score: 0.9855 - val_loss: 0.5031 - val_accuracy: 0.8797 - val_f1_score: 0.8779\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.8650 - f1_score: 0.8886\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 32ms/step - loss: 0.4656 - accuracy: 0.7796 - f1_score: 0.7833 - val_loss: 0.3689 - val_accuracy: 0.8291 - val_f1_score: 0.8219\n","Epoch 2/20\n","104/104 [==============================] - 1s 14ms/step - loss: 0.3004 - accuracy: 0.8818 - f1_score: 0.8800 - val_loss: 0.3791 - val_accuracy: 0.8363 - val_f1_score: 0.8430\n","Epoch 3/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2516 - accuracy: 0.8948 - f1_score: 0.8936 - val_loss: 0.3361 - val_accuracy: 0.8517 - val_f1_score: 0.8389\n","Epoch 4/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1972 - accuracy: 0.9237 - f1_score: 0.9224 - val_loss: 0.3507 - val_accuracy: 0.8653 - val_f1_score: 0.8622\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1585 - accuracy: 0.9418 - f1_score: 0.9412 - val_loss: 0.4107 - val_accuracy: 0.8617 - val_f1_score: 0.8592\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1418 - accuracy: 0.9481 - f1_score: 0.9475 - val_loss: 0.3573 - val_accuracy: 0.8725 - val_f1_score: 0.8717\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0988 - accuracy: 0.9665 - f1_score: 0.9662 - val_loss: 0.4211 - val_accuracy: 0.8590 - val_f1_score: 0.8542\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0660 - accuracy: 0.9759 - f1_score: 0.9757 - val_loss: 0.4885 - val_accuracy: 0.8653 - val_f1_score: 0.8560\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8393 - f1_score: 0.8602\n","47/47 [==============================] - 1s 4ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 22ms/step - loss: 0.4883 - accuracy: 0.7690 - f1_score: 0.7701 - val_loss: 0.3564 - val_accuracy: 0.8418 - val_f1_score: 0.8458\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.8727 - f1_score: 0.8722 - val_loss: 0.3212 - val_accuracy: 0.8608 - val_f1_score: 0.8627\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2501 - accuracy: 0.8966 - f1_score: 0.8956 - val_loss: 0.3172 - val_accuracy: 0.8716 - val_f1_score: 0.8743\n","Epoch 4/20\n","104/104 [==============================] - 1s 12ms/step - loss: 0.2073 - accuracy: 0.9168 - f1_score: 0.9162 - val_loss: 0.3272 - val_accuracy: 0.8743 - val_f1_score: 0.8682\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1565 - accuracy: 0.9397 - f1_score: 0.9392 - val_loss: 0.3608 - val_accuracy: 0.8671 - val_f1_score: 0.8667\n","Epoch 6/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.1167 - accuracy: 0.9545 - f1_score: 0.9540 - val_loss: 0.4378 - val_accuracy: 0.8608 - val_f1_score: 0.8677\n","Epoch 7/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0934 - accuracy: 0.9677 - f1_score: 0.9676 - val_loss: 0.4456 - val_accuracy: 0.8734 - val_f1_score: 0.8785\n","Epoch 8/20\n","104/104 [==============================] - 2s 14ms/step - loss: 0.0673 - accuracy: 0.9759 - f1_score: 0.9758 - val_loss: 0.5200 - val_accuracy: 0.8599 - val_f1_score: 0.8667\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8643 - f1_score: 0.8902\n","47/47 [==============================] - 2s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 31ms/step - loss: 0.4710 - accuracy: 0.7747 - f1_score: 0.7730 - val_loss: 0.3513 - val_accuracy: 0.8499 - val_f1_score: 0.8454\n","Epoch 2/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.3012 - accuracy: 0.8703 - f1_score: 0.8689 - val_loss: 0.3357 - val_accuracy: 0.8472 - val_f1_score: 0.8370\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2446 - accuracy: 0.8932 - f1_score: 0.8920 - val_loss: 0.3029 - val_accuracy: 0.8698 - val_f1_score: 0.8647\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2099 - accuracy: 0.9147 - f1_score: 0.9138 - val_loss: 0.3009 - val_accuracy: 0.8779 - val_f1_score: 0.8747\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1665 - accuracy: 0.9331 - f1_score: 0.9325 - val_loss: 0.3739 - val_accuracy: 0.8590 - val_f1_score: 0.8506\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9502 - f1_score: 0.9498 - val_loss: 0.3435 - val_accuracy: 0.8779 - val_f1_score: 0.8753\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0988 - accuracy: 0.9635 - f1_score: 0.9633 - val_loss: 0.4061 - val_accuracy: 0.8608 - val_f1_score: 0.8505\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0928 - accuracy: 0.9647 - f1_score: 0.9645 - val_loss: 0.4970 - val_accuracy: 0.8635 - val_f1_score: 0.8569\n","Epoch 9/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0582 - accuracy: 0.9774 - f1_score: 0.9773 - val_loss: 0.5077 - val_accuracy: 0.8779 - val_f1_score: 0.8751\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8650 - f1_score: 0.8880\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 23ms/step - loss: 0.4787 - accuracy: 0.7732 - f1_score: 0.7689 - val_loss: 0.3565 - val_accuracy: 0.8400 - val_f1_score: 0.8432\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3113 - accuracy: 0.8709 - f1_score: 0.8701 - val_loss: 0.3110 - val_accuracy: 0.8644 - val_f1_score: 0.8644\n","Epoch 3/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2540 - accuracy: 0.8954 - f1_score: 0.8948 - val_loss: 0.3023 - val_accuracy: 0.8698 - val_f1_score: 0.8689\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2147 - accuracy: 0.9092 - f1_score: 0.9089 - val_loss: 0.3237 - val_accuracy: 0.8707 - val_f1_score: 0.8708\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1654 - accuracy: 0.9376 - f1_score: 0.9373 - val_loss: 0.3036 - val_accuracy: 0.8897 - val_f1_score: 0.8866\n","Epoch 6/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1265 - accuracy: 0.9478 - f1_score: 0.9476 - val_loss: 0.3447 - val_accuracy: 0.8761 - val_f1_score: 0.8758\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0994 - accuracy: 0.9647 - f1_score: 0.9645 - val_loss: 0.3732 - val_accuracy: 0.8752 - val_f1_score: 0.8720\n","Epoch 8/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0705 - accuracy: 0.9756 - f1_score: 0.9754 - val_loss: 0.4817 - val_accuracy: 0.8770 - val_f1_score: 0.8741\n","47/47 [==============================] - 0s 7ms/step - loss: 0.3196 - accuracy: 0.8697 - f1_score: 0.8916\n","47/47 [==============================] - 2s 5ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 25ms/step - loss: 0.4686 - accuracy: 0.7841 - f1_score: 0.7723 - val_loss: 0.3244 - val_accuracy: 0.8617 - val_f1_score: 0.8613\n","Epoch 2/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.3219 - accuracy: 0.8664 - f1_score: 0.8641 - val_loss: 0.2916 - val_accuracy: 0.8716 - val_f1_score: 0.8688\n","Epoch 3/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.2552 - accuracy: 0.8911 - f1_score: 0.8896 - val_loss: 0.2785 - val_accuracy: 0.8825 - val_f1_score: 0.8762\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2150 - accuracy: 0.9147 - f1_score: 0.9133 - val_loss: 0.2768 - val_accuracy: 0.8996 - val_f1_score: 0.8994\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1672 - accuracy: 0.9343 - f1_score: 0.9335 - val_loss: 0.2967 - val_accuracy: 0.8825 - val_f1_score: 0.8831\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1361 - accuracy: 0.9481 - f1_score: 0.9477 - val_loss: 0.3230 - val_accuracy: 0.8888 - val_f1_score: 0.8834\n","Epoch 7/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1110 - accuracy: 0.9626 - f1_score: 0.9623 - val_loss: 0.3197 - val_accuracy: 0.8960 - val_f1_score: 0.8946\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0735 - accuracy: 0.9756 - f1_score: 0.9755 - val_loss: 0.3924 - val_accuracy: 0.8942 - val_f1_score: 0.8954\n","Epoch 9/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.0575 - accuracy: 0.9786 - f1_score: 0.9785 - val_loss: 0.4738 - val_accuracy: 0.8816 - val_f1_score: 0.8734\n","47/47 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.8751 - f1_score: 0.8966\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 11s 25ms/step - loss: 0.4923 - accuracy: 0.7675 - f1_score: 0.7685 - val_loss: 0.3318 - val_accuracy: 0.8608 - val_f1_score: 0.8597\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.3138 - accuracy: 0.8655 - f1_score: 0.8642 - val_loss: 0.3081 - val_accuracy: 0.8689 - val_f1_score: 0.8731\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2511 - accuracy: 0.8917 - f1_score: 0.8914 - val_loss: 0.2910 - val_accuracy: 0.8680 - val_f1_score: 0.8604\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1993 - accuracy: 0.9156 - f1_score: 0.9149 - val_loss: 0.2678 - val_accuracy: 0.8906 - val_f1_score: 0.8911\n","Epoch 5/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1709 - accuracy: 0.9285 - f1_score: 0.9280 - val_loss: 0.2890 - val_accuracy: 0.8825 - val_f1_score: 0.8778\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1331 - accuracy: 0.9487 - f1_score: 0.9486 - val_loss: 0.2868 - val_accuracy: 0.8861 - val_f1_score: 0.8848\n","Epoch 7/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.1081 - accuracy: 0.9638 - f1_score: 0.9636 - val_loss: 0.3024 - val_accuracy: 0.8770 - val_f1_score: 0.8731\n","Epoch 8/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.0846 - accuracy: 0.9683 - f1_score: 0.9683 - val_loss: 0.4177 - val_accuracy: 0.8779 - val_f1_score: 0.8835\n","Epoch 9/20\n","104/104 [==============================] - 1s 13ms/step - loss: 0.0533 - accuracy: 0.9801 - f1_score: 0.9801 - val_loss: 0.4160 - val_accuracy: 0.8779 - val_f1_score: 0.8804\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.8710 - f1_score: 0.8928\n","47/47 [==============================] - 1s 3ms/step\n","Epoch 1/20\n","104/104 [==============================] - 10s 22ms/step - loss: 0.4671 - accuracy: 0.7702 - f1_score: 0.7705 - val_loss: 0.3447 - val_accuracy: 0.8571 - val_f1_score: 0.8621\n","Epoch 2/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2989 - accuracy: 0.8700 - f1_score: 0.8689 - val_loss: 0.2997 - val_accuracy: 0.8680 - val_f1_score: 0.8602\n","Epoch 3/20\n","104/104 [==============================] - 1s 11ms/step - loss: 0.2454 - accuracy: 0.8981 - f1_score: 0.8967 - val_loss: 0.2837 - val_accuracy: 0.8788 - val_f1_score: 0.8741\n","Epoch 4/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.2022 - accuracy: 0.9195 - f1_score: 0.9184 - val_loss: 0.2965 - val_accuracy: 0.8725 - val_f1_score: 0.8726\n","Epoch 5/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1621 - accuracy: 0.9376 - f1_score: 0.9371 - val_loss: 0.3140 - val_accuracy: 0.8843 - val_f1_score: 0.8841\n","Epoch 6/20\n","104/104 [==============================] - 1s 10ms/step - loss: 0.1320 - accuracy: 0.9536 - f1_score: 0.9531 - val_loss: 0.3438 - val_accuracy: 0.8888 - val_f1_score: 0.8883\n","Epoch 7/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0875 - accuracy: 0.9701 - f1_score: 0.9700 - val_loss: 0.3680 - val_accuracy: 0.8843 - val_f1_score: 0.8883\n","Epoch 8/20\n","104/104 [==============================] - 2s 15ms/step - loss: 0.0710 - accuracy: 0.9753 - f1_score: 0.9751 - val_loss: 0.4099 - val_accuracy: 0.8752 - val_f1_score: 0.8745\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8521 - f1_score: 0.8713\n","47/47 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["print(accuracies)\n","print(np.mean(accuracies))\n","print(np.std(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkwpVPThm7mp","executionInfo":{"status":"ok","timestamp":1697719899959,"user_tz":-330,"elapsed":32,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"094da559-ce1a-4355-8eaa-b3624b89c5b3"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.8858879208564758, 0.8683322072029114, 0.8730587363243103, 0.8514516949653625, 0.8804861307144165, 0.852126955986023, 0.8548278212547302, 0.847400426864624, 0.8183659911155701, 0.8588791489601135, 0.8777852654457092, 0.8730587363243103, 0.8838622570037842, 0.8798109292984009, 0.8744091987609863, 0.8696826696395874, 0.8514516949653625, 0.8649561405181885, 0.8392977714538574, 0.8642808794975281, 0.8649561405181885, 0.8696826696395874, 0.875084400177002, 0.8710330724716187, 0.852126955986023]\n","0.8640918326377869\n","0.015219292525449507\n"]}]},{"cell_type":"code","source":["print(losses)\n","print(np.mean(losses))\n","print(np.std(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C51jiTMMm7ti","executionInfo":{"status":"ok","timestamp":1697719899959,"user_tz":-330,"elapsed":19,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"482b7b90-0543-4613-e763-f657c152097e"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.2962283790111542, 0.30397099256515503, 0.29708316922187805, 0.33975568413734436, 0.2936122715473175, 0.3541814386844635, 0.3421485126018524, 0.3477713167667389, 0.38580378890037537, 0.3336997926235199, 0.28851136565208435, 0.31648731231689453, 0.2926662266254425, 0.28521832823753357, 0.29002439975738525, 0.3081214725971222, 0.33155038952827454, 0.33648979663848877, 0.3495808243751526, 0.30968838930130005, 0.30477410554885864, 0.31962448358535767, 0.29838356375694275, 0.3099943995475769, 0.33953091502189636]\n","0.3189960527420044\n","0.02523845814511929\n"]}]},{"cell_type":"code","source":["print(f1scores)\n","print(np.mean(f1scores))\n","print(np.std(f1scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0aXdwYJm75o","executionInfo":{"status":"ok","timestamp":1697719899959,"user_tz":-330,"elapsed":16,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"e7ceddd0-b930-4b39-b0df-855365790553"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.9050027132034302, 0.8911222219467163, 0.8935446739196777, 0.869976282119751, 0.8994889259338379, 0.8762012124061584, 0.8777713775634766, 0.8730335831642151, 0.840922474861145, 0.883953332901001, 0.89859938621521, 0.8925713896751404, 0.9055981636047363, 0.9004473686218262, 0.8970099091529846, 0.8927181363105774, 0.8748577237129211, 0.888641357421875, 0.8601644039154053, 0.8902238607406616, 0.8880178928375244, 0.891633927822113, 0.8965902328491211, 0.8927567601203918, 0.871252179145813]\n","0.8860839796066284\n","0.01475056758134087\n"]}]},{"cell_type":"code","source":["print(matthew_coreff)\n","print(np.mean(matthew_coreff))\n","print(np.std(matthew_coreff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXTxe8CVm8Cy","executionInfo":{"status":"ok","timestamp":1697719899960,"user_tz":-330,"elapsed":14,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}},"outputId":"1f17d1bf-dc01-4062-9c6a-5f3fa0a845a3"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.7673075272619452, 0.7282142088690984, 0.7432595720253554, 0.7186369129266366, 0.759862922937251, 0.698921359884824, 0.7068717359450306, 0.6866232927253988, 0.650528227843739, 0.706505201756686, 0.7491741425746686, 0.7469820511338594, 0.7557453334213131, 0.7528395116045075, 0.7382814199104083, 0.7295635522502932, 0.7000788637114197, 0.7201895292727728, 0.6903203948732207, 0.7130475663177781, 0.7221171147593421, 0.7330158992941743, 0.7427469830027411, 0.7358405462040035, 0.7171808092117654]\n","0.7245541871887293\n","0.02630229679925272\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cgy6jIdsm8L5","executionInfo":{"status":"ok","timestamp":1697719899960,"user_tz":-330,"elapsed":11,"user":{"displayName":"Suryam Gupta","userId":"07887191304479658761"}}},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":["Emb A\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.869/0.011\n","2. Loss - 0.306/0.021\n","3. F1 score - 0.890/0.011\n","4. MCC - 0.733/0.017\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.871/0.006\n","2. Loss - 0.303/0.017\n","3. F1 score - 0.893/0.006\n","4. MCC - 0.735/0.012"],"metadata":{"id":"JelP7hb2ndEL"}},{"cell_type":"markdown","source":["Emb E\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.851/0.008\n","2. Loss - 0.345/0.016\n","3. F1 score - 0.875/0.008\n","4. MCC - 0.699/0.014\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.851/0.006\n","2. Loss - 0.342/0.014\n","3. F1 score - 0.875/0.007\n","4. MCC - 0.697/0.010"],"metadata":{"id":"Ft04XR4-ndK5"}},{"cell_type":"markdown","source":["Emb H\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.853/0.013\n","2. Loss - 0.333/0.025\n","3. F1 score - 0.876/0.014\n","4. MCC - 0.706/0.020\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.858/0.015\n","2. Loss - 0.327/0.023\n","3. F1 score - 0.881/0.016\n","4. MCC - 0.714/0.020"],"metadata":{"id":"_D3hyQtZndRZ"}},{"cell_type":"markdown","source":["Emb I\n","\n","LSTM CNN nothing nothing -\n","\n","1. Accuracy - 0.866/0.009\n","2. Loss - 0.317/0.018\n","3. F1 score - 0.888/0.008\n","4. MCC - 0.726/0.018\n","\n","LSTM CNN LSTM nothing -\n","\n","1. Accuracy - 0.864/0.015\n","2. Loss - 0.318/0.025\n","3. F1 score - 0.886/0.014\n","4. MCC - 0.724/0.016"],"metadata":{"id":"YH_EgM4bndZq"}},{"cell_type":"code","source":[],"metadata":{"id":"I78pE-Xo_3ND"},"execution_count":null,"outputs":[]}]}